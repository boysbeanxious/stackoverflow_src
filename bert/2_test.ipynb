{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zerojsh00.github.io/posts/BERTopic/\n",
    "https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6\n",
    "https://arxiv.org/pdf/2203.05794.pdf\n",
    "\n",
    "https://dacon.io/competitions/official/235900/codeshare?page=1&dtype=recent&ptype=pub&keyword="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import umap.umap_ as umap\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "with open('../../data/bert_df.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3487 entries, 0 to 3486\n",
      "Data columns (total 28 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   q_id                3487 non-null   int64         \n",
      " 1   q_posttypeid        3487 non-null   object        \n",
      " 2   q_acceptedanswerid  1488 non-null   float64       \n",
      " 3   q_parentid          0 non-null      object        \n",
      " 4   q_creationdate      3487 non-null   datetime64[ns]\n",
      " 5   q_score             3487 non-null   int64         \n",
      " 6   q_viewcount         3487 non-null   int64         \n",
      " 7   q_owneruserid       3487 non-null   int64         \n",
      " 8   q_title             3487 non-null   object        \n",
      " 9   q_tags              3487 non-null   object        \n",
      " 10  q_answercount       3487 non-null   int64         \n",
      " 11  q_commentcount      3487 non-null   int64         \n",
      " 12  q_reputation        3487 non-null   int64         \n",
      " 13  q_text              3487 non-null   object        \n",
      " 14  a_id                3487 non-null   int64         \n",
      " 15  a_posttypeid        3487 non-null   object        \n",
      " 16  a_acceptedanswerid  0 non-null      object        \n",
      " 17  a_parentid          3487 non-null   int64         \n",
      " 18  a_creationdate      3487 non-null   datetime64[ns]\n",
      " 19  a_score             3487 non-null   int64         \n",
      " 20  a_viewcount         0 non-null      object        \n",
      " 21  a_owneruserid       3487 non-null   int64         \n",
      " 22  a_title             0 non-null      object        \n",
      " 23  a_tags              0 non-null      object        \n",
      " 24  a_answercount       0 non-null      object        \n",
      " 25  a_commentcount      3487 non-null   int64         \n",
      " 26  a_reputation        3487 non-null   int64         \n",
      " 27  a_text              3487 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(13), object(12)\n",
      "memory usage: 762.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the  columns for text analysis\n",
    "## q_body : question body\n",
    "## a_body : answer body\n",
    "df_qna = df[['q_id','a_id','q_text', 'a_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3487 entries, 0 to 3486\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   q_id    3487 non-null   int64 \n",
      " 1   a_id    3487 non-null   int64 \n",
      " 2   q_text  3487 non-null   object\n",
      " 3   a_text  3487 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 109.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_qna.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "  # 1.Source code in python language is hard to understand, so replace all the <code> tag first\n",
    "  cleantext_1 = re.findall(r'(?<=\\<code>)(.*?)(?=<\\/code>)', raw_html.replace('\\n', '_**_'))\n",
    "  cleantext_1 = [x.replace('_**_', '\\n') for x in cleantext_1]\n",
    "  # 2. replace html tags\n",
    "  # <p>\n",
    "  tag_re = re.compile('<.*?>')\n",
    "  cleantext_2 = [re.sub(tag_re, '', x) for x in cleantext_1]\n",
    "  return cleantext_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function, cleanhtml to the question and body text\n",
    "df_qna.loc[:, 'q_prep_text'] = df_qna['q_text'].apply(cleanhtml)\n",
    "df_qna.loc[:, 'a_prep_text'] = df_qna['a_text'].apply(cleanhtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>q_prep_text</th>\n",
       "      <th>a_prep_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77593805</td>\n",
       "      <td>[]</td>\n",
       "      <td>[n = 20000\\nsum_of_numbers = (n * (n + 1)) // ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77593717</td>\n",
       "      <td>[import hashlib\\n\\nuser_hash_dict = {}\\n\\nwith...</td>\n",
       "      <td>[from hashlib import sha256 as SHA256\\n\\ncpd =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77591118</td>\n",
       "      <td>[London:Alpha\\nLondon\\nLondon:Beta\\nLondon:Del...</td>\n",
       "      <td>[s = pd.Series(['London:Alpha', 'London', 'Lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77590853</td>\n",
       "      <td>[-v, -o, -A, --script, -Pn, -IL]</td>\n",
       "      <td>[pip install python-nmap\\n,  import nmap\\n\\nde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77591142</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>77581497</td>\n",
       "      <td>[df\\n\\nDevice  int   In   Out  Bw_in  Bw_out\\n...</td>\n",
       "      <td>[duckdb, import duckdb\\n\\nconn = duckdb.connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>77580251</td>\n",
       "      <td>[55297173-0087-1  \\n56397873-0186  \\n57885358-...</td>\n",
       "      <td>[   df=pd.DataFrame([x.strip() for x in '''552...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>77567490</td>\n",
       "      <td>[onnxruntime-silicon, onnxruntime, Flask, # Se...</td>\n",
       "      <td>[load_model, post_worker_init, sess = None\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>77582066</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Day, Store ID, Worker ID, # create datetime o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>77582066</td>\n",
       "      <td>[]</td>\n",
       "      <td>[shifts['Day'] = pd.to_datetime(shifts['Day'])...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3487 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          q_id                                        q_prep_text  \\\n",
       "0     77593805                                                 []   \n",
       "1     77593717  [import hashlib\\n\\nuser_hash_dict = {}\\n\\nwith...   \n",
       "2     77591118  [London:Alpha\\nLondon\\nLondon:Beta\\nLondon:Del...   \n",
       "3     77590853                   [-v, -o, -A, --script, -Pn, -IL]   \n",
       "4     77591142                                                 []   \n",
       "...        ...                                                ...   \n",
       "3482  77581497  [df\\n\\nDevice  int   In   Out  Bw_in  Bw_out\\n...   \n",
       "3483  77580251  [55297173-0087-1  \\n56397873-0186  \\n57885358-...   \n",
       "3484  77567490  [onnxruntime-silicon, onnxruntime, Flask, # Se...   \n",
       "3485  77582066                                                 []   \n",
       "3486  77582066                                                 []   \n",
       "\n",
       "                                            a_prep_text  \n",
       "0     [n = 20000\\nsum_of_numbers = (n * (n + 1)) // ...  \n",
       "1     [from hashlib import sha256 as SHA256\\n\\ncpd =...  \n",
       "2     [s = pd.Series(['London:Alpha', 'London', 'Lon...  \n",
       "3     [pip install python-nmap\\n,  import nmap\\n\\nde...  \n",
       "4                                                    []  \n",
       "...                                                 ...  \n",
       "3482  [duckdb, import duckdb\\n\\nconn = duckdb.connec...  \n",
       "3483  [   df=pd.DataFrame([x.strip() for x in '''552...  \n",
       "3484  [load_model, post_worker_init, sess = None\\n\\n...  \n",
       "3485  [Day, Store ID, Worker ID, # create datetime o...  \n",
       "3486  [shifts['Day'] = pd.to_datetime(shifts['Day'])...  \n",
       "\n",
       "[3487 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qna.loc[:, [ 'q_id','q_prep_text', 'a_prep_text']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_src = df_qna[['q_id', 'q_prep_text']].apply(pd.Series.explode)\n",
    "df_a_src = df_qna[['a_id', 'a_prep_text']].apply(pd.Series.explode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_src = df_q_src.reset_index(drop=True)\n",
    "df_a_src = df_a_src.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_src.dropna(inplace=True)\n",
    "df_q_src['q_prep_text_non'] = df_q_src['q_prep_text'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        import hashlib  user_hash_dict = {}  with open...\n",
       "2        London:Alpha London London:Beta London:Delta P...\n",
       "3        London_sub:Alpha London_sub London_sub:Beta Lo...\n",
       "4        names_df[0] = names_df[0] \\         .str.split...\n",
       "5                                     L:o:n:d:o:n:_:s:u:b \n",
       "                               ...                        \n",
       "11467    class GunicornApplication(BaseApplication):   ...\n",
       "11468    if __name__ == '__main__':     options = {'bin...\n",
       "11469    &gt;&gt;&gt; [ERROR] Worker (pid:10517) was se...\n",
       "11470    &gt;&gt;&gt; requests.exceptions.ConnectionErr...\n",
       "11471                                             Gunicorn\n",
       "Name: q_prep_text_non, Length: 11171, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q_src['q_prep_text_non']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = df_q_src['q_prep_text_non'].tolist()\n",
    "# df['sentiments'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n",
      "11171\n"
     ]
    }
   ],
   "source": [
    "print(type(src))\n",
    "print(type(src[0]))\n",
    "print(len(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = src[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-calculate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "embedding_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/63517293/valueerror-textencodeinput-must-be-uniontextinputsequence-tupleinputsequence/63870843#63870843\n",
    "code_tokens=tokenizer(src, truncation=True, padding=True)\n",
    "tokens_ids=tokenizer.convert_tokens_to_ids(code_tokens)\n",
    "embeddings=embedding_model(torch.tensor(tokens_ids)[None,:])[0]\n",
    "# embeddings = embeddings.reshape(-1,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "# model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "# code_tokens=tokenizer.tokenize(src[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 255, 768])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic(\n",
    "\n",
    "  # Pipeline models\n",
    "  embedding_model=embedding_model,\n",
    "  # umap_model=umap_model,\n",
    "  # hdbscan_model=hdbscan_model,\n",
    "  # vectorizer_model=vectorizer_model,\n",
    "  # representation_model=representation_model,\n",
    "\n",
    "  # Hyperparameters\n",
    "  top_n_words=10,\n",
    "  verbose=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "type(embeddings)\n",
    "\n",
    "# Convert the tensor to a NumPy array\n",
    "embeddings_numpy = embeddings.detach().numpy()\n",
    "# embeddings_numpy = embeddings_numpy[0]\n",
    "print(type(embeddings_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'The problem of statistical learning is to construct a predictor of a random\\nvariable $Y$ as a function of a related random variable $X$ on the basis of an\\ni.i.d. training sample from the joint distribution of $(X,Y)$. Allowable\\npredictors are drawn from some specified class, and the goal is to approach\\nasymptotically the performance (expected loss) of the best predictor in the\\nclass. We consider the setting in which one has perfect observation of the\\n$X$-part of the sample, while the $Y$-part has to be communicated at some\\nfinite bit rate. The encoding of the $Y$-values is allowed to depend on the\\n$X$-values. Under suitable regularity conditions on the admissible predictors,\\nthe underlying family of probability distributions and the loss function, we\\ngive an information-theoretic characterization of achievable predictor\\nperformance in terms of conditional distortion-rate functions. The ideas are\\nillustrated on the example of nonparametric regression in Gaussian noise.\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The problem of statistical learning is to construct a predictor of a random\\nvariable $Y$ as a function of a related random variable $X$ on the basis of an\\ni.i.d. training sample from the joint distribution of $(X,Y)$. Allowable\\npredictors are drawn from some specified class, and the goal is to approach\\nasymptotically the performance (expected loss) of the best predictor in the\\nclass. We consider the setting in which one has perfect observation of the\\n$X$-part of the sample, while the $Y$-part has to be communicated at some\\nfinite bit rate. The encoding of the $Y$-values is allowed to depend on the\\n$X$-values. Under suitable regularity conditions on the admissible predictors,\\nthe underlying family of probability distributions and the loss function, we\\ngive an information-theoretic characterization of achievable predictor\\nperformance in terms of conditional distortion-rate functions. The ideas are\\nillustrated on the example of nonparametric regression in Gaussian noise.\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Make sure that the embeddings are a numpy array with shape: (len(docs), vector_dim) where vector_dim is the dimensionality of the vector embeddings. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m topics, probs \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings_numpy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/bertopic/_bertopic.py:374\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[0;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    373\u001b[0m     check_documents_type(documents)\n\u001b[0;32m--> 374\u001b[0m     \u001b[43mcheck_embeddings_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m doc_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(documents)) \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(images))\n\u001b[1;32m    377\u001b[0m documents \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument\u001b[39m\u001b[38;5;124m\"\u001b[39m: documents,\n\u001b[1;32m    378\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m: doc_ids,\n\u001b[1;32m    379\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    380\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m: images})\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/bertopic/_utils.py:55\u001b[0m, in \u001b[0;36mcheck_embeddings_shape\u001b[0;34m(embeddings, docs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(docs):\n\u001b[0;32m---> 55\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure that the embeddings are a numpy array with shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(len(docs), vector_dim) where vector_dim is the dimensionality \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof the vector embeddings. \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Make sure that the embeddings are a numpy array with shape: (len(docs), vector_dim) where vector_dim is the dimensionality of the vector embeddings. "
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(src[0:10], embeddings_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(embeddings_numpy)\n",
    "\n",
    "if isinstance(src[0:2], pd.DataFrame):\n",
    "        raise TypeError(\"Make sure to supply a list of strings, not a dataframe.\")\n",
    "elif isinstance(src[0:2], Iterable) and not isinstance(src[0:2], str):\n",
    "    if not any([isinstance(doc, str) for doc in src[0:2]]):\n",
    "        raise TypeError(\"Make sure that the iterable only contains strings.\")\n",
    "else:\n",
    "    raise TypeError(\"Make sure that the documents variable is an iterable containing strings only.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Make sure that the documents variable is an iterable containing strings only.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure that the iterable only contains strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure that the documents variable is an iterable containing strings only.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Make sure that the documents variable is an iterable containing strings only."
     ]
    }
   ],
   "source": [
    "test\n",
    "\n",
    "if isinstance(test, pd.DataFrame):\n",
    "        raise TypeError(\"Make sure to supply a list of strings, not a dataframe.\")\n",
    "elif isinstance(test, Iterable) and not isinstance(test, str):\n",
    "    if not any([isinstance(doc, str) for doc in test]):\n",
    "        raise TypeError(\"Make sure that the iterable only contains strings.\")\n",
    "else:\n",
    "    raise TypeError(\"Make sure that the documents variable is an iterable containing strings only.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbb\n"
     ]
    }
   ],
   "source": [
    "if not isinstance(src[0], str):\n",
    "    print(\"aaa\")\n",
    "else :\n",
    "    print(\"bbb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(src[0], str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 255, 768)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_src= df_q_src['q_prep_text_non'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
