{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zerojsh00.github.io/posts/BERTopic/\n",
    "https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6\n",
    "https://arxiv.org/pdf/2203.05794.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import umap.umap_ as umap\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "with open('../../data/bert_df.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3487 entries, 0 to 3486\n",
      "Data columns (total 28 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   q_id                3487 non-null   int64         \n",
      " 1   q_posttypeid        3487 non-null   object        \n",
      " 2   q_acceptedanswerid  1488 non-null   float64       \n",
      " 3   q_parentid          0 non-null      object        \n",
      " 4   q_creationdate      3487 non-null   datetime64[ns]\n",
      " 5   q_score             3487 non-null   int64         \n",
      " 6   q_viewcount         3487 non-null   int64         \n",
      " 7   q_owneruserid       3487 non-null   int64         \n",
      " 8   q_title             3487 non-null   object        \n",
      " 9   q_tags              3487 non-null   object        \n",
      " 10  q_answercount       3487 non-null   int64         \n",
      " 11  q_commentcount      3487 non-null   int64         \n",
      " 12  q_reputation        3487 non-null   int64         \n",
      " 13  q_text              3487 non-null   object        \n",
      " 14  a_id                3487 non-null   int64         \n",
      " 15  a_posttypeid        3487 non-null   object        \n",
      " 16  a_acceptedanswerid  0 non-null      object        \n",
      " 17  a_parentid          3487 non-null   int64         \n",
      " 18  a_creationdate      3487 non-null   datetime64[ns]\n",
      " 19  a_score             3487 non-null   int64         \n",
      " 20  a_viewcount         0 non-null      object        \n",
      " 21  a_owneruserid       3487 non-null   int64         \n",
      " 22  a_title             0 non-null      object        \n",
      " 23  a_tags              0 non-null      object        \n",
      " 24  a_answercount       0 non-null      object        \n",
      " 25  a_commentcount      3487 non-null   int64         \n",
      " 26  a_reputation        3487 non-null   int64         \n",
      " 27  a_text              3487 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(13), object(12)\n",
      "memory usage: 762.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the  columns for text analysis\n",
    "## q_body : question body\n",
    "## a_body : answer body\n",
    "df_qna = df[['q_id','a_id','q_text', 'a_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3487 entries, 0 to 3486\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   q_id    3487 non-null   int64 \n",
      " 1   a_id    3487 non-null   int64 \n",
      " 2   q_text  3487 non-null   object\n",
      " 3   a_text  3487 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 109.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_qna.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "  # 1.Source code in python language is hard to understand, so replace all the <code> tag first\n",
    "  cleantext_1 = re.findall(r'(?<=\\<code>)(.*?)(?=<\\/code>)', raw_html.replace('\\n', '_**_'))\n",
    "  cleantext_1 = [x.replace('_**_', '\\n') for x in cleantext_1]\n",
    "  # 2. replace html tags\n",
    "  # <p>\n",
    "  tag_re = re.compile('<.*?>')\n",
    "  cleantext_2 = [re.sub(tag_re, '', x) for x in cleantext_1]\n",
    "  return cleantext_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lk/t243gzpx379bzd9mvx8dcsmm0000gp/T/ipykernel_5535/1671787946.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_qna.loc[:, 'q_prep_text'] = df_qna['q_text'].apply(cleanhtml)\n",
      "/var/folders/lk/t243gzpx379bzd9mvx8dcsmm0000gp/T/ipykernel_5535/1671787946.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_qna.loc[:, 'a_prep_text'] = df_qna['a_text'].apply(cleanhtml)\n"
     ]
    }
   ],
   "source": [
    "# apply the function, cleanhtml to the question and body text\n",
    "df_qna.loc[:, 'q_prep_text'] = df_qna['q_text'].apply(cleanhtml)\n",
    "df_qna.loc[:, 'a_prep_text'] = df_qna['a_text'].apply(cleanhtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>q_prep_text</th>\n",
       "      <th>a_prep_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77593805</td>\n",
       "      <td>[]</td>\n",
       "      <td>[n = 20000\\nsum_of_numbers = (n * (n + 1)) // ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77593717</td>\n",
       "      <td>[import hashlib\\n\\nuser_hash_dict = {}\\n\\nwith...</td>\n",
       "      <td>[from hashlib import sha256 as SHA256\\n\\ncpd =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77591118</td>\n",
       "      <td>[London:Alpha\\nLondon\\nLondon:Beta\\nLondon:Del...</td>\n",
       "      <td>[s = pd.Series(['London:Alpha', 'London', 'Lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77590853</td>\n",
       "      <td>[-v, -o, -A, --script, -Pn, -IL]</td>\n",
       "      <td>[pip install python-nmap\\n,  import nmap\\n\\nde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77591142</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>77581497</td>\n",
       "      <td>[df\\n\\nDevice  int   In   Out  Bw_in  Bw_out\\n...</td>\n",
       "      <td>[duckdb, import duckdb\\n\\nconn = duckdb.connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>77580251</td>\n",
       "      <td>[55297173-0087-1  \\n56397873-0186  \\n57885358-...</td>\n",
       "      <td>[   df=pd.DataFrame([x.strip() for x in '''552...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>77567490</td>\n",
       "      <td>[onnxruntime-silicon, onnxruntime, Flask, # Se...</td>\n",
       "      <td>[load_model, post_worker_init, sess = None\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>77582066</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Day, Store ID, Worker ID, # create datetime o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>77582066</td>\n",
       "      <td>[]</td>\n",
       "      <td>[shifts['Day'] = pd.to_datetime(shifts['Day'])...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3487 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          q_id                                        q_prep_text  \\\n",
       "0     77593805                                                 []   \n",
       "1     77593717  [import hashlib\\n\\nuser_hash_dict = {}\\n\\nwith...   \n",
       "2     77591118  [London:Alpha\\nLondon\\nLondon:Beta\\nLondon:Del...   \n",
       "3     77590853                   [-v, -o, -A, --script, -Pn, -IL]   \n",
       "4     77591142                                                 []   \n",
       "...        ...                                                ...   \n",
       "3482  77581497  [df\\n\\nDevice  int   In   Out  Bw_in  Bw_out\\n...   \n",
       "3483  77580251  [55297173-0087-1  \\n56397873-0186  \\n57885358-...   \n",
       "3484  77567490  [onnxruntime-silicon, onnxruntime, Flask, # Se...   \n",
       "3485  77582066                                                 []   \n",
       "3486  77582066                                                 []   \n",
       "\n",
       "                                            a_prep_text  \n",
       "0     [n = 20000\\nsum_of_numbers = (n * (n + 1)) // ...  \n",
       "1     [from hashlib import sha256 as SHA256\\n\\ncpd =...  \n",
       "2     [s = pd.Series(['London:Alpha', 'London', 'Lon...  \n",
       "3     [pip install python-nmap\\n,  import nmap\\n\\nde...  \n",
       "4                                                    []  \n",
       "...                                                 ...  \n",
       "3482  [duckdb, import duckdb\\n\\nconn = duckdb.connec...  \n",
       "3483  [   df=pd.DataFrame([x.strip() for x in '''552...  \n",
       "3484  [load_model, post_worker_init, sess = None\\n\\n...  \n",
       "3485  [Day, Store ID, Worker ID, # create datetime o...  \n",
       "3486  [shifts['Day'] = pd.to_datetime(shifts['Day'])...  \n",
       "\n",
       "[3487 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qna.loc[:, [ 'q_id','q_prep_text', 'a_prep_text']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_src = df_qna[['q_id', 'q_prep_text']].apply(pd.Series.explode)\n",
    "df_a_src = df_qna[['a_id', 'a_prep_text']].apply(pd.Series.explode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_src = df_q_src.reset_index(drop=True)\n",
    "df_a_src = df_a_src.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_src.dropna(inplace=True)\n",
    "df_q_src['q_prep_text_non'] = df_q_src['q_prep_text'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = df_q_src['q_prep_text_non'].iloc[0:10].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_q_src['q_prep_text_non'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall umap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-calculate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "embedding_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "\n",
    "code_tokens=tokenizer.tokenize(df_q_src['q_prep_text_non'].to_list()[0])\n",
    "\n",
    "tokens=[tokenizer.cls_token]+[tokenizer.sep_token]+code_tokens+[tokenizer.eos_token]\n",
    "\n",
    "tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "embeddings=embedding_model(torch.tensor(tokens_ids)[None,:])[0]\n",
    "\n",
    "embeddings = embeddings.reshape(-1,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preventing Stochastic Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlling Number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=150, metric='euclidean', cluster_selection_method='eom', prediction_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic(\n",
    "\n",
    "  # Pipeline models\n",
    "  embedding_model=embedding_model,\n",
    "  # umap_model=umap_model,\n",
    "  # hdbscan_model=hdbscan_model,\n",
    "  # vectorizer_model=vectorizer_model,\n",
    "  # representation_model=representation_model,\n",
    "\n",
    "  # Hyperparameters\n",
    "  top_n_words=10,\n",
    "  verbose=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Make sure that the embeddings are a numpy array with shape: (len(docs), vector_dim) where vector_dim is the dimensionality of the vector embeddings. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m----> 2\u001b[0m topics, probs \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/bertopic/_bertopic.py:374\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[0;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    373\u001b[0m     check_documents_type(documents)\n\u001b[0;32m--> 374\u001b[0m     \u001b[43mcheck_embeddings_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m doc_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(documents)) \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(images))\n\u001b[1;32m    377\u001b[0m documents \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument\u001b[39m\u001b[38;5;124m\"\u001b[39m: documents,\n\u001b[1;32m    378\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m: doc_ids,\n\u001b[1;32m    379\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    380\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m: images})\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/bertopic/_utils.py:55\u001b[0m, in \u001b[0;36mcheck_embeddings_shape\u001b[0;34m(embeddings, docs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(docs):\n\u001b[0;32m---> 55\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure that the embeddings are a numpy array with shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(len(docs), vector_dim) where vector_dim is the dimensionality \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof the vector embeddings. \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Make sure that the embeddings are a numpy array with shape: (len(docs), vector_dim) where vector_dim is the dimensionality of the vector embeddings. "
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(src, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"import hashlib  user_hash_dict = {}  with open('common_passwords.txt','r' ) as f:     common_passwords = f.read().splitlines()  with open('user_hash.txt', 'r') as f:     text = f.read().splitlines()     for user_hash in text:         username = user_hash.split(&quot;:&quot;)[0]         hash = user_hash.split(&quot;:&quot;)[1]         user_hash_dict[username] = hash  for password in common_passwords:     hashed_password = hashlib.sha256(password.encode('utf-8')).hexdigest()     for username , hash in user_hash_dict.items():         if hashed_password == hash:             print(f'hash found\\\\n{username}:{password}') \",\n",
       " 'London:Alpha London London:Beta London:Delta Paris ',\n",
       " 'London_sub:Alpha London_sub London_sub:Beta London_sub:Delta Paris_sub ',\n",
       " \"names_df[0] = names_df[0] \\\\         .str.split(':') \\\\         .apply(lambda x: x[0] + '_sub') \\\\         .str.join(':') \",\n",
       " 'L:o:n:d:o:n:_:s:u:b ',\n",
       " \"names_df[0] = names_df[0]\\\\     .str.split(':')\\\\     .apply(lambda x: '_sub:'.join(x)) \",\n",
       " '-v, -o, -A, --script, -Pn',\n",
       " '-IL',\n",
       " \"from sqlalchemy.orm import declarative_base, relationship from sqlalchemy import Column, String, Integer, ForeignKey  Base = declarative_base()  class Parent(Base):     __tablename__ = 'parents'          id = Column(Integer, primary_key=True)     name = Column(String(20))          children = relationship('Child', back_populates='parents')           class Child(Base):     __tablename__ = 'children'          id = Column(Integer, primary_key=True)     parent_id = Column(Integer, ForeignKey('parents.id'))     name = Column(String(20))      parents = relationship('Parent', back_populates='children')                 mother = Parent(id=1, name='Sarah') c1 = Child(id=22, parent_id=mother.id, name='Alice') c2 = Child(id=23, parent_id=mother.id, name='Bob')  print(mother.children) \",\n",
       " '[] ']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import hashlib  user_hash_dict = {}  with open('common_passwords.txt','r' ) as f:     common_passwords = f.read().splitlines()  with open('user_hash.txt', 'r') as f:     text = f.read().splitlines()     for user_hash in text:         username = user_hash.split(&quot;:&quot;)[0]         hash = user_hash.split(&quot;:&quot;)[1]         user_hash_dict[username] = hash  for password in common_passwords:     hashed_password = hashlib.sha256(password.encode('utf-8')).hexdigest()     for username , hash in user_hash_dict.items():         if hashed_password == hash:             print(f'hash found\\\\n{username}:{password}') \""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
