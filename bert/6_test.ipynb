{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
    "from collections.abc import Iterable\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from bertopic import BERTopic\n",
    "import torch\n",
    "from collections import deque\n",
    "from bertopic.representation import KeyBERTInspired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "with open('../../data/bert_df.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "with open('../../data/bert_src_df.pkl', 'rb') as f:\n",
    "    bert_src_df = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5223203 entries, 0 to 5223202\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   q_id            int64         \n",
      " 1   a_id            float64       \n",
      " 2   q_creationdate  datetime64[ns]\n",
      " 3   tags            object        \n",
      " 4   body            object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(2)\n",
      "memory usage: 199.2+ MB\n"
     ]
    }
   ],
   "source": [
    "bert_src_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = bert_src_df['q_creationdate']<='2022-11-30'\n",
    "cond2 = bert_src_df['q_creationdate']>='2021-11-30'\n",
    "cond3 = bert_src_df['a_id'].isna()\n",
    "cond4 = bert_src_df['tags'].str.contains('python')\n",
    "cond5 = bert_src_df['q_creationdate']>='2022-12-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_src_bf = bert_src_df.loc[cond1 & cond2 & cond3 & cond4, :]\n",
    "bert_src_af = bert_src_df.loc[cond3 & cond4 & cond5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>a_id</th>\n",
       "      <th>q_creationdate</th>\n",
       "      <th>tags</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>77077227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-10 17:31:31.600</td>\n",
       "      <td>&lt;python&gt;&lt;opengl&gt;&lt;pyqt5&gt;&lt;pyopengl&gt;</td>\n",
       "      <td>&lt;p&gt;I want to display 3d object on top of PyQT5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>77060888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-07 15:17:24.040</td>\n",
       "      <td>&lt;python&gt;&lt;django&gt;&lt;postgresql&gt;&lt;sleep&gt;&lt;pytest-dja...</td>\n",
       "      <td>&lt;p&gt;I need to make a pause in my Django project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>77052025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-06 12:43:17.777</td>\n",
       "      <td>&lt;python&gt;</td>\n",
       "      <td>&lt;p&gt;I am trying to get a list of all compartmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>76937634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-20 01:18:19.203</td>\n",
       "      <td>&lt;python&gt;&lt;django&gt;&lt;asynchronous&gt;&lt;celery&gt;&lt;telegram&gt;</td>\n",
       "      <td>&lt;p&gt;I'm trying to make a parser like a web appl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>76934523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-19 09:57:53.073</td>\n",
       "      <td>&lt;python&gt;&lt;user-interface&gt;&lt;pyqt5&gt;</td>\n",
       "      <td>&lt;p&gt;guys I have a question, i have a code and I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223137</th>\n",
       "      <td>77545627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-24 20:54:56.123</td>\n",
       "      <td>&lt;python&gt;&lt;huggingface&gt;&lt;language-translation&gt;</td>\n",
       "      <td>&lt;h2&gt;Setup&lt;/h2&gt;\\n&lt;p&gt;I've created a HF Inference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223163</th>\n",
       "      <td>77442875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-08 04:40:57.380</td>\n",
       "      <td>&lt;python&gt;&lt;python-imaging-library&gt;&lt;height&gt;&lt;width&gt;</td>\n",
       "      <td>&lt;p&gt;We were given a image(The Traffic stop sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223179</th>\n",
       "      <td>77374676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-27 13:47:11.517</td>\n",
       "      <td>&lt;python&gt;&lt;tensorflow&gt;&lt;keras&gt;</td>\n",
       "      <td>&lt;p&gt;I am having an issue I don't understand how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223196</th>\n",
       "      <td>77336446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-21 14:33:34.623</td>\n",
       "      <td>&lt;python&gt;&lt;animation&gt;&lt;sequence&gt;&lt;vtk&gt;</td>\n",
       "      <td>&lt;p&gt;I have succesfully managed to make a 3d ima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223198</th>\n",
       "      <td>77336843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-21 16:16:36.243</td>\n",
       "      <td>&lt;kubernetes&gt;&lt;grpc&gt;&lt;kubernetes-ingress&gt;&lt;istio&gt;&lt;...</td>\n",
       "      <td>&lt;p&gt;Trying to setup grpc service via istio ingr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63445 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             q_id  a_id          q_creationdate  \\\n",
       "38       77077227   NaN 2023-09-10 17:31:31.600   \n",
       "65       77060888   NaN 2023-09-07 15:17:24.040   \n",
       "73       77052025   NaN 2023-09-06 12:43:17.777   \n",
       "107      76937634   NaN 2023-08-20 01:18:19.203   \n",
       "115      76934523   NaN 2023-08-19 09:57:53.073   \n",
       "...           ...   ...                     ...   \n",
       "5223137  77545627   NaN 2023-11-24 20:54:56.123   \n",
       "5223163  77442875   NaN 2023-11-08 04:40:57.380   \n",
       "5223179  77374676   NaN 2023-10-27 13:47:11.517   \n",
       "5223196  77336446   NaN 2023-10-21 14:33:34.623   \n",
       "5223198  77336843   NaN 2023-10-21 16:16:36.243   \n",
       "\n",
       "                                                      tags  \\\n",
       "38                       <python><opengl><pyqt5><pyopengl>   \n",
       "65       <python><django><postgresql><sleep><pytest-dja...   \n",
       "73                                                <python>   \n",
       "107       <python><django><asynchronous><celery><telegram>   \n",
       "115                        <python><user-interface><pyqt5>   \n",
       "...                                                    ...   \n",
       "5223137        <python><huggingface><language-translation>   \n",
       "5223163    <python><python-imaging-library><height><width>   \n",
       "5223179                        <python><tensorflow><keras>   \n",
       "5223196                 <python><animation><sequence><vtk>   \n",
       "5223198  <kubernetes><grpc><kubernetes-ingress><istio><...   \n",
       "\n",
       "                                                      body  \n",
       "38       <p>I want to display 3d object on top of PyQT5...  \n",
       "65       <p>I need to make a pause in my Django project...  \n",
       "73       <p>I am trying to get a list of all compartmen...  \n",
       "107      <p>I'm trying to make a parser like a web appl...  \n",
       "115      <p>guys I have a question, i have a code and I...  \n",
       "...                                                    ...  \n",
       "5223137  <h2>Setup</h2>\\n<p>I've created a HF Inference...  \n",
       "5223163  <p>We were given a image(The Traffic stop sign...  \n",
       "5223179  <p>I am having an issue I don't understand how...  \n",
       "5223196  <p>I have succesfully managed to make a 3d ima...  \n",
       "5223198  <p>Trying to setup grpc service via istio ingr...  \n",
       "\n",
       "[63445 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_src_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "  # 1.Source code in python language is hard to understand, so replace all the <code> tag first\n",
    "  cleantext_1 = re.findall(r'(?<=\\<code>)(.*?)(?=<\\/code>)', raw_html.replace('\\n', '_**_'))\n",
    "  cleantext_1 = [x.replace('_**_', '\\n') for x in cleantext_1]\n",
    "  # 2. replace html tags\n",
    "  # <p>\n",
    "  tag_re = re.compile('<.*?>')\n",
    "  cleantext_2 = [re.sub(tag_re, '', x) for x in cleantext_1]\n",
    "  return cleantext_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function, cleanhtml to the question and body text\n",
    "bert_src_bf.loc[:, 'q_prep_text'] = bert_src_bf['body'].apply(cleanhtml)\n",
    "bert_src_af.loc[:, 'q_prep_text'] = bert_src_af['body'].apply(cleanhtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>a_id</th>\n",
       "      <th>q_creationdate</th>\n",
       "      <th>tags</th>\n",
       "      <th>body</th>\n",
       "      <th>q_prep_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>77077227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-10 17:31:31.600</td>\n",
       "      <td>&lt;python&gt;&lt;opengl&gt;&lt;pyqt5&gt;&lt;pyopengl&gt;</td>\n",
       "      <td>&lt;p&gt;I want to display 3d object on top of PyQT5...</td>\n",
       "      <td>[import sys\\nfrom OpenGL.GL import *\\nfrom Ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>77060888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-07 15:17:24.040</td>\n",
       "      <td>&lt;python&gt;&lt;django&gt;&lt;postgresql&gt;&lt;sleep&gt;&lt;pytest-dja...</td>\n",
       "      <td>&lt;p&gt;I need to make a pause in my Django project...</td>\n",
       "      <td>[from pytest import mark, fixture, raises\\nfro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>77052025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-06 12:43:17.777</td>\n",
       "      <td>&lt;python&gt;</td>\n",
       "      <td>&lt;p&gt;I am trying to get a list of all compartmen...</td>\n",
       "      <td>[import oci\\n\\nconfig = oci.config.from_file()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>76937634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-20 01:18:19.203</td>\n",
       "      <td>&lt;python&gt;&lt;django&gt;&lt;asynchronous&gt;&lt;celery&gt;&lt;telegram&gt;</td>\n",
       "      <td>&lt;p&gt;I'm trying to make a parser like a web appl...</td>\n",
       "      <td>[from telethon.sync import TelegramClient\\nimp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>76934523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-19 09:57:53.073</td>\n",
       "      <td>&lt;python&gt;&lt;user-interface&gt;&lt;pyqt5&gt;</td>\n",
       "      <td>&lt;p&gt;guys I have a question, i have a code and I...</td>\n",
       "      <td>[1\\.when moving the icon instances the X and Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223137</th>\n",
       "      <td>77545627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-24 20:54:56.123</td>\n",
       "      <td>&lt;python&gt;&lt;huggingface&gt;&lt;language-translation&gt;</td>\n",
       "      <td>&lt;h2&gt;Setup&lt;/h2&gt;\\n&lt;p&gt;I've created a HF Inference...</td>\n",
       "      <td>[request, concurrent, def translate_text(text)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223163</th>\n",
       "      <td>77442875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-08 04:40:57.380</td>\n",
       "      <td>&lt;python&gt;&lt;python-imaging-library&gt;&lt;height&gt;&lt;width&gt;</td>\n",
       "      <td>&lt;p&gt;We were given a image(The Traffic stop sign...</td>\n",
       "      <td>[    def fix_middle(picture):\\n        picture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223179</th>\n",
       "      <td>77374676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-27 13:47:11.517</td>\n",
       "      <td>&lt;python&gt;&lt;tensorflow&gt;&lt;keras&gt;</td>\n",
       "      <td>&lt;p&gt;I am having an issue I don't understand how...</td>\n",
       "      <td>[    def create_teacher_model(img_size, model_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223196</th>\n",
       "      <td>77336446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-21 14:33:34.623</td>\n",
       "      <td>&lt;python&gt;&lt;animation&gt;&lt;sequence&gt;&lt;vtk&gt;</td>\n",
       "      <td>&lt;p&gt;I have succesfully managed to make a 3d ima...</td>\n",
       "      <td>[import vtkmodules.all as vtk\\n\\n#Create a ren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223198</th>\n",
       "      <td>77336843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-21 16:16:36.243</td>\n",
       "      <td>&lt;kubernetes&gt;&lt;grpc&gt;&lt;kubernetes-ingress&gt;&lt;istio&gt;&lt;...</td>\n",
       "      <td>&lt;p&gt;Trying to setup grpc service via istio ingr...</td>\n",
       "      <td>[apiVersion: networking.k8s.io/v1\\nkind: Ingre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63445 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             q_id  a_id          q_creationdate  \\\n",
       "38       77077227   NaN 2023-09-10 17:31:31.600   \n",
       "65       77060888   NaN 2023-09-07 15:17:24.040   \n",
       "73       77052025   NaN 2023-09-06 12:43:17.777   \n",
       "107      76937634   NaN 2023-08-20 01:18:19.203   \n",
       "115      76934523   NaN 2023-08-19 09:57:53.073   \n",
       "...           ...   ...                     ...   \n",
       "5223137  77545627   NaN 2023-11-24 20:54:56.123   \n",
       "5223163  77442875   NaN 2023-11-08 04:40:57.380   \n",
       "5223179  77374676   NaN 2023-10-27 13:47:11.517   \n",
       "5223196  77336446   NaN 2023-10-21 14:33:34.623   \n",
       "5223198  77336843   NaN 2023-10-21 16:16:36.243   \n",
       "\n",
       "                                                      tags  \\\n",
       "38                       <python><opengl><pyqt5><pyopengl>   \n",
       "65       <python><django><postgresql><sleep><pytest-dja...   \n",
       "73                                                <python>   \n",
       "107       <python><django><asynchronous><celery><telegram>   \n",
       "115                        <python><user-interface><pyqt5>   \n",
       "...                                                    ...   \n",
       "5223137        <python><huggingface><language-translation>   \n",
       "5223163    <python><python-imaging-library><height><width>   \n",
       "5223179                        <python><tensorflow><keras>   \n",
       "5223196                 <python><animation><sequence><vtk>   \n",
       "5223198  <kubernetes><grpc><kubernetes-ingress><istio><...   \n",
       "\n",
       "                                                      body  \\\n",
       "38       <p>I want to display 3d object on top of PyQT5...   \n",
       "65       <p>I need to make a pause in my Django project...   \n",
       "73       <p>I am trying to get a list of all compartmen...   \n",
       "107      <p>I'm trying to make a parser like a web appl...   \n",
       "115      <p>guys I have a question, i have a code and I...   \n",
       "...                                                    ...   \n",
       "5223137  <h2>Setup</h2>\\n<p>I've created a HF Inference...   \n",
       "5223163  <p>We were given a image(The Traffic stop sign...   \n",
       "5223179  <p>I am having an issue I don't understand how...   \n",
       "5223196  <p>I have succesfully managed to make a 3d ima...   \n",
       "5223198  <p>Trying to setup grpc service via istio ingr...   \n",
       "\n",
       "                                               q_prep_text  \n",
       "38       [import sys\\nfrom OpenGL.GL import *\\nfrom Ope...  \n",
       "65       [from pytest import mark, fixture, raises\\nfro...  \n",
       "73       [import oci\\n\\nconfig = oci.config.from_file()...  \n",
       "107      [from telethon.sync import TelegramClient\\nimp...  \n",
       "115      [1\\.when moving the icon instances the X and Y...  \n",
       "...                                                    ...  \n",
       "5223137  [request, concurrent, def translate_text(text)...  \n",
       "5223163  [    def fix_middle(picture):\\n        picture...  \n",
       "5223179  [    def create_teacher_model(img_size, model_...  \n",
       "5223196  [import vtkmodules.all as vtk\\n\\n#Create a ren...  \n",
       "5223198  [apiVersion: networking.k8s.io/v1\\nkind: Ingre...  \n",
       "\n",
       "[63445 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_src_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_src_bf = bert_src_bf.reset_index(drop=True)\n",
    "bert_src_af = bert_src_af.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_src_bf = bert_src_bf[['q_id', 'q_prep_text']].apply(pd.Series.explode)\n",
    "bert_src_af = bert_src_af[['q_id', 'q_prep_text']].apply(pd.Series.explode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_src_bf.dropna(inplace=True)\n",
    "bert_src_af.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING FOR CODE SCRIPT\n",
    "def preprocess_script(script):\n",
    "    new_script = deque()\n",
    "    old_script = script.split('\\n')\n",
    "    for line in old_script:\n",
    "        if line.lstrip().startswith('#'): # 주석으로 시작되는 행 skip\n",
    "            continue\n",
    "        line = line.rstrip()\n",
    "        if '#' in line:\n",
    "            line = line[:line.index('#')] # 주석 전까지 코드만 저장\n",
    "        line = line.replace('\\n','') # 개행 문자를 모두 삭제함\n",
    "        line = line.replace('    ','\\t') # 공백 4칸을 tab으로 변환\n",
    "        \n",
    "        if line == '': # 전처리 후 빈 라인은 skip\n",
    "            continue\n",
    "        \n",
    "        new_script.append(line)\n",
    "\n",
    "        \n",
    "    new_script = '\\n'.join(new_script) # 개행 문자로 합침\n",
    "    new_script = re.sub('(\"\"\"[\\w\\W]*?\"\"\")', '<str>', new_script)\n",
    "    new_script = re.sub(\"('''[\\w\\W]*?''')\", '<str>', new_script)\n",
    "    new_script = re.sub('/^(http?|https?):\\/\\/([a-z0-9-]+\\.)+[a-z0-9]{2,4}.*$/', '', new_script)\n",
    "    \n",
    "    return new_script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>q_prep_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77077227</td>\n",
       "      <td>import sys\\nfrom OpenGL.GL import *\\nfrom Open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77060888</td>\n",
       "      <td>from pytest import mark, fixture, raises\\nfrom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77060888</td>\n",
       "      <td>========================================= test...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77052025</td>\n",
       "      <td>import oci\\n\\nconfig = oci.config.from_file()\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76937634</td>\n",
       "      <td>from telethon.sync import TelegramClient\\nimpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63443</th>\n",
       "      <td>77336446</td>\n",
       "      <td>import time\\nimport vtkmodules.all\\n\\nclass vt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63444</th>\n",
       "      <td>77336843</td>\n",
       "      <td>apiVersion: networking.k8s.io/v1\\nkind: Ingres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63444</th>\n",
       "      <td>77336843</td>\n",
       "      <td>apiVersion: networking.k8s.io/v1\\nkind: Ingres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63444</th>\n",
       "      <td>77336843</td>\n",
       "      <td>apiVersion: v1\\nkind: Service\\nmetadata:\\n  na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63444</th>\n",
       "      <td>77336843</td>\n",
       "      <td>export INGRESS_HOST=$(kubectl -n &amp;quot;$INGRES...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           q_id                                        q_prep_text\n",
       "0      77077227  import sys\\nfrom OpenGL.GL import *\\nfrom Open...\n",
       "1      77060888  from pytest import mark, fixture, raises\\nfrom...\n",
       "1      77060888  ========================================= test...\n",
       "2      77052025  import oci\\n\\nconfig = oci.config.from_file()\\...\n",
       "3      76937634  from telethon.sync import TelegramClient\\nimpo...\n",
       "...         ...                                                ...\n",
       "63443  77336446  import time\\nimport vtkmodules.all\\n\\nclass vt...\n",
       "63444  77336843  apiVersion: networking.k8s.io/v1\\nkind: Ingres...\n",
       "63444  77336843  apiVersion: networking.k8s.io/v1\\nkind: Ingres...\n",
       "63444  77336843  apiVersion: v1\\nkind: Service\\nmetadata:\\n  na...\n",
       "63444  77336843  export INGRESS_HOST=$(kubectl -n &quot;$INGRES...\n",
       "\n",
       "[173400 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_src_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_src_bf['q_prep_text_non'] = bert_src_bf['q_prep_text'].apply(preprocess_script)\n",
    "bert_src_af['q_prep_text_non'] = bert_src_af['q_prep_text'].apply(preprocess_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = bert_src_af['q_prep_text_non'].tolist()\n",
    "# df['sentiments'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"import sys\\nfrom OpenGL.GL import *\\nfrom OpenGL.GLU import *\\nfrom PyQt5 import QtGui\\nfrom PyQt5.QtOpenGL import *\\nfrom PyQt5 import QtCore, QtWidgets, QtOpenGL\\nclass Ui_MainWindow(QtWidgets.QWidget):\\n\\tdef __init__(self, parent=None):\\n\\t\\tsuper(Ui_MainWindow, self).__init__()\\n\\t\\tself.widget = glWidget()\\n\\t\\tself.button = QtWidgets.QPushButton('Test', self)\\n\\t\\tmainLayout = QtWidgets.QGridLayout()\\n\\t\\tmainLayout.addWidget(self.widget,0,0)\\n\\t\\tmainLayout.addWidget(self.button,0,0)\\n\\t\\tself.setLayout(mainLayout)\\nclass glWidget(QGLWidget):\\n\\tdef __init__(self, parent=None):\\n\\t\\tQGLWidget.__init__(self, parent)\\n\\t\\tself.setMinimumSize(640, 480)\\n\\tdef paintGL(self):\\n\\t\\tglClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\\n\\t\\tglLoadIdentity()\\n\\t\\tglTranslatef(-5, 0.5, -6.0)\\n\\t\\tglColor3f( 1.0, 1.5, 0.0 );\\n\\t\\tglPolygonMode(GL_FRONT, GL_FILL);\\n\\t\\tglBegin(GL_TRIANGLES)\\n\\t\\tglVertex3f(2.0,-1.2,0.0)\\n\\t\\tglVertex3f(2.6,0.0,0.0)\\n\\t\\tglVertex3f(2.9,-1.2,0.0)\\n\\t\\tglEnd()\\n\\t\\tglFlush()\\n\\tdef initializeGL(self):\\n\\t\\tglClearDepth(1.0)\\n\\t\\tglDepthFunc(GL_LESS)\\n\\t\\tglEnable(GL_DEPTH_TEST)\\n\\t\\tglShadeModel(GL_SMOOTH)\\n\\t\\tglMatrixMode(GL_PROJECTION)\\n\\t\\tglLoadIdentity()\\n\\t\\tgluPerspective(45.0,1.33,0.1, 100.0)\\n\\t\\tglMatrixMode(GL_MODELVIEW)\\nif __name__ == '__main__':\\n\\tapp = QtWidgets.QApplication(sys.argv)\\n\\tForm = QtWidgets.QMainWindow()\\n\\tui = Ui_MainWindow(Form)\\n\\tui.show()\\n\\tsys.exit(app.exec_())\",\n",
       " \"from pytest import mark, fixture, raises\\nfrom django.db import connection\\nfrom django.utils import timezone\\nimport sys, datetime as dt\\n@mark.django_db\\ndef test_db_time ():\\n\\tprint('Code time before:', timezone.now(), file = sys.stderr)\\n\\twith connection.cursor() as cursor:\\n\\t\\tcursor.execute(&quot;SELECT NOW()&quot;)\\n\\t\\tprint('DB NOW() before:',\\n\\t\\t\\t  t_before := cursor.fetchone()[0],\\n\\t\\t\\t  file = sys.stderr)\\n\\tsleep(1.56)\\n\\tprint('Code time after:', timezone.now(), file = sys.stderr)\\n\\twith connection.cursor() as cursor:\\n\\t\\tcursor.execute(&quot;SELECT NOW()&quot;)\\n\\t\\tprint('DB NOW() after:',\\n\\t\\t\\t  t_after := cursor.fetchone()[0],\\n\\t\\t\\t  file = sys.stderr)\\n\\tassert t_before != t_after, 'I need a nap!'\",\n",
       " \"========================================= test session starts =========================================\\nplatform linux -- Python 3.10.1, pytest-7.4.0, pluggy-1.0.0\\ndjango: settings: pms.settings (from ini)\\nrootdir: /home/nikita/files/projects/pms/dev\\nconfigfile: pyproject.toml\\nplugins: django-4.5.2\\ncollected 1 item\\nsis/tests/db/triggers/test_answer.py F\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  [100%]\\n============================================== FAILURES ===============================================\\n____________________________________________ test_db_time _____________________________________________\\n\\tdef test_db_time ():\\n\\t\\tprint('Code time before:', timezone.now(), file = sys.stderr)\\n\\t\\twith connection.cursor() as cursor:\\n\\t\\t\\tcursor.execute(&quot;SELECT NOW()&quot;)\\n\\t\\t\\tprint('DB NOW() before:',\\n\\t\\t\\t\\t  t_before := cursor.fetchone()[0],\\n\\t\\t\\t\\t  file = sys.stderr)\\n\\t\\tsleep(1.56)\\n\\t\\tprint('Code time after:', timezone.now(), file = sys.stderr)\\n\\t\\twith connection.cursor() as cursor:\\n\\t\\t\\tcursor.execute(&quot;SELECT NOW()&quot;)\\n\\t\\t\\tprint('DB NOW() after:',\\n\\t\\t\\t\\t  t_after := cursor.fetchone()[0],\\n\\t\\t\\t\\t  file = sys.stderr)\\n&gt;\\t   assert t_before != t_after, 'I need a nap!'\\nE\\t   AssertionError: I need a nap!\\nE\\t   assert datetime.datetime(2023, 9, 7, 15, 14, 14, 414343, tzinfo=datetime.timezone.utc) != datetime.datetime(2023, 9, 7, 15, 14, 14, 414343, tzinfo=datetime.timezone.utc)\\nsis/tests/db/triggers/test_answer.py:114: AssertionError\\n---------------------------------------- Captured stderr call -----------------------------------------\\nCode time before: 2023-09-07 15:14:14.414191+00:00\\nDB NOW() before: 2023-09-07 15:14:14.414343+00:00\\nCode time after: 2023-09-07 15:14:15.976308+00:00\\nDB NOW() after: 2023-09-07 15:14:14.414343+00:00\\n======================================= short test summary info =======================================\\nFAILED sis/tests/db/triggers/test_answer.py::test_db_time - AssertionError: I need a nap!\\n========================================== 1 failed in 3.05s ==========================================\",\n",
       " 'import oci\\nconfig = oci.config.from_file()\\nidentity = oci.identity.IdentityClient(config)\\nprint(len(identity.list_compartments(config[&quot;tenancy&quot;], compartment_id_in_subtree=True).data))',\n",
       " \"from telethon.sync import TelegramClient\\nimport csv\\nfrom celery import shared_task\\n@shared_task\\ndef main(url):\\n\\tapi_id = ********\\n\\tapi_hash = '********'\\n\\tphone = '******'\\n\\tclient = TelegramClient(phone, api_id, api_hash)\\n\\tclient.connect()\\n\\ttarget_group = client.get_entity(url)\\n\\tprint('Fetching Members...')\\n\\tall_participants = []\\n\\tall_participants = client.get_participants(target_group, aggressive=True)\\n\\tprint('Saving In file...')\\n\\twith open(&quot;members.csv&quot;,&quot;w&quot;,encoding='UTF-8') as f:\\n\\t\\twriter = csv.writer(f,delimiter=&quot;,&quot;,lineterminator=&quot;\\\\n&quot;)\\n\\t\\twriter.writerow(['username','user id', 'access hash','name','group', 'group id'])\\n\\t\\tfor user in all_participants:\\n\\t\\t\\tif user.username:\\n\\t\\t\\t\\tusername= user.username\\n\\t\\t\\telse:\\n\\t\\t\\t\\tusername= &quot;&quot;\\n\\t\\t\\tif user.first_name:\\n\\t\\t\\t\\tfirst_name= user.first_name\\n\\t\\t\\telse:\\n\\t\\t\\t\\tfirst_name= &quot;&quot;\\n\\t\\t\\tif user.last_name:\\n\\t\\t\\t\\tlast_name= user.last_name\\n\\t\\t\\telse:\\n\\t\\t\\t\\tlast_name= &quot;&quot;\\n\\t\\t\\tname= (first_name + ' ' + last_name).strip()\\n\\t\\t\\twriter.writerow([username ,user.id, user.access_hash, name, target_group.title, target_group.id])\\n\\tprint('Members scraped successfully.')\",\n",
       " \"from django.shortcuts import render\\nfrom django.views.decorators.csrf import csrf_exempt\\nfrom .tasks import main\\n@csrf_exempt\\ndef join_the_group(request):\\n\\tif request.method == 'POST':\\n\\t\\turl = request.POST['group-name']\\n\\t\\tmain(url)\\n\\t\\treturn render(request, 'ParseUserData/main_form.html')\\n\\telse:\\n\\t\\treturn render(request, 'ParseUserData/main_form.html')\",\n",
       " \"Traceback (most recent call last):\\n  File &quot;/home/dev/Desktop/DjangoParser/venv/lib/python3.8/site-packages/django/core/handlers/exception.py&quot;, line 55, in inner\\n\\tresponse = get_response(request)\\n  File &quot;/home/dev/Desktop/DjangoParser/venv/lib/python3.8/site-packages/django/core/handlers/base.py&quot;, line 197, in _get_response\\n\\tresponse = wrapped_callback(request, *callback_args, **callback_kwargs)\\n  File &quot;/home/dev/Desktop/DjangoParser/venv/lib/python3.8/site-packages/django/views/decorators/csrf.py&quot;, line 56, in wrapper_view\\n\\treturn view_func(*args, **kwargs)\\n  File &quot;/home/dev/Desktop/DjangoParser/ParserJSON/ParseUserData/views.py&quot;, line 10, in join_the_group\\n\\tmain()\\n  File &quot;/home/dev/Desktop/DjangoParser/venv/lib/python3.8/site-packages/celery/local.py&quot;, line 182, in __call__\\n\\treturn self._get_current_object()(*a, **kw)\\n  File &quot;/home/dev/Desktop/DjangoParser/venv/lib/python3.8/site-packages/celery/app/task.py&quot;, line 411, in __call__\\n\\treturn self.run(*args, **kwargs)\\n  File &quot;/home/dev/Desktop/DjangoParser/ParserJSON/ParseUserData/tasks.py&quot;, line 12, in main\\n\\tclient = TelegramClient(phone, api_id, api_hash)\\n  File &quot;/home/dev/Desktop/DjangoParser/venv/lib/python3.8/site-packages/telethon/client/telegrambaseclient.py&quot;, line 335, in __init__\\n\\tif not callable(getattr(self.loop, 'sock_connect', None)):\\n  File &quot;/home/dev/Desktop/DjangoParser/venv/lib/python3.8/site-packages/telethon/client/telegrambaseclient.py&quot;, line 483, in loop\\n\\treturn helpers.get_running_loop()\\n  File &quot;/home/dev/Desktop/DjangoParser/venv/lib/python3.8/site-packages/telethon/helpers.py&quot;, line 433, in get_running_loop\\n\\treturn asyncio.get_event_loop_policy().get_event_loop()\\n  File &quot;/usr/lib/python3.8/asyncio/events.py&quot;, line 639, in get_event_loop\\n\\traise RuntimeError('There is no current event loop in thread %r.'\\nRuntimeError: There is no current event loop in thread 'Thread-1'.\\n[20/Aug/2023 01:32:00] &quot;POST /user-data/collection-name HTTP/1.1&quot; 500 104535\",\n",
       " '1\\\\.when moving the icon instances the X and Y coordinates of them be printed in the code terminal\\n2\\\\.when left-clicking on the icon instances that we already dropped, an empty widget opens that stays open until we close it\\n3\\\\.when right-clicking on them a Q menu with a bunch of options shows up. save, edit, delete.',\n",
       " 'import sys\\nfrom PyQt5.QtWidgets import QApplication, QGraphicsPixmapItem, QMainWindow, QGraphicsView, QGraphicsScene, QVBoxLayout, QHBoxLayout, QWidget, QToolButton, QMenu, QAction, QDialog\\nfrom PyQt5.QtGui import QIcon, QPixmap, QDrag, QCursor\\nfrom PyQt5.QtCore import QSize, Qt, QMimeData\\nclass DraggableIcon(QToolButton):\\n\\tdef __init__(self, icon_path, parent=None):\\n\\t\\tsuper().__init__(parent)\\n\\t\\tself.setIcon(QIcon(icon_path))\\n\\t\\tself.setIconSize(QSize(64, 64))\\n\\t\\tself.setFixedSize(64, 64)\\n\\t\\tself.setAcceptDrops(True)\\n\\t\\tself.icon_path = icon_path\\n\\tdef mousePressEvent(self, event):\\n\\t\\tif event.button() == Qt.LeftButton:\\n\\t\\t\\tself.openEmptyWidget()\\n\\t\\telif event.button() == Qt.RightButton:\\n\\t\\t\\tself.showContextMenu(event)\\n\\tdef openEmptyWidget(self):\\n\\t\\tempty_widget = QDialog()\\n\\t\\tempty_widget.setWindowTitle(&quot;Empty Widget&quot;)\\n\\t\\tempty_widget.exec_()\\n\\tdef showContextMenu(self, event):\\n\\t\\tmenu = QMenu()\\n\\t\\tsave_action = QAction(&quot;Save&quot;)\\n\\t\\tedit_action = QAction(&quot;Edit&quot;)\\n\\t\\tdelete_action = QAction(&quot;Delete&quot;)\\n\\t\\tmenu.addAction(save_action)\\n\\t\\tmenu.addAction(edit_action)\\n\\t\\tmenu.addAction(delete_action)\\n\\t\\taction = menu.exec_(self.mapToGlobal(event.pos()))\\nclass MyGraphicsView(QGraphicsView):\\n\\tdef __init__(self, scene):\\n\\t\\tsuper().__init__(scene)\\n\\t\\tself.setAcceptDrops(True)\\n\\tdef dragEnterEvent(self, event):\\n\\t\\tif event.mimeData().hasText():\\n\\t\\t\\tevent.acceptProposedAction()\\n\\tdef dragMoveEvent(self, event):\\n\\t\\tif event.mimeData().hasText():\\n\\t\\t\\tevent.acceptProposedAction()\\n\\tdef dropEvent(self, event):\\n\\t\\tmime_data = event.mimeData()\\n\\t\\tif mime_data.hasText():\\n\\t\\t\\ticon_path = mime_data.text()\\n\\t\\t\\tpixmap = QPixmap(icon_path)\\n\\t\\t\\ticon_item = self.scene().addPixmap(pixmap)\\n\\t\\t\\tscene_pos = self.mapToScene(event.pos())\\n\\t\\t\\ticon_item.setPos(scene_pos)\\n\\t\\t\\ticon_item.setFlag(QGraphicsPixmapItem.ItemIsMovable)\\n\\t\\t\\ticon_item.setCursor(QCursor(Qt.PointingHandCursor))\\n\\t\\t\\tevent.acceptProposedAction()\\nclass MyWindow(QMainWindow):\\n\\tdef __init__(self):\\n\\t\\tsuper().__init__()\\n\\t\\tself.setWindowTitle(&quot;Drag and drop&quot;)\\n\\t\\tcentral_widget = QWidget(self)\\n\\t\\tself.setCentralWidget(central_widget)\\n\\t\\tmain_layout = QHBoxLayout(central_widget)\\n\\t\\ticon_layout = QVBoxLayout()\\n\\t\\tself.icons = [&quot;athena_icon.png&quot;, &quot;poseidon_icon.png&quot;, &quot;ares_icon.png&quot;]\\n\\t\\tfor icon_path in self.icons:\\n\\t\\t\\ticon_button = DraggableIcon(icon_path)\\n\\t\\t\\ticon_button.setCursor(QCursor(Qt.PointingHandCursor))  \\n\\t\\t\\ticon_layout.addWidget(icon_button)\\n\\t\\tscene = QGraphicsScene(self)\\n\\t\\tgraphics_view = MyGraphicsView(scene)\\n\\t\\tscene.setSceneRect(0, 0, 800, 800)  \\n\\t\\tscene.setItemIndexMethod(QGraphicsScene.NoIndex)  \\n\\t\\tmain_layout.addLayout(icon_layout)\\n\\t\\tmain_layout.addWidget(graphics_view)\\nif __name__ == &quot;__main__&quot;:\\n\\tapp = QApplication(sys.argv)\\n\\twindow = MyWindow()\\n\\twindow.resize(800, 800)  \\n\\twindow.show()\\n\\tsys.exit(app.exec_())',\n",
       " \"from proxy_checking import ProxyChecker\\nfrom colorama import Back, Fore\\nimport datetime as dt, random as rm\\nproxiesValue = int(input('Enter the number of proxies to check: '))\\nnotProxiesValue = 0\\nchecker = ProxyChecker()\\nrandomProxy = str(rm.randint(1, 239)) + '.' + str(rm.randint(1, 255)) + '.' +str(rm.randint(1, 255)) + '.' +str(rm.randint(1, 255)) + ':8080'\\nprint(f&quot;{Back.BLACK}{Fore.LIGHTCYAN_EX}&quot; + str(dt.datetime.now()) + f&quot; {Fore.WHITE}&quot; + str(randomProxy) + f&quot;{Fore.LIGHTBLUE_EX} &gt;&gt;&gt; &quot;, end='')\\nproxyCurrentStatus = checker.check_proxy(randomProxy)\\nif proxyCurrentStatus != &quot;{'status': False}&quot;:\\n\\tprint(f&quot;{Fore.GREEN}&quot; + str(proxyCurrentStatus))\\nelif proxyCurrentStatus == &quot;{'status': False}&quot;:\\n\\tprint(f&quot;{Fore.RED} Not working!&quot;)\",\n",
       " \"proxyCurrentStatus = checker.check_proxy(randomProxy)\\nif proxyCurrentStatus != &quot;{'status': False}&quot;:\\n\\tprint(f&quot;{Fore.GREEN}&quot; + str(proxyCurrentStatus))\\nelif proxyCurrentStatus == &quot;{'status': False}&quot;:\\n\\tprint(f&quot;{Fore.RED} Not working!&quot;)\",\n",
       " '&lt;|user|&gt;How are you?&lt;|bot|&gt;I’m fine&lt;|endoftext|&gt;\\n&lt;|user|&gt;What films do you like?&lt;|bot|&gt;I like interstellar&lt;|endoftext|&gt;',\n",
       " 'class GPTConfig:\\n\\tdef __init__(self):\\n\\t\\tself.n_layer = n_layer\\n\\t\\tself.n_embd = n_embd\\n\\t\\tself.vocab_size = vocab_size\\n\\t\\tself.n_positions = 1024\\n\\t\\tself.n_ctx = 1024\\n\\t\\tself.n_head = n_head\\n\\t\\tself.layer_norm_epsilon = 1e-5\\ndef gelu(x):\\n\\treturn 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\\nclass LayerNorm(nn.Module):\\n\\tdef __init__(self, hidden_size, eps=1e-12):\\n\\t\\tsuper(LayerNorm, self).__init__()\\n\\t\\tself.weight = nn.Parameter(torch.ones(hidden_size))\\n\\t\\tself.bias = nn.Parameter(torch.zeros(hidden_size))\\n\\t\\tself.variance_epsilon = eps\\n\\tdef forward(self, x):\\n\\t\\tu = x.mean(-1, keepdim=True)\\n\\t\\ts = (x - u).pow(2).mean(-1, keepdim=True)\\n\\t\\tx = (x - u) / torch.sqrt(s + self.variance_epsilon)\\n\\t\\treturn self.weight * x + self.bias\\nclass Conv1D(nn.Module):\\n\\tdef __init__(self, nf, nx):\\n\\t\\tsuper(Conv1D, self).__init__()\\n\\t\\tself.nf = nf\\n\\t\\tw = torch.empty(nx, nf)\\n\\t\\tnn.init.normal_(w, std=0.02)\\n\\t\\tself.weight = nn.Parameter(w)\\n\\t\\tself.bias = nn.Parameter(torch.zeros(nf))\\n\\tdef forward(self, x):\\n\\t\\tsize_out = x.size()[:-1] + (self.nf,)\\n\\t\\tx = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\\n\\t\\tx = x.view(*size_out)\\n\\t\\treturn x\\nclass Attention(nn.Module):\\n\\tdef __init__(self, nx, n_ctx, config, scale=False):\\n\\t\\tsuper(Attention, self).__init__()\\n\\t\\tn_state = nx  \\n\\t\\tassert n_state % n_head == 0\\n\\t\\tself.register_buffer(&quot;bias&quot;, torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\\n\\t\\tself.n_head = n_head\\n\\t\\tself.split_size = n_state\\n\\t\\tself.scale = scale\\n\\t\\tself.c_attn = Conv1D(n_state * 3, nx)\\n\\t\\tself.c_proj = Conv1D(n_state, nx)\\n\\tdef _attn(self, q, k, v):\\n\\t\\tw = torch.matmul(q, k)\\n\\t\\tif self.scale:\\n\\t\\t\\tw = w / math.sqrt(v.size(-1))\\n\\t\\tnd, ns = w.size(-2), w.size(-1)\\n\\t\\tb = self.bias[:, :, ns-nd:ns, :ns]\\n\\t\\tw = w * b - 1e10 * (1 - b)\\n\\t\\tw = nn.Softmax(dim=-1)(w)\\n\\t\\treturn torch.matmul(w, v)\\n\\tdef merge_heads(self, x):\\n\\t\\tx = x.permute(0, 2, 1, 3).contiguous()\\n\\t\\tnew_x_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)\\n\\t\\treturn x.view(*new_x_shape)\\n\\tdef split_heads(self, x, k=False):\\n\\t\\tnew_x_shape = x.size()[:-1] + (self.n_head, x.size(-1) // self.n_head)\\n\\t\\tx = x.view(*new_x_shape)\\n\\t\\tif k:\\n\\t\\t\\treturn x.permute(0, 2, 3, 1)\\n\\t\\telse:\\n\\t\\t\\treturn x.permute(0, 2, 1, 3)\\n\\tdef forward(self, x, layer_past=None):\\n\\t\\tx = self.c_attn(x)\\n\\t\\tquery, key, value = x.split(self.split_size, dim=2)\\n\\t\\tquery = self.split_heads(query)\\n\\t\\tkey = self.split_heads(key, k=True)\\n\\t\\tvalue = self.split_heads(value)\\n\\t\\tif layer_past is not None:\\n\\t\\t\\tpast_key, past_value = layer_past[0].transpose(-2, -1), layer_past[1]\\n\\t\\t\\tkey = torch.cat((past_key, key), dim=-1)\\n\\t\\t\\tvalue = torch.cat((past_value, value), dim=-2)\\n\\t\\tpresent = torch.stack((key.transpose(-2, -1), value))\\n\\t\\ta = self._attn(query, key, value)\\n\\t\\ta = self.merge_heads(a)\\n\\t\\ta = self.c_proj(a)\\n\\t\\treturn a, present\\nclass MLP(nn.Module):\\n\\tdef __init__(self, n_state, config):\\n\\t\\tsuper(MLP, self).__init__()\\n\\t\\tnx = n_embd\\n\\t\\tself.c_fc = Conv1D(n_state, nx)\\n\\t\\tself.c_proj = Conv1D(nx, n_state)\\n\\t\\tself.act = gelu\\n\\tdef forward(self, x):\\n\\t\\th = self.act(self.c_fc(x))\\n\\t\\th2 = self.c_proj(h)\\n\\t\\treturn h2\\nclass Block(nn.Module):\\n\\tdef __init__(self, n_ctx, config, scale=False):\\n\\t\\tsuper(Block, self).__init__()\\n\\t\\tnx = n_embd\\n\\t\\tself.ln_1 = LayerNorm(nx, eps=layer_norm_epsilon)\\n\\t\\tself.attn = Attention(nx, n_ctx, config, scale)\\n\\t\\tself.ln_2 = LayerNorm(nx, eps=layer_norm_epsilon)\\n\\t\\tself.mlp = MLP(4 * nx, config)\\n\\tdef forward(self, x, layer_past=None):\\n\\t\\ta, present = self.attn(self.ln_1(x), layer_past=layer_past)\\n\\t\\tx = x + a\\n\\t\\tm = self.mlp(self.ln_2(x))\\n\\t\\tx = x + m\\n\\t\\treturn x, present\\nclass GPT2Model(nn.Module):\\n\\tdef __init__(self, config):\\n\\t\\tsuper(GPT2Model, self).__init__()\\n\\t\\tself.n_layer = n_layer\\n\\t\\tself.n_embd = n_embd\\n\\t\\tself.n_vocab = vocab_size\\n\\t\\tself.wte = nn.Embedding(vocab_size, n_embd)\\n\\t\\tself.wpe = nn.Embedding(n_positions, n_embd)\\n\\t\\tblock = Block(n_ctx, config, scale=True)\\n\\t\\tself.h = nn.ModuleList([copy.deepcopy(block) for _ in range(n_layer)])\\n\\t\\tself.ln_f = LayerNorm(n_embd, eps=layer_norm_epsilon)\\n\\tdef set_embeddings_weights(self, model_embeddings_weights):\\n\\t\\tembed_shape = model_embeddings_weights.shape\\n\\t\\tself.decoder = nn.Linear(embed_shape[1], embed_shape[0], bias=False)\\n\\t\\tself.decoder.weight = model_embeddings_weights  \\n\\tdef forward(self, input_ids, position_ids=None, token_type_ids=None, past=None):\\n\\t\\tif past is None:\\n\\t\\t\\tpast_length = 0\\n\\t\\t\\tpast = [None] * len(self.h)\\n\\t\\telse:\\n\\t\\t\\tpast_length = past[0][0].size(-2)\\n\\t\\tif position_ids is None:\\n\\t\\t\\tposition_ids = torch.arange(past_length, input_ids.size(-1) + past_length, dtype=torch.long,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tdevice=input_ids.device)\\n\\t\\tinput_shape = input_ids.size()\\n\\t\\tinput_ids = input_ids.view(-1, input_ids.size(-1))\\n\\t\\tif position_ids.ndimension() == 1:  \\n\\t\\t\\tposition_ids = position_ids.unsqueeze(0).expand_as(input_ids)\\n\\t\\telse:\\n\\t\\t\\tposition_ids = position_ids.view(-1, position_ids.size(-1))\\n\\t\\tinputs_embeds = self.wte(input_ids)\\n\\t\\tposition_embeds = self.wpe(position_ids)\\n\\t\\tif token_type_ids is not None:\\n\\t\\t\\ttoken_type_ids = token_type_ids.view(-1, token_type_ids.size(-1))\\n\\t\\t\\ttoken_type_embeds = self.wte(token_type_ids)\\n\\t\\telse:\\n\\t\\t\\ttoken_type_embeds = 0\\n\\t\\thidden_states = inputs_embeds + position_embeds + token_type_embeds\\n\\t\\tpresents = []\\n\\t\\tfor block, layer_past in zip(self.h, past):\\n\\t\\t\\thidden_states, present = block(hidden_states, layer_past)\\n\\t\\t\\tpresents.append(present)\\n\\t\\thidden_states = self.ln_f(hidden_states)\\n\\t\\toutput_shape = input_shape + (hidden_states.size(-1),)\\n\\t\\treturn hidden_states.view(*output_shape), presents\\nclass GPT2LMHead(nn.Module):\\n\\tdef __init__(self, model_embeddings_weights, config):\\n\\t\\tsuper(GPT2LMHead, self).__init__()\\n\\t\\tself.n_embd = n_embd\\n\\t\\tself.set_embeddings_weights(model_embeddings_weights)\\n\\tdef set_embeddings_weights(self, model_embeddings_weights):\\n\\t\\tembed_shape = model_embeddings_weights.shape\\n\\t\\tself.decoder = nn.Linear(embed_shape[1], embed_shape[0], bias=False)\\n\\t\\tself.decoder.weight = model_embeddings_weights  \\n\\tdef forward(self, hidden_state):\\n\\t\\tlm_logits = self.decoder(hidden_state)\\n\\t\\treturn lm_logits\\nclass GPT2LMHeadModel(nn.Module):\\n\\tdef __init__(self, config):\\n\\t\\tsuper(GPT2LMHeadModel, self).__init__()\\n\\t\\tself.transformer = GPT2Model(config)\\n\\t\\tself.lm_head = GPT2LMHead(self.transformer.wte.weight, config)\\n\\tdef set_tied(self):\\n\\t\\tself.lm_head.set_embeddings_weights(self.transformer.wte.weight)\\n\\tdef forward(self, input_ids, position_ids=None, token_type_ids=None, lm_labels=None, past=None):\\n\\t\\thidden_states, presents = self.transformer(input_ids, position_ids, token_type_ids, past)\\n\\t\\tlm_logits = self.lm_head(hidden_states)\\n\\t\\tif lm_labels is not None:\\n\\t\\t\\tloss_fct = nn.CrossEntropyLoss(ignore_index=-1)\\n\\t\\t\\tloss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), lm_labels.view(-1))\\n\\t\\t\\treturn loss\\n\\t\\treturn lm_logits, presents\\nclass GPTLanguageModel(nn.Module):\\n\\tdef __init__(self, config):\\n\\t\\tsuper(GPTLanguageModel, self).__init__()\\n\\t\\tself.model = GPT2LMHeadModel(config)\\n\\tdef forward(self, idx, targets=None):\\n\\t\\tlogits, presents = self.model(idx, lm_labels=targets)\\n\\t\\tloss = None if targets is None else logits\\n\\t\\treturn logits, loss\\n\\tdef generate(self, idx, max_new_tokens):\\n\\t\\t_, presents = self.model(idx)\\n\\t\\tB, T = idx.shape\\n\\t\\tfor _ in range(max_new_tokens):\\n\\t\\t\\tif T &lt;= block_size:\\n\\t\\t\\t\\tidx_cond = idx\\n\\t\\t\\telse:\\n\\t\\t\\t\\tidx_cond = idx[:, -block_size:]\\n\\t\\t\\tlogits, _ = self.model(idx_cond, past=presents)\\n\\t\\t\\tlogits = logits[:, -1, :]\\n\\t\\t\\tprobs = F.softmax(logits, dim=-1)\\n\\t\\t\\tidx_next = torch.multinomial(probs, num_samples=1)\\n\\t\\t\\tidx = torch.cat((idx, idx_next), dim=1)\\n\\t\\t\\tT += 1\\n\\t\\treturn idx',\n",
       " \"eval_players = pd.read_csv(r&quot;file_location&quot;)\\nbld = eval_players ['buildup']\\natt = eval_players ['attack']\\nbld_att = np.column_stack((bld,att))\\nkm_res = KMeans(n_clusters = 3).fit(bld_att)\\ncluster = km_res.cluster_centers_\\nplt.scatter(bld,att)\\nfor k,row in eval_players.iterrows():\\n\\t plt.text(row['buildup'],row['attack'],row['Name'])\\nplt.scatter (cluster[:,0],cluster[:,1], s = 500)\\n   clust = km_res.labels_\\neval_players['cluster'] = clust.tolist()`\",\n",
       " 'import tensorflow.keras as keras\\nimport tensorflow.keras.layers as layers\\nkeras.mixed_precision.set_global_policy(&quot;mixed_float16&quot;)\\nx_train = np.random.normal(size=(32, 512))\\ny_train = np.random.normal(size=(32, 1, 512))\\nbatch_size = 32\\nH, W = x_train.shape\\nrows, cols = np.indices((H, W), sparse=True)\\nembed_dim = 512\\nghost_dim = 1\\ndense_dim = 2048\\nnum_heads = 2\\nx_train = np.expand_dims(x_train, 1)\\nshape = (batch_size, ghost_dim, embed_dim) \\ndecoder_inputs = layers.Input(batch_input_shape=shape, dtype=tensorflow.float16)\\nmha_1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\\nmha_2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\\nlayernorm_1 = layers.LayerNormalization()\\nZ = decoder_inputs\\nZ = mha_1(query=Z, value=Z, key=Z, use_causal_mask=True, attention_mask=padding_mask)\\nZ = layernorm_1(Z + decoder_inputs)\\nZ = mha_2(query=Z, value=decoder_inputs, key=decoder_inputs, attention_mask=padding_mask)\\noutputs = layers.TimeDistributed(keras.layers.Dense(embed_dim, activation=&quot;softmax&quot;))(Z)\\nmodel = keras.Model(decoder_inputs, outputs)\\nmodel.compile(loss=&quot;mean_squared_error&quot;, optimizer=&quot;rmsprop&quot;, metrics=[&quot;accuracy&quot;])\\nhistory = model.fit(x_train, y_train, epochs=200)',\n",
       " \"!pip install dlib\\nimport os\\nimport dlib\\nimport numpy as np\\nfrom skimage import io\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.metrics import accuracy_score\\nimport joblib\\ndetector = dlib.get_frontal_face_detector()\\nface_rec_model_folder = '/kaggle/input/mydrivef/your_dlib_model_folder'  \\nface_rec_model = dlib.face_recognition_model_v1(os.path.join(face_rec_model_folder, 'dlib_face_recognition_resnet_model_v1.dat'))\\ndata_path = '/kaggle/input/mydrivet/train'  \\nimages = []\\nlabels = []\\nfor label_name in os.listdir(data_path):\\n\\tlabel_path = os.path.join(data_path, label_name)\\n\\tfor img_file in os.listdir(label_path):\\n\\t\\timg_path = os.path.join(label_path, img_file)\\n\\t\\timg = io.imread(img_path)\\n\\t\\tdetected_faces = detector(img)\\n\\t\\tif len(detected_faces) &gt; 0:\\n\\t\\t\\tface = detected_faces[0]\\n\\t\\t\\tchip = dlib.get_face_chip(img, face, size=150, padding=0.25)\\n\\t\\t\\tface_descriptor = face_rec_model.compute_face_descriptor(chip)\\n\\t\\t\\timages.append(face_descriptor)\\n\\t\\t\\tlabels.append(label_name)\\nX = np.array(images)\\ny = np.array(labels)\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\nknn_classifier = KNeighborsClassifier(n_neighbors=3)\\nknn_classifier.fit(X_train, y_train)\\ny_pred = knn_classifier.predict(X_test)\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(&quot;Accuracy:&quot;, accuracy)\\nclassifier_save_path = '/kaggle/working/trained_classifier.pkl'\\njoblib.dump(knn_classifier, classifier_save_path)\\nprint(&quot;Trained classifier saved to:&quot;, classifier_save_path)\",\n",
       " 'TypeError\\t\\t\\t\\t\\t\\t\\t\\t Traceback (most recent call last)\\nCell In[8], line 43\\n\\t 40 face = detected_faces[0]\\n\\t 42 \\n---&gt; 43 chip = dlib.get_face_chip(img, face, size=150, padding=0.25)\\n\\t 45 \\n\\t 46 face_descriptor = face_rec_model.compute_face_descriptor(chip)\\nTypeError: get_face_chip(): incompatible function arguments. The following argument types are supported:\\n\\t1. (img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, size: int = 150, padding: float = 0.25) -&gt; numpy.ndarray[(rows,cols,3),numpy.uint8]',\n",
       " '-a  -d\\n-b  -e\\n-c  -f',\n",
       " '-a  -b\\n-c  -d\\n-e  -f',\n",
       " \"import mysql.connector\\nimport os\\nimport datetime\\nfrom mysql.connector import errorcode\\nos.system(&quot;./mysqldumpBashScript.sh&quot;)\\ndef search_str(file_path, word):\\n\\tf = open(file_path, 'r')\\n\\tfiledata = f.read()\\n\\tf.close()\\n\\tnow = datetime.datetime.now().strftime(&quot;%w_%m_%Y_%H_%M&quot;)\\n\\tnewdata = filedata.replace('classicmodels', 'classicmodels_' + now)\\n\\tf = open(file_path, 'w')\\n\\tf.write(newdata)\\n\\tf.close()\\nsearch_str(r'latestDBBackup.sql', 'classicmodels')\",\n",
       " \"if 'lastClick' not in st.session_state:\\n\\tst.session_state.lastClick = -1\\nif 'buttonLen' not in st.session_state:\\n\\tst.session_state.buttonLen = random.randint(2, 5)\\nfake = st.button(&quot;stupid&quot;, disabled=True)\\nif 'buttons' not in st.session_state:\\n\\tst.session_state.buttons = [fake] * 5\\nfor i in range(st.session_state.buttonLen):\\n\\tst.session_state.buttons[i]= st.button(str(i))\\nfor i in range(5):\\n\\tst.write(f&quot;{st.session_state.buttons[i]} currentButton&quot;)\\n\\tif st.session_state.buttons[i]:\\n\\t\\tif i != st.session_state.lastClick:\\n\\t\\t\\tst.session_state.buttons[i] = False\\n\\t\\tst.session_state.lastClick = i\\n\\t\\tst.session_state.buttonLen = random.randint(2, 5)\\n\\t\\tbreak\\nst.write(f&quot;{st.session_state.lastClick} last clicked&quot;)\\nif prompt != &quot;&quot;:\\n\\tprompt_container.empty()\\n\\tst.info(prompt)\\n\\tsub = sub_container.subheader(&quot;Continue your story by choosing from the options below&quot;)\",\n",
       " 'import os\\nimport subprocess\\nimport sys\\nwith subprocess.Popen(sys.argv[1:], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=True) as proc:\\n\\twhile True:\\n\\t\\tbyte = proc.stdout.read(1)\\n\\t\\tif byte:\\n\\t\\t\\tsys.stdout.buffer.write(byte)\\n\\t\\t\\tsys.stdout.flush()\\n\\t\\telse:\\n\\t\\t\\tbreak\\nexit_status = proc.returncode',\n",
       " 'import sys\\nfrom time import sleep\\nwhile True:\\n\\tfor _ in range(8):\\n\\t\\tprint(&quot;test!&quot;)\\n\\t\\tsleep(1)\\n\\tbreak;',\n",
       " '&gt; ./parent.py ./child.py\\ntest!\\ntest!\\ntest!\\ntest!\\ntest!\\ntest!\\ntest!\\ntest!',\n",
       " './child.py',\n",
       " 'print(&quot;test!&quot;, flush=True)',\n",
       " 'airflow standalone',\n",
       " 'airflow dags test example',\n",
       " \"from __future__ import annotations\\nimport os\\nfrom airflow.operators.python import BranchPythonOperator\\nfrom airflow.operators.empty import EmptyOperator\\nfrom airflow.utils.trigger_rule import TriggerRule\\nfrom airflow.exceptions import AirflowException\\nimport subprocess\\nimport shutil\\ninput_dir = &quot;/Users/lll/airflow/video_input/&quot;\\noutput_dir = &quot;/Users/lll/airflow/video_output/&quot;\\nimport pendulum\\nfrom airflow import DAG\\nfrom airflow.operators.python import PythonOperator\\nwith DAG(\\n\\t&quot;ffmpeg_example&quot;,\\n\\tdefault_args={\\n\\t\\t&quot;retries&quot;: 2,\\n\\t},\\n\\tdescription=&quot;cut video into frame and add watermarks&quot;,\\n\\tschedule=None,\\n\\tstart_date=pendulum.datetime(2021, 1, 1, tz=&quot;UTC&quot;),\\n\\tcatchup=False,\\n\\ttags=[&quot;ffmpeg&quot;],\\n) as dag:\\n\\tdag.doc_md = __doc__\\n\\tdef count_func():\\n\\t\\tfile = open(&quot;/Users/lll/airflow/debug1.log&quot;, &quot;a&quot;)\\n\\t\\tfile.write(&quot;start\\\\n&quot;)\\n\\t\\tfile.close()\\n\\t\\tfile_list = os.listdir(input_dir)\\n\\t\\tcnt = 0\\n\\t\\tfor item in file_list:\\n\\t\\t\\tif os.path.isfile(input_dir+item):\\n\\t\\t\\t\\tcnt += 1\\n\\t\\t\\t\\tos.rename(input_dir+item, input_dir+&quot;inWorking&quot;+str(cnt)+item)\\n\\tdef switch_func(lowerLimit: int, UpperLimit: int) -&gt; str:\\n\\t\\tcnt = 0\\n\\t\\tfile_list = os.listdir(input_dir)\\n\\t\\tfor item in file_list:\\n\\t\\t\\tif &quot;inWorking&quot; in item:\\n\\t\\t\\t\\tcnt += 1\\n\\t\\tif cnt &lt; 10:\\n\\t\\t\\treturn &quot;less&quot;\\n\\t\\telse:\\n\\t\\t\\treturn &quot;more&quot;\\n\\tdef convert_to_mp4_func(item: str, output_path: str) -&gt; bool:\\n\\t\\tif item[-3:] == &quot;mp4&quot;:\\n\\t\\t\\tshutil.copy(input_dir+item, output_path+item)\\n\\t\\t\\treturn True\\n\\t\\ttarget = item.split('.')[0] + &quot;.mp4&quot;\\n\\t\\tcommand = [\\n\\t\\t\\t&quot;ffmpeg&quot;,\\n\\t\\t\\t&quot;-i&quot;, input_dir+item,\\n\\t\\t\\t&quot;-c:v&quot;, &quot;libx264&quot;,\\n\\t\\t\\t&quot;-c:a&quot;, &quot;mp3&quot;,\\n\\t\\t\\t&quot;-y&quot;,\\n\\t\\t\\t&quot;-strict&quot;, &quot;experimental&quot;,\\n\\t\\t\\toutput_path+target,\\n\\t\\t]\\n\\t\\ttry:\\n\\t\\t\\tfile = open(&quot;/Users/lll/airflow/debug1.log&quot;, &quot;a&quot;)\\n\\t\\t\\tfile.write(&quot;convert cmd run\\\\n&quot;)\\n\\t\\t\\tfile.close()\\n\\t\\t\\tsubprocess.check_output(command)\\n\\t\\t\\tfile = open(&quot;/Users/lll/airflow/debug1.log&quot;, &quot;a&quot;)\\n\\t\\t\\tfile.write(&quot;convert cmd run\\\\n&quot;)\\n\\t\\t\\tfile.close()\\n\\t\\t\\treturn True\\n\\t\\texcept subprocess.CalledProcessError as e:\\n\\t\\t\\tprint(&quot;convert failed:&quot;, e)\\n\\t\\t\\treturn False\\n\\tdef video_to_frame(item: str, input_path:str, output_path: str) -&gt; bool:\\n\\t\\tfile = open(&quot;/Users/lll/airflow/debug1.log&quot;, &quot;a&quot;)\\n\\t\\tfile.write(&quot;framing\\\\n&quot;)\\n\\t\\tfile.close()\\n\\t\\tprefix = item.split('.')[0]\\n\\t\\tcommand = [\\n\\t\\t\\t&quot;ffmpeg&quot;,\\n\\t\\t\\t&quot;-i&quot;, input_path+item,\\n\\t\\t\\t&quot;-f&quot;, &quot;image2&quot;,\\n\\t\\t\\t&quot;-y&quot;,\\n\\t\\t\\toutput_path+prefix+&quot;%03d.png&quot;,\\n\\t\\t]\\n\\t\\ttry:\\n\\t\\t\\tfile = open(&quot;/Users/lll/airflow/debug1.log&quot;, &quot;a&quot;)\\n\\t\\t\\tfile.write(&quot;frame cmd run\\\\n&quot;)\\n\\t\\t\\tfile.close()\\n\\t\\t\\tsubprocess.check_output(command)\\n\\t\\t\\tfile = open(&quot;/Users/lll/airflow/debug1.log&quot;, &quot;a&quot;)\\n\\t\\t\\tfile.write(&quot;frame cmd end\\\\n&quot;)\\n\\t\\t\\tfile.close()\\n\\t\\t\\treturn True\\n\\t\\texcept subprocess.CalledProcessError as e:\\n\\t\\t\\tprint(&quot;cut into frame failed:&quot;, e)\\n\\t\\t\\treturn False\\n\\tdef add_watermark(item: str, input_path:str, output_path: str) -&gt; bool:\\n\\t\\tfile = open(&quot;/Users/lll/airflow/debug1.log&quot;, &quot;a&quot;)\\n\\t\\tfile.write(&quot;watermarking\\\\n&quot;)\\n\\t\\tfile.close()\\n\\t\\tfile_list = os.listdir(input_path)\\n\\t\\tprefix = item.split('.')[0]\\n\\t\\tfor cur_it in file_list:\\n\\t\\t\\tif prefix in cur_it:\\n\\t\\t\\t\\tcommand = [\\n\\t\\t\\t\\t\\t&quot;ffmpeg&quot;,\\n\\t\\t\\t\\t\\t&quot;-i&quot;, input_path+cur_it,\\n\\t\\t\\t\\t\\t&quot;-y&quot;,\\n\\t\\t\\t\\t\\t&quot;-vf&quot;, &quot;drawtext=fontfile=./tmp/msyhbd.ttc:fontsize=200:x=(w - 10 - text_w):y=10:fontcolor=white:text='lyb':shadowx=4:shadowy=4:alpha=0.5&quot;,\\n\\t\\t\\t\\t\\toutput_dir+cur_it,\\n\\t\\t\\t\\t]\\n\\t\\t\\ttry:\\n\\t\\t\\t\\tsubprocess.check_output(command)\\n\\t\\t\\texcept subprocess.CalledProcessError as e:\\n\\t\\t\\t\\tprint(&quot;cut into frame failed:&quot;, e)\\n\\t\\t\\t\\treturn False\\n\\t\\treturn True\\n\\tdef manual_video_func(index: int, cnt: int):\\n\\t\\tfile_list = os.listdir(input_dir)\\n\\t\\tfor item in file_list:\\n\\t\\t\\tif &quot;inWorking&quot; in item:\\n\\t\\t\\t\\ttemp = &quot;&quot;\\n\\t\\t\\t\\ti = 9\\n\\t\\t\\t\\twhile i &lt; len(item) and item[i] &gt;= '0' and item[i] &lt;= '9':\\n\\t\\t\\t\\t\\ttemp += item[i]\\n\\t\\t\\t\\t\\ti += 1\\n\\t\\t\\t\\tnum = int(temp)\\n\\t\\t\\t\\tif num % cnt == index:\\n\\t\\t\\t\\t\\ttemp_dir_mp4 = input_dir+&quot;mp4/&quot;\\n\\t\\t\\t\\t\\tos.makedirs(temp_dir_mp4, exist_ok=True)\\n\\t\\t\\t\\t\\tif convert_to_mp4_func(item, temp_dir_mp4) != True:\\n\\t\\t\\t\\t\\t\\traise AirflowException(&quot;convert to mp4 failed!&quot;)\\n\\t\\t\\t\\t\\ttarget = item.split('.')[0]+&quot;.mp4&quot;\\n\\t\\t\\t\\t\\ttemp_dir_pic = input_dir+&quot;pic/&quot;\\n\\t\\t\\t\\t\\tos.makedirs(temp_dir_pic, exist_ok=True)\\n\\t\\t\\t\\t\\tif video_to_frame(target, temp_dir_mp4, temp_dir_pic) != True:\\n\\t\\t\\t\\t\\t\\traise AirflowException(&quot;convert to frame failed!&quot;)\\n\\t\\t\\t\\t\\tif add_watermark(item, temp_dir_pic, output_dir) != True:\\n\\t\\t\\t\\t\\t\\traise AirflowException(&quot;add watermark failed!&quot;)\\n\\t\\t\\t\\t\\tos.makedirs(input_dir+&quot;test&quot;)\\n\\tdef finish_func():\\n\\t\\tfile = open(&quot;/Users/lll/airflow/debug1.log&quot;, &quot;a&quot;)\\n\\t\\tfile.write(&quot;end\\\\n&quot;)\\n\\t\\tfile.close()\\n\\t\\tfile_list = os.listdir(input_dir)\\n\\t\\tfor item in file_list:\\n\\t\\t\\tif os.path.isfile and &quot;inWorking&quot; in item:\\n\\t\\t\\t\\tos.remove(input_dir+item)\\n\\t\\t\\telse:\\n\\t\\t\\t\\tshutil.rmtree(input_dir+item)\\n\\tcount_task = PythonOperator(\\n\\t\\ttask_id=&quot;count&quot;,\\n\\t\\tpython_callable=count_func,\\n\\t)\\n\\tswitch_task = BranchPythonOperator(\\n\\t\\ttask_id=&quot;switch&quot;,\\n\\t\\tpython_callable=switch_func,\\n\\t\\top_args=[0, 10],\\n\\t)\\n\\tless_task = EmptyOperator(\\n\\t\\ttask_id=&quot;less&quot;,\\n\\t)\\n\\tmore_task = EmptyOperator(\\n\\t\\ttask_id=&quot;more&quot;,\\n\\t)\\n\\tworker_task_0_0 = PythonOperator(\\n\\t\\ttask_id=&quot;worker_0_0&quot;,\\n\\t\\tpython_callable=manual_video_func,\\n\\t\\top_args=[0, 2],\\n\\t)\\n\\tworker_task_0_1 = PythonOperator(\\n\\t\\ttask_id=&quot;worker_0_1&quot;,\\n\\t\\tpython_callable=manual_video_func,\\n\\t\\top_args=[1, 2],\\n\\t)\\n\\tworker_task_1_0 = PythonOperator(\\n\\t\\ttask_id=&quot;worker_1_0&quot;,\\n\\t\\tpython_callable=manual_video_func,\\n\\t\\top_args=[0, 5],\\n\\t)\\n\\tworker_task_1_1 = PythonOperator(\\n\\t\\ttask_id=&quot;worker_1_1&quot;,\\n\\t\\tpython_callable=manual_video_func,\\n\\t\\top_args=[1, 5],\\n\\t)\\n\\tworker_task_1_2 = PythonOperator(\\n\\t\\ttask_id=&quot;worker_1_2&quot;,\\n\\t\\tpython_callable=manual_video_func,\\n\\t\\top_args=[2, 5],\\n\\t)\\n\\tworker_task_1_3 = PythonOperator(\\n\\t\\ttask_id=&quot;worker_1_3&quot;,\\n\\t\\tpython_callable=manual_video_func,\\n\\t\\top_args=[3, 5],\\n\\t)\\n\\tworker_task_1_4 = PythonOperator(\\n\\t\\ttask_id=&quot;worker_1_4&quot;,\\n\\t\\tpython_callable=manual_video_func,\\n\\t\\top_args=[4, 5],\\n\\t)\\n\\tmore_complete_task = EmptyOperator(\\n\\t\\ttask_id=&quot;more_completed&quot;,\\n\\t)\\n\\tless_complete_task = EmptyOperator(\\n\\t\\ttask_id=&quot;less_completed&quot;,\\n\\t)\\n\\tfinish_task = PythonOperator(\\n\\t\\ttask_id=&quot;finish&quot;,\\n\\t\\tpython_callable=finish_func,\\n\\t\\ttrigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS,\\n\\t)\\n\\tcount_task &gt;&gt; switch_task &gt;&gt; [less_task, more_task]\\n\\tless_task &gt;&gt; [worker_task_0_0, worker_task_0_1] &gt;&gt; less_complete_task\\n\\tmore_task &gt;&gt; [worker_task_1_0, worker_task_1_1, worker_task_1_2, worker_task_1_3, worker_task_1_4] &gt;&gt; more_complete_task\\n\\t[less_complete_task, more_complete_task] &gt;&gt; finish_task\",\n",
       " 'pandas_gbq()',\n",
       " \"pyarrow.lib.ArrowTypeError: Expected bytes, got a 'list' object\",\n",
       " 'df.info()',\n",
       " 'Column, Non-Null, Count, Dtype\\n0,  conversion_date, 366248, non-null, dbdate\\n1,  conversion_timestamp, 366248, non-null, datetime64[ns, UTC]\\n2,  journey_id, 366109, non-null, object\\n3,  path_channels, 366248, non-null, object\\n4,  path_timestamps, 366248, non-null, object\\n5,  conversion, 366248, non-null, boolean\\n6,  conversions_in_session, 366248, non-null, Int64\\n7,  conversion_value, 365595, non-null, float64\\n8,  attr_first_click, 366248, non-null, object\\n9,  attr_last_click, 366248, non-null, object\\n10, attr_last_non_direct_click, 366248, non-null, object\\n11, attr_position, 366248, non-null, object\\n12, attr_time_decay, 366248, non-null, object\\n13 attr_linear 366248 non-null object\\n14 attr_markov 366248 non-null object\\ndtypes: Int64(1), boolean(1), datetime64[ns, UTC](1), dbdate(1), float64(1), object(10)',\n",
       " \"transformer = ColumnTransformer(transformers = [\\n\\t('tnf1', OneHotEncoder(categories=ohe.categories_), ['name','company','fuel_type'])\\n], remainder = 'passthrough')\\nlr = LinearRegression()\\npipe = Pipeline([ ('trf1', transformer), ('lr', lr) ])\",\n",
       " 'xlsx.worksheet.write_row',\n",
       " 'xlsx.worksheet.write',\n",
       " \"formats = [\\nxlsx.workbook.add_format({'italic': True}),\\nxlsx.workbook.add_format({'bold': True}),\\nxlsx.workbook.add_format({'align': 'right'}),\\n]\\nxlsx.worksheet.write_row(0,0,[1,2, &quot;right aligned text&quot;], formats)\",\n",
       " 'write',\n",
       " \"import warnings\\nwarnings.filterwarnings('ignore', category=FutureWarning)\\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\\nwarnings.filterwarnings('ignore', category=PendingDeprecationWarning)\",\n",
       " \"from __future__ import absolute_import, division, print_function, unicode_literals\\nimport numpy as np import pandas as pd import tensorflow as tf import matplotlib.pyplot as plt from tensorflow import feature_column as fc import ssl\\nssl._create_default_https_context = ssl._create_unverified_context dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\\nfeature_columns = [] for feature_name in CATEGORICAL_COLUMNS:\\n\\tvocabulary = dftrain[feature_name].unique()\\t\\n\\tfeature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)) \\nfor feature_name in NUMERIC_COLUMNS:\\n\\tfeature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32)) \\n\\tds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  \\n\\tif shuffle:\\n\\t  ds = ds.shuffle(1000)  \\n\\tds = ds.batch(batch_size).repeat(num_epochs)  \\n\\treturn ds  \\ntrain_input_fn = make_input_fn(dftrain, y_train)  \\nlinear_est.train(train_input_fn)  \",\n",
       " \"Instructions for updating:\\nUse tf.keras instead.\\nWARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/training/monitored_session.py:1474: SessionRunValues.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\\nInstructions for updating:\\nUse tf.keras instead.\\nWARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/training/evaluation.py:260: FinalOpsHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\\nInstructions for updating:\\nUse tf.keras instead.\\n2023-05-24 23:50:24.860561: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype string and shape [264]\\n\\t [[{{node Placeholder/_4}}]]\\n0.7348485\",\n",
       " 'numba',\n",
       " 'parallel=True',\n",
       " 'parallel=False',\n",
       " 'set_num_threads(1)',\n",
       " \"from contextlib import contextmanager\\nfrom time import time\\nfrom numba import njit, prange, set_num_threads\\nimport numpy as np\\n@contextmanager\\ndef time_it(msg=&quot;&quot;):\\n\\ttic = time()\\n\\ttry:\\n\\t\\tyield\\n\\tfinally:\\n\\t\\ttoc = time()\\n\\t\\tprint(f'Computation time: {(toc - tic) * 1e3:.2f} ms \\\\t({msg})')\\n@njit('float64[:,:,:,::1],float64[:,:,:,::1],float64[:,:,:,::1]', parallel=False)\\ndef matrix_mult_single(a, b, out):\\n\\tfor i in range(a.shape[0]):\\n\\t\\tfor j in range(a.shape[1]):\\n\\t\\t\\tfor k in range(11):\\n\\t\\t\\t\\tfor l in range(11):\\n\\t\\t\\t\\t\\tfor m in range(11):\\n\\t\\t\\t\\t\\t\\tout[i, j, k, m] += a[i, j, k, l] * b[i, j, l, m]\\n@njit('float64[:,:,:,::1],float64[:,:,:,::1],float64[:,:,:,::1]', parallel=True)\\ndef matrix_mult_parallel(a, b, out):\\n\\tfor i in prange(a.shape[0]):\\n\\t\\tfor j in range(a.shape[1]):\\n\\t\\t\\tfor l in range(11):\\n\\t\\t\\t\\tfor k in range(11):\\n\\t\\t\\t\\t\\tfor m in range(11):\\n\\t\\t\\t\\t\\t\\tout[i, j, k, m] += a[i, j, k, l] * b[i, j, l, m]\\ndef matmult(a, b, out):\\n\\tnp.matmul(a, b, out=out)\\nA = np.random.rand(201, 201, 11, 11)\\nB = np.random.rand(201, 201, 11, 11)\\nwith time_it(&quot;numpy&quot;):\\n\\tnp.matmul(A, B, out=np.zeros_like(A))\\nmatrix_mult_single(A, B, np.zeros_like(A))\\nwith time_it(&quot;numba - single&quot;):\\n\\tmatrix_mult_single(A, B, np.zeros_like(A))\\nset_num_threads(1)\\nmatrix_mult_parallel(A, B, np.zeros_like(A))\\nwith time_it(&quot;numba - parallel&quot;):\\n\\tmatrix_mult_parallel(A, B, np.zeros_like(A))\",\n",
       " 'Computation time: 16.68 ms  (numpy)\\nComputation time: 43.93 ms  (numba - single)\\nComputation time: 18.88 ms  (numba - parallel)\\nComputation time: 34.46 ms  (numpy)\\nComputation time: 41.82 ms  (numba - single)\\nComputation time: 28.27 ms  (numba - parallel)',\n",
       " \"px_var_name = &quot;Particles_Px_subset_fract_electron&quot;\\nxPx_title = &quot;Px vs. x&quot;\\ndef proc_single_file(file_nam):\\n\\tprint(&quot;starting file processing:&quot; + file_nam)\\n\\tprint(px_var_name)\\n\\tprint(xPx_title)\\nproc_single_file('0000.sdf')\",\n",
       " \"starting file processing:0000.sdf\\nParticles_Px_subset_fract_electron\\nTraceback (most recent call last):\\n  File &quot;phase_space_2d.py&quot;, line 227, in &lt;module&gt;\\n\\tproc_single_file(listfiles[i])\\n  File &quot;phase_space_2d.py&quot;, line 156, in proc_single_file\\n\\tprint(xPx_title)\\nUnboundLocalError: local variable 'xPx_title' referenced before assignment\\nObject deleted\",\n",
       " \"px_var_name = &quot;Particles_Px_subset_fract_electron&quot;\\nxPx_title = &quot;Px vs. x&quot;\\ndef proc_single_file(file_nam):\\n\\tglobal xPx_title\\n\\tprint(&quot;starting file processing:&quot; + file_nam)\\n\\tprint(px_var_name)\\n\\tprint(xPx_title)\\nproc_single_file('0000.sdf')\",\n",
       " 'starting file processing:0000.sdf\\nParticles_Px_subset_fract_electron\\nPx vs. x',\n",
       " 'python3 CVE-2022-22536.py',\n",
       " 'memory pipes desynchronization vulnerability',\n",
       " 'poc()',\n",
       " \" poc = POC()\\n\\thost = 'aesg2-qe8-erp.aesg.accenture.com'\\n\\tport = 443\\n\\tpoc.dia(host, port, secure=True, cert_verify=False)\",\n",
       " \"from Crypto.Hash import SHA256\\nmess = b'hello'\\nh = SHA256.new(mess)\\nprint(h.hexdigest())\",\n",
       " \"Traceback (most recent call last):\\n  File &quot;/Users/thekc/PycharmProjects/MS_CS/Misc/ANS/roughwork.py&quot;, line 4, in &lt;module&gt;\\n\\th = SHA256.new(mess)\\n  File &quot;/Users/thekc/PycharmProjects/MS_CS/venv/lib/python3.9/site-packages/Crypto/Hash/SHA256.py&quot;, line 158, in new\\n\\treturn SHA256Hash().new(data)\\n  File &quot;/Users/thekc/PycharmProjects/MS_CS/venv/lib/python3.9/site-packages/Crypto/Hash/SHA256.py&quot;, line 73, in __init__\\n\\tresult = _raw_sha256_lib.SHA256_init(state.address_of())\\n  File &quot;/Users/thekc/PycharmProjects/MS_CS/venv/lib/python3.9/site-packages/cffi/api.py&quot;, line 912, in __getattr__\\n\\tmake_accessor(name)\\n  File &quot;/Users/thekc/PycharmProjects/MS_CS/venv/lib/python3.9/site-packages/cffi/api.py&quot;, line 908, in make_accessor\\n\\taccessors[name](name)\\n  File &quot;/Users/thekc/PycharmProjects/MS_CS/venv/lib/python3.9/site-packages/cffi/api.py&quot;, line 838, in accessor_function\\n\\tvalue = backendlib.load_function(BType, name)\\nAttributeError: function/symbol 'SHA256_init' not found in library '/Users/thekc/PycharmProjects/MS_CS/venv/lib/python3.9/site-packages/Crypto/Util/../Hash/_SHA256.cpython-39-darwin.so': dlsym(0x88adddf0, SHA256_init): symbol not found\\nProcess finished with exit code 1\",\n",
       " \"flask_unsign import session\\nsession_cookie = &quot;eyJjc3JmX3Rva2VuIjoiY2Q3Y2FiMzBjOTE2NTM5ZjFhMDViYTY2NmVlY2VkNTgzZjYzYzg0MSIsImxvY2FsZSI6ImVuIn0.ZE6ojQ.xpmHBDQeY28iOgZwFtbe-GJOLLE&quot;\\nverified = session.verify(session_cookie, b'Change_me')\\nif verified:\",\n",
       " \"var theSessValue = &quot;eyJjc3JmX3Rva2VuIjoiY2Q3Y2FiMzBjOTE2NTM5ZjFhMDViYTY2NmVlY2VkNTgzZjYzYzg0MSIsImxvY2FsZSI6ImVuIn0.ZE6ojQ.xpmHBDQeY28iOgZwFtbe-GJOLLE&quot;;\\nconst cookieParser = require('cookie-parser');\\nconst base64url = require('base64url');\\nconsole.log(&quot;Parser: &quot; + cookieParser.signedCookie(theSessValue, &quot;Change_me&quot;); //returns eyJjc3JmX3Rva2VuIjoiY2Q3Y2FiMzBjOTE2NTM5ZjFhMDViYTY2NmVlY2VkNTgzZjYzYzg0MSIsImxvY2FsZSI6ImVuIn0.ZE6ojQ.xpmHBDQeY28iOgZwFtbe-GJOLLE\\n//const decodedSessionData = base64url.decode(theSessValue);\\n//const decodedSessionData = Buffer.from(theSessValue, 'base64').toString('utf-8');\\n//console.log(decodedSessionData);\",\n",
       " 'session.verify()',\n",
       " \"import scrapy\\nfrom scrapy.spiders import CrawlSpider, Rule\\nfrom scrapy.linkextractors import LinkExtractor\\nfrom scrapy.crawler import CrawlerProcess\\nfrom scrapy.http import FormRequest\\nclass chnlids(scrapy.Spider):\\n\\tname = &quot;chnlids&quot;\\n\\tpage_number = 0\\n\\tdef start_requests(self):\\n\\t\\tyield scrapy.Request(\\n\\t\\t\\turl='https://starngage.com/plus/en-us/login',\\n\\t\\t\\tcallback=self.login\\n\\t\\t)\\n\\tdef login(self,response):\\n\\t  return scrapy.FormRequest.from_response(\\n\\t\\t\\tresponse,\\n\\t\\t\\tformdata={\\n\\t\\t\\t  'email': 'demo',\\n\\t\\t\\t  'password': 'demo'},\\n\\t\\t\\tcallback=self.parse)\\n\\tdef parse(self,response):\\n\\t  i = 0\\n\\t  if(self.page_number != 10):\\n\\t\\tself.page_number += 1\\n\\t\\tnext_page = f'https://starngage.com/plus/en-us/influencer/ranking/youtube/all-countries?page={self.page_number}'\\n\\t\\tyield scrapy.Request(next_page, callback=self.parse,meta={'dont_redirect': True, 'handle_httpstatus_list': [302]})\\n\\t\\tfor key in range(100):\\n\\t\\t  yield{\\n\\t\\t\\t  &quot;channel_id&quot; : response.css(&quot;a.text-break::text&quot;)[i].get()\\n\\t\\t  }\\n\\t\\ti += 1\",\n",
       " 'ValueError: No &lt;form&gt; element found in &lt;200 https://starngage.com/plus/en-us/login&gt;',\n",
       " \"import pickle\\nfrom google.oauth2.credentials import Credentials\\nimport google_auth_oauthlib\\nfrom googleapiclient.discovery import build\\nfrom googleapiclient.errors import HttpError\\nfrom googleapiclient.http import MediaFileUpload\\nimport os\\nCLIENT_SECRETS_FILE = &quot;client_secret.json&quot;\\nYOUTUBE_UPLOAD_SCOPE = &quot;https://www.googleapis.com/auth2/youtube.upload&quot;\\nYOUTUBE_API_SERVICE_NAME = &quot;youtube&quot;\\nYOUTUBE_API_VERSION = &quot;v3&quot;\\ndef get_authenticated_service():\\n\\tcredentials = None\\n\\tif os.path.exists('token.pickle'):\\n\\t\\twith open('token.pickle', 'rb') as token:\\n\\t\\t\\tcredentials = Credentials.from_authorized_user_info(info=pickle.load(token))\\n\\tif not credentials or not credentials.valid:\\n\\t\\tflow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(CLIENT_SECRETS_FILE, [YOUTUBE_UPLOAD_SCOPE])\\n\\t\\tcredentials = flow.run_local_server(port=8080)\\n\\t\\twith open('token.pickle', 'wb') as token:\\n\\t\\t\\tpickle.dump(credentials.to_authorized_user_info(), token)\\n\\treturn build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, credentials=credentials)\\ndef upload_to_youtube(video_path, title, description):\\n\\ttry:\\n\\t\\tyoutube = get_authenticated_service()\\n\\t\\tmedia = MediaFileUpload(video_path, chunksize=-1, resumable=True)\\n\\t\\tvideo = youtube.videos().insert(\\n\\t\\t\\tpart=&quot;snippet,status&quot;,\\n\\t\\t\\tbody={\\n\\t\\t\\t\\t&quot;snippet&quot;: {\\n\\t\\t\\t\\t\\t&quot;title&quot;: title,\\n\\t\\t\\t\\t\\t&quot;description&quot;: description,\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t&quot;status&quot;: {\\n\\t\\t\\t\\t\\t&quot;privacyStatus&quot;: &quot;private&quot;,\\n\\t\\t\\t\\t},\\n\\t\\t\\t},\\n\\t\\t\\tmedia_body=media,\\n\\t\\t).execute()\\n\\t\\tprint(f'Uploaded video: {video[&quot;id&quot;]}')\\n\\texcept HttpError as e:\\n\\t\\tprint(f'An error occurred: {e}')\\n\\t\\treturn False\\n\\treturn True\\nif __name__ == '__main__':\\n\\tvideo_path = &quot;test.mp4&quot;\\n\\ttitle = &quot;My video title&quot;\\n\\tdescription = &quot;My video description&quot;\\n\\tupload_to_youtube(video_path, title, description)\",\n",
       " \"@bb.before_request\\ndef check_if_auth():\\n\\tif request.method == &quot;OPTIONS&quot;:\\n\\t\\treturn make_response(&quot;OK&quot;, 200)\\n\\tif os.environ.get(&quot;ENV&quot;) == &quot;development&quot;:\\n\\t\\tlogger.info(request.endpoint)\\n\\t\\tlogger.debug(request.headers)\\n\\t\\tpass\\n\\telse:\\n\\t\\tfunc = app.view_functions[request.endpoint]\\n\\t\\tif hasattr(func, '_exclude_from_check'):\\n\\t\\t\\tlogger.info(f&quot;{func} does not require auth check&quot;)\\n\\t\\t\\tpass\\n\\t\\telse:\\n\\t\\t\\tpath = &quot;A&quot;\\n\\t\\t\\theaders = {&quot;Authorization&quot;: request.headers.get(&quot;Authorization&quot;)}\\n\\t\\t\\tres = requests.get(f&quot;auth service URL here&quot;, params={&quot;path&quot;:path}, headers=headers)\",\n",
       " \"@bb.route(&quot;/add&quot;, methods=['POST'])\\ndef create():\\n\\tif 'file' not in request.files:\\n\\t\\tstatus['status'] = &quot;error&quot;\\n\\t\\tstatus['message'] = &quot;Missing File upload&quot;\\n\\t\\treturn make_response(status, 400)\",\n",
       " '/add',\n",
       " 'logger.info(request.files)',\n",
       " '   else:\\n\\t   logger.info(request.files)\\n\\t   func = app.view_functions[request.endpoint]',\n",
       " 'check_if_auth()',\n",
       " 'numpy',\n",
       " 'import os\\nimport nimpy\\nlet pythonPath = &quot;C:/User/Master/anaconda3&quot;\\nputEnv(&quot;PYTHONPATH&quot;, pythonPath)\\nlet pythonHome = &quot;C:/User/Master/anaconda3/Lib/site-packages&quot;\\nputEnv(&quot;PYTHONHOME&quot;, pythonHome)\\nlet np = pyImport(&quot;numpy&quot;)\\nlet arr = np.array([1, 2, 3, 4])\\necho &quot;Import numpy is success!&quot;\\necho arr',\n",
       " \"C:\\\\MyPrograms\\\\Nim_Programs\\\\Training_Project&gt;C:/Users/Master/anaconda3/Scripts/activate\\n(base) C:\\\\MyPrograms\\\\Nim_Programs\\\\Training_Project&gt;conda activate base\\n(base) C:\\\\MyPrograms\\\\Nim_Programs\\\\Training_Project&gt;C:/Users/Master/anaconda3/python.exe c:/MyPrograms/Nim_Programs/Training_Project/CompairPythonAndNim/searchPythonFile.py\\nC:\\\\Users\\\\Master\\\\anaconda3\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py\\n(base) C:\\\\MyPrograms\\\\Nim_Programs\\\\Training_Project&gt;nim c -r ImportPython.nim\\nHint: used config file 'C:\\\\Users\\\\Master\\\\.choosenim\\\\toolchains\\\\nim-1.6.12\\\\config\\\\nim.cfg' [Conf]\\nHint: used config file 'C:\\\\Users\\\\Master\\\\.choosenim\\\\toolchains\\\\nim-1.6.12\\\\config\\\\config.nims' [Conf]\\n.........................................................................................................\\nCC: ../../../Users/Master/.choosenim/toolchains/nim-1.6.12/lib/system.nim\\nCC: ImportPython.nim\\nHint:  [Link]\\nHint: gc: refc; opt: none (DEBUG BUILD, `-d:release` generates faster code)\\n59660 lines; 2.194s; 93.867MiB peakmem; proj: C:\\\\MyPrograms\\\\Nim_Programs\\\\Training_Project\\\\ImportPython.nim; out: C:\\\\MyPrograms\\\\Nim_Programs\\\\Training_Project\\\\ImportPython.exe [SuccessX]\\nHint: C:\\\\MyPrograms\\\\Nim_Programs\\\\Training_Project\\\\ImportPython.exe  [Exec]\\nPython path configuration:\\n  PYTHONHOME = 'C:/User/Master/anaconda3/Lib/site-packages'\\n  PYTHONPATH = 'C:/User/Master/anaconda3'\\n  program name = 'python'\\n  isolated = 0\\n  environment = 1\\n  user site = 1\\n  import site = 1\\n  sys._base_executable = 'C:\\\\\\\\MyPrograms\\\\\\\\Nim_Programs\\\\\\\\Training_Project\\\\\\\\ImportPython.exe'\\n  sys.base_prefix = 'C:/User/Master/anaconda3/Lib/site-packages'\\n  sys.base_exec_prefix = 'C:/User/Master/anaconda3/Lib/site-packages'\\n  sys.platlibdir = 'lib'\\n  sys.executable = 'C:\\\\\\\\MyPrograms\\\\\\\\Nim_Programs\\\\\\\\Training_Project\\\\\\\\ImportPython.exe'\\n  sys.prefix = 'C:/User/Master/anaconda3/Lib/site-packages'\\n  sys.exec_prefix = 'C:/User/Master/anaconda3/Lib/site-packages'\\n  sys.path = [\\n\\t'C:/User/Master/anaconda3',\\n\\t'C:\\\\\\\\Users\\\\\\\\Master\\\\\\\\anaconda3\\\\\\\\python310.zip',\\n\\t'C:/User/Master/anaconda3/Lib/site-packages\\\\\\\\DLLs',\\n\\t'C:/User/Master/anaconda3/Lib/site-packages\\\\\\\\lib',\\n\\t'C:\\\\\\\\MyPrograms\\\\\\\\Nim_Programs\\\\\\\\Training_Project',\\n  ]\\nFatal Python error: init_fs_encoding: failed to get the Python codec of the filesystem encoding\\nPython runtime state: core initialized\\nModuleNotFoundError: No module named 'encodings'\\nCurrent thread 0x00000b54 (most recent call first):\\n  &lt;no Python frame&gt;\\nError: execution of an external program failed: 'C:\\\\MyPrograms\\\\Nim_Programs\\\\Training_Project\\\\ImportPython.exe '\",\n",
       " 'pip',\n",
       " 'conda',\n",
       " 'nim',\n",
       " 'nimble',\n",
       " 'numpy',\n",
       " 'capabilities[&quot;goog:loggingPrefs&quot;] = {&quot;browser&quot;: &quot;ALL&quot;}\\ncurrent_window_handle = driver.current_window_handle\\nfor window_handle in driver.window_handles:\\n\\tdriver.switch_to_window(window_handle)\\n\\tlogs = driver.get_log(&quot;browser&quot;)',\n",
       " 'get_log',\n",
       " 'logs = driver.get_log(&quot;client&quot;)',\n",
       " \"self.execute_script('console.clear();')\",\n",
       " 'from selenium import webdriver\\nfrom selenium.webdriver.common.keys import Keys\\nfrom selenium.webdriver.common.by import By\\nimport time\\ndriver = webdriver.Chrome()\\ndriver.get(&quot;https://accounts.google.com/signin&quot;)\\nusername = driver.find_element(By.NAME, &quot;identifier&quot;)\\nusername.send_keys(&quot;blabla@gmail.com&quot;)\\nusername.send_keys(Keys.RETURN)\\ntime.sleep(50)\\npassword = driver.find_element(By.NAME, &quot;password&quot;)\\npassword.send_keys(&quot;asdf1234&quot;)\\npassword.send_keys(Keys.RETURN)\\ndriver.implicitly_wait(5)\\ndriver.get(&quot;https://www.google.com&quot;)\\nsearch_field = driver.find_element(By.NAME, &quot;q&quot;)\\nsearch_field.send_keys(&quot;pizza&quot;)\\nsearch_field.send_keys(Keys.RETURN)',\n",
       " 'if batch % 100 == 0:\\n\\t loss, current = loss.item(), (batch + 1) * len(X)\\n\\t print(f&quot;loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]&quot;)',\n",
       " 'print(f&quot;Test Error: \\\\n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \\\\n&quot;)',\n",
       " 'size=46323656\\ncurrent=3\\nloss=4.6362635675\\nprint(f&quot;loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]&quot;)',\n",
       " 'loss: 4.636264  [\\t3/46323656]',\n",
       " \"import numpy as np; np.random.seed(sum(map(ord, 'calmap')))\\nimport pandas as pd\\nimport calmap\\nall_days = pd.date_range('1/15/2014', periods=700, freq='D')\\ndays = np.random.choice(all_days, 500)\\nevents = pd.Series(np.random.randn(len(days)), index=days)\\ncalmap.yearplot(events, year=2015)\",\n",
       " 'import nltk\\nfrom sklearn.metrics.pairwise import cosine_similarity\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nhero_archetype = &quot;brave selfless determined sacrifice&quot;\\ntext = &quot;The hero bravely sacrificed himself for the greater good.&quot;\\nhero_tokens = nltk.word_tokenize(hero_archetype)\\ntext_tokens = nltk.word_tokenize(text)\\nprint (hero_tokens)\\nprint (text_tokens)\\nhero_text = &quot; &quot;.join(hero_tokens)\\ntext_text = &quot; &quot;.join(text_tokens)\\nvectorizer = CountVectorizer().fit_transform([hero_text, text_text])\\nprint (vectorizer)\\nsimilarity_matrix = cosine_similarity(vectorizer)\\nprint (similarity_matrix)\\nprint(&quot;Similarity between hero archetype and text:&quot;, similarity_matrix[0][1])',\n",
       " \"import pandas as pd\\ndata = {'warehouse': ['M1', 'M1', 'M1', 'M1', 'M1', 'M1', 'M1', 'M1', 'M1', 'M2'],\\n\\t\\t'item': ['Partxy', 'Partxy', 'Partxy', 'Partxy', 'Partxy', 'Partxy', 'Partxy', 'Partxy', 'Partxy', 'Partz'],\\n\\t\\t'date': ['01/01/2023', '05/01/2023', '07/01/2023', '08/01/2023', '09/01/2023', '10/01/2023', '15/01/2023', '18/01/2023', '19/01/2023', '22/01/2023'],\\n\\t\\t'tot_load_replenishment': [0, 0, 20, 0, 0, 50, 0, 50, 0, 0],\\n\\t\\t'tot_unload': [0, -30, -15, -50, -10, -5, -30, -10, -5, -10],\\n\\t\\t'stock': [100, 70, 75, 25, 15, 60, 30, 70, 65, 300],\\n\\t\\t'stock_before_load': [None, None, 55, None, None, 10, None, 20, None, None]}\\nload_unload = pd.DataFrame(data)\\nload_unload['tot_load_replenishment'] = load_unload['tot_load_replenishment'].astype(int)\\nload_unload['tot_unload'] = load_unload['tot_unload'].astype(int)\\nload_unload['date'] = pd.to_datetime(load_unload['date'], format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\",\n",
       " \"item = 'Partxy'\\nwarehouse = 'M1'\\nitem_war = (load_unload['item'] == item) &amp; (load_unload['warehouse'] == warehouse)\\nload_unload_item_war = load_unload[item_war]\\nmov_replenishment = load_unload_item_war[load_unload_item_war['tot_load_replenishment'] &gt; 0]\\ndef exhaustion_date(row, load_unload_item_war):\\n\\tf_load_unload_item_war = load_unload_item_war[(load_unload_item_war['date'] &gt; row['date'])]\\n\\tresidual = row['stock_before_load']\\n\\tf_load_unload_item_war['cum_unload'] = f_load_unload_item_war['tot_unload'].cumsum()*(-1)\\n\\texhaustion_date = f_load_unload_item_war.loc[f_load_unload_item_war['tot_unload'] &lt; residual, 'date'].min()\\n\\treturn exhaustion_date\\nmov_replenishment['exhaustion_date'] = mov_replenishment.apply(lambda row: exhaustion_date(row, load_unload_item_war), axis=1)\",\n",
       " \"import telnetlib\\npool = [&quot;10.1.1.1&quot;,&quot;10.1.1.2&quot;]\\nuser = &quot;admin&quot;`\\npassword = &quot;admin&quot;`\\nfor IP in pool:\\n print(f&quot;Checking Switch --&gt; {IP}&quot;)\\n tn = telnetlib.Telnet(IP)\\n tn.read_until(b&quot;Username: &quot;)\\n tn.write(user.encode('ascii') + b&quot;\\\\n&quot;)\\n if password:\\n  tn.read_until(b&quot;Password: &quot;)\\n  tn.write(password.encode('ascii') + b&quot;\\\\n&quot;)\\n  for port in range(1,4):\\n  print(f&quot;checking port :{port}&quot;)\\n  tn.write(f&quot;show port-security interface fastethernet0/{port}\\\\n&quot;.encode('ascii'))\\n  output = tn.read_until(b&quot;\\n  print(output)\",\n",
       " 'Checking Switch --&gt; 10.1.1.1\\nchecking port :1\\nPost-4th-lab-2\\nchecking port :2\\nshow port-security interface fastethernet0/1\\nPort Security\\t\\t\\t  : Enabled\\nPort Status\\t\\t\\t\\t: Secure-down\\nViolation Mode\\t\\t\\t : Shutdown\\nAging Time\\t\\t\\t\\t : 0 mins\\nAging Type\\t\\t\\t\\t : Absolute\\nSecureStatic Address Aging : Disabled\\nMaximum MAC Addresses\\t  : 1\\nTotal MAC Addresses\\t\\t: 1\\nConfigured MAC Addresses   : 0\\nSticky MAC Addresses\\t   : 1\\nLast Source Address:Vlan   : 0000.0000.0000:0\\nSecurity Violation Count   : 0\\nPost-4th-lab-2\\nchecking port :3\\nshow port-security interface fastethernet0/2\\nPort Security\\t\\t\\t  : Enabled\\nPort Status\\t\\t\\t\\t: Secure-down\\nViolation Mode\\t\\t\\t : Shutdown\\nAging Time\\t\\t\\t\\t : 0 mins\\nAging Type\\t\\t\\t\\t : Absolute\\nSecureStatic Address Aging : Disabled\\nMaximum MAC Addresses\\t  : 1\\nTotal MAC Addresses\\t\\t: 1\\nConfigured MAC Addresses   : 0\\nSticky MAC Addresses\\t   : 1\\nLast Source Address:Vlan   : 0000.0000.0000:0\\nSecurity Violation Count   : 0',\n",
       " \"import os\\nimport pandas as pd\\npath = &quot;/Users/tjjaglinski/Downloads/--DailyReports/&quot;\\nfilename = []\\nfor (root,dirs, file) in os.walk(path):\\n\\tfor f in file:\\n\\t\\tif not f.startswith('.') and os.path.isfile(os.path.join(root, f)):\\n\\t\\t\\tfilename.append(f)\\n\\t\\t\\tprint(f)\\ndf = pd.DataFrame(list(zip(filename)),columns=['Name'])\\ndf.to_csv(&quot;DailyReport.csv&quot;)\",\n",
       " \"\\tself.Application = win32com.client.dynamic.Dispatch(&quot;CANoe.Application&quot;)\\n\\tVer = self.Application.Version\\n\\tself.Namespaces = self.Application.System.Namespaces\\n\\tself.Namespace = self.Namespaces('BOT')\\n\\tMachine = self.Namespace.Variables('Machine')\\n\\tMachine.value = 8\",\n",
       " \"\\tMachine = self.Namespace.Variables('Machine')\\n\\tMachine.value = getText() // will return &quot;8&quot;\",\n",
       " \"File &quot;C:\\\\Python39\\\\lib\\\\site-packages\\\\win32com\\\\client\\\\dynamic.py&quot;, line 707, in __setattr__\\nraise AttributeError(\\nAttributeError: Property '&lt;unknown&gt;.value' can not be set.\",\n",
       " \"Machine = self.Namespace.Variables('Machine')\\nvar = getText() // will return &quot;8&quot;\\nMachine.value = var\",\n",
       " \"list_LI_concat_cols = ['LI_date_engr_sign', 'Subst_SSO', 'Subst_name', 'Subst_mang_SSO',\\n\\t'Subst_mang_name', 'Signoff_name']\\ndf1.loc[:, ['Subst_SSO','Subst_mang_SSO']] \\\\\\n\\t= df1.loc[:, ['Subst_SSO','Subst_mang_SSO']].fillna('0').astype(int).astype(str)\\nfor col in list_LI_concat_cols:\\n\\tdf_subst_concat = df1.drop_duplicates(subset=['MRB_LI\\n\\t\\t.groupby('MRB_LI\\n\\tdf_LI = df_LI.merge(df_subst_concat, how='left', on='MRB_LI\",\n",
       " \"TypeError\\t\\t\\t\\t\\t\\t\\t\\t Traceback (most recent call last)\\n&lt;ipython-input-10-ec19d16b3b3e&gt; in &lt;module&gt;\\n\\t  9 \\n\\t 10 for col in list_LI_concat_cols:\\n---&gt; 11\\t df_subst_concat = df1.drop_duplicates(subset=['MRB_LI\\n\\t 12\\t\\t .groupby('MRB_LI\\n\\t 13\\t df_LI = df_LI.merge(df_subst_concat, how='left', on='MRB_LI\\n&lt;ipython-input-10-ec19d16b3b3e&gt; in &lt;lambda&gt;(x)\\n\\t 10 for col in list_LI_concat_cols:\\n\\t 11\\t df_subst_concat = df1.drop_duplicates(subset=['MRB_LI\\n---&gt; 12\\t\\t .groupby('MRB_LI\\n\\t 13\\t df_LI = df_LI.merge(df_subst_concat, how='left', on='MRB_LI\\nTypeError: sequence item 0: expected str instance, int found\",\n",
       " '.. autoclass::',\n",
       " 'class TestClass:\\n\\t&quot;&quot;&quot;\\n\\tThis is a brief summary.\\n\\tHere are a few more sentences. Probably more than two.\\n\\tAttributes\\n\\t----------\\n\\ta1 : Any\\n\\t\\tThis is the first attribute, I do not want to see it here.\\n\\ta2 : TestClass\\n\\t\\tOh look a recursive class\\n\\t&quot;&quot;&quot;\\n\\tdef __init__(self, a1, a2):\\n\\t\\t&quot;&quot;&quot;\\n\\t\\tInitialize self\\n\\t\\tParameters\\n\\t\\t----------\\n\\t\\ta1 : Any\\n\\t\\t\\tThe first attribute.\\n\\t\\ta2 : TestClass\\n\\t\\t\\tThe second attribute.\\n\\t\\t&quot;&quot;&quot;\\n\\t\\tself._a1 = a1\\n\\t\\tself._a2 = a2\\n\\t@property\\n\\tdef a1(self):\\n\\t\\t&quot;&quot;&quot;\\n\\t\\tThe first attribute, I want to see it here.\\n\\t\\tReturns\\n\\t\\t-------\\n\\t\\tAny\\n\\t\\t\\tThe first attribute\\n\\t\\t&quot;&quot;&quot;\\n\\t\\treturn self._a1\\n\\t@property\\n\\tdef a2(self):\\n\\t\\t&quot;&quot;&quot;\\n\\t\\tThe second attribute.\\n\\t\\tReturns\\n\\t\\t-------\\n\\t\\tTestClass\\n\\t\\t\\tThe second attribute\\n\\t\\t&quot;&quot;&quot;\\n\\t\\treturn self._a2',\n",
       " \"{{ objname | escape | underline }}\\n.. currentmodule:: {{ module }}\\n.. autoclass:: {{ objname }}\\n   {% block attributes %}\\n   {% if attributes %}\\n   .. rubric:: {{ _('Attributes') }}\\n   .. autosummary::\\n   {% for item in attributes %}\\n\\t  ~{{ name }}.{{ item }}\\n   {%- endfor %}\\n   {% endif %}\\n   {% endblock %}\\n   {% block methods %}\\n   {% if methods %}\\n   .. rubric:: {{ _('Methods') }}\\n   .. autosummary::\\n   {% for item in methods %}\\n\\t  ~{{ name }}.{{ item }}\\n   {%- endfor %}\\n   {% endif %}\\n   {% endblock %}\\n   {% if attributes %}\\n   .. rubric:: {{ _('Attribute details') }}\\n   {% for item in attributes %}\\n   .. autoattribute:: {{ name }}.{{ item }}\\n   {% endfor %}\\n   {% endif %}\\n   {% if methods %}\\n   .. rubric:: {{ _('Method details') }}\\n   {% for item in methods %}\\n   .. automethod:: {{ name }}.{{ item }}\\n   {% endfor %}\\n   {% endif %}\",\n",
       " \"import mne\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nfrom matplotlib.widgets import Slider, Button\\n%matplotlib widget\\nbiosemi_montage = mne.channels.make_standard_montage('biosemi64')\\nn_channels = len(biosemi_montage.ch_names)\\nfake_info = mne.create_info(ch_names=biosemi_montage.ch_names, sfreq=250.,\\n\\t\\t\\t\\t\\t\\t\\tch_types='eeg')\\nrng = np.random.RandomState(0)\\ndata = rng.normal(size=(n_channels, 100)) * 1e-6\\nfake_evoked = mne.EvokedArray(data, fake_info)\\nfake_evoked.set_montage(biosemi_montage)\",\n",
       " \"fig, ax = plt.subplots()\\nvoltage = fake_evoked.data\\ntiming = [round(i, ndigits=3) for i in list(np.linspace(0, 1, 100))]\\ninit_time = 0\\nmne.viz.plot_topomap(voltage[:, timing.index(init_time)], fake_evoked.info, axes=ax,\\n\\t\\t\\t\\t\\t show=False)\\nax.set_title('MNE', fontweight='bold')\\naxtime = fig.add_axes([0.25, 0.01, 0.65, 0.04])\\ntime_slider = Slider(\\n\\tax=axtime,\\n\\tlabel='Time [ms]',\\n\\tvalmin=0,\\tvalmax=1, valstep=100,\\n\\tvalinit=init_time,\\n)\\ndef update(val):\\n\\tinit_time = round(time_slider.val, ndigits=3)\\n\\tmne.viz.plot_topomap(voltage[:, timing.index(init_time)], fake_evoked.info, axes=ax,\\n\\t\\t\\t\\t\\t show=False)\\n\\tfig.canvas.draw_idle()\\ntime_slider.on_changed(update)\\nplt.show()\",\n",
       " 'CHECK_XML()',\n",
       " 'lxml.html.fromstring',\n",
       " \"import pygame\\npygame.init()\\ngui_font = pygame.font.Font(None, 30)\\nscreen = pygame.display.set_mode([1000, 600])\\nclass InputBoxes:\\n\\tdef __init__(self, pos, width, height, text=''):\\n\\t\\tself.rect = pygame.Rect(pos, (width, height))\\n\\t\\tself.rect_colour = '\\n\\t\\tself.text = text\\n\\t\\tself.text_colour = '\\n\\t\\tself.text_look = gui_font.render(text, True, self.text_colour)\\n\\t\\tself.active = False\\n\\tdef draw(self, screen):\\n\\t\\tpygame.draw.rect(screen, self.rect_colour, self.rect)\\n\\t\\tscreen.blit(self.text_look, (0, 0))\\n\\tdef handle_event(self, event):\\n\\t\\tif event.type == pygame.MOUSEBUTTONDOWN:\\n\\t\\t\\tif self.rect.collidepoint(event.pos):\\n\\t\\t\\t\\tself.rect_colour = '\\n\\t\\t\\telse:\\n\\t\\t\\t\\tself.rect_colour = '\\n\\t\\tfor event in pygame.event.get():\\n\\t\\t\\tif event.type == pygame.KEYDOWN:\\n\\t\\t\\t\\tif self.active:\\n\\t\\t\\t\\t\\tif event.key == pygame.K_RETURN:\\n\\t\\t\\t\\t\\t\\tself.text = ''\\n\\t\\t\\t\\t\\t\\tprint(self.text)\\n\\t\\t\\t\\t\\telif event.key == pygame.K_BACKSPACE:\\n\\t\\t\\t\\t\\t\\tself.text = self.text[:-1]\\n\\t\\t\\t\\t\\telse:\\n\\t\\t\\t\\t\\t\\tself.text += event.unicode\\n\\t\\t\\t\\t\\tself.text_look = gui_font.render(self.text, True, self.text_colour)\\n\\tdef update(self):\\n\\t\\twidth = max(200, self.text_look.get_width() + 10)\\n\\t\\tself.rect.w = width\\nclock = pygame.time.Clock()\\ntf_name = InputBoxes((40, 73), 400, 30)\\ntf_gameRoomName = InputBoxes((40, 113), 400, 30)\\ninput_boxes = [tf_name, tf_gameRoomName]\\nhost = pygame.image.load(&quot;Host.png&quot;)\\ndone = False\\nwhile not done:\\n\\tfor event in pygame.event.get():\\n\\t\\tscreen.blit(host, (0, 0))\\n\\t\\tif event.type == pygame.QUIT:\\n\\t\\t\\tdone = True\\n\\t\\tfor box in input_boxes:\\n\\t\\t\\tbox.handle_event(event)\\n\\t\\t\\tbox.draw(screen)\\n\\t\\t\\tbox.update()\\n\\tpygame.display.flip()\\n\\tclock.tick(30)\",\n",
       " \"MYPORT = 8123\\nMYGROUP_4 = '225.0.0.250'\\nMYGROUP_6 = 'ff15:7079:7468:6f6e:6465:6d6f:6d63:6173'\\nMYTTL = 1 \\nimport time\\nimport struct\\nimport socket\\nimport sys\\ndef main():\\n\\tgroup = MYGROUP_6 if &quot;-6&quot; in sys.argv[1:] else MYGROUP_4\\n\\tif &quot;-s&quot; in sys.argv[1:]:\\n\\t\\tsender(group)\\n\\telse:\\n\\t\\treceiver(group)\\ndef sender(group):\\n\\taddrinfo = socket.getaddrinfo(group, None)[0]\\n\\ts = socket.socket(addrinfo[0], socket.SOCK_DGRAM)\\n\\tttl_bin = struct.pack('@i', MYTTL)\\n\\tif addrinfo[0] == socket.AF_INET: \\n\\t\\ts.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, ttl_bin)\\n\\telse:\\n\\t\\ts.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_MULTICAST_HOPS, ttl_bin)\\n\\twhile True:\\n\\t\\tdata = repr(time.time())\\n\\t\\ts.sendto((data + '\\\\0').encode(), (addrinfo[4][0], MYPORT))\\n\\t\\ttime.sleep(1)\\ndef receiver(group):\\n\\taddrinfo = socket.getaddrinfo(group, None)[0]\\n\\ts = socket.socket(addrinfo[0], socket.SOCK_DGRAM)\\n\\ts.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\\n\\ts.bind(('', MYPORT))\\n\\tgroup_bin = socket.inet_pton(addrinfo[0], addrinfo[4][0])\\n\\tif addrinfo[0] == socket.AF_INET: \\n\\t\\tmreq = group_bin + struct.pack('=I', socket.INADDR_ANY)\\n\\t\\ts.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)\\n\\telse:\\n\\t\\tmreq = group_bin + struct.pack('@I', 0)\\n\\t\\ts.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_JOIN_GROUP, mreq)\\n\\twhile True:\\n\\t\\tdata, sender = s.recvfrom(1500)\\n\\t\\twhile data[-1:] == '\\\\0': data = data[:-1] \\n\\t\\tprint (str(sender) + '  ' + repr(data))\\nif __name__ == '__main__':\\n\\tmain()\",\n",
       " 'python3 test.py -6',\n",
       " \"Traceback (most recent call last):\\n  File &quot;test.py&quot;, line 80, in &lt;module&gt;\\n\\tmain()\\n  File &quot;test.py&quot;, line 28, in main\\n\\treceiver(group)\\n  File &quot;test.py&quot;, line 70, in receiver\\n\\ts.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_JOIN_GROUP, mreq)\\nOSError: [Errno 49] Can't assign requested address\",\n",
       " 'ff02::abcd:98',\n",
       " 'Darwin Kernel Version 21.6.0',\n",
       " 'import os\\nimport numpy as np\\nimport tensorflow as tf\\nimport cupy as cp\\ndef cp2dl(cp_array):\\n\\treturn cp_array.toDlpack()\\ndef tf2dl(tf_tensor):\\n\\treturn tf.experimental.dlpack.to_dlpack(tf_tensor)\\ndef cp2tf(cp_array):\\n\\treturn tf.experimental.dlpack.from_dlpack(cp2dl(cp_array))\\ndef tf2cp(tf_tensor):\\n\\treturn cp.fromDlpack(tf2dl(tf_tensor))\\ndef preprocess(tf_tensor):\\n\\ttensor_2_cupy = tf2cp(tf_tensor)\\n\\ttensor_2_cupy = cp.divide(1000)\\n\\treturn cp2tf(tensor_2_cupy)\\nX = np.random.random_sample((100, 128, 128, 128))\\nY = np.random.random_sample((100, 128, 128, 128))\\ndataset = tf.data.Dataset.from_tensor_slices((X, Y))\\ndataset.map(preprocess)',\n",
       " 'InvalidArgumentError: The argument to `to_dlpack` must be a TF tensor, not Python object',\n",
       " \"from openpyxl import load_workbook\\nwb1 = load_workbook('C:/Users/user/Desktop/3.xlsx',data_only = True)\\nws1 = wb1['a']\\nwb2 = load_workbook('C:/Users/user/Desktop/4.xlsx')\\nws2 = wb2['d']\\nfor rows in ws1.iter_rows(min_col=5, max_col=7, min_row=109, max_row=198):\\n\\tfor cell in rows:\\n\\t\\tif cell.value is not None:\\n\\t\\t\\tprint(cell.value, end=&quot; &quot;)\\n\\t\\telse:\\n\\t\\t\\tcontinue\\n\\tprint()\\nwb2.save('C:/Users/user/Desktop/4.xlsx')\",\n",
       " '(min_col=5, max_col=7, min_row=109, max_row=198)',\n",
       " '/stop ban',\n",
       " '/start mute',\n",
       " '@slash_command()',\n",
       " '@slash_command(guild_ids=[MY_SERVER_ID])',\n",
       " 'import cv2\\nimport numpy as np\\nshape = np.shape(img)\\npixels = np.array(img)\\ncolumn_means = np.mean(pixels, axis=0) //can change axis = 1 for row\\ncolumn_max = np.max(pixels, axis=0) //can change axis = 1 for row\\ncolumn_min = np.min(pixels, axis=0) //can change axis = 1 for row\\ncolumn_subtract = column_max - column_min //can change axis = 1 for row\\nprint(shape)\\nprint(column_means)\\nprint(column_max)\\nprint(column_min)\\nprint(column_subtract)',\n",
       " 'root = Tk()\\nroot_2 = Tk()\\nroot.wm_iconphoto(\\nroot_2.wm_iconphoto(',\n",
       " \"Traceback (most recent call last):\\n  File &quot;C:\\\\Users\\\\lenovo\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\tkinter\\\\__init__.py&quot;, line 1948, in __call__\\n\\treturn self.func(*args)\\n\\t\\t   ^^^^^^^^^^^^^^^^\\n  File &quot;c:\\\\Users\\\\lenovo\\\\Desktop\\\\clauth.py&quot;, line 41, in a91\\n\\tb02.wm_iconphoto(False,b52)\\n  File &quot;C:\\\\Users\\\\lenovo\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\tkinter\\\\__init__.py&quot;, line 2183, in wm_iconphoto\\n\\tself.tk.call('wm', 'iconphoto', self._w, *args)\\n_tkinter.TclError: can't use &quot;pyimage1&quot; as iconphoto: not a photo image\",\n",
       " 'player_first_name',\n",
       " 'player_last_name',\n",
       " \"app=Flask(__name)\\n@app.route('/v1/config', methods=['POST'])\\ndef post_income():\\n\\tcontent_type=request.headers.get('Content-Type')\\n\\ttry:\\n\\t\\tif (content_type=='application/json'):\\n\\t\\t\\tjson_in=request.get_json()\\n\\t\\t\\tvalue =' text variable from process'\\n\\t\\t\\tprint(value)\\n\\t\\t\\treturn value\",\n",
       " '&lt;html&gt;\\n&lt;head&gt;\\n\\xa0\\xa0\\xa0 &lt;title&gt;504\\xa0Gateway\\xa0Time-out&lt;/title&gt;\\n&lt;/head&gt;\\n&lt;body&gt;\\n\\xa0\\xa0\\xa0 &lt;center&gt;\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 &lt;h1&gt;504\\xa0Gateway\\xa0Time-out&lt;/h1&gt;\\n\\xa0\\xa0\\xa0 &lt;/center&gt;\\n&lt;/body&gt;\\n&lt;/html&gt;',\n",
       " '\\t\\t &lt;h2&gt;{{ _(&quot;Hello World&quot;) }}&lt;/h2&gt;\\n\\t\\t &lt;input type=&quot;submit&quot; name=&quot;h&quot;  value={{ _(&quot;Hello World&quot;) }}&gt;',\n",
       " '&lt;input type=&quot;submit&quot; name=&quot;h&quot; value=&quot;Hello&quot; world=&quot;&quot;&gt;',\n",
       " \"AttributeError\\t\\t\\t\\t\\t\\t\\tTraceback (most recent call last)\\n~\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_1944\\\\3978847060.py in &lt;module&gt;\\n\\t 11 soup2 = BeautifulSoup(soup1.prettify(), &quot;html.parser&quot;)\\n\\t 12\\n---&gt; 13 title = soup2.find(id='title').get_text()\\n\\t 14\\n\\t 15 print(title)\\nAttributeError: 'NoneType' object has no attribute 'get_text'\",\n",
       " 'from geopy.geocoders import Nominatim\\ngeolocator = Nominatim(user_agent=&quot;ryan_data&quot;)\\nlocation = geolocator.geocode(&quot;175 5th Avenue NYC&quot;)\\nprint(location.address)',\n",
       " \"import requests\\nfile = {'file': open('test.png','rb')}\\nrequest1 = requests.post(\\nurl=&quot;https://pasteboard.co/upload&quot;, files=file)\\nprint(request1.content)\",\n",
       " \"LonField = Annotated[\\n\\tUnion[float, float],\\n\\tField(\\n\\t\\ttitle='Coordinate longitude',\\n\\t\\tgt=-180,\\n\\t\\tlt=180,\\n\\t)\\n]\\nLatField = Annotated[\\n\\tUnion[float, float],\\n\\tField(\\n\\t\\ttitle='Coordinate latitude',\\n\\t\\tgt=-90,\\n\\t\\tlt=90,\\n\\t),\\n]\\nclass CustomCoordinates(NamedTuple):\\n\\tlat: LatField\\n\\tlon: LonField\\nclass PolygonGeo(CamelModel):\\n\\ttype: Optional[str] = Field(None, description='Type of GeoJSon geometry', example='Polygon')\\n\\tcoordinates: Optional[List[List['CustomCoordinates']]] = Field(\\n\\t\\tNone, description='Coordinates of GeoJSon geometry', example='[[[-73.7786925003853,40.63992777725],...]]]')\",\n",
       " \"LonField = Annotated[\\n\\tUnion[float, float],\\n\\tField(\\n\\t\\ttitle='Coordinate longitude',\\n\\t\\tdecimal_places=6,\\n\\t\\tgt=-180,\\n\\t\\tlt=180,\\n\\t)\\n]\",\n",
       " '  File &quot;pydantic\\\\main.py&quot;, line 198, in pydantic.main.ModelMetaclass.__new__\\n  File &quot;pydantic\\\\fields.py&quot;, line 506, in pydantic.fields.ModelField.infer\\n  File &quot;pydantic\\\\fields.py&quot;, line 436, in pydantic.fields.ModelField.__init__\\n  File &quot;pydantic\\\\fields.py&quot;, line 552, in pydantic.fields.ModelField.prepare\\n  File &quot;pydantic\\\\fields.py&quot;, line 661, in pydantic.fields.ModelField._type_analysis\\n  File &quot;pydantic\\\\fields.py&quot;, line 758, in pydantic.fields.ModelField._type_analysis\\n  File &quot;pydantic\\\\fields.py&quot;, line 808, in pydantic.fields.ModelField._create_sub_type\\n  File &quot;pydantic\\\\fields.py&quot;, line 436, in pydantic.fields.ModelField.__init__\\n  File &quot;pydantic\\\\fields.py&quot;, line 552, in pydantic.fields.ModelField.prepare\\n  File &quot;pydantic\\\\fields.py&quot;, line 758, in pydantic.fields.ModelField._type_analysis\\n  File &quot;pydantic\\\\fields.py&quot;, line 808, in pydantic.fields.ModelField._create_sub_type\\n  File &quot;pydantic\\\\fields.py&quot;, line 436, in pydantic.fields.ModelField.__init__\\n  File &quot;pydantic\\\\fields.py&quot;, line 557, in pydantic.fields.ModelField.prepare\\n  File &quot;pydantic\\\\fields.py&quot;, line 831, in pydantic.fields.ModelField.populate_validators\\n  File &quot;pydantic\\\\validators.py&quot;, line 735, in find_validators\\n  File &quot;pydantic\\\\validators.py&quot;, line 599, in pydantic.validators.make_namedtuple_validator\\n  File &quot;pydantic\\\\annotated_types.py&quot;, line 72, in pydantic.annotated_types.create_model_from_namedtuple\\n  File &quot;pydantic\\\\main.py&quot;, line 1026, in pydantic.main.create_model\\n  File &quot;pydantic\\\\main.py&quot;, line 198, in pydantic.main.ModelMetaclass.__new__\\n  File &quot;pydantic\\\\fields.py&quot;, line 504, in pydantic.fields.ModelField.infer\\n  File &quot;pydantic\\\\schema.py&quot;, line 1011, in pydantic.schema.get_annotation_from_field_info\\nValueError: On field &quot;lon&quot; the following field constraints are set but not enforced: decimal_places.\\nFor more details see https://pydantic-docs.helpmanual.io/usage/schema/',\n",
       " \"class CustomCoordinates(NamedTuple):\\n\\tlat: LatField\\n\\tlon: LonField\\n\\t@validator('lat')\\n\\tdef coordinates_roundOff(cls,v):\\n\\t\\treturn round(v, 6)\",\n",
       " 'scale = tk.Scale(master=self.root\\n\\t\\t\\t\\t , orient=tk.HORIZONTAL, from_=self.imgIndex + 1, to=int(len(self.img_lst)), resolution=25,\\n\\t\\t\\t\\t length=250, width =25,\\n\\t\\t\\t\\t showvalue=False, command=self.next_25)\\nscale.place(x=550,y=650, anchor=tk.CENTER)',\n",
       " 'df1:\\n\\tAge\\n0   2.0\\n1   NaN\\n2  20.0\\ndf2:\\n\\tAge\\n0  10.0\\n1  15.0\\n2   NaN',\n",
       " 'df1:\\n\\tAge\\n0   2.0\\n1   15.0\\n2  20.0',\n",
       " 'test-python.yml',\n",
       " 'env',\n",
       " 'env:\\n  SECRET_KEY: test\\n  DEBUG: False\\n...',\n",
       " 'env',\n",
       " 'env',\n",
       " \"import pandas as pd\\nimport numpy as np\\ndef calculate_change(df):\\n\\tdf['absolute_change'] = df.groupby(['place', 'year'])['amount'].diff()\\n\\tdf['relative_change'] = df.groupby(['place', 'year'])['amount'].pct_change()\\n\\treturn df\\ndf = pd.DataFrame({'place': ['A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B'],\\n\\t\\t\\t\\t\\t'year': [2010, 2011, 2012, 2013, 2014, 2010, 2011, 2012, 2013, 2014],\\n\\t\\t\\t\\t\\t'amount': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})\\ncalculate_change(df)\",\n",
       " \"import asyncio\\nclass RemindCommand(commands.Cog):\\n  def __init__(self, client):\\n\\tself.client = client\\n  @commands.command()\\n  async def remind(self, ctx, time, *, task):\\n\\tdef convert(time):\\n\\t  pos = ['s', 'm', 'h', 'd']\\n\\t  time_dict = {&quot;s&quot;: 1, &quot;m&quot;: 60, &quot;h&quot;: 3600, &quot;d&quot;: 3600 * 24}\\n\\t  unit = time[-1]\\n\\t  if unit not in pos:\\n\\t\\treturn -1\\n\\t  try:\\n\\t\\tval = int(time[:-1])\\n\\t  except:\\n\\t\\treturn -2\\n\\t\\treturn val * time_dict[unit]\\n\\tconverted_time = convert(time)\\n\\tif converted_time == -1:\\n\\t  await ctx.send(&quot;you didnt imput the time correctly.&quot;)\\n\\t  return\\n\\tif converted_time == -2:\\n\\t  await ctx.send(&quot;The number must be an integer&quot;)\\n\\t  return\\n\\tawait ctx.send(f&quot;Okay, i will remind you to **{task}** at **{time}**.&quot;)\\n\\tawait asyncio.sleep(converted_time)\\n\\tawait ctx.send(\\n\\t  f&quot;{ctx.author.mention} your reminder for **{task}** has finished!&quot;)\\ndef setup(client):\\n  client.add_cog(RemindCommand(client))\\nbot.run('token')\",\n",
       " 'def search_for_name(name, data):\\n\\tprint(name)\\n\\tdogs_with_name = data[data[&quot;HundenameText&quot;].str.contains(name)]\\n\\treturn dogs_with_name[[&quot;HundenameText&quot;, &quot;GebDatHundJahr&quot;, &quot;SexHundLang&quot;]]',\n",
       " 'Arina Luna',\n",
       " 'Luna',\n",
       " 'import logging\\ndef function_to_test():\\n\\tmessage = &quot;log me&quot;\\n\\tlogger = logging.getLogger(&quot;my-logger&quot;)\\n\\tlogger.setLevel(logging.INFO)\\n\\tlogger.propagate = True\\n\\tlogger.info(message)\\nclass Test():\\n\\tdef test_function(self, caplog):\\n\\t\\twith caplog.at_level(logging.INFO, logger=&quot;my-logger&quot;):\\n\\t\\t\\tfunction_to_test()\\n\\t\\tassert caplog.text != &quot;&quot;',\n",
       " \"class NotificationConsumer(AsyncJsonWebsocketConsumer):\\n\\t@database_sync_to_async\\n\\tdef get_notifications(self, user):\\n\\t\\tnew_messages = NotificationSerializer(Notification.objects.filter(content=1, users_notified__in=[user]), many=True)\\n\\t\\tnotifs = {\\n\\t\\t\\t&quot;new_messages&quot;: new_messages\\n\\t\\t}\\n\\t\\treturn notifs\\n\\tasync def connect(self):\\n\\t\\tuser = self.scope[&quot;user&quot;]\\n\\t\\tif user:\\n\\t\\t\\tself.channel_name = user.username\\n\\t\\t\\tself.room_group_name = 'notification_%s' % self.channel_name\\n\\t\\t\\tnotification = await self.get_notifications(self.scope[&quot;user&quot;])\\n\\t\\t\\tprint(&quot;Notification&quot;, notification)\\n\\t\\t\\tawait self.channel_layer.group_add(\\n\\t\\t\\t\\tself.room_group_name,\\n\\t\\t\\t\\tself.channel_name\\n\\t\\t\\t)\\n\\t\\t\\tawait self.accept()\\n\\t\\tawait self.disconnect(401)\\n\\tasync def disconnect(self, close_code):\\n\\t\\tawait self.channel_layer.group_discard(\\n\\t\\t\\tself.room_group_name,\\n\\t\\t\\tself.channel_name\\n\\t\\t)\\n\\tasync def notify(self, event):\\n\\t\\tawait self.send_json(event[&quot;content&quot;])\",\n",
       " 'self.get_notifications',\n",
       " '&lt;coroutine object SyncToAsync.__call__ at ...&gt;',\n",
       " 'Vehicle Prod\\tOverall_stat   EU\\tEU_variant\\t status  partnumber  Error\\nA223\\tW223\\tNOT_OK\\t\\tJLB21  JLB21_variant  NOT_OK  A23321\\t  software not found\\nC243\\tE453\\tNOT_OK\\t\\tJGG12  JGG12_variant  NOT_OK  A23322\\t  software not found\\nA223\\tW223\\tNOT_OK\\t\\tJBL25  JBL25_variant\\t  OK  A23323\\t  hardware not found\\nB321\\tI992\\tNOT_OK\\t\\tL993   L993_variant   OK\\t  A23324\\t  hardware not found\\n\\t\\tR365\\tNOT_OK\\t\\tL223   L223_variant   NOT_OK  A23325\\t  software not found\\n\\t\\tR543\\tOK\\t\\t\\tL342   L342_variant   OK\\t  A23326\\t  hardware not found',\n",
       " \"url = &quot;https://jira-url/jira/rest/api/2/issue&quot;\\n\\theaders = {\\n\\t\\t&quot;Accept&quot;: &quot;application/json&quot;,\\n\\t\\t&quot;Content-Type&quot;: &quot;application/json&quot;\\n\\t}\\n\\tpayload = json.dumps(\\n\\t\\t{\\n\\t\\t\\t&quot;fields&quot;: {\\n\\t\\t\\t\\t&quot;project&quot;: {\\n\\t\\t\\t\\t\\t&quot;key&quot;: 'project_name'\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t&quot;summary&quot;: 'summary',\\n\\t\\t\\t\\t&quot;description&quot;: 'description',\\n\\t\\t\\t\\t&quot;issuetype&quot;: {\\n\\t\\t\\t\\t\\t&quot;name&quot;: &quot;Problem&quot;\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t&quot;priority&quot;: {\\n\\t\\t\\t\\t\\t&quot;name&quot;: &quot;Major&quot;\\n\\t\\t\\t\\t}\\n\\t\\t\\t}\\n\\t\\t}\\n\\t)\\n\\tresponse = requests.post(url, headers=headers, data=payload, auth=(&quot;username&quot;, &quot;password&quot;), cert=('certificates'))\",\n",
       " \"import asyncio\\nimport nest_asyncio\\nfrom pyppeteer import launch\\nimport time\\ndef get_KW(KW1):\\n\\tfor i in KW1:\\n\\tnest_asyncio.apply()\\n\\tasync def scrape_data(i, browser):\\n\\t\\ttry:\\n\\t\\t\\tcontext = await browser.createIncognitoBrowserContext()\\n\\t\\t\\tpage = await context.newPage()\\n\\t\\t\\turl = 'https://www.helium10.com/tools/free/amazon-keyword-tool/'\\n\\t\\t\\tawait page.goto(url)\\n\\t\\t\\tawait page.type('input[placeholder=&quot;Enter keyword&quot;]', i)\\n\\t\\t\\tflag = await page.querySelector('div.selected-flag[data-value=&quot;amazon.com&quot;]')\\n\\t\\t\\tif flag:\\n\\t\\t\\t\\tawait page.evaluate('(flag) =&gt; { flag.setAttribute(&quot;data-value&quot;, &quot;amazon.in&quot;); }', flag)\\n\\t\\t\\tawait page.evaluate('() =&gt; { document.querySelector(&quot;.btn.btn-primary.btn-block&quot;).click(); }')\\n\\t\\t\\tawait page.waitForSelector('div[class=&quot;sc-jaBegh dUfEDl&quot;]', {'timeout': 10000})  \\n\\t\\t\\tproductHandles = await page.querySelectorAll('div[class=&quot;sc-dVSYCO sc-jEWLvH hPbcsG fSVlOB&quot;]')\\n\\t\\t\\telements = await asyncio.gather(*[\\n\\t\\t\\t\\tpage.evaluate('(el) =&gt; el.querySelector(&quot;.sc-fpAkvV.sc-lmOJGc.geUMvU.bktErp .sc-pRPz.kwdpAU&quot;).textContent', el)\\n\\t\\t\\t\\tfor el in productHandles\\n\\t\\t\\t])\\n\\t\\t\\tsearch_volumes = await asyncio.gather(*[\\n\\t\\t\\t\\tpage.evaluate('(el) =&gt; el.querySelector(&quot;div:nth-child(7) &gt; div:nth-child(3) &gt; div &gt; div&quot;).textContent', el)\\n\\t\\t\\t\\tfor el in productHandles\\n\\t\\t\\t])\\n\\t\\t\\titems = [{\\n\\t\\t\\t\\t&quot;keyword&quot;: i,\\n\\t\\t\\t\\t&quot;element&quot;: element,\\n\\t\\t\\t\\t&quot;search_volume&quot;: volume\\n\\t\\t\\t} for element, volume in zip(elements, search_volumes)]\\n\\t\\t\\tprint(items)\\n\\t\\t\\treturn items\\n\\t\\texcept Exception as e:\\n\\t\\t\\tprint('An error occurred:', str(e))\\n\\t\\tfinally:\\n\\t\\t\\tawait page.close()\\n\\t\\t\\tawait context.close()\\n\\tasync def main():\\n\\t\\tbrowser = await launch(\\n\\t\\t\\theadless=False,  \\n\\t\\t\\tdefaultViewport=None,\\n\\t\\t\\tuserDataDir='./temp'\\n\\t\\t)\\n\\t\\tstart_time = time.time()  \\n\\t\\ttasks = []\\n\\t\\tfor keyword in KW1:\\n\\t\\t\\ttask = asyncio.ensure_future(scrape_data(keyword, browser))\\n\\t\\t\\ttasks.append(task)\\n\\t\\tawait asyncio.gather(*tasks)\\n\\t\\tawait browser.close()\\n\\t\\tend_time = time.time()  \\n\\t\\ttotal_time = end_time - start_time\\n\\t\\tprint(f'Total Execution Time: {total_time} seconds')\\n\\tif __name__ == '__main__':\\n\\t\\tasyncio.run(main())\",\n",
       " 'from Helium10 import *\\nKW1=[&quot;vaccum cleaner&quot;, &quot;Kurti for women&quot;]\\nitems=get_KW(KW1)\\nprint(items)',\n",
       " 'python3_9_7 % ls\\nbin\\t include\\t lib\\t pyvenv.cfg  share',\n",
       " 'Traceback (most recent call last):\\n  File &quot;/Users/emanuelatiberi/Desktop/python3_9_7/bin/ipython&quot;, line 5, in &lt;module&gt;\\n\\tfrom IPython import start_ipython\\n  File &quot;/Users/emanuelatiberi/Desktop/python3_9_7/lib/python3.9/site-packages/IPython/__init__.py&quot;, line 54, in &lt;module&gt;\\n\\tfrom .terminal.embed import embed\\n  File &quot;/Users/emanuelatiberi/Desktop/python3_9_7/lib/python3.9/site-packages/IPython/terminal/embed.py&quot;, line 15, in &lt;module&gt;\\n\\tfrom IPython.core.interactiveshell import DummyMod, InteractiveShell\\n  File &quot;/Users/emanuelatiberi/Desktop/python3_9_7/lib/python3.9/site-packages/IPython/core/interactiveshell.py&quot;, line 73, in &lt;module&gt;\\n\\tfrom IPython.core.history import HistoryManager\\n  File &quot;/Users/emanuelatiberi/Desktop/python3_9_7/lib/python3.9/site-packages/IPython/core/history.py&quot;, line 11, in &lt;module&gt;\\n\\timport sqlite3\\n  File &quot;/Users/emanuelatiberi/opt/anaconda3/lib/python3.9/sqlite3/__init__.py&quot;, line 57, in &lt;module&gt;\\n\\tfrom sqlite3.dbapi2 import *\\n  File &quot;/Users/emanuelatiberi/opt/anaconda3/lib/python3.9/sqlite3/dbapi2.py&quot;, line 27, in &lt;module&gt;\\n\\tfrom _sqlite3 import *\\nImportError: dlopen(/Users/emanuelatiberi/opt/anaconda3/lib/python3.9/lib-dynload/_sqlite3.cpython-39-darwin.so, 2): Symbol not found: _sqlite3_enable_load_extension\\n  Referenced from: /Users/emanuelatiberi/opt/anaconda3/lib/python3.9/lib-dynload/_sqlite3.cpython-39-darwin.so\\n  Expected in: /usr/lib/libsqlite3.dylib\\n in /Users/emanuelatiberi/opt/anaconda3/lib/python3.9/lib-dynload/_sqlite3.cpython-39-darwin.so\\n(base) (python3_9_7) emanuelatiberi@192 python3_9_7 % export DYLD_LIBRARY_PATH=/usr/lib/libsqlite3.dylib\\n(base) (python3_9_7) emanuelatiberi@192 python3_9_7 % ipython\\ndyld: warning, DYLD_ setting caused circular dependency in /usr/lib/libsqlite3.dylib\\ndyld: Symbol not found: __DefaultRuneLocale\\n  Referenced from: /Users/emanuelatiberi/Desktop/python3_9_7/bin/python3\\n  Expected in: /usr/lib/libsqlite3.dylib\\n in /Users/emanuelatiberi/Desktop/python3_9_7/bin/python3\\nzsh: abort\\t  ipython',\n",
       " 'from django.conf import settings\\nfrom ms_identity_web import IdentityWebPython\\nidentity_web = IdentityWebPython(request)\\nprint(identity_web)\\nclaims = identity_web._id_token_claims',\n",
       " 'claims = request.identity_context_data._id_token_claims',\n",
       " 'claims = identity_web._id_token_claims',\n",
       " \"'WSGIRequest' object has no attribute 'identity_context_data'\",\n",
       " \"data = pd.read_excel('/content/training set only distance.xlsx')\\ntarget = pd.read_excel('/content/testing set only distance.xlsx')\\nlabel_enc = preprocessing.LabelEncoder()\\nencoded_x = label_enc.fit_transform(data['TotalDistance'])\\nencoded_y = label_enc.fit_transform(target['TotalDistance'])\",\n",
       " \"data['encoded'] = encoded_x\\ntarget['encoded'] = encoded_y\\nX = data['label', 'encoded']\\ny = target['label', 'encoded']\",\n",
       " \"---------------------------------------------------------------------------\\nKeyError\\t\\t\\t\\t\\t\\t\\t\\t  Traceback (most recent call last)\\n/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance)\\n   3801\\t\\t\\t try:\\n-&gt; 3802\\t\\t\\t\\t return self._engine.get_loc(casted_key)\\n   3803\\t\\t\\t except KeyError as err:\\n4 frames\\npandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()\\npandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()\\nKeyError: ('label', 'encoded')\\nThe above exception was the direct cause of the following exception:\\nKeyError\\t\\t\\t\\t\\t\\t\\t\\t  Traceback (most recent call last)\\n/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance)\\n   3802\\t\\t\\t\\t return self._engine.get_loc(casted_key)\\n   3803\\t\\t\\t except KeyError as err:\\n-&gt; 3804\\t\\t\\t\\t raise KeyError(key) from err\\n   3805\\t\\t\\t except TypeError:\\n   3806\\t\\t\\t\\t \\nKeyError: ('label', 'encoded')\",\n",
       " \"Index(['TotalDistance', 'Label', 'encoded'], dtype='object')\\nIndex(['TotalDistance', 'Label', 'encoded'], dtype='object')\",\n",
       " \"X = data[['label', 'encoded']]\\ny = target[['label', 'encoded']]\",\n",
       " '&lt;?xml version=&quot;1.0&quot;?&gt;\\n&lt;AlteryxJavaScriptPlugin&gt;\\n  &lt;EngineSettings EngineDll=&quot;Python&quot; EngineDllEntryPoint=&quot;PDFExtractToolEngine.py&quot; SDKVersion=&quot;10.1&quot; /&gt;\\n  &lt;GuiSettings Html=&quot;PDFExtractToolGUI.html&quot; Icon=&quot;PDFExtractTool.png&quot; Help=&quot;https://your-help-link-here.com&quot; SDKVersion=&quot;10.1&quot;&gt;\\n\\t&lt;InputConnections&gt;\\n\\t  &lt;Connection Name=&quot;Input&quot; AllowMultiple=&quot;False&quot; Optional=&quot;False&quot; Type=&quot;Connection&quot; Label=&quot;PDF Input&quot;/&gt;\\n\\t&lt;/InputConnections&gt;\\n\\t&lt;OutputConnections&gt;\\n\\t  &lt;Connection Name=&quot;Output&quot; AllowMultiple=&quot;False&quot; Optional=&quot;False&quot; Type=&quot;Connection&quot; Label=&quot;Table Output&quot;/&gt;\\n\\t  &lt;Connection Name=&quot;ErrorOutput&quot; AllowMultiple=&quot;False&quot; Optional=&quot;False&quot; Type=&quot;Connection&quot; Label=&quot;Error Output&quot;/&gt;\\n\\t&lt;/OutputConnections&gt;\\n  &lt;/GuiSettings&gt;\\n  &lt;Properties&gt;\\n\\t&lt;MetaInfo&gt;\\n\\t  &lt;Name&gt;PDF to Table&lt;/Name&gt;\\n\\t  &lt;Description&gt;Reads PDFs and extracts tables&lt;/Description&gt;\\n\\t  &lt;CategoryName&gt;Data Parsing&lt;/CategoryName&gt;\\n\\t  &lt;SearchTags&gt;pdf, table, parsing&lt;/SearchTags&gt;\\n\\t  &lt;ToolVersion&gt;&lt;/ToolVersion&gt;\\n\\t  &lt;Author&gt;&lt;/Author&gt;\\n\\t  &lt;Company&gt;&lt;/Company&gt;\\n\\t  &lt;Copyright&gt;&lt;/Copyright&gt;\\n\\t&lt;/MetaInfo&gt;\\n  &lt;/Properties&gt;\\n&lt;/AlteryxJavaScriptPlugin&gt;',\n",
       " \"&lt;!DOCTYPE html&gt;\\n&lt;html&gt;\\n&lt;head&gt;\\n  &lt;meta charset=&quot;utf-8&quot;&gt;\\n  &lt;title&gt;PDF to Table&lt;/title&gt;\\n  &lt;script type=&quot;text/javascript&quot;&gt;\\n\\tdocument.write('&lt;link rel=&quot;import&quot; href=&quot;' + window.Alteryx.LibDir + '2/lib/includes.html&quot;&gt;');\\n  &lt;/script&gt;\\n&lt;/head&gt;\\n&lt;body&gt;\\n  &lt;h1&gt;PDF to Table&lt;/h1&gt;\\n  &lt;form&gt;\\n\\t&lt;fieldset&gt;\\n\\t  &lt;legend&gt;XMSG(&quot;Select Options&quot;)&lt;/legend&gt;\\n\\t  &lt;section&gt;\\n\\t\\t&lt;label&gt;XMSG(&quot;Select a PDF file:&quot;)&lt;/label&gt;\\n\\t\\t&lt;ayx aria-label=&quot;data-source-metainfo-filebrowse&quot; data-ui-props='{type:&quot;FileBrowse&quot;, widgetId:&quot;dataSourceFilePath&quot;, fileTypeFilters: &quot;PDF Data Source|*.pdf|All Files|*.*&quot;, placeholder:&quot;XMSG(&quot;Select .pdf file...&quot;)&quot;}' data-item-props='{dataName: &quot;PdfField&quot;, dataType:&quot;SimpleString&quot;}'&gt;&lt;/ayx&gt;\\n\\t  &lt;/section&gt;\\n\\t&lt;/fieldset&gt;\\n  &lt;/form&gt;\\n  &lt;style&gt;\\n\\tbody {\\n\\t  font-size: 10pt;\\n\\t  font-family: Arial, sans-serif;\\n\\t  margin: 20px;\\n\\t}\\n\\tlegend {\\n\\t  border: none;\\n\\t}\\n\\tfieldset {\\n\\t  border: 2px solid \\n\\t  border-radius: 5px;\\n\\t}\\n\\tsection, label, select, checkbox, input {\\n\\t  padding: 10px 0;\\n\\t}\\n  &lt;/style&gt;\\n&lt;/body&gt;\\n&lt;/html&gt;\",\n",
       " \"import AlteryxPythonSDK as Sdk\\nimport tabula\\nclass AyxPlugin:\\n\\tdef __init__(self, n_tool_id: int, alteryx_engine: object, output_anchor_mgr: object):\\n\\t\\tself.n_tool_id = n_tool_id\\n\\t\\tself.alteryx_engine = alteryx_engine\\n\\t\\tself.output_anchor_mgr = output_anchor_mgr\\n\\t\\tself.input = None\\n\\tdef pi_init(self, str_xml: str):\\n\\t\\tself.input = None\\n\\tdef pi_add_incoming_connection(self, str_type: str, str_name: str) -&gt; object:\\n\\t\\tself.input = self\\n\\t\\treturn self\\n\\tdef pi_add_outgoing_connection(self, str_name: str) -&gt; bool:\\n\\t\\treturn True\\n\\tdef pi_push_all_records(self, n_record_limit: int) -&gt; bool:\\n\\t\\tself.alteryx_engine.output_message(self.n_tool_id, Sdk.EngineMessageType.info, &quot;Processing PDFs...&quot;)\\n\\t\\treturn False\\n\\tdef pi_close(self, b_has_errors: bool):\\n\\t\\tself.alteryx_engine.output_message(self.n_tool_id, Sdk.EngineMessageType.info, &quot;pi_close...&quot;)\\n\\t\\tpass\\n\\tdef ii_init(self, record_info_in: Sdk.RecordInfo) -&gt; bool:\\n\\t\\tself.pdf_field = record_info_in.get_field_by_name('PdfField')\\n\\t\\treturn True\\n\\tdef ii_push_record(self, in_record: Sdk.RecordRef) -&gt; bool:\\n\\t\\tpdf_path = self.pdf_field.get_as_string(in_record)\\n\\t\\tif pdf_path:\\n\\t\\t\\tself.alteryx_engine.output_message(self.n_tool_id, Sdk.EngineMessageType.info, f&quot;Processing PDF: {pdf_path}&quot;)\\n\\t\\t\\ttry:\\n\\t\\t\\t\\ttables = tabula.read_pdf(pdf_path, pages='all')\\n\\t\\t\\t\\tfor table_num, table in enumerate(tables):\\n\\t\\t\\t\\t\\tself.alteryx_engine.output_message(self.n_tool_id, Sdk.EngineMessageType.info, f&quot;Extracted Table {table_num + 1}:&quot;)\\n\\t\\t\\t\\t\\tself.alteryx_engine.output_message(self.n_tool_id, Sdk.EngineMessageType.info, str(table))\\n\\t\\t\\texcept Exception as e:\\n\\t\\t\\t\\tself.alteryx_engine.output_message(self.n_tool_id, Sdk.EngineMessageType.error, f&quot;Error processing PDF: {str(e)}&quot;)\\n\\t\\t\\t\\treturn False\\n\\t\\telse:\\n\\t\\t\\tself.alteryx_engine.output_message(self.n_tool_id, Sdk.EngineMessageType.warning, &quot;No PDF path found in input record.&quot;)\\n\\t\\treturn True\\n\\tdef ii_update_progress(self, d_percent: float):\\n\\t\\tpass\\n\\tdef ii_close(self):\\n\\t\\tpass\",\n",
       " 'async def chat(input_text):\\n\\tcustom_prompt = Prompt(\\n\\t\\t&quot;&quot;&quot; xxx &quot;&quot;&quot;\\n\\t)\\n\\ttry:\\n\\t\\tquery_engine = index.as_query_engine(streaming=True, similarity_top_k=3)\\n\\t\\tchat_engine = CondenseQuestionChatEngine.from_defaults(\\n\\t\\t\\tquery_engine=query_engine,\\n\\t\\t\\tcondense_question_prompt=custom_prompt,\\n\\t\\t\\tverbose=True,\\n\\t\\t)\\n\\t\\tresponse = chat_engine.chat(input_text)\\n\\t\\tresponseStream = response.print_response_stream()\\n\\t\\tasync for token in responseStream:\\n\\t\\t\\tyield token\\n\\texcept Exception as e:\\n\\t\\tprint(f&quot;Error: {e}&quot;)\\napp = FastAPI()\\napp.add_middleware(\\n\\tCORSMiddleware,\\n\\tallow_origins=[\\n\\t\\t&quot;*&quot;\\n\\t],  \\n\\tallow_methods=[&quot;GET&quot;, &quot;POST&quot;],  \\n\\tallow_headers=[&quot;*&quot;],  \\n)\\n@app.get(&quot;/&quot;)\\nasync def root():\\n\\treturn {&quot;message&quot;: &quot;Hello world&quot;}\\n@app.post(&quot;/chat&quot;)\\nasync def chat_model_001(input_text: InputText):\\n\\tasync def generate_response():\\n\\t\\tasync for token in chat(input_text.input_text):\\n\\t\\t\\tyield token\\n\\treturn StreamingResponse(generate_response(), media_type=&quot;text/event-stream&quot;)',\n",
       " \"Error: 'async for' requires an object with __aiter__ method, got NoneType\",\n",
       " 'import pixabay.core\\npx = pixabay.core(&quot;API KEY&quot;)\\nspace = px.query(&quot;space&quot;)\\nprint(&quot;{} hits&quot;.format(len(space)))\\nspace[0].download(&quot;space.jpg&quot;, &quot;largeImage&quot;)',\n",
       " \"import tkinter as tk\\nfrom tkinter import messagebox\\nimport random\\nclass Card:\\n\\tdef __init__(self, rank, suit):\\n\\t\\tself.rank = rank\\n\\t\\tself.suit = suit\\n\\tdef __str__(self):\\n\\t\\treturn f&quot;{self.rank} of {self.suit}&quot;\\n\\tdef value(self):\\n\\t\\tif self.rank.isdigit():\\n\\t\\t\\treturn int(self.rank)\\n\\t\\telif self.rank in ['J', 'Q', 'K']:\\n\\t\\t\\treturn 10\\n\\t\\telif self.rank == 'A':\\n\\t\\t\\treturn 11\\nclass Deck:\\n\\tdef __init__(self, num_decks):\\n\\t\\tself.num_decks = num_decks\\n\\t\\tself.cards = []\\n\\t\\tself.reset()\\n\\tdef reset(self):\\n\\t\\tself.cards = [Card(rank, suit) for suit in ['Hearts', 'Spades', 'Clubs', 'Diamonds']\\n\\t\\t\\t\\t\\t\\tfor rank in ['2','3','4','5','6','7','8','9','10','J','Q','K','A']]\\n\\t\\trandom.shuffle(self.cards)\\n\\tdef draw(self):\\n\\t\\tif len(self.cards) &gt; 0:\\n\\t\\t\\treturn self.cards.pop()\\n\\t\\telse:\\n\\t\\t\\tmessagebox.showinfo(&quot;Empty Deck&quot;)\\nclass Hand:\\n\\tdef __init__(self):\\n\\t\\tself.cards = []\\n\\tdef add_card(self, card):\\n\\t\\tself.cards.append(card)\\n\\tdef calculate_value(self):\\n\\t\\ttotal_value = sum(card.value() for card in self.cards)\\n\\t\\tnum_aces = sum(1 for card in self.cards if card.rank == 'A')\\n\\t\\twhile total_value &gt; 21 and num_aces &gt; 0:\\n\\t\\t\\ttotal_value -= 10\\n\\t\\t\\tnum_aces -= 1\\n\\t\\treturn total_value\\nclass BlackjackGame:\\n\\tdef __init__(self, num_decks):\\n\\t\\tself.deck = Deck(num_decks)\\n\\t\\tself.player_hand = Hand()\\n\\t\\tself.dealer_hand = Hand()\\n\\t\\tself.window = tk.Tk()\\n\\t\\tself.window.title(&quot;BLACKJACK&quot;)\\n\\t\\tself.window.config()\\n\\t\\tself.player_label = tk.Label(self.window, text=&quot;Player's cards:&quot;)\\n\\t\\tself.player_label.grid(row=0, column=0)\\n\\t\\tself.player_cards_label = tk.Label(self.window, text='', font=(&quot;Courier&quot;, 30))\\n\\t\\tself.player_cards_label.grid(row=1, column=0)\\n\\t\\tself.dealer_label = tk.Label(self.window, text=&quot;Dealer's cards:&quot;)\\n\\t\\tself.dealer_label.grid(row=2, column=0)\\n\\t\\tself.dealer_cards_label = tk.Label(self.window, text='', font=(&quot;Courier&quot;, 30))\\n\\t\\tself.dealer_cards_label.grid(row=3, column=0)\\n\\t\\tself.message_label = tk.Label(self.window, text='')\\n\\t\\tself.message_label.grid(row=4, column=0)\\n\\t\\tself.remaining_cards_label = tk.Label(self.window, text='', font=('Courier', 20))\\n\\t\\tself.remaining_cards_label.grid(row=5, column=0)\\n\\t\\tself.sum_value_label = tk.Label(self.window, text='', font=('Courier', 20))\\n\\t\\tself.sum_value_label.grid(row=6, column=0)\\n\\t\\tself.hit_button = tk.Button(self.window, text=&quot;Hit&quot;, command=self.hit)\\n\\t\\tself.hit_button.grid(row=7, column=0, pady=(10, 0), padx=10)  \\n\\t\\tself.deal_button = tk.Button(self.window, text=&quot;Deal&quot;, command=self.new_round)\\n\\t\\tself.deal_button.grid(row=8, column=0, pady=10)  \\n\\t\\tself.stand_button = tk.Button(self.window, text=&quot;Stand&quot;, command=self.stand)\\n\\t\\tself.stand_button.grid(row=9, column=0, padx=10)\\n\\t\\tself.card_images = {\\n\\t\\t'Hearts': {'A': ' ♥A ', '2': ' ♥2 ', '3': ' ♥3 ', '4': ' ♥4 ', '5': ' ♥5 ', '6': ' ♥6 ',\\n\\t\\t\\t   '7': ' ♥7 ', '8': ' ♥8 ', '9': ' ♥9 ', '10': '♥10', 'J': ' ♥J ', 'Q': ' ♥Q ',\\n\\t\\t\\t   'K': ' ♥K '},\\n\\t'Diamonds': {'A': ' ♦A ', '2': ' ♦2 ', '3': ' ♦3 ', '4': ' ♦4 ', '5': ' ♦5 ', '6': ' ♦6 ',\\n\\t\\t\\t\\t '7': ' ♦7 ', '8': ' ♦8 ', '9': ' ♦9 ', '10': '♦10', 'J': ' ♦J ', 'Q': ' ♦Q ',\\n\\t\\t\\t\\t 'K': ' ♦K '},\\n\\t'Clubs': {'A': ' ♣A ', '2': ' ♣2 ', '3': ' ♣3 ', '4': ' ♣4 ', '5': ' ♣5 ', '6': ' ♣6 ',\\n\\t\\t\\t  '7': ' ♣7 ', '8': ' ♣8 ', '9': ' ♣9 ', '10': '♣10', 'J': ' ♣J ', 'Q': ' ♣Q ',\\n\\t\\t\\t  'K': ' ♣K '},\\n\\t'Spades': {'A': ' ♠A ', '2': ' ♠2 ', '3': ' ♠3 ', '4': ' ♠4 ', '5': ' ♠5 ', '6': ' ♠6 ',\\n\\t\\t\\t   '7': ' ♠7 ', '8': ' ♠8 ', '9': ' ♠9 ', '10': '♠10', 'J': ' ♠J ', 'Q': ' ♠Q ',\\n\\t\\t\\t   'K': ' ♠K '}\\n\\t\\t}\\n\\t\\tself.window.title(&quot;BLACKJACK&quot;)\\n\\t\\tself.window.mainloop()\\n\\tdef start(self):\\n\\t\\tself.deck.reset()\\n\\t\\tself.player_hand = Hand()\\n\\t\\tself.dealer_hand = Hand()\\n\\t\\tself.deal_cards()\\n\\t\\tself.update_ui()\\n\\t\\tself.window.mainloop()\\n\\tdef deal_cards(self):\\n\\t\\tself.player_hand.add_card(self.deck.draw())\\n\\t\\tself.dealer_hand.add_card(self.deck.draw())\\n\\t\\tself.player_hand.add_card(self.deck.draw())\\n\\t\\tself.dealer_hand.add_card(self.deck.draw())\\n\\tdef hit(self):\\n\\t\\tself.player_hand.add_card(self.deck.draw())\\n\\t\\tself.update_ui()\\n\\t\\tif self.player_hand.calculate_value() &gt; 21:\\n\\t\\t\\tself.message_label.config(text=&quot;Player busted!&quot;)\\n\\t\\t\\tself.hit_button.config(state=tk.DISABLED)\\n\\t\\t\\tself.stand_button.config(state=tk.DISABLED)\\n\\t\\t\\tself.show_dealer_cards(reveal_card=True)\\n\\t\\telif self.player_hand.calculate_value() == 21:\\n\\t\\t\\tself.message_label.config(text='Blackjack! Player wins.')\\n\\t\\t\\tself.hit_button.config(state=tk.DISABLED)\\n\\t\\t\\tself.stand_button.config(state=tk.DISABLED)\\n\\tdef stand(self):\\n\\t\\tself.update_ui()\\n\\t\\twhile self.dealer_hand.calculate_value() &gt; 17:\\n\\t\\t\\tself.dealer_hand.add_card(self.deck.draw())\\n\\t\\t\\tself.update_ui()\\n\\t\\tself.update_ui()\\n\\t\\tplayer_value = self.player_hand.calculate_value()\\n\\t\\tdealer_value = self.dealer_hand.calculate_value()\\n\\t\\tif dealer_value &gt; 21:\\n\\t\\t\\tself.message_label.config(text='Dealer busts, you win!')\\n\\t\\t\\tself.update_ui()\\n\\t\\telif dealer_value &lt; player_value:\\n\\t\\t\\tself.message_label.config(text='You win!')\\n\\t\\t\\tself.update_ui()\\n\\t\\telif dealer_value &gt; player_value:\\n\\t\\t\\tself.message_label.config(text='You lose.')\\n\\t\\t\\tself.update_ui()\\n\\t\\tself.hit_button.config(state=tk.DISABLED)\\n\\t\\tself.stand_button.config(state=tk.DISABLED)\\n\\t\\tself.update_ui()\\n\\tdef show_dealer_cards(self, reveal_card=False):\\n\\t\\tcards = self.dealer_hand.cards\\n\\t\\tif reveal_card:\\n\\t\\t\\tself.dealer_cards_label.config(text=' '.join(self.card_images[card.suit][card.rank] for card in cards))\\n\\t\\telse:\\n\\t\\t\\tself.dealer_cards_label.config(text=self.card_images[cards[0].suit][cards[0].rank] + ' ?' * (len(cards)-1))\\n\\tdef update_ui(self):\\n\\t\\tplayer_cards = self.player_hand.cards\\n\\t\\tdealer_cards = self.dealer_hand.cards\\n\\t\\tself.player_cards_label.config(text=' '.join(self.card_images[card.suit][card.rank] for card in player_cards))\\n\\t\\tself.dealer_cards_label.config(text=' '.join(self.card_images[card.suit][card.rank] for card in dealer_cards))\\n\\t\\tself.remaining_cards_label.config(text=f&quot;Remaining Cards : {len(self.deck.cards)}&quot;)\\n\\t\\tself.sum_value_label.config(text=f&quot;Value Player Cards: {self.player_hand.calculate_value()} Value Dealer Cards: {self.dealer_hand.calculate_value()}&quot;)\\n\\tdef new_round(self):\\n\\t\\tself.message_label.config(text='')\\n\\t\\tself.hit_button.config(state=tk.NORMAL)\\n\\t\\tself.stand_button.config(state=tk.NORMAL)\\n\\t\\tself.player_cards_label.config(text='')\\n\\t\\tself.dealer_cards_label.config(text='')\\n\\t\\tself.player_hand = Hand()\\n\\t\\tself.dealer_hand = Hand()\\n\\t\\tself.deal_cards()\\n\\t\\tself.update_ui()\\ngame = BlackjackGame(num_decks=6)\\ngame.start()\",\n",
       " \"Exception in Tkinter callback\\nTraceback (most recent call last):\\n  File &quot;C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\\\lib\\\\tkinter\\\\__init__.py&quot;, line 1892, in __call__\\n\\treturn self.func(*args)\\n  File &quot;game.py&quot;, line 147, in stand\\n\\tself.update_ui()\\n  File &quot;game.py&quot;, line 179, in update_ui\\n\\tself.dealer_cards_label.config(text=' '.join(self.card_images[card.suit][card.rank] for card in dealer_cards))\\n  File &quot;game.py&quot;, line 179, in &lt;genexpr&gt;\\n\\tself.dealer_cards_label.config(text=' '.join(self.card_images[card.suit][card.rank] for card in dealer_cards))\\nAttributeError: 'NoneType' object has no attribute 'suit'\\nTraceback (most recent call last):\\n  File &quot;game.py&quot;, line 198, in &lt;module&gt;\\n\\tgame.start()\\n  File &quot;game.py&quot;, line 118, in start\\n\\tself.update_ui()\\n  File &quot;game.py&quot;, line 178, in update_ui\\n\\tself.player_cards_label.config(text=' '.join(self.card_images[card.suit][card.rank] for card in player_cards))\\n  File &quot;C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\\\lib\\\\tkinter\\\\__init__.py&quot;, line 1646, in configure\\n\\treturn self._configure('configure', cnf, kw)\\n  File &quot;C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\\\lib\\\\tkinter\\\\__init__.py&quot;, line 1636, in _configure\\n\\tself.tk.call(_flatten((self._w, cmd)) + self._options(cnf))\\n_tkinter.TclError: invalid command name &quot;.!label2&quot;\\n***Repl Closed***\",\n",
       " 'ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)',\n",
       " 'openssl',\n",
       " 'python',\n",
       " 'pyenv',\n",
       " 'LD_LIBRARY_PATH',\n",
       " '\\texpire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTE)\\n\\tto_encode.update({&quot;exp&quot;: expire})\\n\\tencoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)\\n\\treturn encoded_jwt\\ndef verify_access_token(token: Annotated[str, Depends(oauth2_scheme)], credentials_exception):\\n\\ttry:\\n\\t\\tpayload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])\\n\\t\\tid: Annotated[str, Depends(oauth2_scheme)] = payload.get(&quot;user_id&quot;)\\n\\t\\tif id is None:\\n\\t\\t\\traise credentials_exception\\n\\t\\ttoken_data = schemas.TokenData(id=id)\\n\\texcept JWTError:\\n\\t\\traise credentials_exception\\n\\treturn token_data\\ndef get_current_user(token: Annotated[str, Depends(oauth2_scheme)], db: Session = Depends(database.get_db)):\\n\\tcredentials_exception = HTTPException(status_code=status.HTTP_401_UNAUTHORIZED,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tdetail=f&quot;Could not validate credentials&quot;, headers={&quot;WWW- Authenticate&quot;: &quot;Bearer&quot;})\\n\\ttoken = verify_access_token(token, credentials_exception)\\n\\tuser = db.query(models.User).filter(models.User.id == token.id).first()\\n\\treturn user`',\n",
       " 'import numpy as np\\nfrom scipy.sparse import csr_matrix\\nfrom scipy.sparse.csgraph import connected_components\\nfrom scipy.sparse.csgraph import dijkstra\\nfrom scipy.spatial.distance import euclidean\\nimport networkx as nx\\nimport heapq\\nfrom scipy.sparse.csgraph import connected_components\\nconnectivity_threshold = 0.125\\ntortuosity_threshold = 1\\ndef calculate_tortuosity(permeability_field, porosity_field,\\nthreshold=tortuosity_threshold):\\n\\tn_layers, n_rows, n_columns = permeability_field.shape\\n\\tgraph = nx.DiGraph()\\n\\tfor k in range(n_layers):\\n\\t\\tfor i in range(n_rows):\\n\\t\\t\\tfor j in range(n_columns):\\n\\t\\t\\t\\tpermeability = permeability_field[k, i, j]\\n\\t\\t\\t\\tporosity = porosity_field[k, i, j]\\n\\t\\t\\t\\teffective_permeability = permeability * porosity\\n\\t\\t\\t\\tif effective_permeability &gt; threshold:\\n\\t\\t\\t\\t\\tif i &gt; 0 and permeability_field[k, i - 1, j] *\\n\\t\\t\\t\\t\\tporosity_field[k, i - 1, j] &gt; threshold:\\n\\t\\t\\t\\t\\t\\tgraph.add_edge((k, i, j), (k, i - 1, j))\\n\\t\\t\\t\\t\\tif i &lt; n_rows - 1 and permeability_field[k, i + 1, j] * porosity_field[k, i + 1, j] &gt; threshold:\\n\\t\\t\\t\\t\\t\\tgraph.add_edge((k, i, j), (k, i + 1, j))\\n\\t\\t\\t\\t\\tif j &gt; 0 and permeability_field[k, i, j - 1] * porosity_field[k, i, j - 1] &gt; threshold:\\n\\t\\t\\t\\t\\t\\tgraph.add_edge((k, i, j), (k, i, j - 1))\\n\\t\\t\\t\\t\\tif j &lt; n_columns - 1 and permeability_field[k, i, j + 1] * porosity_field[k, i, j + 1] &gt; threshold:\\n\\t\\t\\t\\t\\t\\tgraph.add_edge((k, i, j), (k, i, j + 1))\\n\\t\\t\\t\\t\\tif k &gt; 0 and permeability_field[k - 1, i, j] * porosity_field[k - 1, i, j] &gt; threshold:\\n\\t\\t\\t\\t\\t\\tgraph.add_edge((k, i, j), (k - 1, i, j))\\n\\t\\t\\t\\t\\tif k &lt; n_layers - 1 and permeability_field[k + 1, i, j] * porosity_field[k + 1, i, j] &gt; threshold:\\n\\t\\t\\t\\t\\t\\tgraph.add_edge((k, i, j), (k + 1, i, j))\\nshortest_path_lengths =\\ndict(nx.all_pairs_shortest_path_length(graph))\\ntortuosity_values = np.zeros_like(permeability_field, dtype=float)\\nfor k in range(n_layers):\\n\\tfor i in range(n_rows):\\n\\t\\tfor j in range(n_columns):\\n\\t\\t\\tif (k, i, j) in shortest_path_lengths:\\n\\t\\t\\t\\tshortest_lengths = shortest_path_lengths[(k, i, j)]\\n\\t\\t\\t\\ttortuosity_values[k, i, j] =\\n\\t\\t\\t\\tnp.max(list(shortest_lengths.values())) /\\n\\t\\t\\t\\tshortest_lengths[(k, i, j)]\\n\\t\\t\\t\\tif shortest_lengths[(k, i, j)] == 0:\\n\\t\\t\\t\\t\\ttortuosity_values[k, i, j] = 0\\nreturn tortuosity_values\\n def calculate_connectivity(porosity,\\n threshold=connectivity_threshold):\\n\\tn_layers, n_rows, n_columns = porosity.shape\\n\\tconnectivity = np.zeros((n_layers, n_rows, n_columns))\\n\\tmask = porosity &gt; threshold\\n\\tmask_2d = mask.reshape(n_layers, -1)\\n\\tcsr_mask = csr_matrix(mask_2d)\\n\\tn_components, labels = connected_components(csr_mask)\\n\\tlabels_3d = labels.reshape(n_layers, n_rows, n_columns)\\n\\tfor k in range(n_layers):\\n\\t\\tfor i in range(n_rows):\\n\\t\\t\\tfor j in range(n_columns):\\n\\t\\t\\t\\tif mask[k, i, j]:\\n\\t\\t\\t\\t\\tconnectivity[k, i, j] = labels_3d[k, i, j] + 1\\n\\treturn connectivity\\ndef main():\\n\\tporosity = np.random.rand(51, 125, 125)\\n\\tpermeability = np.random.rand(51, 125, 125)\\n\\ttortuosity = calculate_tortuosity(permeability, porosity,\\n\\tthreshold=tortuosity_threshold)\\n\\tconnectivity = calculate_connectivity(porosity,\\n\\tthreshold=connectivity_threshold)\\n\\tnp.save(&quot;tortuosity.npy&quot;, tortuosity)\\n\\tnp.save(&quot;connectivity.npy&quot;, connectivity)\\nif __name__ == &quot;__main__&quot;:\\n  main()',\n",
       " \"import pandas\\nimport sqlite3\\nfrom tkinter import ttk\\nimport tkinter as tk\\nfrom tkinter import messagebox\\nimport login\\nfrom PIL import ImageTk, Image\\nimport richiesta_strumentario\\nimport schede_tecniche\\nclass MainPage(tk.Tk):\\n\\tdef __init__(self, *args, **kwargs):\\n\\t\\ttk.Tk.__init__(self, *args, **kwargs)\\n\\t\\tself.wm_title(&quot;Richiesta Strumentario&quot;)\\n\\t\\tself.wm_geometry(&quot;300x300&quot;)\\n\\t\\tself.update()\\n\\t\\t&quot;&quot;&quot;immagine pagina&quot;&quot;&quot;\\n\\t\\tmenu_image = Image.open(globus_image)\\n\\t\\tmenu_image = menu_image.resize((self.winfo_width()-10,int(self.winfo_height()/2)), Image.ANTIALIAS)\\n\\t\\tmenu_image = ImageTk.PhotoImage(menu_image)\\n\\t\\tlabel1 = tk.Label(image=menu_image)\\n\\t\\tlabel1.image = menu_image\\n\\t\\tlabel1.place(x= 2, y = 0)\\n\\t\\t&quot;&quot;&quot;script&quot;&quot;&quot;\\n\\t\\tbenvenuto_label = tk.Label(self, text=f&quot;Benvenuto, {data[0]}&quot;)\\n\\t\\tbenvenuto_label.place(x=10, y=150)\\n\\t\\trich_strum_button = tk.Button(self, text='Richiesta\\\\nStrumentario', height=5, width=19)\\n\\t\\trich_strum_button.config(command=lambda: richiesta_strumentario.RichStrum())\\n\\t\\trich_strum_button.place(x=5, y=180)\\n\\t\\tvisual_pdf_button = tk.Button(self, text='Visualizza\\\\nSchede Tecniche', height=5, width=18)\\n\\t\\tvisual_pdf_button.config(command=lambda: schede_tecniche.SchedaTecnica())\\n\\t\\tvisual_pdf_button.place(x=157, y=180)\\n\\t\\texit_button = tk.Button(self, text='Exit', width=40, height=1, command=lambda: self.quit())\\n\\t\\texit_button.place(x=5, y=270)\\nif __name__ == '__main__':\\n\\t&quot;&quot;&quot;con = sqlite3.connect(&quot;user_db.db&quot;)\\n\\tcur = con.cursor()\\n\\tcur.execute(&quot;CREATE TABLE IF NOT EXISTS user(name, surname, email, password, azienda)&quot;)\\n\\tcon.close()&quot;&quot;&quot;\\n\\t&quot;&quot;&quot;Login().mainloop()&quot;&quot;&quot;\\n\\t&quot;&quot;&quot;data = Login.data&quot;&quot;&quot;\\n\\tdata = [&quot;test&quot;, &quot;test&quot;, &quot;test&quot;, &quot;test&quot;, &quot;test&quot;]\\n\\tMainPage().mainloop()\",\n",
       " \"import tkinter as tk\\nfrom tkinter import ttk\\nimport os\\nfrom tkPDFViewer import tkPDFViewer as pdf\\nclass ShowPdf(pdf.ShowPdf):\\n\\tdef goto(self, page):\\n\\t\\ttry:\\n\\t\\t\\tself.text.see(self.img_object_li[page - 1])\\n\\t\\texcept IndexError:\\n\\t\\t\\tif self.img_object_li:\\n\\t\\t\\t\\tself.text.see(self.img_object_li[-1])\\nclass SchedaTecnica(tk.Tk):\\n\\tdef __init__(self, *args, **kwargs):\\n\\t\\ttk.Tk.__init__(self, *args, **kwargs)\\n\\t\\tself.geometry(&quot;870x600&quot;)\\n\\t\\tself.attributes(&quot;-topmost&quot;, True)\\n\\t\\tself.focus_force()\\n\\t\\tdef show_pdf(*args):\\n\\t\\t\\tfor widget in pdfframe.winfo_children():\\n\\t\\t\\t\\twidget.destroy()\\n\\t\\t\\tpdf.ShowPdf.img_object_li.clear()\\n\\t\\t\\tfile = listbox_pdffile.get(tk.ANCHOR)\\n\\t\\t\\tpdfview_frame = pdf.ShowPdf().pdf_view(pdfframe, pdf_location=f&quot;{path_cartella_pdf}{file}.pdf&quot;,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   width=80, height=50)\\n\\t\\t\\tpdfview_frame.pack(fill=tk.BOTH)\\n\\t\\tpdf_files = []\\n\\t\\tfor file in os.listdir(path_cartella_pdf):\\n\\t\\t\\tif file.endswith('.pdf') and os.path.isfile(os.path.join(path_cartella_pdf, file)):\\n\\t\\t\\t\\tpdf_files.append(os.path.splitext(file)[0])\\n\\t\\tvar = tk.Variable(value=pdf_files)\\n\\t\\tlistbox_pdffile = tk.Listbox(self, listvariable=var, width=30, selectmode=tk.SINGLE)\\n\\t\\tscroll_bar = tk.Scrollbar(self)\\n\\t\\tscroll_bar.pack(side=tk.LEFT)\\n\\t\\tlistbox_pdffile.pack(side=tk.LEFT, fill=tk.Y)\\n\\t\\tlistbox_pdffile.bind('&lt;&lt;ListboxSelect&gt;&gt;', show_pdf)\\n\\t\\tpdfframe = tk.Frame(self, width=80, height=50)\\n\\t\\tpdfframe.pack()\",\n",
       " \"import xarray as xr\\nfrom mayavi import mlab\\nimport numpy as np\\nimport time as t\\ndataset = xr.open_dataset('time_series.nc', decode_times=False)\\nlatitude = dataset['LAT852_1008'].values\\nlongitude = dataset['LON2982_3207'].values\\ntemperature = dataset['WATER_TEMP'][0,0,:,:]\\nprint(len(temperature[0]))\\nlon_grid, lat_grid = np.meshgrid(longitude, latitude)\\nmlab.figure(size=(800, 600), bgcolor=(0, 0, 0))\\nfor time in range(len(dataset['WATER_TEMP']['TIME'])):\\n\\ttemperatureNEW=dataset['WATER_TEMP'][time,0,:,:]\\n\\tmesh=mlab.mesh(lon_grid, lat_grid, temperatureNEW, colormap='jet', scalars=temperature)\\n\\tmlab.colorbar(title='Temperature')\\n\\tt.sleep(10)\\n\\tmlab.savefig('frame_%04d.png' % time)\\nmlab.show()\",\n",
       " \"import xarray as xr\\nfrom mayavi import mlab\\nimport numpy as np\\nimport time as t\\nfrom PyQt5.QtWidgets import QApplication, QMainWindow, QVBoxLayout, QWidget, QPushButton, QSizePolicy, QHBoxLayout\\nfrom PyQt5.QtCore import Qt\\nfrom PyQt5.QtGui import QPalette\\nfrom mayavi.modules.surface import Surface\\nfrom mayavi.tools.pipeline import scalar_field\\nfrom mayavi.core.ui.mayavi_scene import MayaviScene\\ndataset = xr.open_dataset('time_series.nc', decode_times=False)\\nlatitude = dataset['LAT852_1008'].values\\nlongitude = dataset['LON2982_3207'].values\\ntemperature = dataset['WATER_TEMP'][0, 0, :, :]\\nlon_grid, lat_grid = np.meshgrid(longitude, latitude)\\napp = QApplication([])\\nwindow = QMainWindow()\\nwindow.setWindowTitle('Mayavi with PyQt')\\nmayavi_widget = QWidget(window)\\nmayavi_widget.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\\npalette = QPalette()\\npalette.setColor(QPalette.Window, Qt.black)\\nwindow.setPalette(palette)\\nlayout = QVBoxLayout(mayavi_widget)\\nlayout.setContentsMargins(0, 0, 0, 0)\\nscene = MayaviScene(parent=mayavi_widget)\\nscene.background = (0, 0, 0)\\ndef update_figure():\\n\\tfor time in range(len(dataset['WATER_TEMP']['TIME'])):\\n\\t\\ttemperature_new = dataset['WATER_TEMP'][time, 0, :, :]\\n\\t\\tmlab.clf()\\n\\t\\tmlab.mesh(lon_grid, lat_grid, temperature_new, colormap='jet')\\n\\t\\tmlab.colorbar(title='Temperature')\\n\\t\\tsurface = scalar_field(lon_grid, lat_grid, temperature_new)\\n\\t\\tmlab.pipeline.surface(surface, opacity=0.7)\\n\\t\\tmlab.view(azimuth=180, elevation=90)\\n\\t\\tmlab.savefig('frame_%04d.png' % (time + 1))\\n\\t\\tscene.camera.azimuth(180)\\n\\t\\tscene.camera.elevation(90)\\n\\t\\tscene.render()\\n\\t\\twindow.update()\\n\\t\\tt.sleep(3)\\n\\t\\tmlab.draw()\\npause_button = QPushButton('Pause')\\nplay_button = QPushButton('Play')\\nbuttons_layout = QHBoxLayout()\\nbuttons_layout.addWidget(pause_button)\\nbuttons_layout.addWidget(play_button)\\nlayout.addLayout(buttons_layout)\\npause_button.clicked.connect(lambda: mlab.draw(stop=True))\\nplay_button.clicked.connect(update_figure)\\nupdate_figure()\\nwindow.setCentralWidget(scene)\\nwindow.show()\\napp.exec_()\",\n",
       " 'threadpool',\n",
       " '\\twith concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\\n\\t\\tfor inx, i in enumerate(inputs):\\n\\t\\t\\texecutor.submit(worker, solve_asset, recover, i, inx)',\n",
       " \"response = make_request_with_retry(self.url,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   headers=headers\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   )\\nif response.code == 200:\\n   data = json.loads(response)\\n   save_json_on_disk(response_text)\\nelif response.code == 401:\\n   with lock:\\n   print(&quot;Access token expired. Trying to refresh it...&quot;)\\n   new_token = send_access_key_refresh()  \\n   headers['Authorization'] = 'Bearer ' + new_token\\n\\t\\t\\t```\",\n",
       " 'bohb_search = TuneBOHB(\\n\\tspace=hyperparams,\\n\\tmetric=&quot;episode_reward_mean&quot;,\\n\\tmode=&quot;max&quot;,\\n\\tbohb_config={\\n\\t}\\n)\\nbohb_search = tune.search.ConcurrencyLimiter(bohb_search, max_concurrent=2)\\nbohb_hyperband = HyperBandForBOHB(\\n\\ttime_attr=&quot;training_iteration&quot;,\\n\\tmax_t=TRAINING_ITERATIONS,\\n\\treduction_factor=2,\\n\\tmetric=&quot;episode_reward_mean&quot;,\\n\\tmode=&quot;max&quot;,\\n\\tstop_last_trials=False,\\n)\\ntuner = tune.Tuner(\\n\\t&quot;PPO&quot;,\\n\\trun_config=air.RunConfig(\\n\\t\\tname=&quot;BOHB_exp_1&quot;,\\n\\t\\tstorage_path=os.path.join(&quot;~&quot;, &quot;ray_results&quot;, &quot;tuning&quot;),\\n\\t\\tstop={&quot;training_iteration&quot;: TRAINING_ITERATIONS},\\n\\t),\\n\\ttune_config=tune.TuneConfig(\\n\\t\\tsearch_alg=bohb_search,\\n\\t\\tscheduler=bohb_hyperband,\\n\\t\\tnum_samples=NUM_SAMPLES,\\n\\t),\\n\\tparam_space={\\n\\t\\t&quot;env&quot;: &quot;biopharma_env&quot;,\\n\\t\\t&quot;model&quot;: {\\n\\t\\t\\t&quot;custom_model&quot;: &quot;action_mask_model&quot;,\\n\\t\\t\\t&quot;vf_share_layers&quot;: True,\\n\\t\\t},\\n\\t\\t&quot;framework&quot;: &quot;tf2&quot;,\\n\\t\\t&quot;eager_tracing&quot;: True,\\n\\t\\t&quot;use_kl_loss&quot;: False,\\n\\t\\t&quot;num_gpus&quot;: 0,\\n\\t\\t&quot;num_rollout_workers&quot;: 3,\\n\\t\\t&quot;vf_clip_param&quot;: np.inf,\\n\\t\\t&quot;train_batch_size&quot;: 2048,\\n\\t},\\n)',\n",
       " 'bohb_config',\n",
       " 'TuneBOHB',\n",
       " 'D:/..../gui/vue/dist/img/image.svg',\n",
       " '/img/image.svg',\n",
       " '/tmp/foo\\n|-- bar\\n\\t`-- __init__.py\\n`-- setup.py',\n",
       " 'setup.py',\n",
       " \"from setuptools import find_packages, setup\\npackage_name = 'foo'\\nmodule_name = 'bar'\\nsetup(\\n\\tname=package_name,\\n\\tpackages=find_packages(),\\n\\tpython_requires=&quot;&gt;=3.6&quot;,\\n)\",\n",
       " 'import foo.bar',\n",
       " 'import foo',\n",
       " '_avg',\n",
       " '_avg',\n",
       " 'print(df[&quot;*_avg&quot;])',\n",
       " '*',\n",
       " 'pip install gpt4all',\n",
       " 'Found model file at  C:\\\\\\\\Models\\\\\\\\GPT4All-13B-snoozy.ggmlv3.q4_0.bin Unable to load the model: 1 validation error for GPT4All __root__   Unable to instantiate model (type=value_error) Invalid model file  Process finished with exit code 0',\n",
       " '\\tbutlist_sidebar_ld = [{&quot;name&quot;:&quot;Reports&quot; , &quot;icon&quot;:Path(mainpath+imagepath+ &quot;\\\\icon_reports.png&quot;) , &quot;link&quot;:placeholder},\\n\\t\\t\\t\\t\\t\\t  {&quot;name&quot;:&quot;Stocks&quot; , &quot;icon&quot;:Path(mainpath+imagepath+&quot;\\\\icon_stocks.png&quot;) , &quot;link&quot;:placeholder},\\n\\t\\t\\t\\t\\t\\t  {&quot;name&quot;:&quot;Core Setup&quot; , &quot;icon&quot;:Path(mainpath+imagepath+&quot;\\\\icon_settings.png&quot;) , &quot;link&quot;:placeholder}]',\n",
       " 'for button_info in butlist_sidebar_ld:\\n\\t\\tphoto = PhotoImage(file = button_info.get(&quot;icon&quot;))\\n\\t\\tph_image = photo.subsample(35,35)\\n\\t\\tbutton_list[button_info.get(&quot;name&quot;)] = Button(root,text = button_info.get(&quot;name&quot;), compound=LEFT , command= button_info.get(&quot;link&quot;) , padx = 150 , pady = 30)\\n\\t\\tbutton_list[button_info.get(&quot;name&quot;)].config(image = ph_image)\\n\\t\\tbutton_list[button_info.get(&quot;name&quot;)].pack()',\n",
       " 'for loop:\\n   button_list[button_info.get(&quot;name&quot;)] = Button(root,text = button_info.get(&quot;name&quot;), compound=LEFT , command= button_info.get(&quot;link&quot;) , padx = 150 , pady = 30, image = PhotoImage(file = button_info.get(&quot;icon&quot;)).subsample(35,35))\\nbutton_list[button_info.get(&quot;name&quot;)].pack()',\n",
       " 'from llama_index import SimpleDirectoryReader, GPTListIndex, GPTVectorStoreIndex, LLMPredictor, PromptHelper\\nfrom langchain import OpenAI\\nimport os\\napikey = &quot;sk-fzDu2MtAdhPiR&quot;\\nos.environ[&quot;OPENAI_API_KEY&quot;] = apikey\\ndef createVectorIndex(path):\\n\\tmax_input = 4000\\n\\ttokens = 256\\n\\tchunk_size = 600\\n\\tmax_chunk_overlap = 0.20\\n\\tprompt_helper = PromptHelper(max_input, tokens, max_chunk_overlap, chunk_size_limit = chunk_size)\\n\\tllm_predictor = LLMPredictor(llm=OpenAI(temperature = 0, model_name = &quot;text-ada-001&quot;, max_tokens = tokens))\\n\\tdata = SimpleDirectoryReader(path).load_data()\\n\\tvector_index = GPTVectorStoreIndex(documents = data,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t   llm_predictor = llm_predictor,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t   prompt_helper = prompt_helper,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t   index_name=&quot;my_index&quot;)\\n\\tvector_index.save_to_disc(&quot;vector_index.json&quot;)\\n\\treturn vector_index\\nvector_index = createVectorIndex(&quot;gpt_data&quot;)',\n",
       " 'ValueError\\t\\t\\t\\t\\t\\t\\t\\tTraceback (most recent call last)\\n&lt;ipython-input-39-de1d095ec55f&gt; in &lt;module&gt;\\n----&gt; 1 vector_index = createVectorIndex(&quot;gpt_data&quot;)\\n&lt;ipython-input-38-f5b73669d881&gt; in createVectorIndex(path)\\n\\t 17\\t\\t print(i)\\n\\t 18\\n---&gt; 19\\t vector_index = GPTVectorStoreIndex(documents = data,\\n\\t 20\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tllm_predictor = llm_predictor,\\n\\t 21\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tprompt_helper = prompt_helper,\\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/llama_index/indices/vector_store/base.py in __init__(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, **kwargs)\\n\\t 43\\t\\t self._use_async = use_async\\n\\t 44\\t\\t self._store_nodes_override = store_nodes_override\\n---&gt; 45\\t\\t super().__init__(\\n\\t 46\\t\\t\\t nodes=nodes,\\n\\t 47\\t\\t\\t index_struct=index_struct,\\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/llama_index/indices/base.py in __init__(self, nodes, index_struct, storage_context, service_context, **kwargs)\\n\\t 43\\t\\t &quot;&quot;&quot;Initialize with parameters.&quot;&quot;&quot;\\n\\t 44\\t\\t if index_struct is None and nodes is None:\\n---&gt; 45\\t\\t\\t raise ValueError(&quot;One of documents or index_struct must be provided.&quot;)\\n\\t 46\\t\\t if index_struct is not None and nodes is not None:\\n\\t 47\\t\\t\\t raise ValueError(&quot;Only one of documents or index_struct can be provided.&quot;)\\nValueError: One of documents or index_struct must be provided.',\n",
       " 'index_name=&quot;my_index&quot;',\n",
       " 'data = SimpleDirectoryReader(path).load_data()',\n",
       " \"[Document(text=&quot;Kimberlites are ... m thermochemica, doc_id='5bbe7a75-7817-4c00-bce1-db9256fde270', embedding=None, doc_hash='87fb32e4834c847365178498a6ce166a68df5d5547c8631df46d577616dd37e8', extra_info=None)]\",\n",
       " \"from langchain.document_loaders import DirectoryLoader\\nif __name__ == '__main__':\\n\\tloader = DirectoryLoader('./data/', glob='**/*.md')\\n\\tdocuments = loader.load()\",\n",
       " 'Traceback (most recent call last):\\n  File &quot;/Users/zhangsan/project/python/test/langchain/text01.py&quot;, line 5, in &lt;module&gt;\\n\\tdocuments = loader.load()\\n  File &quot;/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/langchain/document_loaders/directory.py&quot;, line 84, in load\\n\\traise e\\n  File &quot;/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/langchain/document_loaders/directory.py&quot;, line 78, in load\\n\\tsub_docs = self.loader_cls(str(i), **self.loader_kwargs).load()\\n  File &quot;/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/langchain/document_loaders/unstructured.py&quot;, line 70, in load\\n\\telements = self._get_elements()\\n  File &quot;/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/langchain/document_loaders/unstructured.py&quot;, line 102, in _get_elements\\n\\tfrom unstructured.partition.auto import partition\\n  File &quot;/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/unstructured/partition/auto.py&quot;, line 9, in &lt;module&gt;\\n\\tfrom unstructured.partition.doc import partition_doc\\n  File &quot;/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/unstructured/partition/doc.py&quot;, line 7, in &lt;module&gt;\\n\\tfrom unstructured.partition.docx import partition_docx\\n  File &quot;/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/unstructured/partition/docx.py&quot;, line 6, in &lt;module&gt;\\n\\timport docx\\n  File &quot;/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/docx/__init__.py&quot;, line 3, in &lt;module&gt;\\n\\tfrom docx.api import Document  \\n  File &quot;/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/docx/api.py&quot;, line 14, in &lt;module&gt;\\n\\tfrom docx.package import Package\\n  File &quot;/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/docx/package.py&quot;, line 9, in &lt;module&gt;\\n\\tfrom docx.opc.package import OpcPackage\\n  File &quot;/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/docx/opc/package.py&quot;, line 9, in &lt;module&gt;\\n\\tfrom docx.opc.part import PartFactory\\n  File &quot;/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/docx/opc/part.py&quot;, line 12, in &lt;module&gt;\\n\\tfrom .oxml import serialize_part_xml\\n  File &quot;/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/docx/opc/oxml.py&quot;, line 12, in &lt;module&gt;\\n\\tfrom lxml import etree\\nImportError: dlopen(/Users/zhangsan/project/python/test/venv/lib/python3.9/site-packages/lxml/etree.cpython-39-darwin.so, 0x0002): symbol not found in flat namespace (_exsltDateXpathCtxtRegister)',\n",
       " 'import docx',\n",
       " \"def extract_data_from_table_ocr():\\n\\tfrom img2table.ocr import TesseractOCR\\n\\tfrom img2table.document import Image\\n\\tocr = TesseractOCR(n_threads=1, lang=&quot;eng&quot;)\\n\\tdoc = Image('out3.jpg', dpi=200)\\n\\textracted_tables_all = doc.extract_tables(ocr=ocr,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\timplicit_rows=True,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tborderless_tables=True,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tmin_confidence=50)\\n\\tprint(&quot;length : &quot; , len(extracted_tables_all))\\n\\textracted_tables = extracted_tables_all[0]\\n\\tframes = []\\n\\tfor table in extracted_tables_all:\\n\\t\\ttry:\\n\\t\\t\\tframes.append(table.df)\\n\\t\\texcept:\\n\\t\\t\\tframes.append(table)\\n\\tresult = pd.concat(frames)\\n\\tresult.to_csv('tableConverted2.csv', index=False, header = False)\",\n",
       " 'query ($repoOwner: String!, $repoName: String!, $sha: String!) {\\n  repository(name: $repoName, owner: $repoOwner) {\\n\\tcommit: object(expression: $sha) {\\n\\t  ... on Commit {\\n\\t\\tcommitUrl\\n\\t\\tassociatedPullRequests(first: 10) {\\n\\t\\t  edges {\\n\\t\\t\\tnode {\\n\\t\\t\\t  title\\n\\t\\t\\t  number\\n\\t\\t\\t  body\\n\\t\\t\\t  state\\n\\t\\t\\t  mergedAt\\n\\t\\t\\t  closedAt\\n\\t\\t\\t}\\n\\t\\t  }\\n\\t\\t}\\n\\t  }\\n\\t}\\n  }\\n}',\n",
       " '{\\n  &quot;repoOwner&quot;: &quot;&lt;REPOSITORY_OWNER&gt;&quot;,\\n  &quot;repoName&quot;: &quot;&lt;REPOSITORY_NAME&gt;&quot;,\\n  &quot;sha&quot;: &quot;&lt;COMMIT_HASH&gt;&quot;\\n}',\n",
       " '725777de1b8dea22edf9421a47ccf0807b477ae7',\n",
       " '',\n",
       " 'ab2bd9d9b997a315d2c4e3175ba03ab3a435543d',\n",
       " 'https://api.github.com/search/issues?q=repo:numpy/numpy+type:pr+sha:ab2bd9d9b997a315d2c4e3175ba03ab3a435543d',\n",
       " '',\n",
       " 'gdal',\n",
       " 'conda install -c conda-forge gdal',\n",
       " '(StageEnv) C:\\\\Users\\\\julia\\\\Documents\\\\Stage\\\\QGis\\\\QGis1&gt;python3 interannual_mean_values.py',\n",
       " \"Traceback (most recent call last):\\n  File &quot;C:\\\\Users\\\\julia\\\\Documents\\\\Stage\\\\QGis\\\\QGis1\\\\interannual_mean_values.py&quot;, line 3, in &lt;module&gt;\\n\\timport gdal\\nModuleNotFoundError: No module named 'gdal'\",\n",
       " 'from osgeo import gdal',\n",
       " \"no module named 'osgeo'\",\n",
       " 'no module named numpy',\n",
       " 'PS C:\\\\Users\\\\julia&gt;  C:/Users/julia/miniconda3/Scripts/activate\\nPS C:\\\\Users\\\\julia&gt;  conda activate StageEnv',\n",
       " 'conda list',\n",
       " 'no module named gdal',\n",
       " 'def create_player1_paddle(self):\\n\\tself.color(&quot;white&quot;)\\n\\tself.penup()\\n\\tself.shape(&quot;square&quot;)\\n\\tself.shapesize(stretch_wid=5, stretch_len=1)\\n\\tself.goto(-380, 0)\\ndef create_player2_paddle(self):\\n\\tself.color(&quot;white&quot;)\\n\\tself.penup()\\n\\tself.shape(&quot;square&quot;)\\n\\tself.shapesize(stretch_wid=5, stretch_len=1)\\n\\tself.goto(380, 0)',\n",
       " 'virtual venv\\nsource venv/bin/activate\\npip install flask flask_cors gunicorn \\nFLASK_DEBUG=1 FLASK_APP=server flask run --host=0.0.0.0',\n",
       " 'flask run',\n",
       " 'flask run',\n",
       " '...\\n  File &quot;/root/foo/src/server.py&quot;, line 31, in create_app\\n\\tfrom .bar import bar_blueprint\\nImportError: attempted relative import with no known parent package',\n",
       " '(venv) gv@dev:~/foo/src$ python\\nPython 3.10.6 (main, Mar 10 2023, 10:55:28) [GCC 11.3.0] on linux\\nType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more\\ninformation.',\n",
       " '(venv) root@server:~/foo/src\\nPython 3.10.7 (main, Mar 10 2023, 10:47:39) [GCC 12.2.0] on linux\\nType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more\\ninformation.',\n",
       " '~/exercism/python/**/*_test.py',\n",
       " '{\\n\\t&quot;python.testing.unittestArgs&quot;: [\\n\\t\\t&quot;-v&quot;,\\n\\t\\t&quot;-s&quot;,\\n\\t\\t&quot;./python&quot;,\\n\\t\\t&quot;-p&quot;,\\n\\t\\t&quot;**/*_test.py&quot;\\n\\t],\\n\\t&quot;python.testing.pytestEnabled&quot;: false,\\n\\t&quot;python.testing.unittestEnabled&quot;: true\\n}',\n",
       " 'python -m unittest discover -v -s &quot;./python&quot; -p &quot;**/*_test.py&quot;',\n",
       " 'font = pygame.font.SysFont(&quot;Times New Roman&quot;, 26)',\n",
       " 'nextblock_text = font.render(&quot;Next block :&quot;, 1, (0, 0, 0))',\n",
       " 'screen.blit(nextblock_text, (400, 0))',\n",
       " 'data\\n1\\n2\\n4\\n6\\n8\\n9\\n7\\n5\\n3\\n2',\n",
       " 'data  new_col\\n1 1\\n2 1\\n4 1\\n6 1\\n8 2\\n9 2\\n7 2\\n5 2\\n3 3\\n2 3\\n...',\n",
       " 'def read_image(tresh, path, img, show=False) : \\n\\toriginalImage = cv2.imread(path+&quot;\\\\\\\\&quot;+img)\\n\\tgrayImage = cv2.cvtColor(originalImage, cv2.COLOR_BGR2GRAY)\\n\\t(_, blackAndWhiteImage) = cv2.threshold(grayImage, tresh, 255, cv2.THRESH_BINARY_INV) \\n\\ttext = pyt.image_to_string(blackAndWhiteImage, config=&quot;--psm 7 --oem 3 -c tessedit_char_whitelist=0123456789&quot;)\\n\\tstring = str(text).replace(&quot;\\\\n&quot;, &quot;&quot;)\\n\\treturn string',\n",
       " \"import csv\\nimport urllib.request\\nurl = 'http://165.143.226.108/groups/IPNET-Localpeering/topN/IPNET-Localpeering/IPNET-Localpeering.csv'\\npassword_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()\\npassword_mgr.add_password(None, url, username, password)\\nproxy_auth_handler = urllib.request.HTTPBasicAuthHandler()\\nproxy_auth_handler.add_password('realm', f'http://{proxy_server}:{proxy_port}',\\n\\t\\t\\t\\t\\t\\t\\t\\tproxy_username, proxy_password)\\nproxy_handler = urllib.request.ProxyHandler({'http': f'http://{proxy_server}:{proxy_port}',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t 'https': f'https://{proxy_server}:{proxy_port}'})\\nopener = urllib.request.build_opener(proxy_handler, proxy_auth_handler, urllib.request.HTTPHandler)\\nurllib.request.install_opener(opener)\\nresponse = urllib.request.urlopen(url)\\ndata = response.read().decode('utf-8')\\ncsv_data = csv.reader(data.splitlines())\\nfor row in csv_data:\\n\\tprint(row)\",\n",
       " 'iconphoto',\n",
       " 'iconbitmap',\n",
       " ' Traceback (most recent call last):\\n File &quot;/usr/local/lib/python3.9/threading.py&quot;, line 973, in _bootstrap_inner\\n self.run()\\n File &quot;/usr/local/lib/python3.9/threading.py&quot;, line 910, in run\\n self._target(*self._args, **self._kwargs)\\n File &quot;/call_management/audiosocket_server/connection.py&quot;, line 228, in _process\\n self.conn_sock.send(types.audio + PCM_SIZE + bytes(320))\\n ConnectionResetError: [Errno 104] Connection reset by peer```\\nwhy occur this exception? It disconnect call, how i fix it?',\n",
       " 'from tensorflow.keras.applications.resnet50 import preprocess_input',\n",
       " 'hyperparams_list',\n",
       " 'test_hyperparams()',\n",
       " 'hyperparams',\n",
       " 'from multiprocessing import Pool\\ndef test_hyperparams(hyperparams):\\nhyperparams_list = [hyperparams0, ...,hyperparamsN]\\nwith Pool(num_cores) as p:\\n\\tinfos = p.map(test_hyperparams, hyperparams_list)',\n",
       " 'top',\n",
       " 'nvidia-smi',\n",
       " 'df.head()',\n",
       " 'import pandas as pd\\ndf = pd.read_csv(&quot;df.csv&quot;)\\ndf.head()',\n",
       " '   Unnamed: 0\\t\\t\\t\\t\\t\\t\\t\\t\\t address\\tdate  \\\\\\n0\\t\\t   0  0x0000000000000000000000000000000000000000  2016Q3\\n1\\t\\t   1  0x0000000000000000000000000000000000000000  2016Q4\\n2\\t\\t   2  0x0000000000000000000000000000000000000000  2016Q4\\n3\\t\\t   3  0x0000000000000000000000000000000000000000  2017Q1\\n4\\t\\t   4  0x0000000000000000000000000000000000000000  2017Q1\\n\\t\\t\\t\\t\\t\\t\\t\\ttoken_address\\t   balance  decimals  \\\\\\n0  0xd8912c10681d8b21fd3742244f44658dba12264e  2.000000e+19\\t  18.0\\n1  0xd8912c10681d8b21fd3742244f44658dba12264e  2.060000e+19\\t  18.0\\n2  0xe0b7927c4af23765cb51314a0e0521a9645f0e2a  4.500000e+11\\t   9.0\\n3  0xd8912c10681d8b21fd3742244f44658dba12264e  2.060000e+19\\t  18.0\\n4  0xe0b7927c4af23765cb51314a0e0521a9645f0e2a  4.571544e+11\\t   9.0\\n   token_price   tokens_USD\\n0\\t  1.99522\\t39.904400\\n1\\t  1.39913\\t28.822078\\n2\\t  8.53556  3841.002000\\n3\\t  1.33777\\t27.558062\\n4\\t 19.42000  8877.938149',\n",
       " 'from IPython.display import display\\ndisplay(df)',\n",
       " \"myssl = ssl.create_default_context()\\nmyhttpclient = urllib3.PoolManager(\\n\\t  cert_reqs='CERT_REQUIRED',\\n\\t  ca_certs=myssl.get_ca_certs()\\n)\\ns3dev = Minio(&quot;s3dev.mycorp.com:9000,\\n\\t access_key=&quot;myAccessKey&quot;,\\n\\t secret_key=&quot;mySecretKey&quot;\\n\\t secure=True,\\n\\t http_client=myhttpclient\\n)\",\n",
       " 'Spyder 5.3.3.\\npython is 3.9.13,\\ntorch version is 1.13.1.\\nThe environment I am using is setted up by Anaconda 2.3.1.',\n",
       " 'import torch\\nmu0 = torch.tensor([0, 0])\\nsigma0 = torch.tensor([[1, 0.], [0., 1. ]])\\nPDF=torch.distributions.multivariate_normal.MultivariateNormal(mu0,sigma0)',\n",
       " 'Fatal Python error: Segmentation fault\\nThread 0x0000000313346000 (most recent call first):\\n  File Fatal Python error:\\nRestarting kernel...',\n",
       " 'project\\\\\\n   __init__.py\\n   gui\\\\\\n\\t  __init__.py\\n\\t  gui_file_one.py\\n\\t  gui_file_two.py\\n   logic\\\\\\n\\t  __init__.py\\n\\t  logic_file_one.py\\n\\t  logic_file_two.py',\n",
       " 'gui_file_one.py',\n",
       " 'logic_file_one.py',\n",
       " 'logic.logic_file_one import A',\n",
       " \"ModuleNotFoundError: No module named 'logic'\",\n",
       " \"groups = df.groupby(['E', 'D', 'B', 'G', 'I'])\\nstats = pd.concat(\\n   [\\n\\t\\tgroups['N'].mean().rename(&quot;N_mean&quot;),\\n\\t\\tgroups['H'].median().rename('H_median')\\n   ]\\n)\\nstats = stats[stats['N']&gt;0]\",\n",
       " 'stats.index.droplevel(...)',\n",
       " 'None',\n",
       " \"import undetected_chromedriver as webdriver\\nimport time\\nrecreate_localStorage_script = <str>\\noptions = webdriver.ChromeOptions()\\nprofile = &quot;C:\\\\\\\\Users\\\\\\\\nicvaldy\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Google\\\\\\\\Chrome\\\\\\\\User Data\\\\\\\\Profile 38&quot;\\noptions.add_argument(f&quot;user-data=dir={profile}&quot;,)\\nmobile_emulation = {\\n\\t&quot;deviceMetrics&quot;: { &quot;width&quot;: 360, &quot;height&quot;: 640, &quot;pixelRatio&quot;: 3.0 },\\n\\t&quot;userAgent&quot;: &quot;Mozilla/5.0 (iPhone; CPU iPhone OS 10_3 like Mac OS X) AppleWebKit/602.1.50 (KHTML, like Gecko) CriOS/56.0.2924.75 Mobile Safari/535.19&quot; }\\nchrome_options = webdriver.ChromeOptions()\\nchrome_options.add_experimental_option(&quot;mobileEmulation&quot;, mobile_emulation)\\ndriver = webdriver.Chrome(chrome_options=chrome_options,use_subprocess=True)\\ndriver.get(&quot;https://click.discord.com/ls/click?&quot;)\\ndriver.execute_script(recreate_localStorage_script)  \\nprint('token:', driver.execute_script(\\n\\tf&quot;return window.localStorage.getItem('token');&quot;))\\ntime.sleep(160)\",\n",
       " \"tweets=[]\\nfor tweet in tweepy.Cursor(api.search_tweets,\\n\\t\\t\\t\\t\\t\\t   q=query, lang='en', result_type='recent',\\n\\t\\t\\t\\t\\t\\t   tweet_mode='extended', count=100).items(max_tweets):\\n\\ttweets.append(tweet)\",\n",
       " 'Forbidden: 403 Forbidden\\n195 - Missing or invalid url parameter.',\n",
       " 'test_df',\n",
       " \"test_df.info()\\n&lt;class 'pandas.core.frame.DataFrame'&gt;\\nRangeIndex: 100 entries, 0 to 99\\nColumns: 4097 entries, index to 4095\\ndtypes: float16(4096), object(1)\\nmemory usage: 800.9+ KB\",\n",
       " 'from ibm_watson_studio_lib import access_project_or_space\\nwslib = access_project_or_space()\\nwslib.save_data(&quot;test_df.csv&quot;, test_df.to_csv(index=False, header=False).encode())',\n",
       " \"import itc_utils.flight_service as itcfs\\nreadClient = itcfs.get_flight_client()\\nnb_data_request = {\\n\\t'data_name': &quot;&quot;&quot;test_df.csv&quot;&quot;&quot;,\\n\\t'interaction_properties': {\\n\\t\\t'infer_schema': 'true',\\n\\t\\t'infer_as_varchar': 'false'\\n\\t}\\n}\\nflightInfo = itcfs.get_flight_info(readClient, nb_data_request=nb_data_request)\\ntest_df = itcfs.read_pandas_and_concat(readClient, flightInfo, timeout=10000)\\ntest_df.index.name = None\\ntest_df.rename(columns = {'COLUMN1':'index'}, inplace = True)\\nnew_columns = {}\\nfor i in range(len(test_df.columns)-1):\\n\\tnew_columns[test_df.columns[i+1]] = str(i)\\ntest_df = test_df.rename(columns=new_columns)\",\n",
       " \"test_df.info()\\nTime taken: 0.0468 minutes\\n&lt;class 'pandas.core.frame.DataFrame'&gt;\\nRangeIndex: 100 entries, 0 to 99\\nColumns: 4097 entries, index to 4095\\ndtypes: float64(4096), object(1)\\nmemory usage: 3.1+ MB\",\n",
       " \"from bs4 import BeautifulSoup\\nimport requests\\nimport pandas as pd\\nwebsite = &quot;http://ufcstats.com/statistics/fighters?char=a&amp;page=all&quot;\\nresponse = requests.get(website)\\nresponse\\nsoup = BeautifulSoup(response.content, 'html.parser')\\nresults = soup.find('table', {'class' : 'b-statistics__table'}).find('tbody').find_all('tr')\\nlen(results)\\nrow = soup.find('tr')\\nprint(row.get_text())\\ntable = soup.find('table', {'class' : 'b-statistics__table'}).find('thead').find_all('tr')\\nfirst_name = str(results[0].find_all('td')[0].get_text())\\nprint(first_name)\\ndef first_names():\\n\\tfor names in first_name:\\n\\t\\tprint(names)\\n\\treturn\\nlast_name = results[1].find_all('td')[1].get_text()\\nprint(last_name)\\nalias = results[1].find_all('td')[2].get_text()\\nif len(alias) == 0:\\n\\tprint(&quot;n/a&quot;)\\nelse:\\n\\tprint(alias)\\nheight = results[1].find_all('td')[3].get_text()\\nprint(height)\\nweight = results[1].find_all('td')[4].get_text()\\nwins = results[1].find_all('td')[7].get_text()\\nlosses = results[1].find_all('td')[8].get_text()\\ndraws = results[1].find_all('td')[9].get_text()\\nx = input(&quot;Which fighter do you want to know about?&quot;)\\ny = input(&quot;What do you want to know about?&quot;)\\nif x.split()[0] in str(results[1].find_all('td')[0].get_text()) and x.split()[1] in str(results[1].find_all('td')[1].get_text()) and y == &quot;wins&quot;:\\n\\tprint(first_name+ &quot; &quot;+last_name+&quot; has won &quot; + wins + &quot; times.&quot;)\\nif x.split()[1] in str(results[1].find_all('td')[1].get_text()):\\n\\tprint(&quot;ok&quot;)\\nelse:\\n\\tprint('fail')\\nprint(x.split()[0])\\nif x.split()[1] == first_name:\\n\\tprint(x.split()[1])\\nif x.split()[0] in results[1] and x.split()[1] in results[1]:\\n\\tprint('wins')\\nelse:\\n\\tprint(&quot;Who&quot;)\\nprint(str(results[1].find_all('td')[0].get_text()))\",\n",
       " 'import numpy as np\\nimport math\\nimport random as r\\nx = []\\ny = []\\nfor i in range (100):\\n\\tage = r.randint(0, 80)\\n\\tx.append(age)\\n\\tif age  &gt; 18:\\n\\t\\ty.append(1)\\n\\telse:\\n\\t\\ty.append(0)\\ndef sig(x):\\n\\ty = []\\n\\tfor i in x:\\n\\t\\ty.append(1/(1+math.exp(-i)))\\n\\treturn y\\ndef relu(x):\\n\\ty = []\\n\\tfor i in x:\\n\\t\\tif i &gt; 0:\\n\\t\\t\\ty.append(i)\\n\\t\\telse:\\n\\t\\t\\ty.append(0)\\n\\treturn y\\ndef mse(ytrue,ypred):\\n\\ttotal = 0\\n\\tfor yt,yp in zip(ytrue,ypred):\\n\\t\\ttotal += (yt - yp)**2\\n\\treturn total/len(ytrue)\\ndef dmse(ytrue,ypred):\\n\\ttotal = []\\n\\tfor yt,yp in zip(ytrue,ypred):\\n\\t\\ttotal.append((yt - yp)*2)\\n\\treturn total\\ndef d_of_relu(x):\\n\\ty = []\\n\\tfor i in x:\\n\\t\\tif i &gt; 0:\\n\\t\\t\\ty.append(1)\\n\\t\\telse:\\n\\t\\t\\ty.append(0)\\n\\treturn y\\ndef d_of_sig(x):\\n\\ty = []\\n\\tfor i in y:\\n\\t\\ty.append(y*(1-y))\\n\\treturn y\\ndef y_calculation(x,w,b):\\n\\ty = []\\n\\tfor i in x:\\n\\t\\ty.append(i*w+b)\\n\\treturn y\\ndef chain_addition_second_layer_with_weight(dcdz2,dz2dy2,dy2dw2):\\n\\ttotal = 0\\n\\tfor a,b in zip(dcdz2,dz2dy2):\\n\\t\\ttotal += a*b*dy2dw2\\n\\treturn total/len(dcdz2)\\ndef chain_addition_second_layer_with_bias(dcdz2,dz2dy2):\\n\\ttotal = 0\\n\\tfor a,b in zip(dcdz2,dz2dy2):\\n\\t\\ttotal += a*b*1\\n\\treturn total/len(dcdz2)\\ndef chain_addition_first_layer_with_bias(dcdz2,dz2dy2,dy2dz1,dz1dy1):\\n\\ttotal = 0\\n\\tfor a,b,d in zip(dcdz2,dz2dy2,dz1dy1):\\n\\t\\ttotal += a*b*dy2dz1*d*1\\n\\treturn total/len(dcdz2)\\ndef chain_addition_first_layer_with_weight(dcdz2,dz2dy2,dy2dz1,dz1dy1,dy1dw1):\\n\\ttotal = 0\\n\\tfor a,b,d in zip(dcdz2,dz2dy2,dz1dy1):\\n\\t\\ttotal += a*b*dy2dz1*d*dy1dw1\\n\\treturn total/len(dcdz2)\\ndef gradient_descend(x,y,lr,epoch):\\n\\tw1 = w2 = b1 = b2 = 2\\n\\tfor i in range(epoch):\\n\\t\\ty1 = y_calculation(x,w1,b1)\\n\\t\\tz1 = relu(y1)\\n\\t\\ty2 = y_calculation(z1,w2,b2)\\n\\t\\tz2 = sig(y2)\\n\\t\\tcost = mse(y,z2)\\n\\t\\tdcdz2 = dmse(y,z2)\\n\\t\\tdz2dy2 = d_of_sig(z2)\\n\\t\\tdy2dw2 = z1\\n\\t\\tdy2db2 = 1\\n\\t\\tdy2dz1 = w2\\n\\t\\tdz1dy1 = d_of_relu(z1)\\n\\t\\tdy1dw1 = x\\n\\t\\tw2 = w2 - lr * chain_addition_second_layer_with_weight(dcdz2,dz2dy2,dy2dw2)\\n\\t\\tb2 = b2 - lr * chain_addition_second_layer_with_bias(dcdz2,dz2dy2)\\n\\t\\tw1 = w1 - lr * chain_addition_first_layer_with_weight(dcdz2,dz2dy2,dy2dz1,dz1dy1,dy1dw1)\\n\\t\\tb1 = b1 - lr * chain_addition_first_layer_with_bias(dcdz2,dz2dy2,dy2dz1,dz1dy1)\\n\\treturn w2,b2,w1,b1,cost\\nprint(gradient_descend(x,y,0.1,300))',\n",
       " \"import dataclasses\\nimport inspect\\nlazy_chunks_key = '__lazy_chunks__'\\n@dataclasses.dataclass\\nclass LazyChunk:\\n\\t_code: str\\n\\t_global: dict\\n\\t_local: dict\\n\\tdef _load(self):\\n\\t\\tif self._code:\\n\\t\\t\\texec(self._code, self._global, self._local)\\n\\t\\t\\tself._code = ''\\n\\tdef __getattr__(self, item):\\n\\t\\tself._load()\\n\\t\\tif item in self._local:\\n\\t\\t\\treturn self._local[item]\\n\\t\\tif item in self._global:\\n\\t\\t\\treturn self._global[item]\\n\\t\\traise NameError(item)\\n\\tdef __bool__(self):\\n\\t\\treturn False\\ndef lazy_chunk():\\n\\timport re\\n\\tstack = inspect.stack()[1]\\n\\twith open(stack.filename, encoding='utf-8') as _src:\\n\\t\\tsrc = iter(_src)\\n\\t\\tfor _ in range(stack.lineno): next(src)\\n\\t\\tspacing, code = re.match(r&quot;( *)([^ ].*)?&quot;, next(src)).groups()\\n\\t\\tchunk_ind = len(spacing)\\n\\t\\tcode += '\\\\n'\\n\\t\\twhile (line := next(src, None)) is not None:\\n\\t\\t\\tspacing, line_code = re.match(r&quot;( *)([^ ].*)?&quot;, line).groups()\\n\\t\\t\\tif not line_code: continue\\n\\t\\t\\tif (_ind := len(spacing)) &lt; chunk_ind: break\\n\\t\\t\\tcode += ' ' * (_ind - chunk_ind) + line_code + '\\\\n'\\n\\tframe = stack.frame\\n\\tframe.f_locals.setdefault(lazy_chunks_key, []).append(res := LazyChunk(code.strip(), frame.f_globals, frame.f_locals))\\n\\treturn res\",\n",
       " \"def set_fields_from_annotations(cls: typing.Type[_CStruct]) -&gt; typing.Type[_CStruct]:\\n\\tif not (annotations := getattr(cls, '__annotations__', None)): return cls\\n\\tglobal_namespace = getattr(sys.modules.get(cls.__module__, None), '__dict__', {})\\n\\tglobal_namespace[cls.__name__] = cls\\n\\tlocal_namespace = dict(vars(cls))\\n\\tdef str_eval_with_lazy(v):\\n\\t\\tif isinstance(v, str):\\n\\t\\t\\tfor chunk in global_namespace.pop(lazy_chunks_key, ()):\\n\\t\\t\\t\\tchunk._load()\\n\\t\\t\\treturn eval(v, global_namespace, local_namespace)\\n\\t\\treturn v\\n\\t... \",\n",
       " 'lazy_chunk',\n",
       " \"from .node import Node\\n@set_fields_from_annotations\\nclass Node(ctypes.Structure):\\n\\tfirst_node: Node\\nif lazy_chunk():\\n\\tfrom .tree import Tree\\n@set_fields_from_annotations\\nclass Node(ctypes.Structure):\\n\\ttree: 'Tree'\\n\\tvalue: ctypes.c_uint\\n\\tkey: ctypes.c_uint\\n\\tparent: 'ctypes.POINTER(Node)'\\n\\tchild: 'ctypes.POINTER(Node)'\",\n",
       " 'orientation = &quot;v&quot;',\n",
       " 'domain',\n",
       " \"import plotly.graph_objects as go\\nfig = go.Figure(go.Sankey(\\n\\tarrangement = &quot;snap&quot;,\\n\\tnode = {\\n\\t\\t&quot;label&quot;: [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;],\\n\\t\\t&quot;x&quot;: [0.2, 0.1, 0.5, 0.7, 0.3, 0.5],\\n\\t\\t&quot;y&quot;: [0.7, 0.5, 0.2, 0.4, 0.2, 0.3],\\n\\t\\t'pad':10},  \\n\\tlink = {\\n\\t\\t&quot;source&quot;: [0, 0, 1, 2, 5, 4, 3, 5],\\n\\t\\t&quot;target&quot;: [5, 3, 4, 3, 0, 2, 2, 3],\\n\\t\\t&quot;value&quot;: [1, 2, 1, 1, 1, 1, 1, 2]}))\\nfig.show()\",\n",
       " 'orientation',\n",
       " \"import plotly.graph_objects as go\\nfig = go.Figure(go.Sankey(\\n\\torientation = &quot;v&quot;,\\n\\tarrangement = &quot;snap&quot;,\\n\\tnode = {\\n\\t\\t&quot;label&quot;: [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;],\\n\\t\\t&quot;x&quot;: [0.2, 0.1, 0.5, 0.7, 0.3, 0.5],\\n\\t\\t&quot;y&quot;: [0.7, 0.5, 0.2, 0.4, 0.2, 0.3],\\n\\t\\t'pad':10},  \\n\\tlink = {\\n\\t\\t&quot;source&quot;: [0, 0, 1, 2, 5, 4, 3, 5],\\n\\t\\t&quot;target&quot;: [5, 3, 4, 3, 0, 2, 2, 3],\\n\\t\\t&quot;value&quot;: [1, 2, 1, 1, 1, 1, 1, 2]}))\\nfig.show()\",\n",
       " \"import plotly.graph_objects as go\\nfig = go.Figure(go.Sankey(\\n\\torientation = &quot;v&quot;,\\n\\tarrangement = &quot;snap&quot;,\\n\\tnode = {\\n\\t\\t&quot;label&quot;: [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;],\\n\\t\\t'pad':10},  \\n\\tlink = {\\n\\t\\t&quot;source&quot;: [0, 0, 1, 2, 5, 4, 3, 5],\\n\\t\\t&quot;target&quot;: [5, 3, 4, 3, 0, 2, 2, 3],\\n\\t\\t&quot;value&quot;: [1, 2, 1, 1, 1, 1, 1, 2]}))\\nfig.show()\",\n",
       " \"import plotly.graph_objects as go\\nfig = go.Figure(go.Sankey(\\n\\tdomain = dict(\\n\\t\\tx =  [0.5,1],\\n\\t\\ty =  [0.5,1]\\n\\t),\\n\\torientation = &quot;v&quot;,\\n\\tarrangement = &quot;snap&quot;,\\n\\tnode = {\\n\\t\\t&quot;label&quot;: [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;],\\n\\t\\t&quot;x&quot;: [0.2, 0.1, 0.5, 0.7, 0.3, 0.5],\\n\\t\\t&quot;y&quot;: [0.7, 0.5, 0.2, 0.4, 0.2, 0.3],\\n\\t\\t'pad':10},  \\n\\tlink = {\\n\\t\\t&quot;source&quot;: [0, 0, 1, 2, 5, 4, 3, 5],\\n\\t\\t&quot;target&quot;: [5, 3, 4, 3, 0, 2, 2, 3],\\n\\t\\t&quot;value&quot;: [1, 2, 1, 1, 1, 1, 1, 2]}))\\nfig.show()\",\n",
       " 'cmd',\n",
       " 'serve_forever',\n",
       " 'cmdloop',\n",
       " 'class MyServer(TCPServer, Cmd):\\n\\tdef __init__(self, host, port)\\n\\t\\tTCPServer.__init__(self, (host, port), RequestHandler)\\napp = MyServer()\\napp.cmdloop()\\napp.serve_forever()',\n",
       " \"\\tif self.use_rawinput and self.completekey:\\nAttributeError: 'MyServer' object has no attribute 'completekey'. Did you mean: 'complete'?\",\n",
       " 'cmd2',\n",
       " \"ine 5262, in cmdloop\\n\\tself.terminal_lock.acquire()\\nAttributeError: 'Server' object has no attribute 'terminal_lock'\",\n",
       " \"import sys , os , os.path , time , datetime , json , logging, warnings\\nfrom os import listdir\\nfrom os.path import isfile, join\\nfrom flask import Flask\\nfrom flask import render_template\\nfrom flask import request\\nfrom flask import url_for\\nfrom flask import request\\nfrom datetime import datetime\\nfrom logging import FileHandler\\nfrom logging import Formatter\\nhost_url=&quot;localhost&quot;\\nport_number=1234\\napp = Flask(__name__)\\n@app.route('/')\\n@app.route('/index')\\ndef index():\\n\\tserver='Development_Sandbox'\\n\\treturn render_template('index.html',server=server)\\n@app.route('/information/')\\n@app.route('/information/&lt;name&gt;')\\ndef information():\\n\\tname='summary_report'\\n\\treturn render_template('information.html',name=name)\\napp.run(host='localhost', port=1234, debug=True)\",\n",
       " \"import unittest\\nimport test\\nimport sys\\nsys.path.insert(1, 'C:/Users/mm13854/Desktop/Python Project/subscription_app')\\nimport run as flk\\nclass Test_Flask(unittest.TestCase):\\n\\tdef test_checkURL(self):\\n\\t\\tresult=flk.host_url\\n\\t\\tself.assertEqual(result, 'localhost')\\n\\tdef test_checkPortNumber(self):\\n\\t\\tresult=flk.port_number\\n\\t\\tself.assertEqual(result, 1234)\\n\\tdef test_importModules(self):\\nif __name__=='__main__':\\n\\tunittest.main()\",\n",
       " \"import my_module\\ndf2 = df1.trailing_returns(column='1 Mth Returns')\",\n",
       " \"import my_module\\ndf2 = my_module.trailing_returns(df1, column='1 Mth Returns')\",\n",
       " \"class ImageTextObject(QObject, QTextObjectInterface):\\n\\tImageTextFormat = QTextFormat.ObjectTypes.UserObject + 1\\n\\tImageProperty = QTextFormat.Property.UserProperty + 1\\n\\tdef __init__(self):\\n\\t\\tsuper().__init__()\\n\\tdef intrinsicSize(self, doc: typing.Optional['QTextDocument'], posInDocument: int, format: 'QTextFormat') -&gt; QtCore.QSizeF:\\n\\t\\tfilename = format.property(ImageTextObject.ImageProperty)\\n\\t\\tlabel = QLabel()\\n\\t\\tlabel.setPixmap(QPixmap(filename))\\n\\t\\treturn QSizeF(label.size())\\n\\tdef drawObject(self, painter: typing.Optional['QPainter'], rect: QtCore.QRectF, doc: typing.Optional['QTextDocument'], posInDocument: int, format: 'QTextFormat') -&gt; None:\\n\\t\\tfilename = format.property(ImageTextObject.ImageProperty)\\n\\t\\tlabel = QLabel(&quot;hello&quot;)\\n\\t\\tlabel.setPixmap(QPixmap(filename))\\n\\t\\tlabel.setGeometry(rect.toRect())\\nclass Window(QWidget):\\n\\tdef __init__(self):\\n\\t\\tsuper().__init__()\\n\\t\\tself.text_edit = QTextEdit()\\n\\t\\tself.insert_btn = QPushButton(&quot;insert&quot;)\\n\\t\\tself.filename = &quot;../screenshot.png&quot;\\n\\t\\tself.setupUI()\\n\\t\\tself.setupTextObject()\\n\\tdef insertTextObject(self):\\n\\t\\timageTextFormat = QTextCharFormat()\\n\\t\\timageTextFormat.setObjectType(ImageTextObject.ImageTextFormat)\\n\\t\\timageTextFormat.setProperty(ImageTextObject.ImageProperty, self.filename)\\n\\t\\tcursor = self.text_edit.textCursor()\\n\\t\\tcursor.insertText(chr(0xfffc), imageTextFormat)\\n\\t\\tself.text_edit.setTextCursor(cursor)\\n\\t\\tpass\\n\\tdef setupUI(self):\\n\\t\\tself._layout = QVBoxLayout(self)\\n\\t\\tself._layout.addWidget(self.text_edit)\\n\\t\\tself._layout.addWidget(self.insert_btn)\\n\\t\\tself.insert_btn.clicked.connect(self.insertTextObject)\\n\\tdef setupTextObject(self):\\n\\t\\timage_text_object = ImageTextObject()\\n\\t\\timage_text_object.setParent(self)\\n\\t\\tself.text_edit.document().documentLayout().registerHandler(ImageTextObject.ImageTextFormat, image_text_object)\",\n",
       " '/api/v1/scrapy/start',\n",
       " '/api/v1/scrapy/status',\n",
       " 'from scrapy.crawler import CrawlerProcess\\nfrom scrapy.utils.project import get_project_settings\\nprocess = CrawlerProcess(get_project_settings())\\nprocess.crawl(&quot;followall&quot;, domain=&quot;scrapy.org&quot;)\\nprocess.start()  ',\n",
       " 'subprocess',\n",
       " 'import subprocess\\nfrom fastapi import FastAPI\\napp = FastAPI()\\n@app.get(&quot;/run_spider&quot;)\\ndef run_spider():\\n\\tspider_name = &quot;example&quot;\\n\\tcmd = f&quot;scrapy crawl {spider_name}&quot;\\n\\ttry:\\n\\t\\tsubprocess.check_output(cmd, shell=True)\\n\\t\\treturn {&quot;message&quot;: &quot;Successfully executed.&quot;}\\n\\texcept subprocess.CalledProcessError as e:\\n\\t\\treturn {&quot;message&quot;: f&quot;Failed to run the spider. Error: {e}&quot;}',\n",
       " \"import google.ads.googleads.client\\ndef main(request):\\n\\trequest_args = request.args\\n\\tif not request_args:\\n\\t\\treturn 'Error: No request_args provided. Please specify a seed_keyword or page_url.'\\n\\tif 'seed_keyword' not in request_args and 'page_url' not in request_args:\\n\\t\\treturn 'Error: No seed_keyword or page_urls field provided. Please specify a seed_keyword or page_url.'\\n\\tseed_keyword = None\\n\\tpage_url = None\\n\\tlocation = 'US'\\n\\tlanguage = 'EN'\\n\\tsearch_volume = False\\n\\tsize = 100\\n\\tif 'seed_keyword' in request_args:\\n\\t\\tseed_keyword = request_args['seed_keyword']\\n\\telif 'page_url' in request_args:\\n\\t\\tpage_url = request_args['page_url']\\n\\tif 'location' in request_args:\\n\\t\\tlocation = request_args['location']\\n\\tif 'language' in request_args:\\n\\t\\tlanguage = request_args['language']\\n\\tif 'search_volume' in request_args:\\n\\t\\tif request_args['search_volume'] == 'true':\\n\\t\\t\\tsearch_volume = True\\n\\t\\telse:\\n\\t\\t\\tsearch_volume = False\\n\\tif 'size' in request_args:\\n\\t\\tsize = request_args['size']\\n\\tkeywords = generate_keyword_ideas(\\n\\t\\tseed_keyword, page_url, location, language, search_volume, size)\\n\\treturn {'data': keywords}\\ndef generate_keyword_ideas(keyword_text=None, page_url=None, location=None, language=None, search_volume=False, size=100):\\n\\tcustomer_id = '**********'\\n\\tdict_env = {\\n\\t\\t&quot;developer_token&quot;: '**********',\\n\\t\\t&quot;client_id&quot;: '**********',\\n\\t\\t&quot;client_secret&quot;:  '**********',\\n\\t\\t&quot;refresh_token&quot;:  '**********',\\n\\t\\t&quot;customer_id&quot;:  customer_id,\\n\\t\\t&quot;use_proto_plus&quot;: False\\n\\t}\\n\\tlocation_ids = [format_location(location)]\\n\\tlanguage_id = format_language(language)\\n\\tif keyword_text:\\n\\t\\tkeyword_text = [keyword_text]\\n\\tclient = (google.ads.googleads.client.GoogleAdsClient\\n\\t\\t\\t  .load_from_dict(dict_env))\\n\\tkeyword_plan_idea_service = client.get_service(&quot;KeywordPlanIdeaService&quot;, version=&quot;v13&quot;)\\n\\tkeyword_annotation = client.get_type(\\n\\t\\t&quot;KeywordPlanKeywordAnnotationEnum&quot;).KEYWORD_CONCEPT\\n\\tkeyword_plan_network = (\\n\\t\\tclient.enums.KeywordPlanNetworkEnum.GOOGLE_SEARCH_AND_PARTNERS)\\n\\tlocation_rns = _map_locations_ids_to_resource_names(client, location_ids)\\n\\tlanguage_rn = client.get_service(\\n\\t\\t&quot;GoogleAdsService&quot;).language_constant_path(language_id)\\n\\tif not (keyword_text or page_url):\\n\\t\\traise ValueError(\\n\\t\\t\\t&quot;At least one of keywords or page URL is required, &quot;\\n\\t\\t\\t&quot;but neither was specified.&quot;\\n\\t\\t)\\n\\trequest = client.get_type(&quot;GenerateKeywordIdeasRequest&quot;)\\n\\trequest.customer_id = customer_id\\n\\trequest.geo_target_constants.extend(location_rns)\\n\\trequest.language = language_rn\\n\\trequest.include_adult_keywords = False\\n\\trequest.keyword_plan_network = keyword_plan_network\\n\\trequest.keyword_annotation.extend([keyword_annotation])\\n\\tif not keyword_text and page_url:\\n\\t\\trequest.url_seed.url = page_url\\n\\tif keyword_text and not page_url:\\n\\t\\trequest.keyword_seed.keywords.extend(keyword_text)\\n\\tif keyword_text and page_url:\\n\\t\\trequest.keyword_and_url_seed.url = page_url\\n\\t\\trequest.keyword_and_url_seed.keywords.extend(keyword_text)\\n\\tkeyword_ideas = keyword_plan_idea_service.generate_keyword_ideas(\\n\\t\\trequest=request)\\n\\tif search_volume:\\n\\t\\tkeywords = [[keyword.text, keyword.keyword_idea_metrics.avg_monthly_searches]\\n\\t\\t\\t\\t\\tfor keyword in keyword_ideas]\\n\\telse:\\n\\t\\tkeywords = [keyword.text for keyword in keyword_ideas]\\n\\tif keywords:\\n\\t\\tkeywords = keywords[:size]\\n\\treturn keywords\\ndef map_keywords_to_string_values(client, keyword_text):\\n\\tkeyword_protos = []\\n\\tfor keyword in keyword_text:\\n\\t\\tstring_val = client.get_type(&quot;StringValue&quot;)\\n\\t\\tstring_val.value = keyword\\n\\t\\tkeyword_protos.append(string_val)\\n\\treturn keyword_protos\\ndef _map_locations_ids_to_resource_names(client, location_ids):\\n\\tbuild_resource_name = client.get_service(\\n\\t\\t&quot;GeoTargetConstantService&quot;\\n\\t).geo_target_constant_path\\n\\treturn [build_resource_name(location_id) for location_id in location_ids]\\ndef format_location(location):\\n\\tif location == 'AE':\\n\\t\\tlocation_id = '2784'\\n\\telif location == 'FR':\\n\\t\\tlocation_id = '2250'\\n\\telif location == 'IT':\\n\\t\\tlocation_id = '2380'\\n\\telif location == 'US':\\n\\t\\tlocation_id = '2840'\\n\\telif location == 'ES':\\n\\t\\tlocation_id = '2724'\\n\\treturn location_id\\ndef format_language(language):\\n\\tif language == 'EN':\\n\\t\\tlanguage_id = '1000'\\n\\telif language == 'AR':\\n\\t\\tlanguage_id = '1019'\\n\\telif language == 'FR':\\n\\t\\tlanguage_id = '1002'\\n\\telif language == 'ES':\\n\\t\\tlanguage_id = '1003'\\n\\telif language == 'IT':\\n\\t\\tlanguage_id = '1004'\\n\\treturn language_id\",\n",
       " 'def find_point_Q(P1, P2, P3, P4, P2_prime, P3_prime, P4_prime, Q_prime):\\n\\tv1 = P2 - P1\\n\\tv2 = P4 - P1\\n\\tA = np.array([[v1[0], v2[0]], [v1[1], v2[1]]])\\n\\tb = Q_prime - P1\\n\\tx, y = np.linalg.solve(A, b)\\n\\tQ = P1 + x * (P2_prime - P1) + y * (P4_prime - P1)\\n\\treturn Q',\n",
       " \"import time\\nimport math\\nimport pygame\\nimport random\\nimport threading\\nfrom threading import Timer\\npygame.init()\\ngamelength = 0\\ndiffspeed = 0\\ngrey = (117,117,117)\\nwhite = (0,0,0)\\ndiffspeed = 0\\ndifflength = 0\\nnoenemies = 2\\nscale = 1\\nkeys = pygame.key.get_pressed()\\nspeed = 1\\nobsspeed = 1\\nstart = 0\\nsettingres = 0\\nscore = 0\\nX = 1280\\nY= 720\\nobsy = Y * 1.15\\nblack = (0,0,0)\\nred = (255,0,0)\\ngreen = (0,255,0)\\nblue = (0,0,255)\\norange = (255,128,0)\\nyellow = (255,255,0)\\nobreset = 0\\nobs1w1 = X/2\\nobs2w1 = X/8\\nscreen = pygame.display.set_mode((X, Y))\\nclock = pygame.time.Clock()\\nrunning = True\\nobs1_pos = pygame.Vector2(obs1w1, screen.get_height() - obsy)\\nobs2_pos = pygame.Vector2(obs2w1, screen.get_height() - obsy)\\nspeedbo_pos = pygame.Vector2(random.randint(64,X-64),random.randint(64,Y-64))\\nspeedloss_pos = pygame.Vector2(random.randint(64,X-64),random.randint(64,Y-64))\\ndt = 0\\nvelo = 0\\nvelox = 0\\nplayer_pos = pygame.Vector2(random.randint(64,X-64),random.randint(64,Y-64))\\nwhile running:\\n\\tfor event in pygame.event.get():\\n\\t\\tif event.type == pygame.QUIT:\\n\\t\\t\\trunning = False\\n\\tkeys = pygame.key.get_pressed()\\n\\tif keys[pygame.K_SPACE]:\\n\\t\\ttime.sleep(0.5)\\n\\t\\tstart += 1\\n\\tif keys[pygame.K_1]:\\n\\t\\ttime.sleep(0.5)\\n\\t\\tscreen = pygame.display.set_mode((X, Y))\\n\\t\\tstart += 1\\n\\tif keys[pygame.K_UP]:\\n\\t\\ttime.sleep(0.5)\\n\\t\\tdiffspeed += 1\\n\\t\\tdifflength += 1\\n\\t\\tsettingres += 1\\n\\tif keys[pygame.K_DOWN]:\\n\\t\\ttime.sleep(0.5)\\n\\t\\tsettingres -= 1\\n\\t\\tdifflength -= 1\\n\\t\\tdiffspeed -= 1\\n\\tif start == 17:\\n\\t\\tprint(player_pos.x, player_pos.y)\\n\\t\\tscreen.fill(black)\\n\\t\\tif player_pos.x &lt; 0:\\n\\t\\t\\tscreen.fill(&quot;red&quot;)\\n\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\ttext = font.render('You lose', True, black, red)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\t\\trunning = False\\n\\t\\telif player_pos.x &gt; X:\\n\\t\\t\\tscreen.fill(&quot;red&quot;)\\n\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\ttext = font.render('You lose', True, black, red)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\t\\trunning = False\\n\\t\\telif player_pos.y &lt; 0:\\n\\t\\t\\tscreen.fill(&quot;red&quot;)\\n\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\ttext = font.render('You lose', True, black, red)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\t\\trunning = False\\n\\t\\telif player_pos.y &gt; Y:\\n\\t\\t\\tscreen.fill(&quot;red&quot;)\\n\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\ttext = font.render('You lose', True, black, red)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\t\\trunning = False\\n\\t\\tpygame.draw.circle(screen, &quot;blue&quot;, player_pos, 40)\\n\\t\\tkeys = pygame.key.get_pressed()\\n\\t\\tif keys[pygame.K_w]:\\n\\t\\t\\tplayer_pos.y -= 300 * dt * speed * scale\\n\\t\\tif keys[pygame.K_s]:\\n\\t\\t\\tplayer_pos.y += 300 * dt * speed * scale\\n\\t\\tif keys[pygame.K_a]:\\n\\t\\t\\tplayer_pos.x -= 300 * dt * speed * scale\\n\\t\\tif keys[pygame.K_d]:\\n\\t\\t\\tplayer_pos.x += 300 * dt * speed * scale\\n\\t\\tpygame.draw.circle(screen, &quot;white&quot;, obs1_pos, 40*scale)\\n\\t\\tpygame.draw.circle(screen, &quot;white&quot;, obs2_pos, 40*scale)\\n\\t\\tpygame.draw.circle(screen, &quot;green&quot;, speedbo_pos, 20*scale)\\n\\t\\tpygame.draw.circle(screen, &quot;red&quot;, speedloss_pos, 60*scale)\\n\\t\\tvelox = velox + 2\\n\\t\\tobs1_pos.y += (player_pos.y - obs1_pos.y) * 0.02 * scale * obsspeed\\n\\t\\tobs1_pos.x += (player_pos.x - obs1_pos.x) * 0.02 * scale * obsspeed\\n\\t\\tobs2_pos.y += (player_pos.y - obs2_pos.y) * 0.02 * scale * obsspeed\\n\\t\\tobs2_pos.x += (player_pos.x - obs2_pos.x) * 0.02 * scale * obsspeed\\n\\t\\tvelo = velo + 4\\n\\t\\tpygame.display.flip()\\n\\t\\tdt = clock.tick(60) / 1000\\n\\t\\tdef resetSpeed():\\n\\t\\t\\tglobal speed\\n\\t\\t\\tglobal speedbo_pos\\n\\t\\t\\tspeedbo_pos = pygame.Vector2(random.randint(64,X-64),random.randint(64,Y-64))\\n\\t\\t\\tspeed = 1\\n\\t\\tdef resetSpeed1():\\n\\t\\t\\tglobal speed\\n\\t\\t\\tglobal speedloss_pos\\n\\t\\t\\tspeedloss_pos = pygame.Vector2(random.randint(64,X-64),random.randint(64,Y-64))\\n\\t\\t\\tspeed = 1\\n\\t\\tif obs1_pos.y &gt; Y*1.08:\\n\\t\\t\\tobs1_pos = pygame.Vector2(obs1w1, screen.get_height() - obsy)\\n\\t\\t\\tvelo = 0\\n\\t\\t\\tvelox = 0\\n\\t\\t\\tobs1w1 = obs1w1 - X*0.125\\n\\t\\t\\tif obs1_pos.x &lt; 0:\\n\\t\\t\\t\\tobs1w1 = X*1.08\\n\\t\\tif obs2_pos.y &gt; Y*1.08:\\n\\t\\t\\tobs2_pos = pygame.Vector2(obs2w1, screen.get_height() - obsy)\\n\\t\\t\\tvelo = 0\\n\\t\\t\\tvelox = 0\\n\\t\\t\\tobs2w1 = obs2w1 - X*0.125\\n\\t\\t\\tif obs2_pos.x &lt; 0:\\n\\t\\t\\t\\tobs2w1 = X*1.08\\n\\t\\tif math.sqrt((obs1_pos.x - player_pos.x)*(obs1_pos.x - player_pos.x) + (obs1_pos.y - player_pos.y)*(obs1_pos.y - player_pos.y)) - ((40 + 40)* scale) &lt; 0:\\n\\t\\t\\tscreen.fill(&quot;red&quot;)\\n\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\ttext = font.render('You lose', True, black, red)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\t\\trunning = False\\n\\t\\tif math.sqrt((obs2_pos.x - player_pos.x)*(obs2_pos.x - player_pos.x) + (obs2_pos.y - player_pos.y)*(obs2_pos.y - player_pos.y)) - ((40 + 40)* scale) &lt; 0:\\n\\t\\t\\tscreen.fill(&quot;red&quot;)\\n\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\ttext = font.render('You lose', True, black, red)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\t\\trunning = False\\n\\t\\tif math.sqrt((speedbo_pos.x - player_pos.x)*(speedbo_pos.x - player_pos.x) + (speedbo_pos.y - player_pos.y)*(speedbo_pos.y - player_pos.y)) - ((20 + 40)* scale) &lt; 0:\\n\\t\\t\\tspeed = 1.5\\n\\t\\t\\ttime.sleep(0.5)\\n\\t\\t\\tscore += 1\\n\\t\\t\\tif score == 5:\\n\\t\\t\\t\\tscreen.fill(&quot;green&quot;)\\n\\t\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\t\\ttext = font.render('You win!', True, black, green)\\n\\t\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\t\\tpygame.display.flip()\\n\\t\\t\\t\\trunning = False\\n\\t\\t\\telse:\\n\\t\\t\\t\\tspeedbo_pos = pygame.Vector2(2000,1000)\\n\\t\\t\\t\\tstart_time = threading.Timer(10,resetSpeed)\\n\\t\\t\\t\\tstart_time.start()\\n\\t\\tif math.sqrt((speedloss_pos.x - player_pos.x)*(speedloss_pos.x - player_pos.x) + (speedloss_pos.y - player_pos.y)*(speedloss_pos.y - player_pos.y)) - ((60 + 40)* scale) &lt; 0:\\n\\t\\t\\tspeed = 0.6\\n\\t\\t\\tspeedloss_pos = pygame.Vector2(2000,1000)\\n\\t\\t\\tstart_time = threading.Timer(10,resetSpeed1)\\n\\t\\t\\tstart_time.start()\\n\\t\\tif math.sqrt((speedloss_pos.x - speedbo_pos.x)*(speedloss_pos.x - speedbo_pos.x) + (speedloss_pos.y - speedbo_pos.y)*(speedloss_pos.y - speedbo_pos.y)) - ((60 + 20)* scale) &lt; 0:\\n\\t\\t\\tobreset = random.randint(1,2)\\n\\t\\t\\tif obreset == 1:\\n\\t\\t\\t\\tspeedloss_pos = pygame.Vector2(random.randint(64,1216),random.randint(64,656))\\n\\t\\t\\telse:\\n\\t\\t\\t\\tspeedbo_pos = pygame.Vector2(random.randint(64,1216),random.randint(64,656))\\n\\t\\tif math.sqrt((obs2_pos.x - obs1_pos.x)*(obs2_pos.x - obs1_pos.x) + (obs2_pos.y - obs1_pos.y)*(obs2_pos.y - obs1_pos.y)) - ((40 + 40)) &lt; 0:\\n\\t\\t\\tobreset = random.randint(1,2)\\n\\t\\t\\tif obreset == 1:\\n\\t\\t\\t\\tobs1_pos.x = 640\\n\\t\\t\\t\\tobs1_pos.y = -80\\n\\t\\t\\telse:\\n\\t\\t\\t\\tobs2_pos.x = 150\\n\\t\\t\\t\\tobs2_pos.y = -80\\n\\t\\tpygame.display.flip()\\n\\t\\tplayerX = player_pos.x\\n\\t\\tplayerY = player_pos.y\\n\\t\\tfor i in range(20):\\n\\t\\t\\tplayer_pos = pygame.Vector2(playerX,playerY)\\n\\t\\tstart += 1\\n\\tif start == 18:\\n\\t\\tprint(player_pos.x, player_pos.y)\\n\\t\\tscreen.fill(black)\\n\\t\\tif player_pos.x &lt; 0:\\n\\t\\t\\tscreen.fill(&quot;red&quot;)\\n\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\ttext = font.render('You lose', True, black, red)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\t\\trunning = False\\n\\t\\telif player_pos.x &gt; X:\\n\\t\\t\\tscreen.fill(&quot;red&quot;)\\n\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\ttext = font.render('You lose', True, black, red)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\t\\trunning = False\\n\\t\\telif player_pos.y &lt; 0:\\n\\t\\t\\tscreen.fill(&quot;red&quot;)\\n\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\ttext = font.render('You lose', True, black, red)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\t\\trunning = False\\n\\t\\telif player_pos.y &gt; Y:\\n\\t\\t\\tscreen.fill(&quot;red&quot;)\\n\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\ttext = font.render('You lose', True, black, red)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\t\\trunning = False\\n\\t\\tpygame.draw.circle(screen, &quot;blue&quot;, player_pos, 40)\\n\\t\\tkeys = pygame.key.get_pressed()\\n\\t\\tif keys[pygame.K_w]:\\n\\t\\t\\tplayer_pos.y -= 300 * dt * speed * scale\\n\\t\\tif keys[pygame.K_s]:\\n\\t\\t\\tplayer_pos.y += 300 * dt * speed * scale\\n\\t\\tif keys[pygame.K_a]:\\n\\t\\t\\tplayer_pos.x -= 300 * dt * speed * scale\\n\\t\\tif keys[pygame.K_d]:\\n\\t\\t\\tplayer_pos.x += 300 * dt * speed * scale\\n\\t\\tpygame.draw.circle(screen, &quot;white&quot;, obs1_pos, 40*scale)\\n\\t\\tpygame.draw.circle(screen, &quot;white&quot;, obs2_pos, 40*scale)\\n\\t\\tpygame.draw.circle(screen, &quot;green&quot;, speedbo_pos, 20*scale)\\n\\t\\tpygame.draw.circle(screen, &quot;red&quot;, speedloss_pos, 60*scale)\\n\\t\\tvelox = velox + 2\\n\\t\\tobs1_pos.y += (player_pos.y - obs1_pos.y) * 0.02 * scale\\n\\t\\tobs1_pos.x += (player_pos.x - obs1_pos.x) * 0.02 * scale\\n\\t\\tobs2_pos.y += (player_pos.y - obs2_pos.y) * 0.02 * scale\\n\\t\\tobs2_pos.x += (player_pos.x - obs2_pos.x) * 0.02 * scale\\n\\t\\tvelo = velo + 4\\n\\t\\tpygame.display.flip()\\n\\t\\tdt = clock.tick(60) / 1000\\n\\t\\tdef resetSpeed():\\n\\t\\t\\tglobal speed\\n\\t\\t\\tglobal speedbo_pos\\n\\t\\t\\tspeedbo_pos = pygame.Vector2(random.randint(64,X-64),random.randint(64,Y-64))\\n\\t\\t\\tspeed = 1\\n\\t\\tdef resetSpeed1():\\n\\t\\t\\tglobal speed\\n\\t\\t\\tglobal speedloss_pos\\n\\t\\t\\tspeedloss_pos = pygame.Vector2(random.randint(64,X-64),random.randint(64,Y-64))\\n\\t\\t\\tspeed = 1\\n\\t\\tif obs1_pos.y &gt; Y*1.08:\\n\\t\\t\\tobs1_pos = pygame.Vector2(obs1w1, screen.get_height() - obsy)\\n\\t\\t\\tvelo = 0\\n\\t\\t\\tvelox = 0\\n\\t\\t\\tobs1w1 = obs1w1 - X*0.125\\n\\t\\t\\tif obs1_pos.x &lt; 0:\\n\\t\\t\\t\\tobs1w1 = X*1.08\\n\\t\\tif obs2_pos.y &gt; Y*1.08:\\n\\t\\t\\tobs2_pos = pygame.Vector2(obs2w1, screen.get_height() - obsy)\\n\\t\\t\\tvelo = 0\\n\\t\\t\\tvelox = 0\\n\\t\\t\\tobs2w1 = obs2w1 - X*0.125\\n\\t\\t\\tif obs2_pos.x &lt; 0:\\n\\t\\t\\t\\tobs2w1 = X*1.08\\n\\t\\tif math.sqrt((obs1_pos.x - player_pos.x)*(obs1_pos.x - player_pos.x) + (obs1_pos.y - player_pos.y)*(obs1_pos.y - player_pos.y)) - ((40 + 40)* scale) &lt; 0:\\n\\t\\t\\tscreen.fill(&quot;red&quot;)\\n\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\ttext = font.render('You lose', True, black, red)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\t\\trunning = False\\n\\t\\tif math.sqrt((obs2_pos.x - player_pos.x)*(obs2_pos.x - player_pos.x) + (obs2_pos.y - player_pos.y)*(obs2_pos.y - player_pos.y)) - ((40 + 40)* scale) &lt; 0:\\n\\t\\t\\tscreen.fill(&quot;red&quot;)\\n\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\ttext = font.render('You lose', True, black, red)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\t\\trunning = False\\n\\t\\tif math.sqrt((speedbo_pos.x - player_pos.x)*(speedbo_pos.x - player_pos.x) + (speedbo_pos.y - player_pos.y)*(speedbo_pos.y - player_pos.y)) - ((20 + 40)* scale) &lt; 0:\\n\\t\\t\\tspeed = 1.5\\n\\t\\t\\ttime.sleep(0.5)\\n\\t\\t\\tscore += 1\\n\\t\\t\\tif score == 5:\\n\\t\\t\\t\\tscreen.fill(&quot;green&quot;)\\n\\t\\t\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\t\\t\\ttext = font.render('You win!', True, black, green)\\n\\t\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\t\\tpygame.display.flip()\\n\\t\\t\\t\\trunning = False\\n\\t\\t\\telse:\\n\\t\\t\\t\\tspeedbo_pos = pygame.Vector2(2000,1000)\\n\\t\\t\\t\\tstart_time = threading.Timer(10,resetSpeed)\\n\\t\\t\\t\\tstart_time.start()\\n\\t\\tif math.sqrt((speedloss_pos.x - player_pos.x)*(speedloss_pos.x - player_pos.x) + (speedloss_pos.y - player_pos.y)*(speedloss_pos.y - player_pos.y)) - ((60 + 40)* scale) &lt; 0:\\n\\t\\t\\tspeed = 0.6\\n\\t\\t\\tspeedloss_pos = pygame.Vector2(2000,1000)\\n\\t\\t\\tstart_time = threading.Timer(10,resetSpeed1)\\n\\t\\t\\tstart_time.start()\\n\\t\\tif math.sqrt((speedloss_pos.x - speedbo_pos.x)*(speedloss_pos.x - speedbo_pos.x) + (speedloss_pos.y - speedbo_pos.y)*(speedloss_pos.y - speedbo_pos.y)) - ((60 + 20)* scale) &lt; 0:\\n\\t\\t\\tobreset = random.randint(1,2)\\n\\t\\t\\tif obreset == 1:\\n\\t\\t\\t\\tspeedloss_pos = pygame.Vector2(random.randint(64,1216),random.randint(64,656))\\n\\t\\t\\telse:\\n\\t\\t\\t\\tspeedbo_pos = pygame.Vector2(random.randint(64,1216),random.randint(64,656))\\n\\t\\tif math.sqrt((obs2_pos.x - obs1_pos.x)*(obs2_pos.x - obs1_pos.x) + (obs2_pos.y - obs1_pos.y)*(obs2_pos.y - obs1_pos.y)) - ((40 + 40)) &lt; 0:\\n\\t\\t\\tobreset = random.randint(1,2)\\n\\t\\t\\tif obreset == 1:\\n\\t\\t\\t\\tobs1_pos.x = 640\\n\\t\\t\\t\\tobs1_pos.y = -80\\n\\t\\t\\telse:\\n\\t\\t\\t\\tobs2_pos.x = 150\\n\\t\\t\\t\\tobs2_pos.y = -80\\n\\t\\tpygame.display.flip()\\n\\telif start == 0:\\n\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 100)\\n\\t\\ttext = font.render('Press space to begin!', True, black, blue)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\telif start == 1:\\n\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 150)\\n\\t\\ttext = font.render('Instructions', True, black, blue)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\telif start == 2:\\n\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 80)\\n\\t\\ttext = font.render('Collect 5 green orbs to win!', True, black, blue)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\telif start == 3:\\n\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 80)\\n\\t\\ttext = font.render('They also give you a speed boost!', True, black, blue)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\telif start == 4:\\n\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 80)\\n\\t\\ttext = font.render('Red ones decrease your speed.', True, black, blue)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\telif start == 5:\\n\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 80)\\n\\t\\ttext = font.render('Dont touch the white orbs.', True, black, blue)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\telif start == 6:\\n\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 80)\\n\\t\\ttext = font.render('Also, dont leave the screen.', True, black, blue)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\telif start == 7:\\n\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 80)\\n\\t\\ttext = font.render('Use W, A, S and D to move!', True, black, blue)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\telif start == 8:\\n\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 50)\\n\\t\\ttext = font.render('Use the up and down arrows to change the settings', True, black, blue)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\telif start == 9:\\n\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 80)\\n\\t\\tif settingres == 0:\\n\\t\\t\\tscale = 1\\n\\t\\t\\ttext = font.render('720 X 1280', True, black, blue)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif settingres == 1:\\n\\t\\t\\tscale = 1.5\\n\\t\\t\\tX = 1920\\n\\t\\t\\tY= 1080\\n\\t\\t\\ttext = font.render('1080 X 1920', True, black, blue)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (1280 // 2, 720 // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif settingres == 2:\\n\\t\\t\\tscale = 2\\n\\t\\t\\tX = 2560\\n\\t\\t\\tY= 1440\\n\\t\\t\\ttext = font.render('1440 X 2560', True, black, blue)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (1280 // 2, 720 // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif settingres == 3:\\n\\t\\t\\tscale = 3\\n\\t\\t\\tX = 3840\\n\\t\\t\\tY= 2160\\n\\t\\t\\ttext = font.render('2160 X 3840', True, black, blue)\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (1280 // 2, 720 // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif settingres == -1:\\n\\t\\t\\tsettingres = 3\\n\\t\\tif settingres == 4:\\n\\t\\t\\tsettingres = 0\\n\\telif start == 10:\\n\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 80)\\n\\t\\tif diffspeed == 0:\\n\\t\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\t\\tobsspeed = 1\\n\\t\\t\\ttext = font.render('Very Easy', True, black, blue)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif diffspeed == 1:\\n\\t\\t\\tscreen.fill(&quot;green&quot;)\\n\\t\\t\\tobsspeed = 1.1\\n\\t\\t\\ttext = font.render('Easy', True, black, green)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif diffspeed == 2:\\n\\t\\t\\tscreen.fill(yellow)\\n\\t\\t\\tobsspeed = 1.2\\n\\t\\t\\ttext = font.render('Medium', True, black, yellow)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif diffspeed == 3:\\n\\t\\t\\tscreen.fill(orange)\\n\\t\\t\\tobsspeed = 1.35\\n\\t\\t\\ttext = font.render('Hard', True, black, orange)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif diffspeed == 4:\\n\\t\\t\\tscreen.fill(red)\\n\\t\\t\\tobsspeed = 1.5\\n\\t\\t\\ttext = font.render('Extremely Hard', True, black, red)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif diffspeed == 5:\\n\\t\\t\\tscreen.fill(black)\\n\\t\\t\\tobsspeed = 1.7\\n\\t\\t\\ttext = font.render('Impossible', True, grey, black)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif diffspeed == 6:\\n\\t\\t\\tscreen.fill(white)\\n\\t\\t\\tobsspeed = 2\\n\\t\\t\\ttext = font.render('Help Me', True, black, white)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif diffspeed == -1:\\n\\t\\t\\tdiffspeed = 6\\n\\t\\tif diffspeed == 7:\\n\\t\\t\\tdiffspeed = 0\\n\\telif start == 11:\\n\\t\\tprint(&quot;hello&quot;)\\n\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 80)\\n\\t\\tif difflength == 0:\\n\\t\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\t\\tgamelength = 3\\n\\t\\t\\ttext = font.render('Very Short', True, black, blue)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif difflength == 1:\\n\\t\\t\\tscreen.fill(&quot;green&quot;)\\n\\t\\t\\tgamelength = 5\\n\\t\\t\\ttext = font.render('Short', True, black, green)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif difflength == 2:\\n\\t\\t\\tscreen.fill(yellow)\\n\\t\\t\\tgamelength = 7\\n\\t\\t\\ttext = font.render('Somewhat Long', True, black, yellow)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif difflength == 3:\\n\\t\\t\\tscreen.fill(orange)\\n\\t\\t\\tgamelength = 10\\n\\t\\t\\ttext = font.render('Long', True, black, orange)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif difflength == 4:\\n\\t\\t\\tscreen.fill(red)\\n\\t\\t\\tgamelength = 15\\n\\t\\t\\ttext = font.render('Extremely Long', True, black, red)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif difflength == 5:\\n\\t\\t\\tscreen.fill(black)\\n\\t\\t\\tgamelength = 20\\n\\t\\t\\ttext = font.render('Impossibly Long', True, grey, black)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif difflength == 6:\\n\\t\\t\\tscreen.fill(white)\\n\\t\\t\\tgamelength = 30\\n\\t\\t\\ttext = font.render('Longer than my attention span', True, black, white)\\n\\t\\t\\tX = 1280\\n\\t\\t\\tY= 720\\n\\t\\t\\ttextRect = text.get_rect()\\n\\t\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\t\\tscreen.blit(text, textRect)\\n\\t\\t\\tpygame.display.flip()\\n\\t\\tif difflength == -1:\\n\\t\\t\\tdifflength = 6\\n\\t\\tif difflength == 7:\\n\\t\\t\\tdifflength = 0\\n\\telif start == 12:\\n\\t\\tscreen.fill(&quot;blue&quot;)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 80)\\n\\t\\ttext = font.render('Press 1 to begin!', True, black, blue)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (1280 // 2, 720 // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\telif start == 13:\\n\\t\\tscreen.fill(red)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 250)\\n\\t\\ttext = font.render('3', True, black, red)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\t\\ttime.sleep(1)\\n\\t\\tstart += 1\\n\\telif start == 14:\\n\\t\\tscreen.fill(orange)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 250)\\n\\t\\ttext = font.render('2', True, black, orange)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\t\\ttime.sleep(1)\\n\\t\\tstart += 1\\n\\telif start == 15:\\n\\t\\tscreen.fill(yellow)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 250)\\n\\t\\ttext = font.render('1', True, black, yellow)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\t\\ttime.sleep(1)\\n\\t\\tstart += 1\\n\\telif start == 16:\\n\\t\\tscreen.fill(green)\\n\\t\\tfont = pygame.font.SysFont('bahnschrift', 250)\\n\\t\\ttext = font.render('GO!', True, black, green)\\n\\t\\ttextRect = text.get_rect()\\n\\t\\ttextRect.center = (X // 2, Y // 2)\\n\\t\\tscreen.blit(text, textRect)\\n\\t\\tpygame.display.flip()\\n\\t\\ttime.sleep(1)\\n\\t\\tstart += 1\\ntime.sleep(2)\\npygame.quit()\",\n",
       " 'from functools import partial\\nfrom asyncio import run\\nfrom aiometer import run_all\\nasync def main():\\n\\tresult_donations = run_all(\\n\\t\\t[partial(ApiGuara.get_donations, page) for page in range(50)],\\n\\t\\tmax_at_once=10\\n\\t\\t)\\n\\tawait result_donations\\nrun(main())',\n",
       " \"async def get_donations(self, page:int) -&gt; None:\\n\\t\\tasync with AsyncClient(\\n\\t\\t\\tbase_url=f'{self.url}',\\n\\t\\t\\theaders=self.headers,\\n\\t\\t\\ttimeout=None) as asyncclient:\\n\\t\\t\\ttry:\\n\\t\\t\\t\\tr = await asyncclient.get(f'/donations?page={page}')\\n\\t\\t\\t\\tdonations_json = r.json()['data']\\n\\t\\t\\t\\tfor donation in donations_json:\\n\\t\\t\\t\\t\\tdonation['_id'] = donation.pop('id')\\n\\t\\t\\t\\t\\ttry:\\n\\t\\t\\t\\t\\t\\tpass\\n\\t\\t\\t\\t\\texcept errors.DuplicateKeyError:\\n\\t\\t\\t\\t\\t\\tpass\\n\\t\\t\\tfinally:\\n\\t\\t\\t\\tawait asyncclient.aclose()\",\n",
       " 'async def get_users(\\n\\t\\t\\tdb: sqlalchemy.ext.AsyncSession,\\n\\t\\t\\tstart_id: int = ...,\\n\\t\\t\\tend_id: int = ...,\\n\\t\\t):\\n\\treturn await db.execute(sql.select(models.User).offset(start_id).limit(\\n\\t\\tabs(end_id - start_id) + 1\\n\\t))',\n",
       " \"@router.get('/')\\nasync def get_users(\\n\\t\\t\\tpage: int = 1,\\n\\t\\t\\tpage_size: int = 20,\\n\\t\\t\\tdb: asyncio.AsyncSession = fastapi.Depends(crud.get_session),\\n\\t\\t):\\n\\tusers = await crud.get_users(\\n\\t\\tdb,\\n\\t\\tstart_id=((page - 1) * page_size),\\n\\t\\tend_id=((page - 1) * page_size)\\n\\t)\\n\\tfor user in users:\\n\\t\\tprint(user)\\n\\tprint('!')\\n\\tfor user in users:\\n\\t\\tprint(user)\\n\\tprint('!')\\n\\tprint({\\n\\t\\t'error': False,\\n\\t\\t'page': 1,\\n\\t\\t'page_size': 20,\\n\\t\\t'users': [{\\n\\t\\t\\t'id': user.id,\\n\\t\\t\\t'email': user.email,\\n\\t\\t\\t'is_banned': user.is_banned,\\n\\t\\t\\t'balance': 0,\\n\\t\\t} for user in users],\\n\\t}\\n\\t...\\n)\",\n",
       " \"(&lt;models.User object at 0x7f152fa3b760&gt;,)\\n!\\n!\\n{'error': False, 'page': 1, 'page_size': 20, 'users': []}\",\n",
       " \"def start_requests(self):\\n\\t\\tfor payload in self.checkin_checkout():\\n\\t\\t\\tyield scrapy.Request(\\n\\t\\t\\t\\turl=self.api_url,\\n\\t\\t\\t\\theaders=self.headers,\\n\\t\\t\\t\\tbody=payload,\\n\\t\\t\\t\\tmethod='POST',\\n\\t\\t\\t\\tcallback=self.parse,\\n\\t\\t\\t\\tdont_filter=True,\\n\\t\\t\\t\\tmeta={'dpayload': payload}  \\n\\t\\t\\t)\\ndef checkin_checkout(self):\\n\\t  data = json.loads(self.default_payload)\\n\\t\\tcurrent_date = datetime.date.today()\\n\\t\\tif current_date.weekday() == 6:\\n\\t\\t\\tcurrent_date = current_date + datetime.timedelta(days=1)\\n\\t\\tend_date = current_date + datetime.timedelta(days=30)\\n\\t\\tcheckin_dates = []\\n\\t\\tcheckout_dates = []\\n\\t\\twhile current_date &lt;= end_date:\\n\\t\\t\\tif current_date.weekday() == 4:\\n\\t\\t\\t\\tcheckin_dates.append(current_date)\\n\\t\\t\\tif current_date.weekday() == 6:\\n\\t\\t\\t\\tcheckout_dates.append(current_date)\\n\\t\\t\\tcurrent_date += datetime.timedelta(days=1)\\n\\t\\tdate_payloads = []\\n\\t\\tfor i in range(len(checkout_dates)):\\n\\t\\t\\tcheckin_date = checkin_dates[i]\\n\\t\\t\\tcheckout_date = checkout_dates[i]\\n\\t\\t\\tdata['variables']['staysSearchRequest']['rawParams'][2]['filterValues'] = str(checkin_date)\\n\\t\\t\\tdata['variables']['staysSearchRequest']['rawParams'][3]['filterValues'] = str(checkout_date)\\n\\t\\t\\tdate_payload = json.dumps(data)\\n\\t\\t\\tdate_payloads.append(date_payload)\\n\\t\\treturn date_payloads\\ndef parse(self, response):\\n\\t\\tdata = json.loads(response.text)\\n\\t\\tinfo = data['data']['presentation']['explore']['sections']['sectionIndependentData']['staysSearch']['searchResults']\\n\\t\\tfor i in range(0, 17):\\n\\t\\t\\tdate = strftime(&quot;%d/%m/%Y&quot;)\\n\\t\\t\\tid_value = info[i]['listing']['id']\\n\\t\\t\\tname = info[i]['listing'][&quot;name&quot;]\\n\\t\\t\\trating = info[i]['listing'][&quot;avgRatingLocalized&quot;]\\n\\t\\t\\tPricePerNight = info[i]['pricingQuote'][&quot;structuredStayDisplayPrice&quot;]['primaryLine']['accessibilityLabel'].replace(&quot;$&quot;, &quot;&quot;).replace(&quot;total&quot;, &quot;&quot;).strip()[:2]\\n\\t\\t\\ttotalPrice_inDollars = info[i]['pricingQuote'][&quot;structuredStayDisplayPrice&quot;]['secondaryLine']['price'].replace(&quot;$&quot;, &quot;&quot;).replace(&quot;total&quot;, &quot;&quot;).strip()\\n\\t\\t\\tcheckIn_date = data['data']['presentation']['explore']['sections']['sectionIndependentData']['staysSearch']['filters']['filterState'][4]['value']['dateValue']\\n\\t\\t\\tcheckOut_date = data['data']['presentation']['explore']['sections']['sectionIndependentData']['staysSearch']['filters']['filterState'][5]['value']['dateValue']\\n\\t\\t\\turl = urljoin(self.rooms_url, id_value)\\n\\t\\t\\tyield {\\n\\t\\t\\t\\t'date': date,\\n\\t\\t\\t\\t'id': id_value,\\n\\t\\t\\t\\t&quot;title&quot;: name,\\n\\t\\t\\t\\t&quot;PricePerNight&quot;: PricePerNight,\\n\\t\\t\\t\\t&quot;totalPrice_inDollars&quot;: totalPrice_inDollars,\\n\\t\\t\\t\\t&quot;checkIn_date&quot;: checkIn_date,\\n\\t\\t\\t\\t'checkOut_date': checkOut_date,\\n\\t\\t\\t\\t&quot;rating&quot;: rating,\\n\\t\\t\\t\\t'url': url\\n\\t\\t\\t}\\n\\t\\turl_path = data['data']['presentation']['explore']['sections']['sectionIndependentData']['staysSearch']\\n\\t\\tx = response.meta.get('dpayload')\\n\\t\\tfor i in range(0, 13):\\n\\t\\t\\tpayload_cursor = json.loads(x)\\n\\t\\t\\tpage_cursor = url_path['paginationInfo']['pageCursors'][i]\\n\\t\\t\\tpayload_cursor['variables']['staysSearchRequest']['cursor'] = page_cursor\\n\\t\\t\\tnext_page_payload = json.dumps(payload_cursor)\\n\\t\\t\\tyield scrapy.Request(\\n\\t\\t\\t\\turl=self.api_url,\\n\\t\\t\\t\\theaders=self.headers,\\n\\t\\t\\t\\tbody=next_page_payload,\\n\\t\\t\\t\\tmethod='POST',\\n\\t\\t\\t\\tcallback=self.parse,\\n\\t\\t\\t\\tdont_filter=True\\n\\t\\t\\t)\",\n",
       " \"Traceback (most recent call last):\\n  File &quot;C:\\\\Users\\\\Haseeb Tahir\\\\Desktop\\\\workk\\\\myvenv\\\\Lib\\\\site-packages\\\\scrapy\\\\utils\\\\defer.py&quot;, line 277, in iter_errback\\n\\tyield next(it)\\n\\t\\t  ^^^^^^^^\\n  File &quot;C:\\\\Users\\\\Haseeb Tahir\\\\Desktop\\\\workk\\\\myvenv\\\\Lib\\\\site-packages\\\\scrapy\\\\utils\\\\python.py&quot;, line 350, in __next__\\n\\treturn next(self.data)\\n\\t\\t   ^^^^^^^^^^^^^^^\\n  File &quot;C:\\\\Users\\\\Haseeb Tahir\\\\Desktop\\\\workk\\\\myvenv\\\\Lib\\\\site-packages\\\\scrapy\\\\utils\\\\python.py&quot;, line 350, in __next__\\n\\treturn next(self.data)\\n\\t\\t   ^^^^^^^^^^^^^^^\\n  File &quot;C:\\\\Users\\\\Haseeb Tahir\\\\Desktop\\\\workk\\\\myvenv\\\\Lib\\\\site-packages\\\\scrapy\\\\core\\\\spidermw.py&quot;, line 106, in process_sync\\n\\tfor r in iterable:\\n  File &quot;C:\\\\Users\\\\Haseeb Tahir\\\\Desktop\\\\workk\\\\myvenv\\\\Lib\\\\site-packages\\\\scrapy\\\\spidermiddlewares\\\\offsite.py&quot;, line 28, in &lt;genexpr&gt;\\n\\treturn (r for r in result or () if self._filter(r, spider))\\n\\t\\t   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File &quot;C:\\\\Users\\\\Haseeb Tahir\\\\Desktop\\\\workk\\\\myvenv\\\\Lib\\\\site-packages\\\\scrapy\\\\core\\\\spidermw.py&quot;, line 106, in process_sync\\n\\tfor r in iterable:\\n  File &quot;C:\\\\Users\\\\Haseeb Tahir\\\\Desktop\\\\workk\\\\myvenv\\\\Lib\\\\site-packages\\\\scrapy\\\\spidermiddlewares\\\\referer.py&quot;, line 352, in &lt;genexpr&gt;\\n\\treturn (self._set_referer(r, response) for r in result or ())\\n\\t\\t   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File &quot;C:\\\\Users\\\\Haseeb Tahir\\\\Desktop\\\\workk\\\\myvenv\\\\Lib\\\\site-packages\\\\scrapy\\\\core\\\\spidermw.py&quot;, line 106, in process_sync\\n\\tfor r in iterable:\\n  File &quot;C:\\\\Users\\\\Haseeb Tahir\\\\Desktop\\\\workk\\\\myvenv\\\\Lib\\\\site-packages\\\\scrapy\\\\spidermiddlewares\\\\urllength.py&quot;, line 27, in &lt;genexpr&gt;\\n\\treturn (r for r in result or () if self._filter(r, spider))\\n\\t\\t   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File &quot;C:\\\\Users\\\\Haseeb Tahir\\\\Desktop\\\\workk\\\\myvenv\\\\Lib\\\\site-packages\\\\scrapy\\\\core\\\\spidermw.py&quot;, line 106, in process_sync\\n\\tfor r in iterable:\\n  File &quot;C:\\\\Users\\\\Haseeb Tahir\\\\Desktop\\\\workk\\\\myvenv\\\\Lib\\\\site-packages\\\\scrapy\\\\spidermiddlewares\\\\depth.py&quot;, line 31, in &lt;genexpr&gt;\\n\\treturn (r for r in result or () if self._filter(r, response, spider))\\n\\t\\t   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File &quot;C:\\\\Users\\\\Haseeb Tahir\\\\Desktop\\\\workk\\\\myvenv\\\\Lib\\\\site-packages\\\\scrapy\\\\core\\\\spidermw.py&quot;, line 106, in process_sync\\n\\tfor r in iterable:\\n  File &quot;C:\\\\Users\\\\Haseeb Tahir\\\\Desktop\\\\workk\\\\travelling\\\\travelling\\\\spiders\\\\airbnb2.py&quot;, line 125, in parse\\n\\tpayload_cursor = json.loads(x)\\n\\t\\t\\t\\t\\t ^^^^^^^^^^^^^\\n  File &quot;C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\\\\Lib\\\\json\\\\__init__.py&quot;, line 339, in loads\\n\\traise TypeError(f'the JSON object must be str, bytes or bytearray, '\\nTypeError: the JSON object must be str, bytes or bytearray, not NoneType\",\n",
       " \"from borb.pdf.canvas.layout.page_layout.multi_column_layout import SingleColumnLayout\\nfrom borb.pdf.canvas.layout.page_layout.page_layout import PageLayout\\nfrom borb.pdf.canvas.layout.text.paragraph import Paragraph\\nfrom borb.pdf.document.document import Document\\nfrom borb.pdf.page.page import Page\\nfrom borb.pdf.pdf import PDF\\nfrom borb.pdf.canvas.layout.page_layout.multi_column_layout import SingleColumnLayout\\nfrom decimal import Decimal\\nfrom borb.pdf.canvas.layout.table.fixed_column_width_table import (\\n\\tFixedColumnWidthTable as Table,\\n)\\nfrom borb.pdf.canvas.layout.layout_element import Alignment\\nfrom borb.pdf.canvas.layout.image.image import Image\\nfrom datetime import datetime\\nimport random\\nfrom borb.pdf.pdf import PDF\\nfrom borb.pdf.canvas.color.color import HexColor, X11Color\\nfrom borb.pdf.canvas.layout.table.fixed_column_width_table import (\\n\\tFixedColumnWidthTable as Table,\\n)\\nfrom borb.pdf.canvas.layout.table.table import TableCell\\nfrom borb.pdf import Page\\nimport json\\nfrom google.cloud import storage\\nfrom datetime import datetime\\nimport firebase_admin\\nfrom firebase_admin import credentials\\nfrom firebase_admin import firestore\\nimport logging\\nexport_time = datetime.now().strftime(&quot;%d_%m_%Y&quot;)\\ninvoice_date_month = datetime.now().strftime(&quot;%m_%Y&quot;)\\ncred = credentials.ApplicationDefault()\\nfirebase_admin.initialize_app(cred)\\ndb = firestore.client()\\nlogging.basicConfig(format='%(message)s')\\ndef generate_pdf_invoice(data, context):\\n\\t&quot;&quot;&quot; Triggered by a change to a Firestore document.\\n\\tArgs:\\n\\t\\tdata (dict): The event payload.\\n\\t\\tcontext (google.cloud.functions.Context): Metadata for the event.\\n\\t&quot;&quot;&quot;\\n\\tlogging.warning(data)\\n\\tlogging.warning(context)\\n\\tpadding_value = Decimal(5)  \\n\\ttable_001 = Table(number_of_rows=5, number_of_columns=4)\\n\\ttable_001.add(\\n\\t\\tParagraph(\\n\\t\\t\\t&quot;Raó Social&quot;, font=&quot;Helvetica-Bold&quot;, horizontal_alignment=Alignment.LEFT\\n\\t\\t)\\n\\t)\\n\\ttable_001.add(\\n\\t\\tParagraph(\\n\\t\\t\\tdata[&quot;value&quot;][&quot;fields&quot;][&quot;seller_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][\\n\\t\\t\\t\\t&quot;seller_name&quot;\\n\\t\\t\\t][&quot;stringValue&quot;]\\n\\t\\t)\\n\\t)\\n\\ttable_001.add(\\n\\t\\tParagraph(&quot;Data&quot;, font=&quot;Helvetica-Bold&quot;, horizontal_alignment=Alignment.RIGHT)\\n\\t)\\n\\tnow = datetime.now()\\n\\ttable_001.add(Paragraph(&quot;%d/%d/%d&quot; % (now.day, now.month, now.year)))\\n\\ttable_001.add(\\n\\t\\tParagraph(&quot;Carrer&quot;, font=&quot;Helvetica-Bold&quot;, horizontal_alignment=Alignment.LEFT)\\n\\t)\\n\\ttable_001.add(\\n\\t\\tParagraph(\\n\\t\\t\\tdata[&quot;value&quot;][&quot;fields&quot;][&quot;seller_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;seller_address_street&quot;][&quot;stringValue&quot;]\\n\\t\\t)\\n\\t)\\n\\ttable_001.add(\\n\\t\\tParagraph(\\n\\t\\t\\t&quot;Factura \\n\\t\\t)\\n\\t)\\n\\ttable_001.add(\\n\\t\\tParagraph(str(data[&quot;value&quot;][&quot;fields&quot;][&quot;invoice_number&quot;][&quot;integerValue&quot;]))\\n\\t)\\n\\ttable_001.add(\\n\\t\\tParagraph(\\n\\t\\t\\t&quot;Població&quot;, font=&quot;Helvetica-Bold&quot;, horizontal_alignment=Alignment.LEFT\\n\\t\\t)\\n\\t)\\n\\ttable_001.add(\\n\\t\\tParagraph(\\n\\t\\t\\tdata[&quot;value&quot;][&quot;fields&quot;][&quot;seller_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;seller_address_city_postal_code_country&quot;][&quot;stringValue&quot;]\\n\\t\\t)\\n\\t)\\n\\ttable_001.add(\\n\\t\\tParagraph(\\n\\t\\t\\t&quot;Telèfon&quot;, font=&quot;Helvetica-Bold&quot;, horizontal_alignment=Alignment.RIGHT\\n\\t\\t)\\n\\t)\\n\\ttable_001.add(\\n\\t\\tParagraph(\\n\\t\\t\\tdata[&quot;value&quot;][&quot;fields&quot;][&quot;seller_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][\\n\\t\\t\\t\\t&quot;seller_phone&quot;\\n\\t\\t\\t][&quot;stringValue&quot;]\\n\\t\\t)\\n\\t)\\n\\ttable_001.add(\\n\\t\\tParagraph(\\n\\t\\t\\t&quot;Venciment&quot;, font=&quot;Helvetica-Bold&quot;, horizontal_alignment=Alignment.LEFT\\n\\t\\t)\\n\\t)\\n\\ttable_001.add(Paragraph(&quot;%d/%d/%d&quot; % (now.day+4, now.month, now.year)))\\n\\ttable_001.add(\\n\\t\\tParagraph(&quot;Email&quot;, font=&quot;Helvetica-Bold&quot;, horizontal_alignment=Alignment.RIGHT)\\n\\t)\\n\\ttable_001.add(\\n\\t\\tParagraph(\\n\\t\\t\\tdata[&quot;value&quot;][&quot;fields&quot;][&quot;seller_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][\\n\\t\\t\\t\\t&quot;seller_email&quot;\\n\\t\\t\\t][&quot;stringValue&quot;]\\n\\t\\t)\\n\\t)\\n\\ttable_001.add(\\n\\t\\tParagraph(\\n\\t\\t\\t&quot;BIC&quot;, font=&quot;Helvetica-Bold&quot;, horizontal_alignment=Alignment.LEFT\\n\\t\\t)\\n\\t)\\n\\ttable_001.add(Paragraph(data[&quot;value&quot;][&quot;fields&quot;][&quot;seller_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;seller_BIC&quot;][&quot;stringValue&quot;]))\\n\\tsmall_font_size = 8  \\n\\ttable_001.add(\\n\\t\\tParagraph(\\n\\t\\t\\t&quot;IBAN&quot;, font=&quot;Helvetica-Bold&quot;, horizontal_alignment=Alignment.RIGHT\\n\\t\\t)\\n\\t)\\n\\ttable_001.add(Paragraph(data[&quot;value&quot;][&quot;fields&quot;][&quot;seller_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;seller_IBAN&quot;][&quot;stringValue&quot;], font_size=small_font_size))\\n\\ttable_001.set_padding_on_all_cells(padding_value, padding_value, padding_value, padding_value)\\n\\ttable_001.no_borders()\\n\\ttable_002 = Table(number_of_rows=6, number_of_columns=1)\\n\\ttable_002.add(\\n\\t\\tParagraph(\\n\\t\\t\\t&quot;Facturat a&quot;,\\n\\t\\t\\tbackground_color=HexColor(&quot;263238&quot;),\\n\\t\\t\\tfont_color=X11Color(&quot;White&quot;),\\n\\t\\t)\\n\\t)\\n\\ttable_002.add(\\n\\t\\tParagraph(data[&quot;value&quot;][&quot;fields&quot;][&quot;buyer_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;buyer_name&quot;][&quot;stringValue&quot;])\\n\\t)  \\n\\ttable_002.add(\\n\\t\\tParagraph(data[&quot;value&quot;][&quot;fields&quot;][&quot;buyer_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;buyer_address_street&quot;][&quot;stringValue&quot;])\\n\\t)  \\n\\ttable_002.add(\\n\\t\\tParagraph(\\n\\t\\t\\tdata[&quot;value&quot;][&quot;fields&quot;][&quot;buyer_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;buyer_address_city_postal_code_country&quot;][&quot;stringValue&quot;]\\n\\t\\t)\\n\\t)  \\n\\ttable_002.add(\\n\\t\\tParagraph(data[&quot;value&quot;][&quot;fields&quot;][&quot;buyer_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;buyer_phone&quot;][&quot;stringValue&quot;])\\n\\t)  \\n\\ttable_002.add(\\n\\t\\tParagraph(data[&quot;value&quot;][&quot;fields&quot;][&quot;buyer_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;buyer_email&quot;][&quot;stringValue&quot;])\\n\\t)  \\n\\ttable_002.set_padding_on_all_cells(padding_value, padding_value, padding_value, padding_value)\\n\\ttable_002.no_borders()\\n\\ttable_003 = Table(number_of_rows=7, number_of_columns=4)\\n\\tfor h in [&quot;Descripció&quot;, &quot;Quantitat&quot;, &quot;Preu per unitat&quot;, &quot;Import&quot;]:\\n\\t\\ttable_003.add(\\n\\t\\t\\tTableCell(\\n\\t\\t\\t\\tParagraph(h, font_color=X11Color(&quot;White&quot;)),\\n\\t\\t\\t\\tbackground_color=HexColor(&quot;000000&quot;),\\n\\t\\t\\t)\\n\\t\\t)\\n\\todd_color = HexColor(&quot;BBBBBB&quot;)\\n\\teven_color = HexColor(&quot;FFFFFF&quot;)\\n\\tfor row_number, item in enumerate(\\n\\t\\t[\\n\\t\\t\\t(\\n\\t\\t\\t\\tdata[&quot;value&quot;][&quot;fields&quot;][&quot;product&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;description&quot;][&quot;stringValue&quot;],\\n\\t\\t\\t\\tdata[&quot;value&quot;][&quot;fields&quot;][&quot;product&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;quantity&quot;][&quot;doubleValue&quot;],\\n\\t\\t\\t\\tdata[&quot;value&quot;][&quot;fields&quot;][&quot;product&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;amount&quot;][&quot;doubleValue&quot;],\\n\\t\\t\\t\\tlist(data[&quot;value&quot;][&quot;fields&quot;][&quot;product&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;amount&quot;].values())[0]*data[&quot;value&quot;][&quot;fields&quot;][&quot;product&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;quantity&quot;][&quot;doubleValue&quot;]\\n\\t\\t\\t),\\n\\t\\t]\\n\\t):\\n\\t\\tc = even_color if row_number % 2 == 0 else odd_color\\n\\t\\ttable_003.add(TableCell(Paragraph(item[0]), background_color=c))\\n\\t\\ttable_003.add(TableCell(Paragraph(str(item[1])), background_color=c))\\n\\t\\ttable_003.add(TableCell(Paragraph(&quot;€ &quot; + str(item[2])), background_color=c))\\n\\t\\ttable_003.add(TableCell(Paragraph(&quot;€ &quot; + str(item[3])), background_color=c))\\n\\tfor row_number in range(3, 5):\\n\\t\\tc = even_color if row_number % 2 == 0 else odd_color\\n\\t\\tfor _ in range(0, 4):\\n\\t\\t\\ttable_003.add(TableCell(Paragraph(&quot; &quot;), background_color=c))\\n\\ttable_003.add(\\n\\t\\tTableCell(\\n\\t\\t\\tParagraph(\\n\\t\\t\\t\\t&quot;Subtotal&quot;, font=&quot;Helvetica-Bold&quot;, horizontal_alignment=Alignment.RIGHT,\\n\\t\\t\\t),\\n\\t\\t\\tcol_span=3,\\n\\t\\t)\\n\\t)\\n\\ttable_003.add(\\n\\t\\tTableCell(\\n\\t\\t\\tParagraph(\\n\\t\\t\\t\\tstr(data[&quot;value&quot;][&quot;fields&quot;][&quot;product&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;amount&quot;][&quot;doubleValue&quot;]),\\n\\t\\t\\t\\thorizontal_alignment=Alignment.RIGHT,\\n\\t\\t\\t)\\n\\t\\t)\\n\\t)\\n\\ttable_003.add(\\n\\t\\tTableCell(\\n\\t\\t\\tParagraph(\\n\\t\\t\\t\\t&quot;IGI&quot;, font=&quot;Helvetica-Bold&quot;, horizontal_alignment=Alignment.RIGHT\\n\\t\\t\\t),\\n\\t\\t\\tcol_span=3,\\n\\t\\t)\\n\\t)\\n\\ttable_003.add(\\n\\t\\tTableCell(\\n\\t\\t\\tParagraph(\\n\\t\\t\\t\\t&quot;{0:.2f}&quot;.format(\\n\\t\\t\\t\\t\\tdata[&quot;value&quot;][&quot;fields&quot;][&quot;product&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;amount&quot;][&quot;doubleValue&quot;]* (4.5 / 100)\\n\\t\\t\\t\\t),\\n\\t\\t\\t\\thorizontal_alignment=Alignment.RIGHT,\\n\\t\\t\\t)\\n\\t\\t)\\n\\t)\\n\\ttable_003.add(\\n\\t\\tTableCell(\\n\\t\\t\\tParagraph(\\n\\t\\t\\t\\t&quot;Total&quot;, font=&quot;Helvetica-Bold&quot;, horizontal_alignment=Alignment.RIGHT\\n\\t\\t\\t),\\n\\t\\t\\tcol_span=3,\\n\\t\\t)\\n\\t)\\n\\ttable_003.add(\\n\\t\\tTableCell(\\n\\t\\t\\tParagraph(\\n\\t\\t\\t\\t&quot;{0:.2f}&quot;.format(\\n\\t\\t\\t\\t\\tdata[&quot;value&quot;][&quot;fields&quot;][&quot;product&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;amount&quot;][&quot;doubleValue&quot;]* (1 + 4.5 / 100)\\n\\t\\t\\t\\t),\\n\\t\\t\\t\\thorizontal_alignment=Alignment.RIGHT,\\n\\t\\t\\t)\\n\\t\\t)\\n\\t)\\n\\ttable_003.set_padding_on_all_cells(padding_value, padding_value, padding_value, padding_value)\\n\\ttable_003.no_borders()\\n\\tpdf = Document()\\n\\tpage = Page()\\n\\tpdf.add_page(page)\\n\\tpage_layout = SingleColumnLayout(page)\\n\\tlogging.warning(&quot;Page height:&quot;)\\n\\tlogging.warning(page.get_page_info().get_height())\\n\\tlogging.warning(&quot;Table&quot;)\\n\\tlogging.warning(table_001)\\n\\tpage_layout.vertical_margin = page.get_page_info().get_height() * Decimal(0.02)\\n\\tpage_layout.add(\\n\\t\\tImage(\\n\\t\\t\\t&quot;https://firebasestorage.googleapis.com/v0/b/my-app.appspot.com/o/stores%2F2322e310-1743-11ed-87c2-9f7ebec4c7dc?alt=media&amp;token=71ebb1be-a9ae-4f49-b3e1-b46619cdfb4a&quot;,\\n\\t\\t\\twidth=Decimal(128),\\n\\t\\t\\theight=Decimal(128),\\n\\t\\t)\\n\\t)\\n\\tlogging.warning(&quot;Adding Table 001...&quot;)\\n\\tlogging.warning(table_001)\\n\\tpage_layout.add(table_001)\\n\\tlogging.warning(&quot;Table 001 added successfully.&quot;)\\n\\tpage_layout.add(Paragraph(&quot; &quot;))\\n\\tlogging.warning(&quot;Adding Table 002...&quot;)\\n\\tlogging.warning(table_002)\\n\\tpage_layout.add(table_002)\\n\\tlogging.warning(&quot;Table 002 added successfully.&quot;)\\n\\tlogging.warning(&quot;Adding Table 003...&quot;)\\n\\tlogging.warning(table_003)\\n\\tpage_layout.add(table_003)\\n\\tlogging.warning(&quot;Table 003 added successfully.&quot;)\\n\\tdb = firestore.Client()\\n\\tdoc_ref = db.collection('my_collection').document('my_document')\\n\\tdoc_id = doc_ref.id\\n\\tstorage_client = storage.Client()\\n\\tbucket = storage_client.bucket(&quot;my-app-prod.appspot.com&quot;)\\n\\tinvoice_id = doc_id\\n\\tfile_name = f&quot;My_App_pagaments_Restaurant_Invoice_{export_time}_{invoice_id}.pdf&quot;\\n\\tblob = bucket.blob(f&quot;Invoices/{invoice_date_month}/{file_name}&quot;)\\n\\twith open(&quot;/tmp/output.pdf&quot;, &quot;wb&quot;) as pdf_file_handle:\\n\\t\\tPDF.dumps(pdf_file_handle, pdf)\\n\\tblob.upload_from_filename(&quot;/tmp/output.pdf&quot;)\\n\\tblob.make_public()\\n\\tpublic_url = blob.public_url\\n\\tseller_email = data[&quot;value&quot;][&quot;fields&quot;][&quot;seller_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;seller_email&quot;][&quot;stringValue&quot;]\\n\\tseller_name = data[&quot;value&quot;][&quot;fields&quot;][&quot;seller_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;seller_name&quot;][&quot;stringValue&quot;]\\n\\tmail_ref = db.collection(u'mail').document()\\n\\tmail_ref.set({\\n\\t\\tu'to': [seller_email, 'myemail@gmail.com'],\\n\\t\\tu'template': {\\n\\t\\t\\tu'name': 'invoice_store_ca',\\n\\t\\t\\tu'data': {\\n\\t\\t\\t\\tu'name': seller_name,\\n\\t\\t\\t\\tu'invoiceNumber': data[&quot;value&quot;][&quot;fields&quot;][&quot;invoice_number&quot;][&quot;integerValue&quot;],\\n\\t\\t\\t\\tu'invoiceName': file_name,\\n\\t\\t\\t\\tu'invoiceUrl': [public_url],\\n\\t\\t\\t},\\n\\t\\t}})\\n\\tprint(\\n\\t\\tf&quot;Blob {blob.name} is publicly accessible at {blob.public_url}&quot;\\n\\t)\\n\\tstore_id = data[&quot;value&quot;][&quot;fields&quot;][&quot;seller_details&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;seller_id&quot;][&quot;stringValue&quot;]\\n\\tdecrease_amount = float(data[&quot;value&quot;][&quot;fields&quot;][&quot;product&quot;][&quot;mapValue&quot;][&quot;fields&quot;][&quot;amount&quot;][&quot;doubleValue&quot;])\\n\\tstore = db.collection('stores').document(store_id)\\n\\tlogging.warning(store_id)\\n\\tlogging.warning(store)\\n\\tincreaseBy = firestore.FieldValue.increment(-decrease_amount);\\n\\tstore.update({&quot;pendingNetAmount&quot;: increaseBy})\",\n",
       " 'restaurants_invoices57tg2dhgll0j Traceback (most recent call last): File &quot;/layers/google.python.pip/pip/lib/python3.9/site-packages/flask/app.py&quot;, line 2529, in wsgi_app response = self.full_dispatch_request() File &quot;/layers/google.python.pip/pip/lib/python3.9/site-packages/flask/app.py&quot;, line 1825, in full_dispatch_request rv = self.handle_user_exception(e) File &quot;/layers/google.python.pip/pip/lib/python3.9/site-packages/flask/app.py&quot;, line 1823, in full_dispatch_request rv = self.dispatch_request() File &quot;/layers/google.python.pip/pip/lib/python3.9/site-packages/flask/app.py&quot;, line 1799, in dispatch_request return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args) File &quot;/layers/google.python.pip/pip/lib/python3.9/site-packages/functions_framework/__init__.py&quot;, line 171, in view_func function(data, context) File &quot;/workspace/main.py&quot;, line 302, in generate_pdf_invoice page_layout.add(table_001) File &quot;/layers/google.python.pip/pip/lib/python3.9/site-packages/borb/pdf/canvas/layout/page_layout/multi_column_layout.py&quot;, line 201, in add layout_rect = layout_element.layout( File &quot;/layers/google.python.pip/pip/lib/python3.9/site-packages/borb/pdf/canvas/layout/layout_element.py&quot;, line 307, in layout return self.calculate_layout_box_and_do_layout(page, bounding_box) File &quot;/layers/google.python.pip/pip/lib/python3.9/site-packages/borb/pdf/canvas/layout/layout_element.py&quot;, line 320, in calculate_layout_box_and_do_layout layout_box = self._calculate_layout_box(page, bounding_box) File &quot;/layers/google.python.pip/pip/lib/python3.9/site-packages/borb/pdf/canvas/layout/layout_element.py&quot;, line 230, in _calculate_layout_box returned_layout_box = self._calculate_layout_box_without_padding( File &quot;/layers/google.python.pip/pip/lib/python3.9/site-packages/borb/pdf/canvas/layout/layout_element.py&quot;, line 258, in _calculate_layout_box_without_padding layout_rect = self._do_layout_without_padding(page, bounding_box) File &quot;/layers/google.python.pip/pip/lib/python3.9/site-packages/borb/pdf/canvas/layout/table/fixed_column_width_table.py&quot;, line 131, in _do_layout_without_padding t.layout(page, Rectangle(x, y, w, h)) File &quot;/layers/google.python.pip/pip/lib/python3.9/site-packages/borb/pdf/canvas/layout/table/table.py&quot;, line 145, in layout modified_layout_box: Rectangle = Rectangle( File &quot;/layers/google.python.pip/pip/lib/python3.9/site-packages/borb/pdf/canvas/geometry/rectangle.py&quot;, line 26, in __init__ assert height &gt;= 0, &quot;A Rectangle must have a non-negative height.&quot; AssertionError: A Rectangle must have a non-negative height.',\n",
       " \"restaurants_invoices57tg2dhgll0j {'oldValue': {}, 'updateMask': {}, 'value': {'createTime': '2023-09-28T19:59:18.390991Z', 'fields': {'buyer_details': {'mapValue': {'fields': {'buyer_address_city_postal_code_country': {'stringValue': 'Errrrrrr-Errrrrrr, NNNNNN, BC500'}, 'buyer_address_street': {'stringValue': 'Test 1,2'}, 'buyer_email': {'stringValue': 'test@gmail.com'}, 'buyer_id': {'stringValue': 'xrr1p3s5Fh7NLzSknd1a'}, 'buyer_name': {'stringValue': 'test'}, 'buyer_phone': {'stringValue': '+235234566'}}}}, 'invoice_number': {'integerValue': '12'}, 'product': {'mapValue': {'fields': {'amount': {'doubleValue': 7.49}, 'description': {'stringValue': 'Payments genreated during the peroid'}, 'quantity': {'doubleValue': 1.0}}}}, 'seller_details': {'mapValue': {'fields': {'seller_BIC': {'stringValue': 'CDAERTEWXXX'}, 'seller_IBAN': {'stringValue': 'BC2356789954332123456778'}, 'seller_address_city_postal_code_country': {'stringValue': 'NDORWE TT TELLE BC700 bertyeq'}, 'seller_address_street': {'stringValue': ''}, 'seller_email': {'stringValue': 'mcrerttyycxde1@gmail.com'}, 'seller_id': {'stringValue': 'mOCXjlKsbwTAgUMo9uKz'}, 'seller_name': {'stringValue': 'tewqertts | dedddfe'}, 'seller_phone': {'stringValue': '+11 22 2222222'}}}}, 'status': {'stringValue': 'pending'}}, 'name': 'projects/my-app-prod/databases/(default)/documents/invoices_restaurants/7mzWObLnyZEGjsS0qAao', 'updateTime': '2023-09-28T19:59:18.390991Z'}}\",\n",
       " 'Traceback (most recent call last):\\n  File &quot;C:\\\\Users\\\\wilme\\\\Desktop\\\\Programming\\\\pyton dedikation\\\\små projekt\\\\getcoord.py&quot;, line 8, in &lt;module&gt;\\n\\tiploc = pyautogui.center(ip)\\n\\t\\t\\t^^^^^^^^^^^^^^^^^^^^\\n  File &quot;C:\\\\Users\\\\wilme\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\pyscreeze\\\\__init__.py&quot;, line 649, in center\\n\\treturn Point(coords[0] + int(coords[2] / 2), coords[1] + int(coords[3] / 2))\\n\\t\\t\\t\\t ~~~~~~^^^',\n",
       " \"import pyautogui\\nimport time\\nscreenWidth, screenHeight = pyautogui.size()\\ncurrentMouseX, currentMouseY = pyautogui.position()\\nip = pyautogui.locateOnScreen(&quot;ip.png&quot;)\\niploc = pyautogui.center(ip)\\nq = pyautogui.confirm('vad vill du göra?', buttons=['skapa ip', 'skicka meddelande till jesper'])\\nif q == 'skapa ip':\\n\\tpyautogui.moveTo(27,1062)\\n\\tpyautogui.click()\\n\\tpyautogui.write('ngrok')\\n\\tpyautogui.moveTo(107,466)\\n\\ttime.sleep(2)\\n\\tpyautogui.click()\\n\\tpyautogui.write('ngrok tcp -region eu 25565')\\n\\tpyautogui.press('enter')\\n\\ttime.sleep(2)\\n\\tpyautogui.moveTo(iploc)\",\n",
       " \"'\\n'\\nPrivate oGpib As NSIGpibInterface.INsiGpib\\nSub Main\\n\\tSet oGpib = New NsiGPIBPlus.cNSIGPIBPlus\\n\\tIf oGpib.DeviceInit(0,16,0, 13, 10, 1) Then\\n\\t\\tsID = oGpib.Query(&quot;*IDN?&quot;,100)\\n\\t\\tIf InStr(1,sID,&quot;Agilent&quot;) Then\\n\\t\\t\\tMsgBox sID\\n\\t\\t\\t  End If\\n\\t   End If\\nEnd Sub\",\n",
       " 'import win32com.client, pythoncom\\ngpib = win32com.client.Dispatch(&quot;NSIGpibInterface.INsiGpib&quot;)\\ngpib2 = win32com.client.DispatchEx(&quot;NsiGPIBPlus.cNSIGPIBPlus&quot;)\\nprint_members(gpib)\\ngpib = gpib2 \\nprint(str(gpib.DeviceInit(0,16,0, 13, 10, 1)))\\nprint(gpib.Query(&quot;*IDN?&quot;,100))',\n",
       " \"from selenium import webdriver\\nimport time\\nimport pandas as pd\\nfrom selenium.webdriver.support.ui import WebDriverWait\\nfrom selenium.webdriver.support import expected_conditions as EC\\nfrom selenium.webdriver.common.by import By\\ndef listToString(s):\\n\\tstr1 = &quot; &quot;\\n\\treturn (str1.join(s))\\nbrowser = webdriver.Chrome()\\nbrowser.implicitly_wait(2)\\nbrowser.get(&quot;https://www.emlakjet.com/satilik-konut/istanbul-sariyer/3/&quot;)\\ni = 1\\nwhile i&lt;=2:\\n\\tclickme = browser.find_element('xpath', &quot;//*[@id=\\\\&quot;listing-search-wrapper\\\\&quot;]/div[&quot;+str(i)+&quot;]&quot;)\\n\\tclickme .click()\",\n",
       " \"------------------------\\nElementClickInterceptedExceptionTraceback (most recent call last)\\nCell In[84], line 28\\n\\t 26 clickme= browser.find_element('xpath', &quot;//*[@id=\\\\&quot;listing-search-wrapper\\\\&quot;]/div[&quot;+str(i)+&quot;]&quot;)\\n---&gt; 28 clickme.click()\\n\\t 30 elements = browser.find_elements(By.CSS_SELECTOR, &quot;._2xeaw&quot;)\\nFile ~\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\selenium\\\\webdriver\\\\remote\\\\webelement.py:93, in WebElement.click(self)\\n\\t 91 def click(self) -&gt; None:\\n\\t 92\\t &quot;&quot;&quot;Clicks the element.&quot;&quot;&quot;\\n---&gt; 93\\t self._execute(Command.CLICK_ELEMENT)\\nFile ~\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\selenium\\\\webdriver\\\\remote\\\\webelement.py:394, in WebElement._execute(self, command, params)\\n\\t392\\t params = {}\\n\\t393 params[&quot;id&quot;] = self._id\\n--&gt; 394 return self._parent.execute(command, params)\\nFile ~\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\selenium\\\\webdriver\\\\remote\\\\webdriver.py:344, in WebDriver.execute(self, driver_command, params)\\n\\t342 response = self.command_executor.execute(driver_command, params)\\n\\t343 if response:\\n--&gt; 344\\t self.error_handler.check_response(response)\\n\\t345\\t response[&quot;value&quot;] = self._unwrap_value(response.get(&quot;value&quot;, None))\\n\\t346\\t return response\\nFile ~\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\selenium\\\\webdriver\\\\remote\\\\errorhandler.py:229, in ErrorHandler.check_response(self, response)\\n\\t227\\t\\t alert_text = value[&quot;alert&quot;].get(&quot;text&quot;)\\n\\t228\\t raise exception_class(message, screen, stacktrace, alert_text)  \\n--&gt; 229 raise exception_class(message, screen, stacktrace)\\nElementClickInterceptedException: Message: element click intercepted: Element &lt;div class=&quot;_3qUI9q&quot; data-index=&quot;71&quot; data-id=&quot;13866619&quot;&gt;...&lt;/div&gt; is not clickable at point (483, 592). Other element would receive the click: &lt;div class=&quot;_1sxDFE&quot;&gt;...&lt;/div&gt;\\n  (Session info: chrome=115.0.5790.171)\\nStacktrace:\\nBacktrace:\\n\\tGetHandleVerifier [0x00007FF6F54D4A62+57106]\\n\\t(No symbol) [0x00007FF6F544CF52]\\n\\t(No symbol) [0x00007FF6F531E2CB]\\n\\t(No symbol) [0x00007FF6F535D290]\\n\\t(No symbol) [0x00007FF6F535B90D]\\n\\t(No symbol) [0x00007FF6F53598F5]\\n\\t(No symbol) [0x00007FF6F5358B05]\\n\\t(No symbol) [0x00007FF6F534EE2F]\\n\\t(No symbol) [0x00007FF6F53769BA]\\n\\t(No symbol) [0x00007FF6F534E746]\\n\\t(No symbol) [0x00007FF6F5376BD0]\\n\\t(No symbol) [0x00007FF6F538E522]\\n\\t(No symbol) [0x00007FF6F5376793]\\n\\t(No symbol) [0x00007FF6F534CE81]\\n\\t(No symbol) [0x00007FF6F534E064]\\n\\tGetHandleVerifier [0x00007FF6F5784222+2873042]\\n\\tGetHandleVerifier [0x00007FF6F57D6590+3209792]\\n\\tGetHandleVerifier [0x00007FF6F57CF3AF+3180639]\\n\\tGetHandleVerifier [0x00007FF6F5565F25+652245]\\n\\t(No symbol) [0x00007FF6F5458618]\\n\\t(No symbol) [0x00007FF6F54547C4]\\n\\t(No symbol) [0x00007FF6F54548BC]\\n\\t(No symbol) [0x00007FF6F5444C33]\\n\\tBaseThreadInitThunk [0x00007FFC8D4055A0+16]\\n\\tRtlUserThreadStart [0x00007FFC8EE6485B+43]\",\n",
       " 'tf.data.Dataset.from_tensor_slices',\n",
       " 'tf.data.Dataset.from_tensor_slices',\n",
       " ' File d:\\\\scripts\\\\train.py:69\\n\\ttrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\\n  File ~\\\\miniconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\data\\\\ops\\\\dataset_ops.py:814 in from_tensor_slices\\n\\treturn TensorSliceDataset(tensors, name=name)\\n  File ~\\\\miniconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\data\\\\ops\\\\dataset_ops.py:4708 in __init__\\n\\telement = structure.normalize_element(element)\\n  File ~\\\\miniconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\data\\\\util\\\\structure.py:126 in normalize_element\\n\\tops.convert_to_tensor(t, name=&quot;component_%d&quot; % i, dtype=dtype))\\n  File ~\\\\miniconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\profiler\\\\trace.py:183 in wrapped\\n\\treturn func(*args, **kwargs)\\n  File ~\\\\miniconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\framework\\\\ops.py:1638 in convert_to_tensor\\n\\tret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\\n  File ~\\\\miniconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\framework\\\\tensor_conversion_registry.py:48 in _default_conversion_function\\n\\treturn constant_op.constant(value, dtype, name=name)\\n  File ~\\\\miniconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\framework\\\\constant_op.py:267 in constant\\n\\treturn _constant_impl(value, dtype, shape, name, verify_shape=False,\\n  File ~\\\\miniconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\framework\\\\constant_op.py:279 in _constant_impl\\n\\treturn _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\\n  File ~\\\\miniconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\framework\\\\constant_op.py:304 in _constant_eager_impl\\n\\tt = convert_to_eager_tensor(value, ctx, dtype)\\n  File ~\\\\miniconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\framework\\\\constant_op.py:102 in convert_to_eager_tensor\\n\\treturn ops.EagerTensor(value, ctx.device_name, dtype)\\nInternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.',\n",
       " \"import os\\nos.chdir(os.path.dirname(os.path.abspath(__file__)))\\nimport joblib\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import Model\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\nimport tensorflow_addons as tfa\\nfrom tensorflow.keras.layers import Input, Dense, LSTM, multiply, concatenate, Activation, Masking, Reshape\\nfrom tensorflow.keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout\\ndef squeeze_excite_block(input):\\n\\tfilters = input.shape[-1]\\n\\tse = GlobalAveragePooling1D()(input)\\n\\tse = Reshape((1, filters))(se)\\n\\tse = Dense(filters // 16,  activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\\n\\tse = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\\n\\tse = multiply([input, se])\\n\\treturn se\\ndef generate_model(lstm_size, conv_size, num_variables, num_timesteps):\\n\\tip = Input(shape=(num_timesteps, num_variables))\\n\\tx = Masking()(ip)\\n\\tx = LSTM(lstm_size)(x)\\n\\ty = Masking()(ip)\\n\\ty = Conv1D(conv_size, 8, padding='same', kernel_initializer='he_uniform')(y)\\n\\ty = BatchNormalization()(y)\\n\\ty = Activation('elu')(y)\\n\\ty = squeeze_excite_block(y)\\n\\ty = Conv1D(conv_size*2, 5, padding='same', kernel_initializer='he_uniform')(y)\\n\\ty = BatchNormalization()(y)\\n\\ty = Activation('elu')(y)\\n\\ty = squeeze_excite_block(y)\\n\\ty = Conv1D(conv_size, 3, padding='same', kernel_initializer='he_uniform')(y)\\n\\ty = BatchNormalization()(y)\\n\\ty = Activation('elu')(y)\\n\\ty = GlobalAveragePooling1D()(y)\\n\\tx = concatenate([x, y])\\n\\tout = Dense(1, activation='sigmoid')(x)\\n\\tmodel = Model(ip, out)\\n\\tmodel.summary()\\n\\treturn model\\nX_train = joblib.load(&quot;X_train.pkl&quot;)\\ny_train = joblib.load(&quot;y_train.pkl&quot;)\\nX_test = joblib.load(&quot;X_test.pkl&quot;)\\ny_test = joblib.load(&quot;y_test.pkl&quot;)\\nnum_variables=8\\nnum_timesteps=20\\nlstm_size=8\\nconv_size = 32\\nlearning_rate = 0.001\\nnum_epochs=100\\nmodel = generate_model(lstm_size, conv_size, num_variables, num_timesteps)\\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tfa.metrics.F1Score(num_classes=2)])\\ncheckpoint_filepath = str(lstm_size)+'_'+str(conv_size)+'_best_model.h5'\\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\\ntest_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\\nmodel_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, save_best_only=True, monitor='val_f1_score',\\\\\\n\\t\\t\\t\\t\\tmode='max', save_weights_only=True, verbose=1)\\nearly_stopping_callback = EarlyStopping(monitor='val_f1_score', mode='max', patience=5,\\\\\\n\\t\\t\\t\\t\\tverbose=1, restore_best_weights=True)\\nhistory = model.fit(train_dataset, epochs=num_epochs, callbacks=[model_checkpoint_callback, early_stopping_callback])\",\n",
       " 'Project/\\n|-- config/\\n|   |-- config.yaml\\n|\\n|-- bin/\\n|   |-- tests/\\n|   |   |-- test_one.py\\n|   |-- __init__.py\\n|   |-- one.py\\n|\\n|-- lib/\\n|   |-- tests/\\n|   |   |-- test_two.py\\n|   |-- __init__.py\\n|   |-- two.py\\n|\\n|-- main.py\\n|-- setup.py\\n|-- README',\n",
       " '\\tdef getPermissions(self):\\n\\t\\tparams = {\\n\\t\\t\\t&quot;response_type&quot;: &quot;code&quot;,\\n\\t\\t\\t&quot;client_id&quot;: self._CLIENT_ID,\\n\\t\\t\\t&quot;scope&quot;: self.SCOPE,\\n\\t\\t\\t&quot;redirect_uri&quot;: &quot;https://youtube.com&quot;,\\n\\t\\t\\t&quot;state&quot;: self.getRandomString(),\\n\\t\\t\\t&quot;show_dialog&quot;: &quot;false&quot;\\n\\t\\t}\\n\\t\\tself.mostRecentResponse = requests.get(self.AUTH_URL, params=params)\\n\\t\\twebbrowser.open(self.mostRecentResponse.url)',\n",
       " 'self.mostRecentResponse',\n",
       " 'tf.distribute.MultiWorkerMirroredStrategy()',\n",
       " 'shuffle',\n",
       " 'tf.data.Dataset.list_files',\n",
       " 'socket.makefile()',\n",
       " '.readline()',\n",
       " \"import datetime\\nimport json\\nimport socket\\nimport threading\\nimport time\\nimport timeit\\nfrom typing import Optional\\nBUFFER_SIZE = 1024\\nN_BATCHES_OF_DATA = 100\\nPORT = 5678\\ndef server(n_batches_of_data, port):\\n\\tdata = [\\n\\t\\tjson.dumps({&quot;a&quot;: &quot;b&quot;}).encode('utf-8') + b'\\\\r\\\\n',\\n\\t\\tjson.dumps({&quot;c&quot;: &quot;d&quot;, &quot;e&quot;: &quot;f&quot;}).encode('utf-8') + b'\\\\r\\\\n',\\n\\t\\tjson.dumps({&quot;g&quot; * (512-5): &quot;h&quot; * (512-5)}).encode('utf-8') + b'\\\\r\\\\n',  \\n\\t\\tjson.dumps({&quot;i&quot; * (512-4): &quot;j&quot; * (512-4)}).encode('utf-8') + b'\\\\r\\\\n',  \\n\\t\\tjson.dumps({&quot;k&quot; * (256-5): &quot;l&quot; * (256-5)}).encode('utf-8') + b'\\\\r\\\\n',  \\n\\t\\tjson.dumps({&quot;m&quot; * (256-5): &quot;n&quot; * (256-5)}).encode('utf-8') + b'\\\\r\\\\n',  \\n\\t\\tjson.dumps({&quot;o&quot; * (1024-5): &quot;p&quot; * (1024-5)}).encode('utf-8') + b'\\\\r\\\\n',  \\n\\t\\tjson.dumps({&quot;q&quot; * 100: &quot;r&quot; * 100})[0:25].encode('utf-8'),  \\n\\t\\tjson.dumps({&quot;q&quot; * 100: &quot;r&quot; * 100})[25:50].encode('utf-8'),  \\n\\t\\tjson.dumps({&quot;q&quot; * 100: &quot;r&quot; * 100})[50:75].encode('utf-8'),  \\n\\t\\tjson.dumps({&quot;q&quot; * 100: &quot;r&quot; * 100})[50:75].encode('utf-8'),  \\n\\t\\tjson.dumps({&quot;q&quot; * 100: &quot;r&quot; * 100})[75:].encode('utf-8') + b'\\\\r\\\\n',  \\n\\t\\tjson.dumps({&quot;s&quot;: &quot;t&quot;}).encode('utf-8') + b'\\\\r\\\\n' + json.dumps({&quot;u&quot;: &quot;v&quot;}).encode('utf-8') + b'\\\\r\\\\n' + json.dumps({&quot;w&quot;: &quot;x&quot;}).encode('utf-8') + b'\\\\r\\\\n'+ json.dumps({&quot;y&quot;: &quot;z&quot;}).encode('utf-8') + b'\\\\r\\\\n',  \\n\\t] * n_batches_of_data\\n\\tserver_socket = socket.socket()\\n\\tserver_socket.bind((&quot;localhost&quot;, port))\\n\\tserver_socket.listen(2)\\n\\twhile True:\\n\\t\\tconn, address = server_socket.accept()  \\n\\t\\tfor d in data:\\n\\t\\t\\tconn.sendall(d)\\n\\t\\tconn.close()\\ndef read_using_recv(buffer_size, port):\\n  s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n  s.settimeout(10)\\n  s.connect((&quot;localhost&quot;, port))\\n  (data, part) = (&quot;&quot;, &quot;&quot;)\\n  while True:\\n\\t  try:\\n\\t\\t  part = s.recv(buffer_size)\\n\\t  except (socket.timeout, socket.error) as e:\\n\\t\\t\\treturn\\n\\t  if len(part) == 0:\\n\\t\\t  return\\n\\t  data += part.decode('utf8')\\n\\t  if data.endswith('\\\\r\\\\n'):\\n\\t\\tdata.split('\\\\r\\\\n')\\n\\t\\tdata = ''\\ndef read_using_readline(buffer_size, port):\\n  s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n  s.settimeout(10)\\n  s.connect((&quot;localhost&quot;, port))\\n  f = s.makefile('r', buffering=buffer_size, newline='\\\\r\\\\n', encoding='utf8')\\n  while True:\\n\\t  try:\\n\\t\\t  part = f.readline()\\n\\t  except (socket.timeout, socket.error) as e:\\n\\t\\t\\treturn\\n\\t  if len(part) == 0:\\n\\t\\t  return\\nif __name__ == '__main__':\\n  t = threading.Thread(target=server, args=[N_BATCHES_OF_DATA, PORT], daemon=True)\\n  t.start()\\n  time.sleep(5)\\n  print('read_using_recv', timeit.timeit((lambda: read_using_recv(BUFFER_SIZE, PORT)), number=5000))\\n  print('read_using_readline', timeit.timeit((lambda: read_using_readline(BUFFER_SIZE, PORT)), number=5000))\",\n",
       " 'read_using_recv: 134.77089489999344\\nread_using_readline: 78.2258090999967',\n",
       " 'read_using_recv 22.800755036994815\\nread_using_readline 20.403162219095975',\n",
       " \"import asyncio\\nfrom concurrent.futures import ThreadPoolExecutor\\nfrom typing import List, Optional\\nfrom fastapi import FastAPI, Request, Query, Body\\nimport SERVER\\napp = FastAPI()\\ndef get_flag(flag):\\n\\tSERVER.FindRequest(flag)\\n\\treturn {}\\nasync def handle_request(flag, loop, executor):\\n\\tresult = await loop.run_in_executor(executor, get_flag, flag)\\n\\treturn result\\n@app.get('/get_flag')\\nasync def get_data():\\n\\ttest_required = [True, False, True, False]\\n\\ttasks = []\\n\\tloop = asyncio.get_event_loop()\\n\\texecutor = ThreadPoolExecutor()\\n\\ttasks = [handle_request(request, loop, executor) for request in test_required]\\n\\tprocessed_data = await asyncio.gather(*tasks)\\n\\texecutor.shutdown()\\n\\treturn {}\",\n",
       " \"import DB\\ndef FindRequest(flag=False):\\n\\tprint('flag', 'DB.DB_MODE')\\n\\tprint(flag, DB.DB_MODE)\\n\\tif (flag == True):\\n\\t\\tDB.DB_MODE = 0\\n\\tprint('flag', 'DB.DB_MODE')\\n\\tprint(flag, DB.DB_MODE)\\n\\treturn {}\",\n",
       " 'DB_MODE = 1',\n",
       " \"from flask import Flask, request, jsonify\\nfrom flask_cors import CORS\\nfrom waitress import serve\\nimport os\\nfrom os import path\\nimport json\\nimport asyncio\\nimport time\\nfrom scraper import scrap\\nDEBUG = True\\napp = Flask(__name__)\\napp.config.from_object(__name__)\\nCORS(app)\\n@app.route('/api/v1/request', methods=['POST'])\\ndef process_order():\\nasync def get_new_prices():\\n\\tprint('async started')\\n\\tstart = time.time()\\n\\tres = await scrap()\\n\\tend = time.time() - start\\n\\tprint(res, end)\\nasyncio.run(get_new_prices())\\nif __name__ == '__main__':\\n\\tapp.run()\",\n",
       " 'fs.MemoryFS()',\n",
       " 'mem_fs.tree()',\n",
       " '-- decrypted_model\\n\\t|-- variables\\n\\t|   |-- variables.data-00000-of-00001\\n\\t|   `-- variables.index\\n\\t|-- keras_metadata.pb\\n\\t`-- saved_model.pb',\n",
       " 'tf.keras.models.load_model',\n",
       " 'OSError: Unable to load model. Filepath is not an hdf5 file (or h5py is not available) or SavedModel. Received: filepath=&lt;memfs&gt;/decrypted_model',\n",
       " \"mem_fs = MemoryFS()\\ntemp_dir = mem_fs.makedir('/decrypted_model', recreate=True)\\nmem_fs.makedirs('/decrypted_model/variables', recreate=True)\\nfor root, dirs, files in os.walk(encrypted_model_dir):\\n\\tfor file in files:\\n\\t\\tfile_path = os.path.join(root, file)\\n\\t\\twith open(file_path, 'rb') as f:\\n\\t\\t\\tencrypted_file_data = f.read()\\n\\t\\tdecrypted_file_data = Decryption(encrypted_file_data)\\n\\t\\tif file_path.split('\\\\\\\\')[-2] == 'variables':\\n\\t\\t\\tdecrypted_file_path = '/decrypted_model/variables/' + file_path.split('\\\\\\\\')[-1]\\n\\t\\telse:\\n\\t\\t\\tdecrypted_file_path = '/decrypted_model/' + file_path.split('\\\\\\\\')[-1]\\n\\t\\twith mem_fs.open(decrypted_file_path, 'wb') as f:\\n\\t\\t\\tf.write(decrypted_file_data)\\nmodel = tf.keras.models.load_model(temp_dir)\",\n",
       " \"import random\\nimport string\\nwebsite = input(&quot;What website are you creating a password for? &quot;).capitalize()\\ndef char_length():\\n\\twhile True:\\n\\t\\tlength = input(&quot;How many characters would you like your password to be? &quot;)\\n\\t\\tif length.isdigit() and 0 &lt; int(length) &lt; 51:\\n\\t\\t\\treturn int(length)\\n\\t\\telse:\\n\\t\\t\\tprint('Response must be a number between 0 and 50')\\ndef random_pass(length):\\n\\twhile True:\\n\\t\\tspec_char = input(&quot;Would you like special characters in your password y/n? &quot;).lower()\\n\\t\\tif spec_char == &quot;y&quot;:\\n\\t\\t\\tcharacters =  string.ascii_letters + string.digits + string.punctuation\\n\\t\\t\\tpassword = ''.join(random.choice(characters) for i in range(length))\\n\\t\\t\\tprint(&quot;Your password for&quot;, website, &quot;is:&quot;, password)\\n\\t\\t\\treturn password\\n\\t\\telif spec_char == &quot;n&quot;:\\n\\t\\t\\tcharacters = ''.join(random.choice(string.ascii_letters) for i in range(length))\\n\\t\\t\\tprint(&quot;Your password for&quot;, website, &quot;is:&quot;, characters)\\n\\t\\t\\treturn characters\\n\\t\\telse:\\n\\t\\t\\tprint(&quot;Please only type 'Yes' or 'No'.&quot;)\\nrandom_pass(char_length())\\nfile = open(&quot;password.txt&quot;, &quot;a+&quot;)\\nwebname = file.write(website)\\nfile.write(&quot;: &quot;)\\nnew_pass = file.write(random_pass(char_length()))\\nfile.write(&quot;\\\\n&quot;)\\nprint(webname)\\nprint(new_pass)\\nfile.close()\",\n",
       " \"ox.graph_from_bbox(lat1, lat2, lng1, lng1, network_type='bike', simplify=True)\",\n",
       " 'import numpy as np\\nimport cv2\\nimport matplotlib.pyplot as plt\\noutput_width, output_height = 1000, 600',\n",
       " 'values = 1 + np.random.rand(5, 11).astype(&quot;float32&quot;)\\nsource_points = np.array(\\n\\t[\\n\\t\\t[-0.5, -0.5], [10.5, -0.5], [-0.5, 4.5], [10.5, 4.5],\\n\\t], dtype=&quot;float32&quot;\\n)\\ntarget_points = np.array(\\n\\t[\\n\\t\\t[1, 0], [1000, 0], [250, 250], [750, 250],\\n\\t], dtype=&quot;float32&quot;\\n)\\ntransformation = cv2.getPerspectiveTransform(source_points, target_points)\\nwarped_values = cv2.warpPerspective(\\n\\tvalues,\\n\\ttransformation,\\n\\t(output_width, output_height),\\n\\tborderMode=cv2.BORDER_TRANSPARENT,\\n\\tflags=cv2.INTER_NEAREST\\n)\\nplt.imshow(warped_values)',\n",
       " 'values = 1 + np.random.rand(5, 2).astype(&quot;float32&quot;)\\nsource_points = np.array(\\n\\t[\\n\\t\\t[-0.5, -0.5], [1.5, -0.5], [-0.5, 4.5], [1.5, 4.5],\\n\\t], dtype=&quot;float32&quot;\\n)\\ntarget_points = np.array(\\n\\t[\\n\\t\\t[201, 0],  [800, 0], [450, 250], [550, 250],\\n\\t], dtype=&quot;float32&quot;\\n)\\ntransformation = cv2.getPerspectiveTransform(source_points, target_points)\\nwarped_values = cv2.warpPerspective(\\n\\tvalues,\\n\\ttransformation,\\n\\t(output_width, output_height),\\n\\tflags=cv2.INTER_NEAREST,\\n\\tborderMode=cv2.BORDER_TRANSPARENT\\n)\\nplt.imshow(warped_values)',\n",
       " \"import csv\\ndef html_stats(csv_file: str, html_file: str, title: str = None):\\n   grouped_data = {}\\n   with open(csv_file, 'r') as cal_file:\\n\\t  reader = csv.DictReader(cal_file)\\n\\t  for i in reader:\\n\\t\\t  for k, v in i.items():\\n\\t\\t\\t grouped_data.setdefault(k, []).append(v)\\n\\t\\t\\t for i in range(len(grouped_data)):\\n\\t\\t\\t\\t keys = list(grouped_data.keys())[i]\\n\\t\\t\\t\\t calc = grouped_data.get(keys)\\n\\t\\t\\t\\t int_stats = [int(m) for m in calc]\\n\\t\\t\\t\\t max_value = max(int_stats)\\n\\t\\t\\t\\t min_value = min(int_stats)\\n\\t\\t\\t\\t mean_value = sum(int_stats) / len(int_stats)\\n\\t\\t\\t\\t s = sorted(int_stats)\\n\\t\\t\\t\\t n = len(int_stats)\\n\\t\\t\\t\\t median_value = (s[n // 2 - 1] / 2.0 + s[n // 2] / 2.0, s[n // 2])[n % 2] if n else None\\n\\t\\t\\t\\t print(max_value)\\n\\t\\t\\t\\t print(min_value)\\n\\t\\t\\t\\t print(mean_value)\\n\\t\\t\\t\\t print(median_value)\",\n",
       " '  9533\\n  9533\\n  9533.0\\n  9533\\n  9533\\n  9533\\n  and then like 50 - 60 more outputs\\n  the only output I need is the output below\\n  11587\\n  6493\\n  8724.35\\n  8539.0\\n  10562\\n  5778\\n  7822.3\\n  7668.0\\n  63963\\n  5086\\n  43479.25\\n  44933.5',\n",
       " 'original_layer = QgsVectorLayer(input_file_path, &quot;Original Layer&quot;, &quot;ogr&quot;)\\ntemp_layer = QgsVectorLayer(&quot;LineString&quot;, &quot;Output_layer&quot;, &quot;memory&quot;)\\nQgsProject.instance().addMapLayer(temp_layer)\\nfeatures = []\\nattributes = []\\nfor feature in original_layer.getFeatures():\\nattribute = feature.attributes()\\nattributes.append(attribute)\\nfeatures.append(feature)\\ntemp_layer.startEditing()\\ndata_provider = temp_layer.dataProvider()\\ndata_provider.addAttributes(attributes)\\ndata_provider.addFeatures(features)\\ntemp_layer.commitChanges()',\n",
       " '&lt; 202   dac1d06a-e9e1-4739-a80c-9ae913e345c3\\t2023-05-23 12:05:58.972111+00   199 \\\\N  139 \\\\N  dut001  f   \\\\N  script  initial commit  f\\n&lt; 203   410ced4d-e2cf-4006-8cf0-f143f744f953\\t2023-05-23 12:05:58.980174+00   199 \\\\N  141 201 duthandler  t   \\\\N  script  initial commit  f\\n&gt; 202   dac1d06a-e9e1-4739-a80c-9ae913e345c3\\t2023-05-23 14:05:58.972111+02   199 \\\\N  139 \\\\N  dut001  f   \\\\N  script  initial commit  f\\n&gt; 203   410ced4d-e2cf-4006-8cf0-f143f744f953\\t2023-05-23 14:05:58.980174+02   199 \\\\N  141 201 duthandler  t   \\\\N  script  initial commit  f',\n",
       " 'class MyClass(Base):\\n\\t__tablename__ = &quot;alias_map_expanded&quot;\\n\\tseq2 = Sequence(name=&quot;seq2&quot;)\\n\\tid = Column(\\n\\t\\tBigInteger, sumo_seq2, server_default=seq2.next_value(), primary_key=True\\n\\t)\\n\\tuuid = Column(\\n\\t\\tUUID(as_uuid=True), server_default=func.gen_random_uuid(), nullable=False\\n\\t)\\n\\tcreation_date = Column(\\n\\t\\tDateTime(timezone=True), server_default=func.current_timestamp(), nullable=False\\n\\t)\\n\\t...',\n",
       " 'pyenv',\n",
       " 'pyenv install 3.11.4',\n",
       " \"python-build: use openssl@1.1 from homebrew\\npython-build: use readline from homebrew\\nDownloading Python-3.11.4.tar.xz...\\n-&gt; https://www.python.org/ftp/python/3.11.4/Python-3.11.4.tar.xz\\nInstalling Python-3.11.4...\\npython-build: use tcl-tk from homebrew\\npython-build: use readline from homebrew\\nBUILD FAILED (OS X 13.5 using python-build 20180424)\\nInspect or clean up the working tree at /var/folders/kv/l0jzxgbj1kggff_kd35bfzkw0000gn/T/python-build.20230728132126.31601\\nResults logged to /var/folders/kv/l0jzxgbj1kggff_kd35bfzkw0000gn/T/python-build.20230728132126.31601.log\\nLast 10 log lines:\\nchecking pkg-config is at least version 0.9.0... yes\\nchecking for --enable-universalsdk... no\\nchecking for --with-universal-archs... no\\nchecking MACHDEP... &quot;darwin&quot;\\nchecking for gcc... x86_64-apple-darwin13.4.0-clang\\nchecking whether the C compiler works... no\\nconfigure: error: in `/var/folders/kv/l0jzxgbj1kggff_kd35bfzkw0000gn/T/python-build.20230728132126.31601/Python-3.11.4':\\nconfigure: error: C compiler cannot create executables\\nSee `config.log' for more details\\nmake: *** No targets specified and no makefile found.  Stop.\",\n",
       " '***THIS IS A RED FLAG ERROR***\\nPITFT /boot/overlays/drm-minipitft13.dtbo: Warning (unit_address_vs_reg): /fragment@0/__overlay__/spidev@0: node has a unit name, but no reg property\\n/boot/overlays/drm-minipitft13.dtbo: Warning (unit_address_vs_reg): /fragment@0/__overlay__/spidev@1: node has a unit name, but no reg property\\nUpdating packages...\\nUpgrading packages...\\nPITFT Reading package lists...\\nPITFT\\nPITFT Building dependency tree...\\nPITFT Reading state information...\\nPITFT\\nPITFT Calculating upgrade...\\nPITFT\\nPITFT 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\\nPinning kernel to version 5.4\\nPITFT Failed to pin all kernel files! ***THIS IS A YELLOW WARNING***',\n",
       " \"def home(request):\\n\\tusers = CustomUser.objects.all()\\n\\tevents = Event.objects.all()\\n\\ttags = Tag.objects.all()\\n\\tevent_categorys = EventCategory.objects.all()\\n\\ttickets = Ticket.objects.all()\\n\\tif request.user.is_authenticated:\\n\\t\\temail = request.user.email\\n\\telse:\\n\\t\\temail = 'AnonymousUser'\\n\\tif request.method == &quot;GET&quot;:\\n\\t\\turl = request.get_full_path()\\n\\t\\tcode_index = url.find('code=')\\n\\t\\tif code_index != -1:\\n\\t\\t\\tcode = url[code_index + 5:]\\n\\t\\t\\tprint(&quot;Code is :&quot;, code)\\n\\t\\t\\trequest.session['code'] = code\\n\\t\\t\\tsession_code = code\\n\\t\\telse:\\n\\t\\t\\tsession_code = request.session.get('code')\\n\\t\\tget_bearer_token(request)\\n\\t\\tprint(&quot;ssssssssssssssssssssssssssssssssssss: &quot;, session_code)\\n\\treturn render(request, 'home.html',\\n\\t\\t\\t\\t  context={'events': events, 'tags': tags, 'event_categorys': event_categorys, 'tickets': tickets,\\n\\t\\t\\t\\t\\t\\t   'session_code': session_code})\",\n",
       " \"def get_bearer_token(request):\\n\\tauth_url = &quot;https://account-test.bog.ge/auth/realms/bog-id/protocol/openid-connect/token&quot;\\n\\tsession_code = request.session.get('session_code')\\n\\tif session_code:\\n\\t\\tprint(&quot;Session Code:&quot;, session_code)\\n\\telse:\\n\\t\\tprint(&quot;Session Code not found&quot;)\\n\\tpayload = {\\n\\t\\t&quot;grant_type&quot;: session_code,\\n\\t\\t&quot;client_id&quot;: &quot;your_client_id&quot;,\\n\\t\\t&quot;client_secret&quot;: &quot;your_client_secret&quot;\\n\\t}\\n\\tresponse = requests.post(auth_url,data=payload)\\n\\treturn HttpResponse(&quot;asdasd&quot;)\",\n",
       " 'session_code',\n",
       " 'get_bearer_token',\n",
       " 'while True',\n",
       " 'from importlib import abc',\n",
       " 'from importlib import util',\n",
       " 'ImportError',\n",
       " 'importlib2',\n",
       " 'import importlib2',\n",
       " \"remote:\\nremote: -----&gt; Building on the Heroku-22 stack\\nremote: -----&gt; Using buildpack: heroku/python\\nremote: -----&gt; App not compatible with buildpack: https://buildpack-registry.s3.amazonaws.com/buildpacks/heroku/python.tgz\\nremote:\\t\\tMore info: https://devcenter.heroku.com/articles/buildpacks\\nremote:\\nremote:  !\\t Push failed\\nremote:  !\\nremote:  ! \\nremote:  !\\nremote:  ! We have detected that you have triggered a build from source code with version 9124da0df6637b15c4ade2f515a79c463ea52ed0\\nremote:  ! at least twice. One common cause of this behavior is attempting to deploy code from a different branch.\\nremote:  !\\nremote:  ! If you are developing on a branch and deploying via git you must run:\\nremote:  !\\nremote:  !\\t git push heroku &lt;branchname&gt;:main\\nremote:  !\\nremote:  ! This article goes into details on the behavior:\\nremote:  !   https://devcenter.heroku.com/articles/duplicate-build-version\\nremote:\\nremote: Verifying deploy...\\nremote:\\nremote: !\\t   Push rejected to nartonmusic.\\nremote:\\nTo https://git.heroku.com/nartonmusic.git\\n ! [remote rejected] master -&gt; master (pre-receive hook declined)\\nerror: failed to push some refs to 'https://git.heroku.com/nartonmusic.git'\",\n",
       " \"fig = plt.figure()\\nax = fig.add_subplot(projection='3d')\\nfor j in range(N):\\n\\tax.cla()\\n\\tax.set_xlim3d(-20, 80)\\n\\tax.set_ylim3d(-20,80)\\n\\tax.set_zlim3d(0,100)\\n\\tax.set_xlabel('X axis')\\n\\tax.set_ylabel('Y axis')\\n\\tax.set_zlabel('Z axis')\\n\\tfor i in range(2):\\n\\t\\tax.plot([VecStart_x1[i], VecEnd_x1[i]], [VecStart_y1[i],VecEnd_y1[i]],zs=[VecStart_z1[i],VecEnd_z1[i]])\\n\\t\\tax.scatter3D(States[6],States[7],50,s=10)\\n\\t\\tplt.pause(0.1)\\nplt.show()\",\n",
       " 'def error_function(x):\\n\\traise ValueError\\nimport numpy as np\\nx = np.empty(int(1e10))\\nx[:] = 0.\\nerror_function(x)  \\nx = None\\t\\t   ',\n",
       " 'gc.collect()',\n",
       " 'raise ValueError\\t\\t   \\nimport gc; gc.collect();   ',\n",
       " 'error_function',\n",
       " 'cell [1]',\n",
       " 'cell [1]',\n",
       " 'x',\n",
       " 'x = np.empty...',\n",
       " 'import torch\\nimport detectron2\\nfrom detectron2.config import get_cfg\\nfrom detectron2.engine import DefaultPredictor\\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\\nfrom detectron2.data import build_detection_test_loader\\nfrom detectron2.data.datasets import register_coco_instances\\nfrom detectron2 import model_zoo\\nimport os\\ncfg = get_cfg()\\ncfg.MODEL.DEVICE = &quot;cpu&quot;\\nregister_coco_instances(&quot;validation&quot;, {}, &quot;test/output.json&quot;, &quot;test&quot;)\\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, &quot;best_model.pth&quot;)\\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   \\ncfg.DATASETS.TEST = (&quot;validation&quot;, )\\npredictor = DefaultPredictor(cfg)\\nevaluator = COCOEvaluator(&quot;validation&quot;, cfg, distributed=False, output_dir=&quot;./output&quot;)\\nval_loader = build_detection_test_loader(cfg, &quot;validation&quot;)\\nprint(inference_on_dataset(predictor.model, val_loader, evaluator))',\n",
       " \"Traceback (most recent call last):\\n  File &quot;c:\\\\Users\\\\ajilson\\\\Downloads\\\\model_evaluation\\\\model_evaluator.py&quot;, line 20, in &lt;module&gt;\\n\\tpredictor = DefaultPredictor(cfg)\\n  File &quot;C:\\\\Users\\\\ajilson\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\Sig-d\\\\lib\\\\site-packages\\\\detectron2\\\\engine\\\\defaults.py&quot;, line 194, in __init__\\n\\tcheckpointer.load(cfg.MODEL.WEIGHTS)\\n  File &quot;C:\\\\Users\\\\ajilson\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\Sig-d\\\\lib\\\\site-packages\\\\fvcore\\\\common\\\\checkpoint.py&quot;, line 156, in load\\n\\tincompatible = self._load_model(checkpoint)\\n  File &quot;C:\\\\Users\\\\ajilson\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\Sig-d\\\\lib\\\\site-packages\\\\detectron2\\\\checkpoint\\\\detection_checkpoint.py&quot;, line 71, in _load_model\\n\\tincompatible = super()._load_model(checkpoint)\\n  File &quot;C:\\\\Users\\\\ajilson\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\Sig-d\\\\lib\\\\site-packages\\\\fvcore\\\\common\\\\checkpoint.py&quot;, line 273, in _load_model\\n\\tself._convert_ndarray_to_tensor(checkpoint_state_dict)\\n  File &quot;C:\\\\Users\\\\ajilson\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\Sig-d\\\\lib\\\\site-packages\\\\fvcore\\\\common\\\\checkpoint.py&quot;, line 369, in _convert_ndarray_to_tensor\\n\\traise ValueError(\\nValueError: Unsupported type found in checkpoint! epoch: &lt;class 'int'&gt;\",\n",
       " 'Tab',\n",
       " 'python3 ./module rollback -c',\n",
       " 'tab',\n",
       " \"import argparse\\nparser = argparse.ArgumentParser()\\nsubparsers = parser.add_subparsers(dest='command')\\nrollback = subparsers.add_parser('rollback', help='Rollback to previous commit')\\nrollback.add_argument('-c', '--commit', dest='incomingCommitHash', default=None, type=str, required=False, help='Commit to deploy')\",\n",
       " \"`@app.post('/test/almost whole')\\nasync def create_catch(catch: tag_shemas.CatchCreate, files: list[UploadFile],\\n\\t\\t\\t\\t\\t   user: User = Depends(current_user),\\n\\t\\t\\t\\t\\t   db: Session = Depends(get_db)):\\n\\tif not files:\\n\\t\\treturn {&quot;message&quot;: &quot;No upload file sent&quot;}\\n\\tfor file in files:\\n\\t\\tif file.content_type != &quot;image/jpeg&quot;:\\n\\t\\t\\treturn {&quot;message&quot;: 'incorrect file'}\\n\\treturn crud.create_test(db=db, uploaded_file=files, id=user.id, catch=catch)\\nCRUD\\ndef create_catch(db: Session, uploaded_file, id, catch: tag_shemas.CatchCreate):\\n\\tdb_geo = models.Geo(coordinates_n=catch.coordinates_n, coordinates_e=catch.coordinates_e)\\n\\tdb_description = models.Descriptions(description=catch.description, user_id=id)\\n\\tdb.add_all([db_geo, db_description])\\n\\tdb.commit()\\n\\tdb.refresh(db_geo)\\n\\tdb.refresh(db_description)\\n\\tdb_tag = models.Tags(description_id=db_description.id, geo_id=db_geo.id, user_id=id)\\n\\tdb.add(db_tag)\\n\\tdb.commit()\\n\\tdb.refresh(db_tag)\\n\\tfor file in uploaded_file:\\n\\t\\tfile_location = rf&quot;C:\\\\Users\\\\v/{file.filename}&quot;\\n\\t\\twith open(file_location, 'wb+') as file_object:\\n\\t\\t\\tshutil.copyfileobj(file.file, file_object)\\n\\t\\t\\tdb_photo = models.Photos(tags_id=db_tag.id, description_id=db_description.id, photo_url=file_location)\\n\\t\\t\\tdb.add(db_photo)\\n\\t\\tdb.commit()\\n\\treturn {'OOOOOkkkk'}`\",\n",
       " 'requests.PUT()',\n",
       " 'query',\n",
       " 'dimensions',\n",
       " 'query',\n",
       " 'dimension',\n",
       " '{\\n  &quot;job_type&quot;: &quot;export&quot;,\\n  &quot;payload&quot;: {\\n\\t&quot;username&quot;: &quot;myID&quot;,\\n\\t&quot;project&quot;: &quot;website.com&quot;,\\n\\t&quot;export_size&quot;: 50,\\n\\t&quot;formatter&quot;: &quot;csv&quot;,\\n\\t&quot;formatter_config&quot;: {\\n\\t\\t\\t&quot;delimiter&quot;: &quot;,&quot;,\\n\\t\\t\\t&quot;print_delimiter&quot;: &quot;False&quot;,\\n\\t\\t\\t&quot;print_header&quot;: &quot;True&quot;,\\n\\t\\t\\t&quot;header_format&quot;: &quot;verbose&quot;\\n\\t\\t},\\n\\t&quot;connector&quot;: &quot;direct_download&quot;,\\n\\t&quot;extra_config&quot;: {},\\n\\t&quot;query&quot;: {\\n\\t  &quot;collections&quot;: [&quot;crawl.20230515&quot;],\\n\\t  &quot;query&quot;: {\\n\\t\\t&quot;dimensions&quot;: [&quot;url&quot;,\\n\\t\\t\\t\\t\\t   &quot;crawl.20230515.date_crawled&quot;,\\n\\t\\t\\t\\t\\t   &quot;crawl.20230515.content_type&quot;,\\n\\t\\t\\t\\t\\t   &quot;crawl.20230515.http_code&quot;,\\n\\t\\t\\t\\t\\t   &quot;segments.pagetype.value&quot;,\\n\\t\\t\\t\\t\\t   &quot;compliant.is_compliant&quot;,\\n\\t\\t\\t\\t\\t   &quot;metadata.robots.noindex&quot;,\\n\\t\\t\\t\\t\\t   &quot;http_redirect.to.final.path&quot;\\n\\t\\t\\t\\t\\t   ],\\n\\t\\t&quot;metrics&quot;: [],\\n\\t\\t&quot;sort&quot;: [1]\\n\\t  }\\n\\t}\\n  }\\n}',\n",
       " 'dimension',\n",
       " 'compliant.is_compliant\\nmetadata.robots.noindex\\nhttp_redirect.to.final.path',\n",
       " \"{'job_id': 1831591, 'job_type': 'export', 'job_url': '/v1/jobs/1831591', 'job_status': 'FAILED', 'results': {'nb_lines': None}, 'date_created': '2023-05-27T17:12:54.074062Z', 'payload': {'query': {'query': {'sort': [1], 'metrics': [], 'dimensions': ['url', 'crawl.20230515.date_crawled', 'crawl.20230515.content_type', 'crawl.20230515.http_code', 'segments.pagetype.value', 'segments.country.value', 'crawl.20230515.is_compliant']}, 'collections': ['crawl.20230515']}, 'export_size': 50, 'connector': 'direct_download', 'formatter': 'csv', 'formatter_config': {'delimiter': ',', 'print_header': True, 'header_format': 'verbose', 'print_delimiter': False}, 'extra_config': {}, 'sort_url_id': False, 'export_job_name': None}, 'user': 'XXXXXXXX', 'metadata': None, 'crawl_date': None}\",\n",
       " \"process = subprocess.Popen(['bash', self.beeline_path], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\\nline = self.process.stdout.readline().decode(&quot;utf-8&quot;).strip()\\nwhile line is not None and len(line) &gt; 0:\\n\\tif line.startswith(&quot;0: jdbc:hive2://&quot;):\\n\\t\\tlogging.info(&quot;Found prompt: &quot; + line) \\n\\t\\tbreak\\n\\telse:\\n\\t\\tline = self.process.stdout.readline().decode(&quot;utf-8&quot;).strip()\",\n",
       " 'NoSuchElementException: Message: Unable to locate element: .horse-764aj7-startlistraceinfodetails-styles--container',\n",
       " 'raceProp = driver.find_element(By.CLASS_NAME,&quot;horse-764aj7-startlistraceinfodetails-styles--container&quot;)\\nspans = driver.find_elements(By.TAG_NAME,&quot;span&quot;)',\n",
       " '&lt;div class=&quot;startlist-header__race-title&quot;&gt;\\n  &lt;div role=&quot;button&quot; tabindex=&quot;0&quot; class=&quot;race-info-toggle race-info-toggle--expanded&quot; data-test-id=&quot;toggle-race-info&quot;&gt;\\n\\t&lt;svg viewBox=&quot;0 0 32 32&quot; focusable=&quot;false&quot; aria-hidden=&quot;true&quot; class=&quot;horse-1r0kb3k-SvgIcon-styles--rootStyle-SvgIcon-styles--fontSize-startlistheader-styles--toggleIcon-SvgIcon--SvgIcon&quot;&gt;\\n\\t\\t  &lt;path d=&quot;M13.5 17.2c.7-.6 1.5-1 2.5-1s1.8.4 2.5 1l8.8 8.9c.7.7 1.1 1.5 1.1 2.4 0 .9-.4 1.8-1 2.5-.7.6-1.6 1-2.5 1-.9 0-1.8-.4-2.5-1L16 24.6 9.6 31c-.7.6-1.5 1-2.5 1s-1.8-.4-2.4-1c-1.4-1.4-1.4-3.6 0-4.9l8.8-8.9zM24.9 15.8c-.9 0-1.8-.3-2.5-1L16 8.4l-6.4 6.4c-.7.7-1.5 1-2.5 1-.9 0-1.8-.3-2.4-1-1.4-1.3-1.4-3.5 0-4.9l8.8-8.8c.7-.7 1.5-1 2.5-1s1.8.3 2.5 1l8.8 8.8c.7.7 1.1 1.6 1.1 2.5 0 .9-.4 1.8-1 2.4-.7.7-1.6 1-2.5 1z&quot;&gt;&lt;/path&gt;\\n\\t&lt;/svg&gt;\\n  &lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=&quot;flexboxgrid2_col-xs-12_2A&quot;&gt;\\n  &lt;div data-test-id=&quot;startlist-info-container&quot; class=&quot;horse-764aj7-startlistraceinfodetails-styles--container&quot;&gt;\\n\\t&lt;span class=&quot;horse-nqsei7-startlistraceinfodetails-styles--infoContainer-startlistraceinfodetails-styles--infoName-startlistraceinfodetails--StartlistRaceInfoDetails&quot;&gt;Breddlopp - Sleipner Bergsåkers Månadstäcke - P21-lopp&lt;/span&gt;\\n\\t&lt;span class=&quot;horse-nxbcp8-startlistraceinfodetails-styles--infoContainer&quot;&gt;Pris: 10.000-5.000-3.500-2.500-2.100-2.000-2.000-2.000 kr (8 priser). Lägst 1.500 kr till alla tävlande.&lt;/span&gt;\\n  &lt;/div&gt;\\n&lt;/div&gt;',\n",
       " 'kubectl version',\n",
       " 'The connection to the server localhost:8080 was refused - did you specify the right host or port?',\n",
       " \"2023-05-11 17:33:42,157: Error running WSGI application\\n2023-05-11 17:33:42,159: werkzeug.exceptions.BadRequestKeyError: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\\n2023-05-11 17:33:42,159: KeyError: 'select_installer'\\n2023-05-11 17:33:42,159:   File &quot;/usr/local/lib/python3.10/site-packages/flask/app.py&quot;, line 2095, in __call__\\n2023-05-11 17:33:42,160:\\t return self.wsgi_app(environ, start_response)\\n2023-05-11 17:33:42,160:\\n2023-05-11 17:33:42,160:   File &quot;/usr/local/lib/python3.10/site-packages/flask/app.py&quot;, line 2080, in wsgi_app\\n2023-05-11 17:33:42,160:\\t response = self.handle_exception(e)\\n2023-05-11 17:33:42,160:\\n2023-05-11 17:33:42,160:   File &quot;/usr/local/lib/python3.10/site-packages/flask/app.py&quot;, line 2077, in wsgi_app\\n2023-05-11 17:33:42,160:\\t response = self.full_dispatch_request()\\n2023-05-11 17:33:42,160:\\n2023-05-11 17:33:42,161:   File &quot;/usr/local/lib/python3.10/site-packages/flask/app.py&quot;, line 1525, in full_dispatch_request\\n2023-05-11 17:33:42,161:\\t rv = self.handle_user_exception(e)\\n2023-05-11 17:33:42,161:\\n2023-05-11 17:33:42,161:   File &quot;/usr/local/lib/python3.10/site-packages/flask/app.py&quot;, line 1523, in full_dispatch_request\\n2023-05-11 17:33:42,161:\\t rv = self.dispatch_request()\\n2023-05-11 17:33:42,161:\\n2023-05-11 17:33:42,162:   File &quot;/usr/local/lib/python3.10/site-packages/flask/app.py&quot;, line 1509, in dispatch_request\\n2023-05-11 17:33:42,162:\\t return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\\n2023-05-11 17:33:42,162:\\n2023-05-11 17:33:42,162:   File &quot;/home/wildstarapps/mysite/ibt_blueprint.py&quot;, line 63, in home\\n2023-05-11 17:33:42,163:\\t installer = installer_info(request.form['select_installer'])[0]\\n2023-05-11 17:33:42,163:\\n2023-05-11 17:33:42,163:   File &quot;/usr/local/lib/python3.10/site-packages/werkzeug/datastructures.py&quot;, line 375, in __getitem__\\n2023-05-11 17:33:42,163:\\t raise exceptions.BadRequestKeyError(key)\",\n",
       " \"&lt;div class=&quot;card card--avatar&quot;&gt;\\n\\t\\t&lt;button onclick=&quot;document.getElementById('profile-modal').style.display='flex'&quot; class=&quot;btn-profile&quot;\\n\\t\\t  aria-label=&quot;interactive button&quot;&gt;\\n\\t\\t  &lt;svg aria-hidden=&quot;true&quot; width=&quot;21&quot; height=&quot;5&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;\\n\\t\\t\\t&lt;path\\n\\t\\t\\t  d=&quot;M2.5 0a2.5 2.5 0 1 1 0 5 2.5 2.5 0 0 1 0-5Zm8 0a2.5 2.5 0 1 1 0 5 2.5 2.5 0 0 1 0-5Zm8 0a2.5 2.5 0 1 1 0 5 2.5 2.5 0 0 1 0-5Z&quot;\\n\\t\\t\\t  fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot; /&gt;\\n\\t\\t  &lt;/svg&gt;\\n\\t\\t&lt;/button&gt;\\n\\t\\t&lt;div class=&quot;card--avatar-top card--lg&quot;&gt;\\n\\t\\t  &lt;img class=&quot;avatar&quot;\\n\\t\\t\\tsrc=&quot;{{ url_for('static', filename='images/profile_pics/'+ installer.profile_pic )}}&quot;&gt;\\n\\t\\t  &lt;h1&gt;\\n\\t\\t\\t&lt;span&gt;Report for&lt;/span&gt;&lt;br&gt;\\n\\t\\t\\t{{ installer.f_name }}\\n\\t\\t\\t{{ installer.l_name }}\\n\\t\\t  &lt;/h1&gt;\\n\\t\\t&lt;/div&gt;\\n\\t\\t&lt;div class=&quot;card--avatar-bottom card--sm&quot; role=&quot;tablist&quot; aria-label=&quot;Time Tracking Cross sections&quot;&gt;\\n\\t\\t  &lt;button name=&quot;all-tab&quot; id=&quot;tab-all&quot; class=&quot;btn tab active&quot;\\n\\t\\t\\tonclick=&quot;update_stats(this.attributes['name'].value)&quot;&gt;\\n\\t\\t\\tAll\\n\\t\\t  &lt;/button&gt;\\n\\t\\t  &lt;button name=&quot;day-tab&quot; id=&quot;tab-daily&quot; class=&quot;btn tab&quot; onclick=&quot;update_stats(this.attributes['name'].value)&quot;&gt;\\n\\t\\t\\tDay\\n\\t\\t  &lt;/button&gt;\\n\\t\\t  &lt;button name=&quot;week-tab&quot; id=&quot;tab-weekly&quot; class=&quot;btn tab&quot; onclick=&quot;update_stats(this.attributes['name'].value)&quot;&gt;\\n\\t\\t\\tWeek\\n\\t\\t  &lt;/button&gt;\\n\\t\\t  &lt;button name=&quot;month-tab&quot; id=&quot;tab-monthly&quot; class=&quot;btn tab&quot;\\n\\t\\t\\tonclick=&quot;update_stats(this.attributes['name'].value)&quot;&gt;\\n\\t\\t\\tMonth\\n\\t\\t  &lt;/button&gt;\\n\\t\\t  &lt;form method=&quot;POST&quot; name=&quot;date_form&quot; id=&quot;date_form&quot;&gt;\\n\\t\\t\\t&lt;input type=&quot;hidden&quot; name=&quot;select_installer&quot; value=&quot;{{ installer.id }}&quot;&gt;\\n\\t\\t\\t&lt;input id=&quot;day_selected&quot; name=&quot;day_selector&quot; value=&quot;{{ date_input }}&quot; type=&quot;date&quot; class=&quot;date-selector&quot;\\n\\t\\t\\t  onchange=&quot;submitForm()&quot;&gt;\\n\\t\\t  &lt;/form&gt;\\n\\t\\t&lt;/div&gt;\\n\\t  &lt;/div&gt;\\n&lt;div class=&quot;card timecard&quot; style=&quot;display: none;&quot; id=&quot;google-reviews&quot;&gt;\\n\\t\\t\\t&lt;div class=&quot;card--sm timecard--top&quot;&gt;\\n\\t\\t\\t&lt;/div&gt;\\n\\t\\t\\t&lt;div class=&quot;timecard--bottom card--lg&quot;&gt;\\n\\t\\t\\t  &lt;div class=&quot;timecard--title&quot;&gt;\\n\\t\\t\\t\\t&lt;h2&gt;\\n\\t\\t\\t\\t  5 Star Reviews\\n\\t\\t\\t\\t&lt;/h2&gt;\\n\\t\\t\\t\\t{% if session.user_info.role|lower == 'admin' %}\\n\\t\\t\\t\\t&lt;button onclick=&quot;document.getElementById('review-modal').style.display='flex'&quot; class=&quot;btn&quot; aria-label=&quot;interactive button&quot;&gt;\\n\\t\\t\\t\\t  &lt;svg aria-hidden=&quot;true&quot; width=&quot;21&quot; height=&quot;5&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;\\n\\t\\t\\t\\t\\t&lt;path\\n\\t\\t\\t\\t\\t  d=&quot;M2.5 0a2.5 2.5 0 1 1 0 5 2.5 2.5 0 0 1 0-5Zm8 0a2.5 2.5 0 1 1 0 5 2.5 2.5 0 0 1 0-5Zm8 0a2.5 2.5 0 1 1 0 5 2.5 2.5 0 0 1 0-5Z&quot;\\n\\t\\t\\t\\t\\t  fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot; /&gt;\\n\\t\\t\\t\\t  &lt;/svg&gt;\\n\\t\\t\\t\\t&lt;/button&gt;\\n\\t\\t\\t\\t{% endif %}\\n\\t\\t\\t  &lt;/div&gt;\\n\\t\\t\\t  &lt;div class=&quot;timecard--amt&quot;&gt;\\n\\t\\t\\t\\t&lt;p class=&quot;current&quot;&gt;\\n\\t\\t\\t\\t  {{ review_count }}\\n\\t\\t\\t\\t&lt;/p&gt;\\n\\t\\t\\t  &lt;/div&gt;\\n\\t\\t\\t&lt;/div&gt;\\n\\t\\t  &lt;/div&gt;\\n&lt;form method=&quot;POST&quot; id=&quot;installer-submit&quot;&gt;\\n  &lt;input type=&quot;hidden&quot; name=&quot;day_selector&quot; value=&quot;{{ date_input }}&quot;&gt;\\n  &lt;div id=&quot;user-modal&quot; class=&quot;modal&quot;&gt;\\n\\t&lt;div class=&quot;modal-content modal-card modal-animate&quot; style=&quot;max-width:600px&quot;&gt;\\n\\t  &lt;div class=&quot;modal-container&quot;&gt;\\n\\t\\t&lt;div class=&quot;modal-section&quot;&gt;\\n\\t\\t  &lt;label for=&quot;select-installer&quot;&gt;Please select a tech:&lt;/label&gt;\\n\\t\\t  &lt;select name=&quot;select_installer&quot; id=&quot;select-installer&quot; onchange=&quot;submit_installer_form()&quot;&gt;\\n\\t\\t\\t{% for installers in all_installers %}\\n\\t\\t\\t\\t{% if installers['id'] == installer['id'] %}\\n\\t\\t\\t\\t\\t&lt;option value=&quot;{{ installer['id'] }}&quot; selected=&quot;&quot;&gt;{{ installer['f_name'] + ' ' + installer['l_name'] }}&lt;/option&gt;\\n\\t\\t\\t\\t{% else %}\\n\\t\\t\\t\\t\\t&lt;option value=&quot;{{ installers['id'] }}&quot;&gt;{{ installers['f_name'] + ' ' + installers['l_name'] }}&lt;/option&gt;\\n\\t\\t\\t\\t{% endif %}\\n\\t\\t\\t{% endfor %}\\n\\t\\t  &lt;/select&gt;\\n\\t\\t  &lt;div class=&quot;buttons&quot;&gt;\\n\\t\\t\\t&lt;button onclick=&quot;document.getElementById('user-modal').style.display='none'&quot; type=&quot;button&quot;\\n\\t\\t\\tclass=&quot;modal-button-close&quot;&gt;Close&lt;/button&gt;\\n\\t\\t  &lt;/div&gt;\\n\\t\\t&lt;/div&gt;\\n\\t  &lt;/div&gt;\\n\\t&lt;/div&gt;\\n  &lt;/div&gt;\\n&lt;/form&gt;\\n&lt;form method=&quot;POST&quot; id=&quot;review-form&quot;&gt;\\n  &lt;div id=&quot;review-modal&quot; class=&quot;modal&quot;&gt;\\n\\t&lt;div class=&quot;modal-content modal-card modal-animate&quot; style=&quot;max-width:600px&quot;&gt;\\n\\t  &lt;div class=&quot;modal-container&quot;&gt;\\n\\t\\t&lt;div class=&quot;modal-section&quot;&gt;\\n\\t\\t  &lt;label for=&quot;review-date&quot;&gt;Review Date:&lt;/label&gt;\\n\\t\\t  &lt;input type=&quot;month&quot; id=&quot;review-date&quot; name=&quot;review_date&quot;&gt;\\n\\t\\t  &lt;label for=&quot;tech-select&quot;&gt;Choose tech(s):&lt;/label&gt;\\n\\t\\t  &lt;select id=&quot;tech-select&quot; name=&quot;selected_tech&quot;&gt;\\n\\t\\t\\t{% for installers in all_installers %}\\n\\t\\t\\t&lt;option value=&quot;{{ installers['l_name'] + ',' + ' ' + installers['f_name'] }}&quot;&gt;{{ installers['f_name'] + ' ' + installers['l_name'] }}&lt;/option&gt;\\n\\t\\t\\t{% endfor %}\\n\\t\\t  &lt;/select&gt;\\n\\t\\t  &lt;label for=&quot;account-id&quot;&gt;Account ID:&lt;/label&gt;\\n\\t\\t  &lt;input type=&quot;text&quot; id=&quot;account-id&quot; name=&quot;account_id&quot;&gt;\\n\\t\\t  &lt;div class=&quot;buttons&quot;&gt;\\n\\t\\t\\t&lt;button type=&quot;submit&quot; name=&quot;review_submit&quot; id=&quot;review-submit&quot; value=&quot;Submit Review&quot; class=&quot;modal-button-submit&quot;&gt;Submit&lt;/button&gt;\\n\\t\\t\\t&lt;button onclick=&quot;document.getElementById('review-modal').style.display='none'&quot; type=&quot;button&quot;\\n\\t\\t\\tclass=&quot;modal-button-close&quot;&gt;Close&lt;/button&gt;\\n\\t\\t  &lt;/div&gt;\\n\\t\\t&lt;/div&gt;\\n\\t  &lt;/div&gt;\\n\\t&lt;/div&gt;\\n  &lt;/div&gt;\\n&lt;/form&gt;\",\n",
       " \"if request.method == &quot;POST&quot;:\\n\\t\\treview_date = request.form.get(&quot;review_date&quot;)\\n\\t\\tselected_tech = request.form.get(&quot;selected_tech&quot;)\\n\\t\\treview_account_id = request.form.get(&quot;account_id&quot;)\\n\\t\\tif review_date and selected_tech and review_account_id:\\n\\t\\t\\tparsed_date = datetime.strptime(review_date, &quot;%Y-%m&quot;)\\n\\t\\t\\tmonth = parsed_date.strftime(&quot;%-m&quot;)\\n\\t\\t\\tyear = parsed_date.strftime(&quot;%Y&quot;)\\n\\t\\t\\tlast_row = len(gReviewWorksheet.get_all_values()) + 1\\n\\t\\t\\tgReviewWorksheet.update(f&quot;A{last_row}&quot;, month)\\n\\t\\t\\tgReviewWorksheet.update(f&quot;B{last_row}&quot;, year)\\n\\t\\t\\tgReviewWorksheet.update(f&quot;C{last_row}&quot;, selected_tech)\\n\\t\\t\\tgReviewWorksheet.update(f&quot;F{last_row}&quot;, review_account_id)\\n\\t\\tinstaller_hours_dict = {}\\n\\t\\tinstaller = installer_info(request.form['select_installer'])[0]\\n\\t\\tselected_date = datetime.strptime(request.form['day_selector'], '%Y-%m-%d')\\n\\t\\thours = hoursDf.query(f<str>).to_dict('records')\\n\\t\\treviews = gReviewDf.query(f<str>).to_dict('records')\\n\\t\\treview_count = len(reviews)\",\n",
       " 'simulate',\n",
       " 'update',\n",
       " 'update',\n",
       " 'import numpy as np\\ndef autoregressive_process():\\n\\tiT = 100\\n\\tlag = 1\\n\\tphi = 0.02\\n\\tvY = np.empty(iT)\\n\\tvX = np.random.rand(iT+lag)\\n\\tvEps = np.random.rand(iT)\\n\\tfor t in range(lag,iT):\\n\\t\\tvY[t] = phi * vX[t-1] + vEps[t]\\n\\treturn vY',\n",
       " 'import numpy as np\\ndef ramp_process():\\n\\tiT = 100\\n\\tvY = np.empty(iT)\\n\\tvEps = np.random.rand(iT)\\n\\tfor t in range(iT):\\n\\t\\tvY[t] = (t % 10) + vEps[t]\\n\\treturn vY',\n",
       " 'X',\n",
       " 'import numpy as np\\ndef autoregressive(time, phi, X_lag, error):\\n\\treturn phi * X_lag + error\\ndef ramp(time, phi, X_lag, error):\\n\\treturn (time % 10) + error\\ndef simulate(update):\\n\\tiT = 100\\n\\tlag = 1\\n\\tphi = 0.02\\n\\tvY = np.empty(iT)\\n\\tvX = np.random.rand(iT+lag)\\n\\tvEps = np.random.rand(iT)\\n\\tfor t in range(iT):\\n\\t\\tvY[t] = update(t, phi, vX[t-1], vEps[t])\\n\\treturn vY',\n",
       " 'update',\n",
       " \"import disnake\\nfrom disnake.ext import commands\\nimport time\\nfrom disnake import Intents\\nbot = commands.Bot(command_prefix=&quot;*&quot;, intents=disnake.Intents.all())\\n@bot.event\\nasync def on_ready():\\n\\tprint(f'{bot.user.name} has connected to Discord!')\\n\\tchannel1 = bot.get_channel(1105450189688414208)\\n\\tchannel2 = bot.get_channel(1105452174546321498)\\n\\tlast_line_file1 = ''\\n\\tlast_line_file2 = ''\\n\\twhile True:\\n\\t\\twith open('&quot;C:\\\\\\\\Users\\\\\\\\______\\\\\\\\____\\\\\\\\_____\\\\\\\\______\\\\\\\\_____\\\\\\\\_____\\\\\\\\server_chat_log.txt&quot;', 'r', encoding='cp1251') as file2:\\n\\t\\t\\tlast_line = file2.readlines()[-1].strip()\\n\\t\\t\\tif last_line != last_line_file2:\\n\\t\\t\\t\\tawait channel2.send(last_line)\\n\\t\\t\\t\\tlast_line_file2 = last_line\\n\\t\\ttime.sleep(0.5)\\nbot.run('---')\",\n",
       " '[00:15:59]: [Say] (KU_LnRtDiLl) groznyjsasison: Сѓ РјРµРЅСЏ РЅРѕСЂРј Р»СѓС‚ С‚РµРїРµСЂСЊ\\n[00:16:56]: [Say] (KU_l2ws0ArT) РљРѕРЅРЅРѕСЂ RK800 (????): СЃРєРѕРє Сѓ С‚РµР±СЏ РєР°РјРЅСЏ?\\n[00:17:05]: [Say] (KU_LnRtDiLl) groznyjsasison: РєР°РјРЅСЏ 14\\n[00:17:06]: [Join Announcement] Aleksey Meatballs in DST\\n[00:17:09]: [Say] (KU_LnRtDiLl) groznyjsasison: РєСЂРµРјРЅСЏ 24\\n[00:17:13]: [Say] (KU_l2ws0ArT) РљРѕРЅРЅРѕСЂ RK800 (????): РґРѕР±СѓРґСЊ 40 С…РѕС‚СЏ Р±С‹\\n[00:17:17]: [Say] (KU_LnRtDiLl) groznyjsasison: Р·РЅР°СЋ\\n[00:17:18]: [Say] (KU_l2ws0ArT) РљРѕРЅРЅРѕСЂ RK800 (????): РєСЂРµРјРЅСЏ РёС‚Р°Рє Сѓ РјРµРЅСЏ 40\\n[00:19:42]: [Say] (KU_LnRtDiLl) groznyjsasison: РґР°РІР°Р№ СЏ СѓРіР»СЏ РґРѕР±СѓРґСѓ\\n[00:19:46]: [Say] (KU_LnRtDiLl) groznyjsasison: РґР»СЏ РєР°Р·Р°РЅР°\\n[00:19:49]: [Say] (KU_l2ws0ArT) РљРѕРЅРЅРѕСЂ RK800 (????): РіРѕ\\n[00:19:59]: [Say] (KU_l2ws0ArT) РљРѕРЅРЅРѕСЂ RK800 (????): СЏ Р·РѕР»РѕС‚Рѕ РґРѕР±С‹Р»\\n[00:20:09]: [Say] (KU_LnRtDiLl) groznyjsasison: Сѓ РјРµРЅСЏ 2 Р·РѕР»РѕС‚Р°\\n[00:20:24]: [Say] (KU_l2ws0ArT) РљРѕРЅРЅРѕСЂ RK800 (????): РґРѕР±Р°РІСЊ РјРµРЅСЏ РІ РґСЂ\\n[00:20:31]: [Say] (KU_l2ws0ArT) РљРѕРЅРЅРѕСЂ RK800 (????): РЅР°С… РµС‚Рѕ РіРѕРІРѕСЂРёС‚СЊ РІ РѕР±С‰РёР№ С‡Р°С‚\\n[00:20:38]: [Say] (KU_LnRtDiLl) groznyjsasison: РєР°Рє\\n[00:20:40]: [Say] (KU_LnRtDiLl) groznyjsasison: РІ РґСЂ\\n[00:20:41]: [Say] (KU_l2ws0ArT) РљРѕРЅРЅРѕСЂ RK800 (????): РІ СЃС‚РёРјРµ\\n[00:20:47]: [Say] (KU_LnRtDiLl) groznyjsasison: СЏ РЅРµ РјРѕРіСѓ\\n[00:20:52]: [Say] (KU_LnRtDiLl) groznyjsasison: РЅРµ РґРѕРЅРёР»\\n[00:20:52]: [Say] (KU_l2ws0ArT) РљРѕРЅРЅРѕСЂ RK800 (????): СЏ С‚РµР±Рµ Р·Р°СЏРІРєСѓ РєРёРЅСѓ',\n",
       " 'import boto3\\ns3 = boto3.client(&quot;s3&quot;)',\n",
       " 'from settings import s3\\ndef do_something():\\n\\tresponse = s3.list_objects_v2(...)',\n",
       " 'from settings import s3\\ndef do_something(s3_client = s3):\\n\\tresponse = s3_client.list_objects_v2(...)\\ndo_something(s3)',\n",
       " \"`import joblib\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom facenet_pytorch import MTCNN\\nimport cv2\\nmtcnn = MTCNN(image_size=160, margin=14, min_face_size=20,device='cpu', post_process=False)\\nfrom numpy import expand_dims\\nfrom cv2 import resize, INTER_CUBIC, INTER_AREA\\nfrom tensorflow.keras.preprocessing.image import img_to_array\\npca = joblib.load ('pca_model.joblib')\\nscaler = joblib.load('scaler.joblib')\\nclf = joblib.load ('SVC.joblib')\\nimport tensorflow as tf\\nmodel = tf.keras.models.load_model('saved_model\\\\my_model')\\ndef preprocess_image(img):\\n\\timg = img_to_array(img)\\n\\timg = img / 255.0\\n\\timg = expand_dims(img, axis=0)\\n\\treturn img\\ndef Face_Recognition(roi, model, scaler, pca, clf):\\n\\troi = resize(roi, dsize=(224, 224), interpolation=INTER_CUBIC)\\n\\troi = preprocess_image(roi)\\n\\tembedding_vector = model.predict(roi)[0]\\n\\tembedding_vector = scaler.transform(embedding_vector.reshape(1, -1))\\n\\tembedding_vector_pca = pca.transform(embedding_vector)\\n\\tresult1 = clf.predict(embedding_vector_pca)[0]\\n\\ty_predict = clf.predict_proba(embedding_vector_pca)[0]\\n\\tprint(y_predict)\\n\\tresult = np.where(y_predict &gt; 0.8)[0]\\n\\tprint(result)\\n\\treturn result, y_predict\\ncap=cv2.VideoCapture(1)\\ncap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\\ncap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\\nclasses = {'Esraa': 0, 'Mohamed': 1, 'Tasneem':2, 'nesma': 3, 'salma':4, 'kero': 5}\\ndef ImageClass(n):\\n\\tfor x , y in classes.items():\\n\\t\\tif n == y :\\n\\t\\t\\treturn x`\",\n",
       " 'tol',\n",
       " 'ftol',\n",
       " \"'callback'\",\n",
       " \"'minimizer_kwargs'\",\n",
       " 'True',\n",
       " \"res = optimize.basinhopping(objectivefunc, x0,callback=basinhopping_callback, T=T0, stepsize=stepsize0,\\n\\t\\t\\t\\t\\t\\t\\tminimizer_kwargs={'method':'SLSQP','bounds': bnds, 'constraints': cons,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  'callback' : print_callback,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t 'options' :{'disp': True,'maxiter':50,'ftol':1e-4}},\\n\\t\\t\\t\\t\\t\\t\\tseed=123456, niter=maxiter,interval=5,take_step=my_take_step)\",\n",
       " 'print_callback',\n",
       " 'ftol_local = 1e-2\\nmax_runs_below_threshold = 3\\nnum_runs_below_threshold = 0\\nprev_fun = np.inf\\nn = 1\\ndef print_callback(xk):\\n\\tglobal num_runs_below_threshold, prev_fun,n\\n\\tn+=1\\n\\tprint(n)\\n\\t f_new = objectivefunc(xk)\\n\\t print(n,prev_fun,f_new,f_new-prev_fun)\\n\\t n+=1\\n\\t if np.abs(f_new - prev_fun) &lt;= ftol_local:\\n\\t\\t num_runs_below_threshold += 1\\n\\t  else:\\n\\t\\t  num_runs_below_threshold = 0\\n\\t prev_fun = f_new\\n\\t if num_runs_below_threshold &gt;= max_runs_below_threshold:\\n\\t\\t return True\\n\\t else:\\n\\t\\t return False',\n",
       " 'basinhopping_callback',\n",
       " 'df_iter_basinhopping = pd.DataFrame()\\niter1=0\\ndef basinhopping_callback(x, f, accepted):\\n\\tglobal df_iter_basinhopping,iter1\\n\\tdf_iter_basinhopping = df_iter_basinhopping.append({&quot;f&quot;: -f, &quot;accepted&quot;: accepted,&quot;x&quot;: x}, ignore_index=True)\\n\\titer1+=1\\n\\tprint(f&quot;Iteration: {iter1} - Function value: {-f}&quot;)',\n",
       " 'data',\n",
       " '(N, W, D)',\n",
       " 'index',\n",
       " '(B,)',\n",
       " 'data',\n",
       " 'index',\n",
       " '(B,N,D)',\n",
       " 'index',\n",
       " 'data',\n",
       " 'grid_sample',\n",
       " 'grid_sample',\n",
       " 'data',\n",
       " 'index',\n",
       " 'data',\n",
       " 'data',\n",
       " 'index',\n",
       " 'data',\n",
       " 'B',\n",
       " 'grid_sample',\n",
       " \"import io\\nfrom rembg import remove\\nfrom PIL import Image\\nimport requests\\nfrom io import BytesIO\\nimport firebase_admin\\nfrom firebase_admin import credentials, storage\\nurl = 'https://upload.wikimedia.org/wikipedia/commons/1/15/Red_Apple.jpg'\\nresponse = requests.get(url)\\ninput = Image.open(BytesIO(response.content))\\noutputPath = 'new.png'\\noutput = remove(input)\\nfile_path = &quot;posts/&quot; + 'somefolder/' + outputPath\\nbucket = storage.bucket()\\nblob = bucket.blob(file_path)\\nblob.upload_from_file(output)\",\n",
       " 'Traceback (most recent call last):\\n  File &quot;/Users/finnborchers/Desktop/Code/Python_Klausur/Unisecs/testLocal.py&quot;, line 36, in &lt;module&gt;\\n\\tblob.upload_from_file(output)\\n  File &quot;/Users/finnborchers/Library/Python/3.9/lib/python/site-packages/google/cloud/storage/blob.py&quot;, line 2540, in upload_from_file\\n\\tcreated_json = self._do_upload(\\n  File &quot;/Users/finnborchers/Library/Python/3.9/lib/python/site-packages/google/cloud/storage/blob.py&quot;, line 2371, in _do_upload\\n\\tresponse = self._do_resumable_upload(\\n  File &quot;/Users/finnborchers/Library/Python/3.9/lib/python/site-packages/google/cloud/storage/blob.py&quot;, line 2215, in _do_resumable_upload\\n\\tresponse = upload.transmit_next_chunk(transport, timeout=timeout)\\n  File &quot;/Users/finnborchers/Library/Python/3.9/lib/python/site-packages/google/resumable_media/requests/upload.py&quot;, line 503, in transmit_next_chunk\\n\\tmethod, url, payload, headers = self._prepare_request()\\n  File &quot;/Users/finnborchers/Library/Python/3.9/lib/python/site-packages/google/resumable_media/_upload.py&quot;, line 614, in _prepare_request\\n\\tstart_byte, payload, content_range = get_next_chunk(\\n  File &quot;/Users/finnborchers/Library/Python/3.9/lib/python/site-packages/google/resumable_media/_upload.py&quot;, line 968, in get_next_chunk\\n\\tpayload = stream.read(chunk_size)\\n  File &quot;/Users/finnborchers/Library/Python/3.9/lib/python/site-packages/PIL/Image.py&quot;, line 528, in __getattr__\\n\\traise AttributeError(name)\\nAttributeError: read',\n",
       " \"import os\\nimport sys\\nfrom Bio import SeqIO\\nab1_files = [f for f in os.listdir() if f.endswith('.ab1')]\\nfor ab1_file in ab1_files:\\n\\tfasta_file = os.path.splitext(ab1_file)[0] + '.fasta'  \\n\\twith open(ab1_file, 'rb') as ab1_handle, open(fasta_file, 'w') as fasta_handle:\\n\\t\\tSeqIO.convert(ab1_handle, 'abi', fasta_handle, 'fasta')\\nall_fasta_file = 'all_sequences.fasta'\\nwith open(all_fasta_file, 'w') as all_fasta_handle:\\n\\tfor ab1_file in ab1_files:\\n\\t\\tfasta_file = os.path.splitext(ab1_file)[0] + '.fasta'\\n\\t\\theader = '&gt;' + ab1_file + '\\\\n'\\n\\t\\twith open(fasta_file, 'r') as fasta_handle:\\n\\t\\t\\tsequence = fasta_handle.read().strip()\\n\\t\\t\\tall_fasta_handle.write(header + sequence + '\\\\n')\\n\\t\\tos.remove(fasta_file)  \\nprint('All AB1 files converted to FASTA format and concatenated into ' + all_fasta_file)\",\n",
       " \"Traceback (most recent call last):\\n  File &quot;01_ab1_to_fasta.py&quot;, line 12, in &lt;module&gt;\\n\\tSeqIO.convert(ab1_handle, 'abi', fasta_handle, 'fasta')\\n  File &quot;/Users/pmi12/Library/Python/3.8/lib/python/site-packages/Bio/SeqIO/__init__.py&quot;, line 1072, in convert\\n\\trecords = parse(in_file, in_format)\\n  File &quot;/Users/pmi12/Library/Python/3.8/lib/python/site-packages/Bio/SeqIO/__init__.py&quot;, line 605, in parse\\n\\treturn iterator_generator(handle)\\n  File &quot;/Users/pmi12/Library/Python/3.8/lib/python/site-packages/Bio/SeqIO/AbiIO.py&quot;, line 353, in __init__\\n\\tsuper().__init__(source, mode=&quot;b&quot;, fmt=&quot;ABI&quot;)\\n  File &quot;/Users/pmi12/Library/Python/3.8/lib/python/site-packages/Bio/SeqIO/Interfaces.py&quot;, line 63, in __init__\\n\\tself.records = self.parse(self.stream)\\n  File &quot;/Users/pmi12/Library/Python/3.8/lib/python/site-packages/Bio/SeqIO/AbiIO.py&quot;, line 364, in parse\\n\\traise OSError(f&quot;File should start ABIF, not {marker!r}&quot;)\\nOSError: File should start ABIF, not b'\\\\x00\\\\x05\\\\x16\\\\x07'\",\n",
       " 'pandas',\n",
       " \"\\temail_sender = &quot;xxxxx&quot;\\n\\temail_receiver = &quot;yyyyy&quot;\\n\\temail_subject = 'Email Subject'\\n\\tmsg = MIMEMultipart()\\n\\tmsg['From'] = email_sender\\n\\tmsg['To'] = email_receiver\\n\\tmsg['Subject'] = email_subject\\n\\tfilename1 = 'BAP1.xlsx'\\n\\tdf = pandas.read_excel('cases.xlsx', sheet_name='new_sheet')\\n\\tdf.to_csv('my_csv_file.csv', index=False)\\n\\thtml_table = df.to_html()\\n\\thtml_table.replace('\\\\n', '')  \\n\\thtml_table.replace('border=&quot;1&quot;', '')  \\n\\thtml_table.replace('&lt;th&gt;', '&lt;th style=&quot;text-align: center&quot;&gt;')\\n\\thtml_table.replace('&lt;table', '&lt;table  style=&quot;text-align: center&quot; ; white-space: nowrap &gt;')\\n\\tmsg.attach(MIMEText(html_table, 'html'))\\n\\twith open(filename1, 'rb') as file1:\\n\\t\\tattachment = MIMEBase('application', 'octet-stream')\\n\\t\\tattachment.set_payload(file1.read())\\n\\t\\tencoders.encode_base64(attachment)\\n\\t\\tattachment.add_header('Content-Disposition', f'attachment; filename=&quot;{filename1}&quot;')\\n\\tmsg.attach(attachment)\\n\\twith smtplib.SMTP('smtp.office365.com', 587) as smtp:\\n\\t\\tsmtp.starttls()\\n\\t\\tsmtp.login('s.arvindh@applieddatafinance.com', 'hqxgnrgdfpkryfdz')\\n\\t\\tsmtp.send_message(msg)\\n\\t\\tprint(&quot;Email sent!&quot;)\",\n",
       " \"dae = keras.models.Sequential([\\n\\tkeras.layers.GaussianNoise(.1),\\n\\tkeras.layers.Dense(14, activation='relu'),\\n\\tkeras.layers.Dense(1500, activation='relu'),\\n\\tkeras.layers.Dense(1500, activation='relu'),\\n\\tkeras.layers.Dense(1500, activation='relu'),\\n\\tkeras.layers.Dense(14, activation='relu'),\\n])\",\n",
       " 'python-docx',\n",
       " 'win32com',\n",
       " 'inherited-members',\n",
       " 'False',\n",
       " 'conf.py',\n",
       " 'P',\n",
       " 'B',\n",
       " 'B',\n",
       " 'P',\n",
       " 'A',\n",
       " 'P',\n",
       " 'P',\n",
       " 'inherited-members',\n",
       " 'import matplotlib.pyplot as plt\\nimport numpy as np\\nfrom pyscript import Element\\nimport datetime\\nx = np.random.randn(1000)\\ny = np.random.randn(1000)\\nfig, ax = plt.subplots()\\nax.scatter(x, y)\\ndisplay(fig, target=&quot;plot&quot;)\\ndef current_time():\\n\\tnow = datetime.datetime.now()\\n\\tparagraph = Element(&quot;current-time&quot;)\\n\\tparagraph.write(now.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;))',\n",
       " 'py-script',\n",
       " \"&lt;py-script src=&quot;{% static 'py/script.py' %}&quot;&gt;&lt;/py-script&gt;\",\n",
       " \"{% extends &quot;proj/base.html&quot; %}\\n{% load static %}\\n{% block head %}\\n&lt;link rel=&quot;stylesheet&quot;\\n\\t  href=&quot;https://pyscript.net/latest/pyscript.css&quot;/&gt;\\n&lt;script defer src=&quot;https://pyscript.net/latest/pyscript.js&quot;&gt;&lt;/script&gt;\\n&lt;py-config type=&quot;toml&quot;&gt;\\n\\tpackages = [&quot;numpy&quot;, &quot;matplotlib&quot;]\\n&lt;/py-config&gt;\\n{% endblock head %}\\n{% block content %}\\n&lt;div id=&quot;plot&quot;&gt;&lt;/div&gt;\\n&lt;button py-click=&quot;current_time()&quot; id=&quot;get-time&quot; class=&quot;py-button&quot;&gt;Get current time&lt;/button&gt;\\n&lt;p id=&quot;current-time&quot;&gt;&lt;/p&gt;\\n{% endblock content %}\\n{% block script %}\\n&lt;py-script src=&quot;{% static 'py/script.py' %}&quot;&gt;&lt;/py-script&gt;\\n{% endblock script %}\",\n",
       " \"{% extends &quot;proj/base.html&quot; %}\\n{% load static %}\\n{% block head %}\\n&lt;link rel=&quot;stylesheet&quot;\\n\\t  href=&quot;https://pyscript.net/latest/pyscript.css&quot;/&gt;\\n&lt;script defer src=&quot;https://pyscript.net/latest/pyscript.js&quot;&gt;&lt;/script&gt;\\n&lt;py-config type=&quot;toml&quot;&gt;\\n\\tpackages = [&quot;numpy&quot;, &quot;matplotlib&quot;]\\n&lt;/py-config&gt;\\n{% endblock head %}\\n{% block content %}\\n&lt;div id=&quot;plot&quot;&gt;&lt;/div&gt;\\n&lt;button py-click=&quot;current_time()&quot; id=&quot;get-time&quot; class=&quot;py-button&quot;&gt;Get current time&lt;/button&gt;\\n&lt;p id=&quot;current-time&quot;&gt;&lt;/p&gt;\\n&lt;py-script&gt;\\nimport datetime\\ndef current_time():\\n\\tnow = datetime.datetime.now()\\n\\tparagraph = Element(&quot;current-time&quot;)\\n\\tparagraph.write(now.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;))\\n&lt;/py-script&gt;\\n{% endblock content %}\\n{% block script %}\\n&lt;py-script src=&quot;{% static 'py/script.py' %}&quot;&gt;&lt;/py-script&gt;\\n{% endblock script %}\",\n",
       " \"{% load static %}\\n&lt;!DOCTYPE html&gt;\\n&lt;head&gt;\\n\\t&lt;meta charset=&quot;UTF-8&quot;&gt;\\n\\t&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt;\\n\\t&lt;title&gt;{{ title }}&lt;/title&gt;\\n\\t&lt;link href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;\\n\\t\\t  rel=&quot;stylesheet&quot;\\n\\t\\t  integrity=&quot;sha384-Zenh87qX5JnK2Jl0vWa8Ck2rdkQ2Bzep5IDxbcnCeuOxjzrPF/et3URy9Bv1WTRi&quot;\\n\\t\\t  crossorigin=&quot;anonymous&quot;&gt;\\n\\t&lt;!-- Custom styles for this template --&gt;\\n\\t&lt;link href=&quot;{% static 'css/proj.css' %}&quot; rel=&quot;stylesheet&quot;&gt;\\n\\t&lt;link href=&quot;{% static 'css/forms.css' %}&quot; rel=&quot;stylesheet&quot;&gt;\\n\\t&lt;!-- Block which is reserved for extensions of the head (e.g. stylesheets) --&gt;\\n\\t{% block head %}{% endblock %}\\n&lt;/head&gt;\\n&lt;body&gt;\\n&lt;main class=&quot;d-flex flex-nowrap&quot;&gt;\\n\\t{% include 'proj/navbar.html' %}\\n\\t&lt;div class=&quot;b-example-divider b-example-vr&quot;&gt;&lt;/div&gt;\\n\\t&lt;div class=&quot;content&quot;&gt;\\n\\t\\t{% block content %}{% endblock %}\\n\\t&lt;/div&gt;\\n&lt;/main&gt;\\n&lt;!-- Block which is reserved for extensions of scripts --&gt;\\n{% block script %}{% endblock %}\\n&lt;script src=&quot;https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js&quot;\\n\\t\\tintegrity=&quot;sha384-oBqDVmMz9ATKxIep9tiCxS/Z9fNfEXiDAYTujMAeBAsjFuCZSmKbSSUnQlmh/jp3&quot;\\n\\t\\tcrossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;\\n&lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.min.js&quot;\\n\\t\\tintegrity=&quot;sha384-IDwe1+LCz02ROU9k972gdyvl+AESN10+x7tBKgc9I5HFtuNz0wWnPclzo6p9vxnk&quot;\\n\\t\\tcrossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;\\n&lt;/body&gt;\\n&lt;/html&gt;\",\n",
       " 'update_employee',\n",
       " 'search_employee',\n",
       " 'if condition',\n",
       " 'search_employee',\n",
       " 'if condition',\n",
       " 'search_from_database',\n",
       " \"import mysql.connector\\nfrom tkinter import *\\nclass AdminPanel:\\n\\tdef __init__(self, main):\\n\\t\\tself.main = main\\n\\t\\tself.frame = None\\n\\t\\tself.UPDATE = {'ID': '', 'Found': False}\\n\\t\\tself.connection = mysql.connector.connect(\\n\\t\\t\\thost=&quot;localhost&quot;,\\n\\t\\t\\tuser=&quot;root&quot;,\\n\\t\\t\\tpassword=&quot;&quot;,\\n\\t\\t\\tdatabase=&quot;employee-management&quot;\\n\\t\\t)\\n\\t\\tself.cursor = self.connection.cursor()\\n\\tdef update_employee(self):\\n\\t\\tself.search_employee()\\n\\t\\tif self.UPDATE['Found']:\\n\\tdef search_employee(self):\\n\\t\\tif self.frame is not None:\\n\\t\\t\\tself.frame.destroy()\\n\\t\\tself.frame = Frame(self.main, pady=10, padx=10, relief=RAISED)\\n\\t\\tfirst_name = Entry(self.frame, font='lucid 15', width=15)\\n\\t\\tfirst_name.grid(row=0, column=1)\\n\\t\\tlast_name = Entry(self.frame, font='lucid 15', width=15)\\n\\t\\tlast_name.grid(row=1, column=1)\\n\\t\\tButton(self.frame, text='Search', font='arial 10 bold', pady=3, padx=5,\\n\\t\\t\\t   command=lambda: self.search_from_database(first_name.get(), last_name.get()))\\\\\\n\\t\\t\\t.grid(row=3, column=1, pady=10)\\n\\t\\tself.frame.pack(side=LEFT, fill=BOTH)\\n\\tdef search_from_database(self, f_name, l_name):\\n\\t\\tquery = &quot;SELECT id,fname,lname FROM empdata&quot;\\n\\t\\tself.cursor.execute(query)\\n\\t\\tvalues = self.cursor.fetchall()\\n\\t\\tfor data in values:\\n\\t\\t\\tif data[1] == f_name and data[2] == l_name:\\n\\t\\t\\t\\tself.UPDATE.update({'ID': data[0], 'Found': True})\\n\\t\\t\\t\\tbreak\\nroot = Tk()\\nobj = AdminPanel(root)\\nobj.update_employee()\\nroot.mainloop()\",\n",
       " 'search_from_database',\n",
       " 'update_employee',\n",
       " 'search_from_database',\n",
       " \"import os\\nimport re\\nfrom pdfminer.high_level import extract_text\\npdf_file = 'C:\\\\\\\\Users\\\\\\\\xx\\\\\\\\statement.pdf'\\ntext = extract_text(pdf_file)\\npattern = r'(-?\\\\d,\\\\d{2})[\\\\s\\\\S]*?(\\\\nRestaurant)'\\nmatch = re.search(pattern, text)\\nif match:\\n\\tprint(f'Found &quot;Restaurant&quot; with number &quot;{match.group(1)}&quot;')\\nelse:\\n\\tprint(&quot;No entries of such endeavour were found&quot;)\",\n",
       " '  x x\\ny|z|z|\\ny|z|z|',\n",
       " '\\tTraceback (most recent call last):\\n  File &quot;C:\\\\Users\\\\ellio\\\\.conda\\\\envs\\\\rtxtraining\\\\lib\\\\site-packages\\\\spyder_kernels\\\\py3compat.py&quot;, line 356, in compat_exec\\n\\texec(code, globals, locals)\\n  File &quot;c:\\\\users\\\\ellio\\\\programs\\\\rffae_clustering_stackoverflow.py&quot;, line 278, in &lt;module&gt;\\n\\toutput = autoencoder(x)\\n  File &quot;C:\\\\Users\\\\ellio\\\\.conda\\\\envs\\\\rtxtraining\\\\lib\\\\site-packages\\\\keras\\\\utils\\\\traceback_utils.py&quot;, line 70, in error_handler\\n\\traise e.with_traceback(filtered_tb) from None\\n  File &quot;C:\\\\Users\\\\ellio\\\\.conda\\\\envs\\\\rtxtraining\\\\lib\\\\site-packages\\\\keras\\\\engine\\\\input_spec.py&quot;, line 232, in assert_input_compatibility\\n\\traise ValueError(\\nValueError: Exception encountered when calling layer &quot;model_128&quot; &quot;\\t\\t\\t\\t f&quot;(type Functional).\\nInput 0 of layer &quot;random_fourier_features_141&quot; is incompatible with the layer: expected ndim=2, found ndim=1. Full shape received: (128,)\\nCall arguments received by layer &quot;model_128&quot; &quot;\\t\\t\\t\\t f&quot;(type Functional):\\n  • inputs=tf.Tensor(shape=(256,), dtype=float32)\\n  • training=False\\n  • mask=None',\n",
       " \"import numpy as np\\nimport math\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers\\nimport random\\nfrom os import listdir\\nimport pickle\\ndef loadData(basePath, samplesPerFile, sampleRate):\\n\\treal = []\\n\\timag = []\\n\\tfileOrder = []\\n\\tfor file in listdir(basePath):\\n\\t\\tif((file != &quot;READ_ME&quot;) and ((file != &quot;READ_ME.txt&quot;))):\\n\\t\\t\\tfid = open(basePath + &quot;\\\\\\\\&quot; + file, &quot;r&quot;)\\n\\t\\t\\tfileOrder.append(file)\\n\\t\\t\\tt = 0\\n\\t\\t\\tsampleEvery = samplesPerFile / sampleRate\\n\\t\\t\\ttemp1 = []\\n\\t\\t\\ttemp2 = []\\n\\t\\t\\ttimes = []\\n\\t\\t\\tfor line in fid.readlines():\\n\\t\\t\\t\\ttimes.append(t)\\n\\t\\t\\t\\tsamples = line.split(&quot;\\\\t&quot;)\\n\\t\\t\\t\\ttemp1.append(float(samples[0]))\\n\\t\\t\\t\\ttemp2.append(float(samples[1]))\\n\\t\\t\\t\\tt = t + sampleEvery\\n\\t\\t\\treal.append(temp1)\\n\\t\\t\\timag.append(temp2)\\n\\t\\t\\tfid.close()\\n\\treal = np.array(real)\\n\\timag = np.array(imag)\\n\\treturn real, imag, times, fileOrder\\ndef loadRadioml(path):\\n\\tdata = pickle.load(open(path, 'rb'), encoding='latin')\\n\\tkeys = data.keys()\\n\\tsnrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], keys)))), [1,0])\\n\\tX = []\\n\\tlbl = []\\n\\tfor mod in mods:\\n\\t\\tfor snr in snrs:\\n\\t\\t\\tX.append(data[(mod,snr)])\\n\\t\\t\\tfor i in range(data[(mod,snr)].shape[0]):  lbl.append((mod,snr))\\n\\tX = np.vstack(X)\\n\\tlabel=[]\\n\\tmod=[]\\n\\tdata=[]\\n\\tfor i in range(len(lbl)):\\n\\t\\tlabel.append(lbl[i][0])\\n\\t\\tmod.append(lbl[i][1])\\n\\t\\tdata.append(X[i])\\n\\tfor i in range(len(data)):\\n\\t\\tr = np.random.randint(low=0, high = len(data))\\n\\t\\ttemp1 = label[i]\\n\\t\\ttemp2 = mod[i]\\n\\t\\ttemp3 = data[i]\\n\\t\\tlabel[i] = label[r]\\n\\t\\tmod[i] = mod[r]\\n\\t\\tdata[i] = data[r]\\n\\t\\tlabel[r] = temp1\\n\\t\\tmod[r] = temp2\\n\\t\\tdata[r] = temp3\\n\\treturn data, mod, label\\ndef breakUpData(real, imag, times, numPartitions, basePath):\\n\\tif(len(real) % numPartitions != 0):\\n\\t\\traise ValueError(&quot;Error: The length of the dataset must be divisible by the number of partitions.&quot;)\\n\\tnewReal = []\\n\\tnewImag = []\\n\\tnewTimes = []\\n\\tfileOrder = listdir(basePath)\\n\\tdataFiles = []\\n\\tinterval = int(len(real[0]) / numPartitions)\\n\\tfor i in range(0, interval):\\n\\t\\tnewTimes.append(times[i])\\n\\tfor i in range(0, len(real)):\\n\\t\\ttempI = []\\n\\t\\ttempQ = []\\n\\t\\tfor j in range(0, len(real[0])):\\n\\t\\t\\ttempI.append(real[i, j])\\n\\t\\t\\ttempQ.append(imag[i, j])\\n\\t\\t\\tif((j + 1) % interval == 0):\\n\\t\\t\\t\\tnewReal.append(tempI)\\n\\t\\t\\t\\tnewImag.append(tempQ)\\n\\t\\t\\t\\tdataFiles.append(fileOrder[i])\\n\\t\\t\\t\\ttempI = []\\n\\t\\t\\t\\ttempQ = []\\n\\tfor i in range(0, len(newReal)):\\n\\t\\tr = random.randint(0, len(newReal) - 1)\\n\\t\\ttempReal = newReal[i]\\n\\t\\ttempImag = newImag[i]\\n\\t\\tnewReal[i] = newReal[r]\\n\\t\\tnewImag[i] = newImag[r]\\n\\t\\tnewReal[r] = tempReal\\n\\t\\tnewImag[r] = tempImag\\n\\t\\ttempFile = dataFiles[i]\\n\\t\\tdataFiles[i] = dataFiles[r]\\n\\t\\tdataFiles[r] = tempFile\\n\\treturn newReal, newImag, newTimes, dataFiles\\ndef input_split(x):\\n\\ttf.print(x)\\n\\tx1, x2 = tf.split(x, 2, -1)\\n\\ttf.print(tf.shape(x1))\\n\\ttf.print(tf.shape(x2))\\n\\treturn x1, x2\\ndef test(x):\\n\\ttf.print(tf.shape(x))\\n\\ttf.squeeze(x, 0)\\n\\treturn x\\nclass RffConnected(tf.keras.layers.Layer):\\n\\tdef __init__(self, output_dim, loss_dim, batchSize, beta, alpha):\\n\\t\\tsuper(RffConnected, self).__init__()\\n\\t\\tself.iters = 0.0\\n\\t\\tself.beta = beta\\n\\t\\tself.alpha = alpha\\n\\t\\tself.batchSize = batchSize\\n\\t\\tself.output_dim = output_dim\\n\\t\\tself.sum = tf.zeros(output_dim, tf.float32)\\n\\t\\tself.moving_average = tf.zeros(output_dim, tf.float32)\\n\\t\\tself.clusterloss = tf.zeros(loss_dim, tf.float32)\\n\\t@tf.function\\n\\tdef call(self, inputs):\\n\\t\\tdef calc1(moving_average, clusterloss, inputs, beta, alpha):\\n\\t\\t\\tclusterloss = tf.math.exp(\\\\\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   tf.math.multiply(-1.000 * beta, tf.math.reduce_euclidean_norm(tf.math.subtract(inputs, moving_average))))\\n\\t\\t\\treturn tf.math.multiply(clusterloss, alpha)\\n\\t\\tdef calc2(moving_average, clusterloss):\\n\\t\\t\\treturn clusterloss\\n\\t\\tself.iters = self.iters + 1\\n\\t\\tself.sum = tf.math.add(self.sum, inputs)\\n\\t\\tself.moving_average = tf.math.divide(self.sum, tf.math.subtract(self.iters, self.batchSize))\\n\\t\\tself.clusterloss = tf.cond(tf.math.less_equal(self.batchSize, int(self.iters)),\\\\\\n\\t\\t\\t\\tlambda: calc1(self.moving_average, self.clusterloss, inputs,\\\\\\n\\t\\t\\t\\t\\t\\t\\t  self.beta, self.alpha), lambda: calc2(self.moving_average, self.clusterloss))\\n\\t\\tself.add_loss(self.clusterloss)\\n\\t\\treturn inputs\\ndef customloss(y_true, y_pred):\\n\\tloss = tf.math.reduce_euclidean_norm(tf.math.subtract(y_true, y_pred))\\n\\treturn loss\\nsdrPath = r&quot;C:\\\\Users\\\\ellio\\\\Programs\\\\Datasets/SDR_DATA&quot;\\nradiomlPath = r&quot;C:\\\\Users\\\\ellio\\\\Programs\\\\Datasets\\\\RML2016.10a_dict.pkl&quot;\\ndata, modulation, snr = loadRadioml(radiomlPath)\\niData = [data[i][0] for i in range(0, len(data))]\\nqData = [data[i][1] for i in range(0, len(data))]\\nrealTraining = np.array(iData[0:50000])\\nrealTesting = np.array(iData[50000:100000])\\nimagTraining = np.array(qData[0:50000])\\nimagTesting = np.array(qData[50000:100000])\\nnumInputs = len(realTraining[0])\\ni_sig = tf.keras.Input(shape=(numInputs,))\\nq_sig = tf.keras.Input(shape=(numInputs,))\\ninitCombine = layers.Concatenate()([i_sig, q_sig])\\ncombiner = tf.keras.Model(inputs=[i_sig, q_sig], outputs=initCombine)\\ncombinedTraining = combiner.predict([realTraining, imagTraining])\\ncombinedTesting = combiner.predict([realTesting, imagTesting])\\nmodelInputs = tf.keras.Input(shape=(2*numInputs))\\nsplit1, split2 = tf.keras.layers.Lambda(input_split, output_shape=(numInputs))(modelInputs)\\niRff = tf.keras.layers.experimental.RandomFourierFeatures(numInputs * 8, \\\\\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t kernel_initializer='gaussian', scale=9.0)(split1)\\nqRff = tf.keras.layers.experimental.RandomFourierFeatures(numInputs * 8, \\\\\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t kernel_initializer='gaussian', scale=9.0)(split2)\\ncombined = layers.Concatenate(axis=1)([iRff, qRff])\\ncombineRff = tf.keras.layers.experimental.RandomFourierFeatures(32 * numInputs, \\\\\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tkernel_initializer='gaussian', scale=10.0)(combined)\\nconnected1 = layers.Dense(256, activation=&quot;sigmoid&quot;)(combineRff)\\nclusterLossLayer = RffConnected(256, 2*numInputs, 15, 1.00, 100.00)(connected1)\\nconnected2 = layers.Dense(256, activation=&quot;sigmoid&quot;)(clusterLossLayer)\\nrelu1 = layers.ReLU()(connected2)\\ndropout = layers.Dropout(0.3)(relu1)\\nreshape1 = layers.Reshape((16, 16, 1))(dropout)\\nbn1 = layers.BatchNormalization()(reshape1)\\ntrans1 = layers.Conv2DTranspose(1, (3, 3), padding=&quot;same&quot;)(bn1)\\nups1 = layers.UpSampling2D(size=(1, 1))(trans1)\\nrelu2 = layers.ReLU()(ups1)\\nbn2 = layers.BatchNormalization()(relu2)\\ntrans2 = layers.Conv2DTranspose(1, (3, 3), padding=&quot;same&quot;)(bn2)\\nups2 = layers.UpSampling2D(size=(1, 1))(trans2)\\nrelu3 = layers.ReLU()(ups2)\\nbn3 = layers.BatchNormalization()(relu3)\\ntrans3 = layers.Conv2DTranspose(1, (3, 3), padding=&quot;same&quot;)(bn3)\\nups3 = layers.UpSampling2D(size=(1, 1))(trans3)\\nrelu4 = layers.ReLU()(ups3)\\nbn4 = layers.BatchNormalization()(relu4)\\ntrans4 = layers.Conv2DTranspose(1, (3, 3), padding=&quot;same&quot;)(bn4)\\nreshape2 = layers.Reshape((2*numInputs, 1, 1))(trans4)\\nautoencoder = tf.keras.Model(inputs=modelInputs, outputs=reshape2)\\ntrain_loss = tf.keras.metrics.Accuracy()\\noptimizer = tf.keras.optimizers.Adam()\\nfor i in range(5):\\n\\tfor x in combinedTraining:\\n\\t\\twith tf.GradientTape() as tape:\\n\\t\\t\\toutput = autoencoder(x)\\n\\t\\t\\tloss = customloss(x, output)\\n\\t\\tgradients = tape.gradient(loss, autoencoder.trainable_variables)\\n\\t\\toptimizer.apply_gradients(zip(gradients, autoencoder.trainable_variables))\\n\\t\\ttrain_loss(loss)\\n\\tprint(f'Epoch {i} Loss: {train_loss.result():=4.4f}')\\n\\ttrain_loss.reset_states()\",\n",
       " '&lt;10 pieces: 10$ for final customer, 9$ wholesalers, 8$ for VIP customers\\n&gt;=10 &amp; &lt;50 pieces: 9$ for final customer, 8$ wholesalers, 7$ for VIP customers\\n&gt;= 50 pieces: 8$ for final customer, 7$ wholesalers, 6$ for VIP customers',\n",
       " \"price_by_quantity = {\\n'id': '792095',\\n'key': '_fixed_price_rules',\\n'value': {str(pack_qt): str(float(pack_price)), str(box_qt): str(float(box_price))}\\n}\\nmeta_data.append(price_by_quantity)\\nupdate = {\\n'id': str(child_code),\\n'price': str(float(single_price)),\\n'regular_price': str(float(single_price)),\\n'meta_data': meta_data\\n}\",\n",
       " \"import serial\\nfrom serial import ReaderThread\\ntry:\\n\\ts = serial.Serial('COM1')\\n\\tres = s.read()\\n\\tprint(res)\\nexcept Exception as ex:\\n\\tprint(&quot;Error: &quot; + str(ex))\",\n",
       " 'import win32com.client\\nwmi = win32com.client.GetObject(&quot;winmgmts:&quot;)\\nfor serial in wmi.InstancesOf(&quot;Win32_SerialPort&quot;):\\n\\t   print (serial.Name, serial.Description, serial.DeviceID)',\n",
       " 'files',\n",
       " \"def train_loop(device, dataloader, model, loss_fn, optimizer, epoch=None, files=None):\\n\\tsize = len(dataloader.dataset)\\n\\tnum_batches = len(dataloader)\\n\\tcorrect, train_loss = 0, 0\\n\\tfor batch, (X, y) in enumerate(dataloader):\\n\\t\\tX, y = X.to(device), y.to(device)\\n\\t\\toptimizer.zero_grad()\\n\\t\\tpred = model(X)\\n\\t\\tloss = loss_fn(pred, y)\\n\\t\\tcorrect += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\\n\\t\\tloss.backward()\\n\\t\\toptimizer.step()\\n\\t\\tloss, current = loss.item(), batch * len(X)\\n\\t\\ttrain_loss += loss\\n\\t\\tif files is not None:\\n\\t\\t\\tfiles.logfile.write(f&quot;loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]\\\\n&quot;)\\n\\t\\tprint(f&quot;loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]&quot;)\\n\\t\\tif epoch is not None and files is not None:\\n\\t\\t\\tfiles.sumwriter.add_scalar('Training Loss/batch', loss, epoch * len(dataloader) + batch)\\n\\t\\t\\tfiles.training_loss.writerow([epoch * len(dataloader) + batch, loss])\\n\\ttrain_loss /= num_batches\\n\\tcorrect /= size\\n\\tif epoch is not None and files is not None:\\n\\t\\tfiles.sumwriter.add_scalar(&quot;Train Accuracy&quot;, correct, epoch)\\n\\t\\tfiles.sumwriter.add_scalar('Train Loss/epoch', train_loss, epoch)\\n\\t\\tfiles.training_acc.writerow([epoch, correct])\",\n",
       " '\\t\\tfor training, testing in itr:\\n\\t\\t\\ttraining_dl = DataLoader(training, batch_size=batch_size, shuffle=True)\\n\\t\\t\\ttesting_dl = DataLoader(testing, batch_size=batch_size, shuffle=False)  \\n\\t\\t\\tif files:\\n\\t\\t\\t\\tfiles.logfile.write(&quot;{:&lt;30}{:&gt;20}\\\\n&quot;.format(&quot;TAG: &quot;, tag))\\n\\t\\t\\t\\tfiles.logfile.write(&quot;{:&lt;30}{:&gt;20}\\\\n&quot;.format(&quot;TRANSFORM: &quot;, &quot;, &quot;.join(transform).upper()))\\n\\t\\t\\t\\tfiles.logfile.write(&quot;{:&lt;30}{:&gt;20}\\\\n&quot;.format(&quot;LR: &quot;, learning_rate))\\n\\t\\t\\t\\tfiles.logfile.write(&quot;{:&lt;30}{:&gt;20}\\\\n&quot;.format(&quot;EPOCHS: &quot;, epochs))\\n\\t\\t\\ttrain(epochs, device, training_dl, testing_dl, model, loss_fn, optimizer, files, debug=debug)\\n\\t\\t\\tif save_model:\\n\\t\\t\\t\\ttorch.save(model.state_dict(), os.path.join(files.logpath, &quot;model&quot;))\\n\\t\\t\\tif kfolds:\\n\\t\\t\\t\\tmodel = findmodel(model_str, batch_norm, device=device) \\n\\t\\t\\t\\toptimizer = findoptimizer(optimizer_str, model, learning_rate)\\n\\t\\t\\t\\tfiles.refresh() ',\n",
       " 'def train(epochs, device, training_dl, validation_dl, model, loss_fn, optimizer, files=None, debug=False):\\n\\tstart = dt.datetime.now()\\n\\tstart_str = start.strftime(&quot;%H:%M:%S&quot;)\\n\\tif files is not None:\\n\\t\\tfiles.logfile.write(&quot;{:&lt;30}{:&gt;20}\\\\n&quot;.format(&quot;MODEL: &quot;, files.model_name))\\n\\t\\tfiles.logfile.write(&quot;{:&lt;30}{:&gt;20}\\\\n&quot;.format(&quot;LOSS FUNCTION: &quot;, files.loss_fn_name))\\n\\t\\tfiles.logfile.write(&quot;{:&lt;30}{:&gt;20}\\\\n&quot;.format(&quot;OPTIMIZER: &quot;, files.optimizer_name))\\n\\t\\tfiles.logfile.write(&quot;{:&lt;30}{:&gt;20}\\\\n&quot;.format(&quot;BATCH SIZE: &quot;, files.batch_size_str))\\n\\t\\tfiles.logfile.write(&quot;{:&lt;30}{:&gt;20}\\\\n&quot;.format(&quot;BATCH NORMALIZATION: &quot;, files.batchnorm))\\n\\t\\tfiles.logfile.write(&quot;{:&lt;30}{:&gt;20}\\\\n&quot;.format(&quot;START: &quot;, start_str))\\n\\ttest_loop(device, validation_dl, model, loss_fn, epoch=-1, files=files)\\n\\tfor ep in range(epochs):\\n\\t\\tprint(f&quot;Epoch {ep + 1}\\\\n-------------------------------&quot;)\\n\\t\\tif files is not None:\\n\\t\\t\\tfiles.logfile.write(f&quot;Epoch {ep + 1}\\\\n-------------------------------\\\\n&quot;)\\n\\t\\ttrain_loop(device, training_dl, model, loss_fn, optimizer, ep, files)\\n\\t\\ttest_loop(device, validation_dl, model, loss_fn, ep, files)\\n\\tif files is not None:\\n\\t\\tend = dt.datetime.now()\\n\\t\\telapsed = end - start\\n\\t\\tend_str = end.strftime(&quot;%H:%M:%S&quot;)\\n\\t\\tfiles.logfile.write(&quot;{:&lt;30}{:&gt;20}\\\\n&quot;.format(&quot;END: &quot;, end_str))\\n\\t\\tfiles.logfile.write(&quot;{:&lt;30}{!s:&gt;20}\\\\n&quot;.format(&quot;Total elapsed time: &quot;, elapsed))\\n\\tprint(&quot;Finished !&quot;)',\n",
       " 'frame.insert',\n",
       " 'newframe = frame.copy()',\n",
       " \"File &quot;/usr/lib/python3/dist-packages/pkg_resources/__init__.py&quot;, line 2464, in\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  load\\n\\tself.require(*args, **kwargs)\\n  File &quot;/usr/lib/python3/dist-packages/pkg_resources/__init__.py&quot;, line 2487, in\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  require\\n\\titems = working_set.resolve(reqs, env, installer, extras=self.extras)\\n  File &quot;/usr/lib/python3/dist-packages/pkg_resources/__init__.py&quot;, line 785, in\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  resolve\\n\\tnew_requirements = dist.requires(req.extras)[::-1]\\n  File &quot;/usr/lib/python3/dist-packages/pkg_resources/__init__.py&quot;, line 2756, in\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  requires\\n\\traise UnknownExtra(\\npkg_resources.UnknownExtra: jsonschema 3.2.0 has no such extra feature 'format-nongpl\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t '\",\n",
       " 'import nltk\\nnltk.download()',\n",
       " \"&gt;&gt;&gt; nltk.set_proxy('http://proxy.example.com:3128', ('USERNAME', 'PASSWORD'))\\n&gt;&gt;&gt; nltk.download()\",\n",
       " \"cookie_test = {\\n'session': 'hidden',\\n'csrf_token':'hidden',\\n'Locale-Supported':'en',\\n'game':'csgo',\\n'Device-Id':'hidden',\\n}\\nheaders = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36' }\\nurl = 'https://buff.163.com/goods/43011?from=market\\nsession = requests.session()\\nsession.cookies.update(cookie_test)\\nsession.headers.update(headers)\\nresponse = session.get(url)\",\n",
       " \"import numpy as np\\nimport tensorflow as tf\\nfrom tensorflow import keras\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import MinMaxScaler\\ndataset = np.load('/path to .npy dataset/')\\nnum_samples = dataset.shape[0]\\ntimesteps = dataset.shape[1]\\ninput_dim = dataset.shape[2]\\ndata = dataset.reshape(num_samples, timesteps, input_dim)\\nscaler = MinMaxScaler(feature_range=(0, 1))\\ndata = scaler.fit_transform(data)\\ntrain_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\\nmodel = keras.Sequential()\\nmodel.add(keras.layers.LSTM(128, input_shape=(timesteps, input_dim), return_sequences=True))\\nmodel.add(keras.layers.Attention(timesteps))\\nmodel.add(keras.layers.Dense(64, activation='relu'))\\nmodel.add(keras.layers.Dense(num_classes, activation='softmax'))\\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\\nhistory = model.fit(train_data, train_labels, batch_size=64, epochs=50, validation_data=(test_data, test_labels))\\ntest_loss, test_accuracy = model.evaluate(test_data, test_labels, verbose=0)\\nprint('Test Accuracy: {:.4f}'.format(test_accuracy))\",\n",
       " 'ValueError: cannot reshape array of size 1080000 into shape (24,3,300)',\n",
       " \"import time\\nimport configparser\\nimport datetime as dt\\nimport os\\nfrom typing import (\\n\\tAny,\\n\\tOptional,\\n\\tDict,\\n\\tList\\n)\\nimport discord\\nfrom discord.ext import commands\\nfrom irc import IRCSimpleClient\\nroot_path = os.path.dirname(__file__)\\nconfig = configparser.ConfigParser()\\nconfig.read(&quot;config.cfg&quot;)\\nclass Main(commands.Bot):\\n\\tdef __init__(self) -&gt; None:\\n\\t\\tintents = discord.Intents.all()\\n\\t\\tsuper().__init__(command_prefix=commands.when_mentioned_or('!'),\\n\\t\\t\\t\\t\\t\\t intents=intents)\\n\\tasync def on_ready(self):\\n\\t\\tpass\\ndef watch_message():\\n\\twhile True:\\n\\t\\tmsg = irc.get_response()\\n\\t\\tmsg = &quot;&quot;\\n\\t\\tif &quot;PING&quot; in msg:\\n\\t\\t\\tirc.respond_ping(msg)\\n\\t\\t\\tprint(dt.datetime.strftime(dt.datetime.now(), &quot;%H:%M&quot;) + &quot; PONG&quot;)\\n\\t\\ttry:\\n\\t\\t\\tmsg = msg.strip().split(&quot;:&quot;)\\n\\t\\t\\tprint(&quot;[{}][{}]&lt;{}&gt; {}&quot;.format(\\n\\t\\t\\t\\tdt.datetime.strftime(dt.datetime.now(), &quot;%H:%M&quot;),\\n\\t\\t\\t\\t&quot;\\n\\t\\t\\t\\tmsg[1].split(&quot;!&quot;)[0],\\n\\t\\t\\t\\tmsg[2].strip()))\\n\\t\\texcept IndexError:\\n\\t\\t\\tpass\\nbot = Main()\\n@bot.command(name=&quot;join&quot;)\\nasync def test(ctx: commands.Context):\\n\\tirc.join_channel(&quot;test&quot;)\\nusername = config[&quot;Auth&quot;][&quot;username&quot;]\\noauth = config[&quot;Auth&quot;][&quot;oauth&quot;]\\nirc = IRCSimpleClient(username, oauth)\\nirc.connect()\\nirc.join_channel(&quot;lcs&quot;)\\ntoken = config[&quot;discord&quot;][&quot;token&quot;]\\nbot.run(token)\",\n",
       " 'import socket\\nimport time\\nclass IRCSimpleClient():\\n\\tdef __init__(self, nick, oauth):\\n\\t\\tself.username = nick\\n\\t\\tself.oauth = oauth\\n\\t\\tself.server = &quot;irc.chat.twitch.tv&quot;\\n\\t\\tself.port = 80\\n\\tdef connect(self):\\n\\t\\tself.conn = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n\\t\\tself.conn.connect((self.server, self.port))\\n\\t\\tself.conn.send(f&quot;PASS oauth:{self.oauth}\\\\r\\\\n&quot;.encode(&quot;utf-8&quot;))\\n\\t\\tself.conn.send(f&quot;NICK {self.username}\\\\r\\\\n&quot;.encode(&quot;utf-8&quot;))\\n\\t\\twhile not self.is_connected:\\n\\t\\t\\tresp = self.get_response()\\n\\t\\t\\tprint(resp.strip())\\n\\t\\t\\tif &quot;376&quot; in resp:\\n\\t\\t\\t\\tself.is_connected = True\\n\\t\\t\\tif &quot;PING&quot; in resp:\\n\\t\\t\\t\\tself.respond_ping(resp)\\n\\tdef get_response(self):\\n\\t\\treturn self.conn.recv(1024).decode(&quot;utf-8&quot;, &quot;ignore&quot;)\\n\\tdef send_cmd(self, cmd, message):\\n\\t\\tcommand = &quot;{} {}\\\\r\\\\n&quot;.format(cmd, message).encode(&quot;utf-8&quot;)\\n\\t\\tself.conn.send(command)\\n\\tdef send_message_to_channel(self, channel, message):\\n\\t\\tcommand = &quot;PRIVMSG {}&quot;.format(channel)\\n\\t\\tmessage = &quot;:&quot; + message\\n\\t\\tself.send_cmd(command, message)\\n\\tdef join_channel(self, channel: str):\\n\\t\\tjoined = False\\n\\t\\tcmd = &quot;JOIN&quot;\\n\\t\\tif not channel.startswith(&quot;\\n\\t\\t\\tchannel = &quot;\\n\\t\\tself.send_cmd(cmd, channel)\\n\\t\\twhile not joined:\\n\\t\\t\\tresp = self.get_response()\\n\\t\\t\\tprint(resp.strip())\\n\\t\\t\\tif &quot;366&quot; in resp:\\n\\t\\t\\t\\tjoined = True\\n\\t\\t\\tif &quot;PING&quot; in resp:\\n\\t\\t\\t\\tself.respond_ping(resp)\\n\\tdef part_channel(self, channel: str):\\n\\t\\tcmd = &quot;PART&quot;\\n\\t\\tif not channel.startswith(&quot;\\n\\t\\t\\tchannel = &quot;\\n\\t\\tself.send_cmd(cmd, channel)\\n\\tdef respond_ping(self, message):\\n\\t\\tself.send_cmd(&quot;PONG&quot;, &quot;:&quot; + message.split(&quot;:&quot;)[1])',\n",
       " 'geopandas.explore()',\n",
       " 'vocrec_write()',\n",
       " \"import pyaudio, signal, sys\\nglobal mic_stream\\nvoc_frames=[]\\ndef vocrec_callback(in_data, frame_count, time_info, status):\\n\\tglobal voc_frames\\n\\tvoc_frames.append(in_data)\\n\\treturn (in_data, pyaudio.paContinue)\\ndef vocrec_start():\\n\\tglobal mic_stream\\n\\tvoc_rate=44100\\n\\tmic_stream = pa.open(format=pa.get_format_from_width(2),\\n\\t\\t\\t\\t\\tchannels=1 if sys.platform == 'darwin' else 2,\\n\\t\\t\\t\\t\\trate=voc_rate,\\n\\t\\t\\t\\t\\tinput=True,\\n\\t\\t\\t\\t\\toutput=False,\\n\\t\\t\\t\\t\\tstream_callback=vocrec_callback)\\n\\treturn mic_stream\\ndef vocrec_stop():\\n\\tmic_stream.close()\\n\\tpa.terminate()\\ndef vocrec_write():\\n\\twith open(&quot;output.wav&quot;, &quot;wb&quot;) as file:\\n\\t\\tfile.write(voc_frames)\\nclass SIGINT_handler():\\n\\tdef __init__(self):\\n\\t\\tself.SIGINT = False\\n\\tdef signal_handler(self, signal, frame):\\n\\t\\tself.SIGINT = True\\n\\t\\tprint('You pressed Ctrl+C!')\\n\\t\\tvocrec_stop()\\n\\t\\tquit()\\ndef get_data ():\\n\\tvocrec_start()\\n\\tuser_input = input(&quot;Enter text: &quot;)\\n\\tvocrec_stop()\\n\\tvocrec_write()\\n\\tquit()\\nhandler = SIGINT_handler()\\nsignal.signal(signal.SIGINT, handler.signal_handler)\\npa = pyaudio.PyAudio()\\nget_data()\",\n",
       " 'import multiprocessing as mp\\nimport threading\\nimport queue\\np_num = 2\\nt_num = 13\\ndef fill_queue(q):\\n\\tfor i in range(10000):\\n\\t\\tq.put(i)\\ndef do_sth(job: int):\\n\\treturn\\ndef run_in_thread(q):\\n\\twhile True:\\n\\t\\ttry:\\n\\t\\t\\tjob = q.get(block=False)\\n\\t\\texcept queue.Empty:\\n\\t\\t\\treturn\\n\\t\\telse:\\n\\t\\t\\ttry:\\n\\t\\t\\t\\tdo_sth(job)\\n\\t\\t\\texcept BaseException as e:\\n\\t\\t\\t\\traise e\\n\\t\\t\\tfinally:\\n\\t\\t\\t\\tcontinue\\ndef run_in_proc(q):\\n\\tthreads = [threading.Thread(target=run_in_thread, args=(q,)) for _ in range(t_num)]\\n\\tfor thread in threads:\\n\\t\\tthread.start()\\n\\tfor thread in threads:\\n\\t\\tthread.join()\\nif __name__ == &quot;__main__&quot;:\\n\\tmanager = mp.Manager()\\n\\tq = manager.Queue()\\n\\tfill_queue(q)\\n\\tprocs = [mp.Process(target=run_in_proc, args=(q,)) for _ in range(p_num)]\\n\\tfor proc in procs:\\n\\t\\tproc.start()\\n\\tfor proc in procs:\\n\\t\\tproc.join()',\n",
       " \"Exception in thread Thread-11:\\nTraceback (most recent call last):\\n  File &quot;/Users/my_name/.pyenv/versions/3.8.10/lib/python3.8/multiprocessing/managers.py&quot;, line 827, in _callmethod\\n\\tconn = self._tls.connection\\nAttributeError: 'ForkAwareLocal' object has no attribute 'connection'\\nDuring handling of the above exception, another exception occurred:\\nTraceback (most recent call last):\\n  File &quot;/Users/my_name/.pyenv/versions/3.8.10/lib/python3.8/threading.py&quot;, line 932, in _bootstrap_inner\\n\\tself.run()\\n  File &quot;/Users/my_name/.pyenv/versions/3.8.10/lib/python3.8/threading.py&quot;, line 870, in run\\n\\tself._target(*self._args, **self._kwargs)\\n  File &quot;/Users/my_name/century/Easy/temp/demo.py&quot;, line 22, in run_in_thread\\n\\tjob = q.get(block=False)\\n  File &quot;&lt;string&gt;&quot;, line 2, in get\\n  File &quot;/Users/my_name/.pyenv/versions/3.8.10/lib/python3.8/multiprocessing/managers.py&quot;, line 831, in _callmethod\\n\\tself._connect()\\n  File &quot;/Users/my_name/.pyenv/versions/3.8.10/lib/python3.8/multiprocessing/managers.py&quot;, line 818, in _connect\\n\\tconn = self._Client(self._token.address, authkey=self._authkey)\\n  File &quot;/Users/my_name/.pyenv/versions/3.8.10/lib/python3.8/multiprocessing/connection.py&quot;, line 502, in Client\\n\\tc = SocketClient(address)\\n  File &quot;/Users/my_name/.pyenv/versions/3.8.10/lib/python3.8/multiprocessing/connection.py&quot;, line 630, in SocketClient\\n\\ts.connect(address)\\nConnectionRefusedError: [Errno 61] Connection refused\",\n",
       " 'sudo sysctl -w kern.ipc.somaxconn=102400',\n",
       " \"def add_questions(**kwargs):\\n\\ttry:\\n\\t\\tquestion = QuestionMaster(\\n\\t\\t\\t\\tuuid.uuid4(),\\n\\t\\t\\t\\tkwargs['question'],\\n\\t\\t\\t\\tkwargs['choice1'],\\n\\t\\t\\t\\tkwargs['choice2'],\\n\\t\\t\\t\\tkwargs['choice3'],\\n\\t\\t\\t\\tkwargs['choice4'],\\n\\t\\t\\t\\tkwargs['answer'],\\n\\t\\t\\t\\tkwargs['marks'],\\n\\t\\t\\t\\tkwargs['remarks']\\n\\t\\t\\t)\\n\\tdb.session.add(question)\\n\\tdb.session.commit()\\n  except Exception as e:\\n\\t raise e\",\n",
       " \"class AddQuestionAPI(MethodResource, Resource):\\n\\t@doc(description='Add Question API', tags=['Question'])\\n\\t@use_kwargs(AddQustionRequest, location = ('json'))\\n\\t@marshal_with(APIResponse)\\n\\tdef post(self, **kwargs):\\n\\t\\ttry:\\n\\t\\t\\tis_active, user_id = check_if_session_is_active(kwargs['session_id'])\\n\\t\\t\\tif not is_active:\\n\\t\\t\\t\\treturn APIResponse().dump(dict(message ='User is not logged in' )), 404\\n\\t\\t\\tis_admin = check_if_admin(user_id)\\n\\t\\t\\tif not is_admin:\\n\\t\\t\\t\\treturn APIResponse().dump(dict(message ='User is not a Admin' )), 401\\n\\t\\t\\tadd_questions(**kwargs)\\n\\t\\t\\treturn APIResponse().dump(dict(message ='Qustion sucessfully added' )), 200\\n\\t\\texcept Exception as e:\\n\\t\\t\\tprint(Str(e))\\n\\t\\t\\treturn APIResponse().dump(dict(message=f'Error in adding qustion: {str(e)}')), 400\\napi.add_resource(AddQuestionAPI, '/add.question')\\ndocs.register(AddQuestionAPI)\",\n",
       " 'class AddQustionRequest(Schema):\\n\\tsession_id = fields.Str(default=&quot;session_id&quot;)\\n\\tqustion = fields.Str(default=&quot;question&quot;)\\n\\tchoice1 = fields.Str(default=&quot;choice1&quot;)\\n\\tchoice2 = fields.Str(default=&quot;choice2&quot;)\\n\\tchoice3 = fields.Str(default=&quot;choice3&quot;)\\n\\tchoice4 = fields.Str(default=&quot;choice4&quot;)\\n\\tmarks = fields.Int(default= 0)\\n\\tremarks = fields.Str(default=&quot;remarks&quot;)\\n\\tanswer = fields.Int(default= 0)',\n",
       " \"class QuestionMaster(db.Model):\\n__tablename__ = 'question_master'\\nid = db.Column(db.String(100), primary_key=True)\\nquestion = db.Column(db.String(500), unique=True)\\nchoice1 = db.Column(db.String(500))\\nchoice2 = db.Column(db.String(500))\\nchoice3 = db.Column(db.String(500))\\nchoice4 = db.Column(db.String(500))\\nanswer = db.Column(db.Integer)\\nmarks = db.Column(db.Integer)\\nremarks = db.Column(db.String(200))\\nis_active = db.Column(db.Integer, default=1)\\ncreated_ts = db.Column(db.DateTime, default=datetime.utcnow())\\nupdated_ts = db.Column(db.DateTime)\\ndef __init__(self, id, question, choice1,\\n\\t\\t\\t choice2, choice3, choice4, answer, marks, remarks):\\n\\tself.id = id\\n\\tself.question = question\\n\\tself.choice1 = choice1\\n\\tself.choice2 = choice2\\n\\tself.choice2 = choice3\\n\\tself.choice2 = choice4\\n\\tself.answer = answer\\n\\tself.marks = marks\\n\\tself.remarks = remarks\\n\\tself.is_active = 1\\n\\tself.created_ts = datetime.utcnow()\",\n",
       " \"from tkinter import *\\nfrom tkinter import filedialog\\nfrom moviepy import *\\nfrom moviepy.editor import VideoFileClip\\nfrom pytube import YouTube\\nimport shutil\\nscreen = Tk()\\ntitle = screen.title(&quot;Youtube Downloader&quot;)\\ncanvas = Canvas(screen, width=500, height=500)\\ncanvas.pack()\\ndef select_path():\\n\\tpath = filedialog.askdirectory()\\n\\tpath_label.config(text=path)\\ndef download_video():\\n\\tget_link = link_field.get()\\n\\tuser_path = path_label.cget(&quot;text&quot;)\\n\\tscreen.title('Downloading...Please Wait...')\\n\\tmp4_video = YouTube(get_link).streams.get_highest_resolution().download()\\n\\tvid_clip = VideoFileClip(mp4_video)\\n\\tvid_clip.close()\\n\\tshutil.move(mp4_video, user_path)\\n\\tscreen.title('Download Completed!')\\nlogoimg = PhotoImage(file=&quot;images/download.png&quot;)\\nlogoimg = logoimg.subsample(2, 2)\\ncanvas.create_image(250, 80, image=logoimg)\\nlink_field = Entry(screen, width=50)\\nlink_label = Label(screen, text=&quot;Paste Download Link: &quot;, font=(&quot;Sans Serif&quot;, 13))\\ncanvas.create_window(250, 170, window=link_label)\\ncanvas.create_window(250, 210, window=link_field)\\npath_label = Label(screen, text=&quot;Select Local Path: &quot;, font=(&quot;Sans Serif&quot;, 13))\\nselect_button = Button(screen, text=&quot;Select&quot;, command=select_path)\\t\\ncanvas.create_window(250, 270, window=path_label)\\ncanvas.create_window(250, 320, window=select_button)\\ndownload_bttn = Button(screen, text=&quot;Download Video&quot;, font=(&quot;Sans Serif&quot;, 12),  command=download_video)\\ncanvas.create_window(250, 400, window=download_bttn)\\nscreen.mainloop()\",\n",
       " 'filesystem',\n",
       " 'os.sep',\n",
       " 'def beautify():\\n\\tfor  file in os.listdir(path):\\n\\t\\tfname, fext = os.path.splitext(file)\\n\\t\\tif not file.find(&quot;.py&quot;):\\n\\t\\t\\tif fname.find(&quot;.&quot;) &gt; 0:\\n\\t\\t\\t\\tos.rename(os.path.join(path, file), os.path.join(path, fname.replace(&quot;.&quot;, &quot; &quot;) + fext))',\n",
       " 'print()',\n",
       " 'os.walk',\n",
       " 'def log(x,base):\\n\\tresult = ln(x)/ln(base)\\n\\treturn result',\n",
       " 'def log(x,base):\\n\\tresult = ln(x)/ln(base)\\n\\treturn result',\n",
       " 'data = torch_geometric.utils.from_networkx(graph) \\nn2v = Node2Vec(data.edge_index, embedding_dim=dim, walk_length=wl, context_size=cs, \\n\\t\\t\\twalks_per_node=wpn, p=hp, q=hq,\\n\\t\\t\\tsparse=True).to(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)\\nemb = n2v.forward().detach().numpy()\\nwith open(&quot;output.txt&quot;, &quot;w&quot;) as f:\\n\\tf.write(str(emb.shape))\\n\\tf.write(&quot;\\\\n&quot;)\\n\\tfor w in emb:\\n\\t\\t f.write(&quot; &quot;.join(str(e) for e in w))\\n\\t\\t f.write(&quot;\\\\n&quot;)',\n",
       " 'dim',\n",
       " 'n',\n",
       " 'n',\n",
       " 'n',\n",
       " '5 3\\n0.390297 -0.419280 1.298374\\n0.927178 1.112397 -0.298474\\n0.810569 0.2981626 1.298739\\n1.987988 -1.728364 -1.308479\\n-0.829874 0.297298 1.298756',\n",
       " 'dim',\n",
       " 'import sys\\nfrom PyQt5 import uic\\nfrom PyQt5.QtCore import *\\nfrom PyQt5.QtGui import *\\nfrom PyQt5.QtWidgets import *\\nQApplication.setAttribute(Qt.AA_EnableHighDpiScaling)\\napp = QApplication([])\\nwindow = uic.loadUi(&quot;studyDesign.ui&quot;)  \\nclass keyWidget(QWidget):\\n\\tkeyPressed = pyqtSignal(str)\\n\\tdef keyPressEvent(self, keyEvent):\\n\\t\\tif keyEvent.text() == &quot;f&quot;:\\n\\t\\t\\tself.keyPressed.emit(keyEvent.text())\\n\\t\\telif keyEvent.text() == &quot;e&quot;:\\n\\t\\t\\tself.keyPressed.emit(keyEvent.text())\\n\\t\\telif keyEvent.text() == &quot;i&quot;:\\n\\t\\t\\tself.keyPressed.emit(keyEvent.text())\\nkeyWindow = keyWidget(window)\\nexp = experiment(window, keyWindow)\\nwindow.nextBtn.clicked.connect(exp.next)\\nkeyWidget.keyPressed.connect(exp.response)\\nwindow.show()\\napp.exec_()',\n",
       " 'def reverse(self, head):\\n\\tif head is None or head.next is None:\\n\\t\\treturn head\\n\\tprev = None\\n\\tcurrent = head\\n\\twhile current is not None:\\n\\t\\ttemp = current\\n\\t\\tcurrent.next = prev\\n\\t\\tprev = temp\\n\\t\\tcurrent = prev.next\\n\\treturn prev',\n",
       " '1. Set temp to reference to the current which is the head of the linked list. Thus, temp.val = 1 and temp.next.val = 2. &lt;br&gt;\\n2. current.next = prev means that the current is now pointing to None. &lt;br&gt;\\n3. prev = temp means that prev.val = 1 and prev.next.val = 2 &lt;br&gt;\\n4. current = prev.next means that current.val = 2 and current.next.val = 3 &lt;br&gt;',\n",
       " 'while current is not None:\\n\\ttemp = current.next\\n\\tcurrent.next = prev\\n\\tprev = current\\n\\tcurrent = temp',\n",
       " \"import sys\\nfrom PyQt6 import QtWidgets, QtGui, QtCore\\nfrom PyQt6.QtWidgets import QApplication\\nclass MainWindow(QtWidgets.QMainWindow):\\n\\tdef __init__(self):\\n\\t\\tsuper().__init__()\\n\\t\\tself.setMinimumSize(600, 600)\\n\\t\\tself.main_frame = QtWidgets.QFrame(self)\\n\\t\\tself.main_layout = QtWidgets.QVBoxLayout(self.main_frame)\\n\\t\\tself.setCentralWidget(self.main_frame)\\n\\t\\tself.create_ui()\\n\\tdef create_ui(self):\\n\\t\\tself.menu_bar = self.menuBar()\\n\\t\\tself.view_menu = QtWidgets.QMenu('View')\\n\\t\\tself.backup_menu = QtWidgets.QMenu('Backup')\\n\\t\\tself.wakeup_time_backup = QtGui.QAction('Wakeup time')\\n\\t\\tself.wakeup_time_backup.triggered.connect(self.open_backup)\\n\\t\\tself.backup_menu.addAction(self.wakeup_time_backup)\\n\\t\\tself.view_menu.addAction(self.wakeup_time_backup)\\n\\t\\tself.menu_bar.addMenu(self.view_menu)\\n\\tdef open_backup(self):\\n\\t\\twakeup_time_input = QtWidgets.QInputDialog(self, QtCore.Qt.WindowType.Popup)\\n\\t\\twakeup_time_input.setLabelText('Wakeup time')\\n\\t\\twakeup_time_input.setOkButtonText('Save')\\n\\t\\tparent_x = self.rect().center().x()\\n\\t\\tparent_y = self.rect().center().y()\\n\\t\\twakeup_time_input.move(QtCore.QPoint(parent_x, 10))\\n\\t\\twakeup_time_input.exec()\\napp = QApplication([])\\nwin = MainWindow()\\nwin.show()\\nsys.exit(app.exec())\",\n",
       " 'PATH',\n",
       " 'PATH',\n",
       " 'conda',\n",
       " 'python',\n",
       " 'PATH',\n",
       " 'conda',\n",
       " 'python',\n",
       " 'PATH',\n",
       " 'PATH',\n",
       " 'PATH',\n",
       " '_conda.exe',\n",
       " 'PATH',\n",
       " \"\\tpost_search_comments= PostInLanguages.objects.filter(comment_data__is_post_comment=True).annotate(c=Count('comment_data', distinct=True)).filter(c__gte=0)\\n\\t\\tpost_search_likes =  PostInLanguages.objects.annotate(l=Count('like_model', distinct=True)).filter(l__gte = 1)\",\n",
       " '\\t\\tintersection = post_search_comments &amp; post_search_likes\\n\\t\\tprint(intersection)\\n\\t\\tpaginator = CustomPageNumberPagination()\\n\\t\\tpage = paginator.paginate_queryset(post_search_comments, request)\\n\\t\\tserializer = PostInLanguagesSerializer(page, many=True)\\n\\t\\tresponse = paginator.get_paginated_response(serializer.data)\\n\\t\\treturn response',\n",
       " 'gino.exceptions.UninitializedError: Gino engine is not initialized.',\n",
       " '@functools.lru_cache\\ndef get_db_service():\\n\\tdb = Gino(dsn=settings.get_settings().postgresql_conn_url)\\n\\treturn db',\n",
       " \"_db = get_db_service()\\nclass EdaTableInstance(_db.Model):\\n\\t__tablename__ = &quot;eda_table_instance&quot;\\n   @classmethod\\n\\tasync def get_all(cls) -&gt; List['EdaTableInstance']:\\n\\t\\tasync with _db.acquire():\\n\\t\\t\\t  return await EdaTableInstance.query.gino.all()\",\n",
       " '@pytest.fixture(autouse=True)\\ndef mock_get_db_service(mocker):\\n\\tdb = Gino(dsn=&quot;sqlite//:memory:&quot;)\\n\\tasync_mock = AsyncMock(db)\\n\\tmocker.patch(&quot;gateway_api.services.get_db_service&quot;, return_value=async_mock)\\n\\tyield',\n",
       " \"@pytest.fixture\\nasync def db_initialize():\\n   await db.set_bind('sqlite:///:memory:')\\n   await db.gino.create_all()\\n   await EdaTableInstance.create_eda_table_instance(\\n\\t   EdaTableInstanceInputOnCreate({&quot;name&quot;:&quot;table_server1&quot;, &quot;host&quot;:&quot;123.123.123.123&quot;})\\n   )\\n   yield\",\n",
       " '@pytest.fixture\\ndef mock_gino_get_all(mocker):\\n\\tmocker.patch(&quot;gino.api.GinoExecutor.all&quot;, return_value=[])\\n@pytest.mark.asyncio\\n@pytest.mark.parametrize(&quot;id, expected&quot;, [(None, None)])\\nasync def test_01_table_instance_get_all(id, expected):\\n\\tmock_cursor = MagicMock()\\n\\tmock_cursor.configure_mock(\\n\\t\\t**{\\n\\t\\t\\t&quot;get_one.return_value&quot;:[id]\\n\\t\\t}\\n\\t)\\n\\tres = await EdaTableInstance().get_one(mock_cursor)\\n\\tassert res == expected',\n",
       " 'from dash import Dash, dcc, html, Input, Output\\nimport dash_bootstrap_components as dbc\\nfrom plotly import express as px\\nimport plotly.graph_objects as go\\nimport pandas as pd\\nimport numpy as np\\nimport requests\\napp = Dash()\\napp.layout = html.Div(\\n\\t[\\n\\t\\thtml.H1(&quot;Hello World&quot;)\\n\\t]\\n)\\napp.run_server(debug=True, port = 8152)',\n",
       " 'def generate_translation(language):\\n\\tdictionary = DICTIONARIES[language]\\n\\twords = list(dictionary.keys())\\n\\trandom.shuffle(words)\\n\\ttest = dict()\\n\\tfor key in words:\\n\\t\\ttest[key]=dictionary[key]\\n\\tjs_test = json.dumps(test)\\n\\twith open(os.path.join(&quot;/workspaces/78624234/CS50X/project/static&quot;, &quot;js_test.json&quot;), &quot;w&quot;) as f:\\n\\t\\tf.write(js_test)\\n\\t\\tf.close\\n\\treturn test, js_test\\n\\t...\\n\\ttest, js_test = generate_translation(selected)\\n\\treturn render_template(&quot;study.html&quot;, language=selected, dictionary=test, js_dictionary=js_test)',\n",
       " \"import data from './js_test.json' assert { type: 'json'};\\nvar dict = data;\",\n",
       " '{&quot;8&quot;: &quot;huit&quot;, &quot;5&quot;: &quot;cinq&quot;, &quot;3&quot;: &quot;trois&quot;, &quot;9&quot;: &quot;neuf&quot;, &quot;2&quot;: &quot;deux&quot;, &quot;1&quot;: &quot;un&quot;, &quot;4&quot;: &quot;quatre&quot;, &quot;10&quot;: &quot;dix&quot;, &quot;7&quot;: &quot;sept&quot;, &quot;6&quot;: &quot;six&quot;}',\n",
       " \"{1: 'un', 2: 'deux', 3: 'trois', 4: 'quatre', 5: 'cinq', 6: 'six', 7: 'sept', 8: 'huit', 9: 'neuf', 10: 'dix'}\",\n",
       " \"import pandas as pd\\nimport matplotlib.pyplot as plt\\nimport matplotlib\\nimport seaborn as sns\\ndf = pd.read_csv('/Linux/Case_study/IncandMass.csv', delimiter=&quot;,&quot;, header=None,skiprows=1)\\ndf.info()\",\n",
       " 'Out[64]:\\n\\t\\t 0\\t\\t 1\\t\\t 2\\t ...\\t  1436\\t  1437\\t  1438\\n174  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\\n173  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\\n172  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\\n171  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\\n170  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\\n..\\t\\t...\\t   ...\\t   ...  ...\\t   ...\\t   ...\\t   ...\\n9\\t0.037891  0.051185  0.026712  ...  0.042928  0.055719  0.051363\\n8\\t0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\\n7\\t0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\\n6\\t0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\\n5\\t0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\\n[170 rows x 1439 columns]',\n",
       " 'fig, ax = plt.subplots(figsize=(12, 7))\\nsns.heatmap(df, cmap=&quot;jet&quot;, linewidths=0.0)',\n",
       " \"num = pd.read_csv('/Linux/Case_study/Incandnum.csv', delimiter=&quot;,&quot;, header=None,skiprows=1)\\ndf.info()\",\n",
       " 'sns.heatmap(da, cmap=&quot;jet&quot;, linewidths=0.0,annot = num)',\n",
       " 'Editor.exe: error: unrecognized arguments: C:\\\\Users\\\\Doan 1\\\\Desktop\\\\test.huy',\n",
       " 'Editor.py -f &quot;C:\\\\Users\\\\Doan 1\\\\Desktop\\\\test.huy&quot;',\n",
       " \"parser = argparse.ArgumentParser(description='test')\\nparser.add_argument('-f', metavar='FILE')\\nargs = parser.parse_args()\\nlocation = str(args)[13:-2]\\nif location and location != 'on':\\n\\tload(location)\",\n",
       " 'python-telegram-bot',\n",
       " 'CmmandHandler',\n",
       " \"ConversationHandler(\\n\\tentry_points=[commandhandler('trade',trade)],\\n\\tstates={\\n\\t\\tNAME_adduser: [MessageHandler(Filters.text, callback=binance)],\\n\\t},\\n\\tfallbacks=[CommandHandler('quit', quit)]\\n)\",\n",
       " 'InlineKeyboardButton',\n",
       " \"class MyModel(TimeStampedModel):\\n\\tMY_CHOICES = [tuple([x,x]) for x in range(1,8)]\\n\\tp1 = models.IntegerField(&quot;P1&quot;, default='1', help_text='text1')\\n\\tp2 = models.IntegerField(&quot;P2&quot;, default='1', , help_text='text2')\\n\\tParent = models.ForeignKey(ParentModel, on_delete=models.CASCADE)\",\n",
       " \"class MyModelForm(ModelForm):\\n\\tdef __init__(self, *args, **kwargs):\\n\\t\\tsuper().__init__(*args, **kwargs)\\n\\t\\tself.helper = FormHelper(self)\\n\\t\\tself.helper.form_id = 'id-CaseForm'\\n\\t\\tself.helper.form_class = 'blueForms'\\n\\t\\tself.helper.form_method = 'post'\\n\\t\\tself.helper.form_tag = False\\n\\t\\tself.helper.help_text_inline = False\\n\\t\\tself.helper.form_show_labels = False\\n\\t\\tself.helper.layout = Layout(\\n\\t\\t\\tRow(Field(PrependedText('p1', 'field_label1',  wrapper_class='col-12 col-lg-6 pe-0 stretchprepend'))),\\n\\t\\t  Row(Field(PrependedText('p2', 'field_label2',  wrapper_class='col-12 col-lg-6 pe-0 stretchprepend'))))\\n\\t\\tCHOICES = [tuple([x,x]) for x in range(1,8)]\\n\\t\\tp1 = IntegerField( label='field_label1', widget=Select(choices=CHOICES))\\n\\t\\tp2 = IntegerField( label='field_label2', widget=Select(choices=CHOICES))\\n\\tclass Meta:\\n\\t\\tmodel = MyModel\\n\\t\\tfields = ['p1', 'p2',]\",\n",
       " '{% crispy MyModelForm  %}',\n",
       " \"hdfs_client = HdfsClient(hosts='10.1.103.49:50070')\\nroot_files = hdfs_client.listdir('/')\\nprint(root_files)\\nhdfs_client.copy_from_local('./Readme.md', '/image/Readme.md')\",\n",
       " \"HTTPConnectionPool(host='ubuntu-ms-7d25', port=50075): Max retries exceeded with url: /webhdfs/v1/image/Readme.md?op=CREATE&amp;user.name=zzz&amp;namenoderpcaddress=10.1.103.49:9000&amp;overwrite=false&amp;user.name=zzz (Caused by NameResolutionError(&quot;&lt;urllib3.connection.HTTPConnection object at 0x7fe3d8c157b0&gt;: Failed to resolve 'ubuntu-ms-7d25' ([Errno -2] Name or service not known)&quot;))\",\n",
       " 'This page isn’t working 127.0.0.1 didn’t send any data.\\nERR_EMPTY_RESPONSE',\n",
       " \"from flask import Flask\\napp = Flask(__name__)\\n@app.route('/')\\ndef hello_world():\\n\\treturn 'Hello World'\\nif __name__ == '__main__':\\n\\tapp.run(debug=True)\",\n",
       " 'FROM python:3.11.6\\nWORKDIR /app\\nCOPY requirements.txt requirements.txt\\nRUN pip3 install -r requirements.txt\\nCOPY . .\\nENV PORT=8080\\nEXPOSE 8080\\nCMD python main.py',\n",
       " \"Error: Cannot find module 'C:\\\\Users\\\\gabri\\\\OneDrive\\\\Desktop\\\\Desktop\\\\FreeBling-V1.1.2\\\\node_modules\\\\sqlite3\\\\lib\\\\binding\\\\napi-v6-win32-unknown-x64\\\\node_sqlite3.node'\\nRequire stack:\\n- C:\\\\Users\\\\gabri\\\\OneDrive\\\\Desktop\\\\Desktop\\\\FreeBling-V1.1.2\\\\node_modules\\\\sqlite3\\\\lib\\\\sqlite3-binding.js\\n- C:\\\\Users\\\\gabri\\\\OneDrive\\\\Desktop\\\\Desktop\\\\FreeBling-V1.1.2\\\\node_modules\\\\sqlite3\\\\lib\\\\sqlite3.js\\n- C:\\\\Users\\\\gabri\\\\OneDrive\\\\Desktop\\\\Desktop\\\\FreeBling-V1.1.2\\\\next.config.js\\n\\tat Module._resolveFilename (node:internal/modules/cjs/loader:1077:15)\\n\\tat Module._load (node:internal/modules/cjs/loader:922:27)\\n\\tat Module.require (node:internal/modules/cjs/loader:1143:19)\\n\\tat require (node:internal/modules/cjs/helpers:110:18)\\n\\tat Object.&lt;anonymous&gt; (C:\\\\Users\\\\gabri\\\\OneDrive\\\\Desktop\\\\Desktop\\\\FreeBling-V1.1.2\\\\node_modules\\\\sqlite3\\\\lib\\\\sqlite3-binding.js:4:17)\\n\\tat Module._compile (node:internal/modules/cjs/loader:1256:14)\\n\\tat Module._extensions..js (node:internal/modules/cjs/loader:1310:10)\\n\\tat Module.load (node:internal/modules/cjs/loader:1119:32)\\n\\tat Module._load (node:internal/modules/cjs/loader:960:12)\\n\\tat Module.require (node:internal/modules/cjs/loader:1143:19) {\\n  code: 'MODULE_NOT_FOUND',\\n  requireStack: [\\n\\t'C:\\\\\\\\Users\\\\\\\\gabri\\\\\\\\OneDrive\\\\\\\\Desktop\\\\\\\\Desktop\\\\\\\\FreeBling-V1.1.2\\\\\\\\node_modules\\\\\\\\sqlite3\\\\\\\\lib\\\\\\\\sqlite3-binding.js',\\n\\t'C:\\\\\\\\Users\\\\\\\\gabri\\\\\\\\OneDrive\\\\\\\\Desktop\\\\\\\\Desktop\\\\\\\\FreeBling-V1.1.2\\\\\\\\node_modules\\\\\\\\sqlite3\\\\\\\\lib\\\\\\\\sqlite3.js',\\n\\t'C:\\\\\\\\Users\\\\\\\\gabri\\\\\\\\OneDrive\\\\\\\\Desktop\\\\\\\\Desktop\\\\\\\\FreeBling-V1.1.2\\\\\\\\next.config.js'\\n  ]\\n}\\nNode.js v18.17.0\\nerror - Failed to load next.config.js, see more info here https://nextjs.org/docs/messages/next-config-error\\nError: Cannot find module 'C:\\\\Users\\\\gabri\\\\OneDrive\\\\Desktop\\\\Desktop\\\\FreeBling-V1.1.2\\\\node_modules\\\\sqlite3\\\\lib\\\\binding\\\\napi-v6-win32-unknown-x64\\\\node_sqlite3.node'\\nRequire stack:\\n- C:\\\\Users\\\\gabri\\\\OneDrive\\\\Desktop\\\\Desktop\\\\FreeBling-V1.1.2\\\\node_modules\\\\sqlite3\\\\lib\\\\sqlite3-binding.js\\n- C:\\\\Users\\\\gabri\\\\OneDrive\\\\Desktop\\\\Desktop\\\\FreeBling-V1.1.2\\\\node_modules\\\\sqlite3\\\\lib\\\\sqlite3.js\\n- C:\\\\Users\\\\gabri\\\\OneDrive\\\\Desktop\\\\Desktop\\\\FreeBling-V1.1.2\\\\next.config.js\\n\\tat Module._resolveFilename (node:internal/modules/cjs/loader:1077:15)\\n\\tat mod._resolveFilename (C:\\\\Users\\\\gabri\\\\OneDrive\\\\Desktop\\\\Desktop\\\\FreeBling-V1.1.2\\\\node_modules\\\\next\\\\dist\\\\build\\\\webpack\\\\require-hook.js:23:32)\\n\\tat Module._load (node:internal/modules/cjs/loader:922:27)\\n\\tat Module.require (node:internal/modules/cjs/loader:1143:19)\\n\\tat require (node:internal/modules/cjs/helpers:110:18)\\n\\tat Object.&lt;anonymous&gt; (C:\\\\Users\\\\gabri\\\\OneDrive\\\\Desktop\\\\Desktop\\\\FreeBling-V1.1.2\\\\node_modules\\\\sqlite3\\\\lib\\\\sqlite3-binding.js:4:17)\\n\\tat Module._compile (node:internal/modules/cjs/loader:1256:14)\\n\\tat Module._extensions..js (node:internal/modules/cjs/loader:1310:10)\\n\\tat Module.load (node:internal/modules/cjs/loader:1119:32)\\n\\tat Module._load (node:internal/modules/cjs/loader:960:12) {\\n  code: 'MODULE_NOT_FOUND',\\n  requireStack: [\\n\\t'C:\\\\\\\\Users\\\\\\\\gabri\\\\\\\\OneDrive\\\\\\\\Desktop\\\\\\\\Desktop\\\\\\\\FreeBling-V1.1.2\\\\\\\\node_modules\\\\\\\\sqlite3\\\\\\\\lib\\\\\\\\sqlite3-binding.js',\\n\\t'C:\\\\\\\\Users\\\\\\\\gabri\\\\\\\\OneDrive\\\\\\\\Desktop\\\\\\\\Desktop\\\\\\\\FreeBling-V1.1.2\\\\\\\\node_modules\\\\\\\\sqlite3\\\\\\\\lib\\\\\\\\sqlite3.js',\\n\\t'C:\\\\\\\\Users\\\\\\\\gabri\\\\\\\\OneDrive\\\\\\\\Desktop\\\\\\\\Desktop\\\\\\\\FreeBling-V1.1.2\\\\\\\\next.config.js'\\n  ]\\n}\",\n",
       " \"import sshtunnel\\nserver = sshtunnel.SSHTunnelForwarder(\\n\\t('jump host', jump_port),\\n\\tssh_username = 'my_user_name',\\n\\tssh_pkey = '~/.ssh/id_rsa',\\n\\tssh_private_key_password = 'my private key pwd',\\n\\tremote_bind_address = ('remote_host', remote_port),\\n\\tlocal_bind_address = ('localhost', local_port)\\n\\t)\",\n",
       " '| ERROR   | Password is required for key C:\\\\Users\\\\&lt;my_local_user_name&gt;/.ssh\\\\id_rsa',\n",
       " \"import paramiko\\npkey='C:/Users/&lt;my_local_user_name&gt;/.ssh/id_rsa'\\nkey=paramiko.RSAKey.from_private_key_file(pkey, 'my private key pwd')\",\n",
       " 'key',\n",
       " 'sshtunnel',\n",
       " 'pkey_class.from_private_key_file',\n",
       " 'paramiko.RSAKey.from_private_key_file',\n",
       " 'PasswordRequiredException',\n",
       " 'allow_agent = True',\n",
       " 'ssh_pkey',\n",
       " 'paramiko.RSAKey',\n",
       " \"npm ERR! code 1\\nnpm ERR! path /Users/shamilyusuf/Documents/Mite/WorkFolder/node_modules/node-sass\\nnpm ERR! command failed\\nnpm ERR! command sh -c node scripts/build.js\\nnpm ERR! Building: /usr/local/Cellar/node/21.1.0/bin/node /Users/shamilyusuf/Documents/Mite/WorkFolder/node_modules/node-gyp/bin/node-gyp.js rebuild --verbose --libsass_ext= --libsass_cflags= --libsass_ldflags= --libsass_library=\\nnpm ERR! gyp info it worked if it ends with ok\\nnpm ERR! gyp verb cli [\\nnpm ERR! gyp verb cli   '/usr/local/Cellar/node/21.1.0/bin/node',\\nnpm ERR! gyp verb cli   '/Users/shamilyusuf/Documents/Mite/WorkFolder/node_modules/node-gyp/bin/node-gyp.js',\\nnpm ERR! gyp verb cli   'rebuild',\\nnpm ERR! gyp verb cli   '--verbose',\\nnpm ERR! gyp verb cli   '--libsass_ext=',\\nnpm ERR! gyp verb cli   '--libsass_cflags=',\\nnpm ERR! gyp verb cli   '--libsass_ldflags=',\\nnpm ERR! gyp verb cli   '--libsass_library='\\nnpm ERR! gyp verb cli ]\\nnpm ERR! gyp info using node-gyp@7.1.2\\nnpm ERR! gyp info using node@21.1.0 | darwin | x64\\nnpm ERR! gyp verb command rebuild []\\nnpm ERR! gyp verb command clean []\\nnpm ERR! gyp verb clean removing &quot;build&quot; directory\\nnpm ERR! gyp verb command configure []\\nnpm ERR! gyp verb find Python Python is not set from command line or npm configuration\\nnpm ERR! gyp verb find Python Python is not set from environment variable PYTHON\\nnpm ERR! gyp verb find Python checking if &quot;python3&quot; can be used\\nnpm ERR! gyp verb find Python - executing &quot;python3&quot; to get executable path\\nnpm ERR! gyp verb find Python - executable path is &quot;/Applications/Xcode.app/Contents/Developer/usr/bin/python3&quot;\\nnpm ERR! gyp verb find Python - executing &quot;/Applications/Xcode.app/Contents/Developer/usr/bin/python3&quot; to get version\\nnpm ERR! gyp verb find Python - version is &quot;3.8.9&quot;\\nnpm ERR! gyp info find Python using Python version 3.8.9 found at &quot;/Applications/Xcode.app/Contents/Developer/usr/bin/python3&quot;\\nnpm ERR! gyp verb get node dir no --target version specified, falling back to host node version: 21.1.0\\nnpm ERR! gyp verb command install [ '21.1.0' ]\\nnpm ERR! gyp verb install input version string &quot;21.1.0&quot;\\nnpm ERR! gyp verb install installing version: 21.1.0\\nnpm ERR! gyp verb install --ensure was passed, so won't reinstall if already installed\\nnpm ERR! (node:67630) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\\nnpm ERR! (Use `node --trace-deprecation ...` to show where the warning was created)\\nnpm ERR! gyp verb install version is already installed, need to check &quot;installVersion&quot;\\nnpm ERR! gyp verb got &quot;installVersion&quot; 9\\nnpm ERR! gyp verb needs &quot;installVersion&quot; 9\\nnpm ERR! gyp verb install version is good\\nnpm ERR! gyp verb get node dir target node version installed: 21.1.0\\nnpm ERR! gyp verb build dir attempting to create &quot;build&quot; dir: /Users/shamilyusuf/Documents/Mite/WorkFolder/node_modules/node-sass/build\\nnpm ERR! gyp verb build dir &quot;build&quot; dir needed to be created? /Users/shamilyusuf/Documents/Mite/WorkFolder/node_modules/node-sass/build\\nnpm ERR! gyp verb build/config.gypi creating config file\\nnpm ERR! gyp ERR! UNCAUGHT EXCEPTION\\nnpm ERR! gyp ERR! stack TypeError: Cannot assign to read only property 'cflags' of object '\\nnpm ERR! gyp ERR! stack\\t at createConfigFile (/Users/shamilyusuf/Documents/Mite/WorkFolder/node_modules/node-gyp/lib/configure.js:117:21)\\nnpm ERR! gyp ERR! stack\\t at /Users/shamilyusuf/Documents/Mite/WorkFolder/node_modules/node-gyp/lib/configure.js:84:9\\nnpm ERR! gyp ERR! stack\\t at FSReqCallback.oncomplete (node:fs:189:23)\\nnpm ERR! gyp ERR! System Darwin 21.6.0\\nnpm ERR! gyp ERR! command &quot;/usr/local/Cellar/node/21.1.0/bin/node&quot; &quot;/Users/shamilyusuf/Documents/Mite/WorkFolder/node_modules/node-gyp/bin/node-gyp.js&quot; &quot;rebuild&quot; &quot;--verbose&quot; &quot;--libsass_ext=&quot; &quot;--libsass_cflags=&quot; &quot;--libsass_ldflags=&quot; &quot;--libsass_library=&quot;\\nnpm ERR! gyp ERR! cwd /Users/shamilyusuf/Documents/Mite/WorkFolder/node_modules/node-sass\\nnpm ERR! gyp ERR! node -v v21.1.0\\nnpm ERR! gyp ERR! node-gyp -v v7.1.2\\nnpm ERR! gyp ERR! Node-gyp failed to build your package.\\nnpm ERR! gyp ERR! Try to update npm and/or node-gyp and if it does not help file an issue with the package author.\\nnpm ERR! Build failed with error code: 7\",\n",
       " \"import numpy as np\\nimport matplotlib.pyplot as plt\\npath = '.../Partikel 1.csv' \\ndat = np.loadtxt(path, dtype='str', delimiter=',', skiprows=2)\\t\\t\\nx = dat[:,0]\\t\\t\\ny = dat[:,1]\\t\\t\\nfor i in range(y.size):\\t \\n\\t  y[i] = float(y[i])\\nfor i in range(x.size):\\t \\n\\t  x[i] = int(x[i])\\nplt.figure(dpi=1200)\\nplt.plot(x,y)\\nplt.grid()\\nplt.xticks(np.linspace(0,x.size,12),['0','2u','3u','4u','5u','6u','7u','8u','9u','10u','11u','12u'])\\nprint(plt.ylim())\\nplt.show()\\nprint(max(y))\\nprint(min(y))\",\n",
       " 'X,CH1,Start,Increment,\\nSequence,Volt,-6.280000e-04,2.000000e-06\\n0,3.92e+00,\\n1,3.88e+00,\\n2,3.92e+00,\\n3,3.88e+00,\\n4,3.92e+00,\\n5,3.88e+00,\\n6,3.88e+00,\\n7,3.92e+00,\\n8,3.92e+00,\\n9,3.88e+00,\\n10,3.92e+00,\\n11,3.88e+00,\\n12,3.92e+00,\\n13,3.88e+00,\\n14,3.92e+00,\\n15,3.88e+00,\\n16,3.92e+00,\\n17,3.88e+00,\\n18,3.92e+00,\\n19,3.88e+00,\\n20,3.92e+00,\\n21,3.88e+00,\\n22,3.92e+00,\\n23,3.88e+00,\\n24,3.92e+00,\\n25,3.88e+00,\\n26,3.92e+00,\\n27,3.88e+00,\\n28,3.92e+00,\\n29,3.88e+00,\\n30,3.88e+00,\\n31,3.92e+00,\\n32,3.92e+00,\\n33,3.88e+00,\\n34,3.92e+00,\\n35,3.88e+00,\\n36,3.92e+00,\\n37,3.88e+00,\\n38,3.92e+00,\\n39,3.88e+00,\\n40,3.92e+00,\\n41,3.88e+00,\\n42,3.88e+00,\\n43,3.92e+00,\\n44,3.92e+00,\\n45,3.88e+00,\\n46,3.92e+00,\\n47,3.88e+00,\\n48,3.92e+00,\\n49,3.88e+00,\\n50,3.92e+00,\\n51,3.88e+00,\\n52,3.92e+00,\\n53,3.88e+00,\\n54,3.92e+00,\\n55,3.88e+00,\\n56,3.92e+00,\\n57,3.88e+00,\\n58,3.88e+00,\\n59,3.92e+00,\\n60,3.92e+00,\\n61,3.88e+00,\\n62,3.92e+00,\\n63,3.88e+00,\\n64,3.92e+00,\\n65,3.88e+00,\\n66,3.92e+00,\\n67,3.88e+00,\\n68,3.92e+00,\\n69,3.88e+00,\\n70,3.92e+00,\\n71,3.88e+00,\\n72,3.92e+00,\\n73,3.88e+00,\\n74,3.92e+00,\\n75,3.88e+00,\\n76,3.92e+00,\\n77,3.88e+00,\\n78,3.92e+00,\\n79,3.88e+00,\\n80,3.92e+00,\\n81,3.88e+00,\\n82,3.88e+00,\\n83,3.92e+00,\\n84,3.92e+00,\\n85,3.88e+00,\\n86,3.92e+00,\\n87,3.88e+00,\\n88,3.92e+00,\\n89,3.88e+00,\\n90,3.92e+00,\\n91,3.88e+00,\\n92,3.92e+00,\\n93,3.88e+00,\\n94,3.88e+00,\\n95,3.92e+00,\\n96,3.92e+00,\\n97,3.88e+00,\\n98,3.92e+00,\\n99,3.88e+00,\\n100,3.88e+00,\\n101,3.92e+00,\\n102,3.92e+00,\\n103,3.88e+00,\\n104,3.92e+00,\\n105,3.88e+00,\\n106,3.92e+00,\\n107,3.88e+00,\\n108,3.88e+00,\\n109,3.92e+00,\\n110,3.88e+00,\\n111,3.92e+00,\\n112,3.92e+00,\\n113,3.88e+00,\\n114,3.88e+00,\\n115,3.92e+00,\\n116,3.92e+00,\\n117,3.88e+00,\\n118,3.92e+00,\\n119,3.88e+00,\\n120,3.92e+00,\\n121,3.88e+00,\\n122,3.92e+00,\\n123,3.88e+00,\\n124,3.88e+00,\\n125,3.92e+00,\\n126,3.88e+00,\\n127,3.92e+00,\\n128,3.92e+00,\\n129,3.88e+00,\\n130,3.92e+00,\\n131,3.88e+00,\\n132,3.92e+00,\\n133,3.88e+00,\\n134,3.92e+00,\\n135,3.88e+00,\\n136,3.88e+00,\\n137,3.92e+00,\\n138,3.88e+00,\\n139,3.92e+00,\\n140,3.92e+00,\\n141,3.88e+00,\\n142,3.92e+00,\\n143,3.88e+00,\\n144,3.88e+00,\\n145,3.92e+00,\\n146,3.92e+00,\\n147,3.88e+00,\\n148,3.88e+00,\\n149,3.92e+00,\\n150,3.92e+00,\\n151,3.88e+00,\\n152,3.88e+00,\\n153,3.92e+00,\\n154,3.92e+00,\\n155,3.88e+00,\\n156,3.88e+00,\\n157,3.92e+00,\\n158,3.88e+00,\\n159,3.92e+00,\\n160,3.88e+00,\\n161,3.92e+00,\\n162,3.92e+00,\\n163,3.88e+00,\\n164,3.88e+00,\\n165,3.92e+00,\\n166,3.88e+00,\\n167,3.92e+00,\\n168,3.92e+00,\\n169,3.88e+00,\\n170,3.88e+00,\\n171,3.92e+00,\\n172,3.88e+00,\\n173,3.92e+00,\\n174,3.88e+00,\\n175,3.92e+00,\\n176,3.92e+00,\\n177,3.88e+00,\\n178,3.92e+00,\\n179,3.88e+00,\\n180,3.92e+00,\\n181,3.88e+00,\\n182,3.88e+00,\\n183,3.92e+00,\\n184,3.88e+00,\\n185,3.92e+00,\\n186,3.88e+00,\\n187,3.92e+00,\\n188,3.88e+00,\\n189,3.92e+00,\\n190,3.88e+00,\\n191,3.92e+00,\\n192,3.92e+00,\\n193,3.88e+00,\\n194,3.88e+00,\\n195,3.92e+00,\\n196,3.88e+00,\\n197,3.92e+00,\\n198,3.88e+00,\\n199,3.92e+00,\\n200,3.88e+00,\\n201,3.92e+00,\\n202,3.88e+00,\\n203,3.92e+00,\\n204,3.92e+00,\\n205,3.88e+00,\\n206,3.88e+00,\\n207,3.92e+00,\\n208,3.88e+00,\\n209,3.92e+00,\\n210,3.88e+00,\\n211,3.92e+00,\\n212,3.88e+00,\\n213,3.92e+00,\\n214,3.92e+00,\\n215,3.88e+00,\\n216,3.90e+00,\\n217,3.88e+00,\\n218,3.88e+00,\\n219,3.90e+00,\\n220,3.88e+00,\\n221,3.90e+00,\\n222,3.90e+00,\\n223,3.88e+00,\\n224,3.90e+00,\\n225,3.88e+00,\\n226,3.88e+00,\\n227,3.90e+00,\\n228,3.88e+00,\\n229,3.92e+00,\\n230,3.90e+00,\\n231,3.88e+00,\\n232,3.90e+00,\\n233,3.88e+00,\\n234,3.88e+00,\\n235,3.92e+00,\\n236,3.88e+00,\\n237,3.92e+00,\\n238,3.88e+00,\\n239,3.90e+00,\\n240,3.88e+00,\\n241,3.92e+00,\\n242,3.88e+00,\\n243,3.94e+00,\\n244,3.88e+00,\\n245,3.94e+00,\\n246,3.88e+00,\\n247,3.94e+00,\\n248,3.94e+00,\\n249,3.88e+00,\\n250,3.94e+00,\\n251,3.88e+00,\\n252,3.88e+00,\\n253,3.94e+00,\\n254,3.94e+00,\\n255,3.88e+00,\\n256,3.88e+00,\\n257,3.94e+00,\\n258,3.94e+00,\\n259,3.88e+00,\\n260,3.94e+00,\\n261,3.88e+00,\\n262,3.90e+00,\\n263,3.94e+00,\\n264,3.94e+00,\\n265,3.92e+00,\\n266,3.92e+00,\\n267,3.94e+00,\\n268,3.94e+00,\\n269,3.92e+00,\\n270,3.94e+00,\\n271,3.92e+00,\\n272,3.94e+00,\\n273,3.90e+00,\\n274,3.94e+00,\\n275,3.90e+00,\\n276,3.90e+00,\\n277,3.94e+00,\\n278,3.90e+00,\\n279,3.96e+00,\\n280,3.92e+00,\\n281,3.96e+00,\\n282,3.96e+00,\\n283,3.92e+00,\\n284,3.92e+00,\\n285,3.98e+00,\\n286,3.94e+00,\\n287,4.00e+00,\\n288,3.96e+00,\\n289,4.02e+00,\\n290,3.98e+00,\\n291,4.02e+00,\\n292,4.00e+00,\\n293,4.06e+00,\\n294,4.04e+00,\\n295,4.10e+00,\\n296,4.06e+00,\\n297,4.12e+00,\\n298,4.10e+00,\\n299,4.16e+00,\\n300,4.12e+00,\\n301,4.20e+00,\\n302,4.16e+00,\\n303,4.24e+00,\\n304,4.22e+00,\\n305,4.30e+00,\\n306,4.26e+00,\\n307,4.34e+00,\\n308,4.30e+00,\\n309,4.40e+00,\\n310,4.36e+00,\\n311,4.44e+00,\\n312,4.42e+00,\\n313,4.50e+00,\\n314,4.48e+00,\\n315,4.58e+00,\\n316,4.54e+00,\\n317,4.64e+00,\\n318,4.60e+00,\\n319,4.70e+00,\\n320,4.66e+00,\\n321,4.76e+00,\\n322,4.74e+00,\\n323,4.84e+00,\\n324,4.80e+00,\\n325,4.90e+00,\\n326,4.90e+00,\\n327,4.98e+00,\\n328,4.96e+00,\\n329,5.06e+00,\\n330,5.04e+00,\\n331,5.14e+00,\\n332,5.10e+00,\\n333,5.22e+00,\\n334,5.18e+00,\\n335,5.28e+00,\\n336,5.26e+00,\\n337,5.36e+00,\\n338,5.34e+00,\\n339,5.44e+00,\\n340,5.42e+00,\\n341,5.52e+00,\\n342,5.48e+00,\\n343,5.58e+00,\\n344,5.56e+00,\\n345,5.66e+00,\\n346,5.62e+00,\\n347,5.70e+00,\\n348,5.70e+00,\\n349,5.78e+00,\\n350,5.76e+00,\\n351,5.82e+00,\\n352,5.80e+00,\\n353,5.86e+00,\\n354,5.84e+00,\\n355,5.90e+00,\\n356,5.88e+00,\\n357,5.94e+00,\\n358,5.92e+00,\\n359,5.98e+00,\\n360,5.96e+00,\\n361,6.02e+00,\\n362,5.98e+00,\\n363,6.06e+00,\\n364,6.02e+00,\\n365,6.08e+00,\\n366,6.06e+00,\\n367,6.12e+00,\\n368,6.08e+00,\\n369,6.16e+00,\\n370,6.12e+00,\\n371,6.18e+00,\\n372,6.14e+00,\\n373,6.20e+00,\\n374,6.18e+00,\\n375,6.24e+00,\\n376,6.20e+00,\\n377,6.26e+00,\\n378,6.22e+00,\\n379,6.30e+00,\\n380,6.26e+00,\\n381,6.32e+00,\\n382,6.28e+00,\\n383,6.34e+00,\\n384,6.30e+00,\\n385,6.36e+00,\\n386,6.34e+00,\\n387,6.40e+00,\\n388,6.36e+00,\\n389,6.42e+00,\\n390,6.38e+00,\\n391,6.44e+00,\\n392,6.44e+00,\\n393,6.40e+00,\\n394,6.46e+00,\\n395,6.40e+00,\\n396,6.42e+00,\\n397,6.48e+00,\\n398,6.44e+00,\\n399,6.50e+00,\\n400,6.48e+00,\\n401,6.50e+00,\\n402,6.46e+00,\\n403,6.52e+00,\\n404,6.48e+00,\\n405,6.54e+00,\\n406,6.50e+00,\\n407,6.50e+00,\\n408,6.50e+00,\\n409,6.56e+00,\\n410,6.56e+00,\\n411,6.52e+00,\\n412,6.52e+00,\\n413,6.54e+00,\\n414,6.52e+00,\\n415,6.56e+00,\\n416,6.58e+00,\\n417,6.52e+00,\\n418,6.54e+00,\\n419,6.58e+00,\\n420,6.54e+00,\\n421,6.58e+00,\\n422,6.54e+00,\\n423,6.56e+00,\\n424,6.54e+00,\\n425,6.58e+00,\\n426,6.54e+00,\\n427,6.60e+00,\\n428,6.58e+00,\\n429,6.60e+00,\\n430,6.60e+00,\\n431,6.56e+00,\\n432,6.60e+00,\\n433,6.56e+00,\\n434,6.56e+00,\\n435,6.60e+00,\\n436,6.56e+00,\\n437,6.58e+00,\\n438,6.56e+00,\\n439,6.58e+00,\\n440,6.56e+00,\\n441,6.58e+00,\\n442,6.56e+00,\\n443,6.58e+00,\\n444,6.56e+00,\\n445,6.60e+00,\\n446,6.56e+00,\\n447,6.62e+00,\\n448,6.56e+00,\\n449,6.62e+00,\\n450,6.56e+00,\\n451,6.62e+00,\\n452,6.62e+00,\\n453,6.56e+00,\\n454,6.62e+00,\\n455,6.58e+00,\\n456,6.62e+00,\\n457,6.58e+00,\\n458,6.58e+00,\\n459,6.62e+00,\\n460,6.62e+00,\\n461,6.58e+00,\\n462,6.62e+00,\\n463,6.58e+00,\\n464,6.62e+00,\\n465,6.58e+00,\\n466,6.62e+00,\\n467,6.58e+00,\\n468,6.62e+00,\\n469,6.58e+00,\\n470,6.62e+00,\\n471,6.58e+00,\\n472,6.58e+00,\\n473,6.62e+00,\\n474,6.58e+00,\\n475,6.62e+00,\\n476,6.58e+00,\\n477,6.62e+00,\\n478,6.58e+00,\\n479,6.62e+00,\\n480,6.62e+00,\\n481,6.58e+00,\\n482,6.62e+00,\\n483,6.58e+00,\\n484,6.62e+00,\\n485,6.58e+00,\\n486,6.58e+00,\\n487,6.62e+00,\\n488,6.62e+00,\\n489,6.56e+00,\\n490,6.62e+00,\\n491,6.58e+00,\\n492,6.58e+00,\\n493,6.62e+00,\\n494,6.62e+00,\\n495,6.58e+00,\\n496,6.62e+00,\\n497,6.56e+00,\\n498,6.62e+00,\\n499,6.58e+00,\\n500,6.62e+00,\\n501,6.56e+00,\\n502,6.62e+00,\\n503,6.56e+00,\\n504,6.62e+00,\\n505,6.56e+00,\\n506,6.62e+00,\\n507,6.56e+00,\\n508,6.62e+00,\\n509,6.56e+00,\\n510,6.62e+00,\\n511,6.56e+00,\\n512,6.56e+00,\\n513,6.62e+00,\\n514,6.56e+00,\\n515,6.62e+00,\\n516,6.62e+00,\\n517,6.56e+00,\\n518,6.56e+00,\\n519,6.62e+00,\\n520,6.56e+00,\\n521,6.62e+00,\\n522,6.56e+00,\\n523,6.62e+00,\\n524,6.56e+00,\\n525,6.62e+00,\\n526,6.56e+00,\\n527,6.62e+00,\\n528,6.60e+00,\\n529,6.56e+00,\\n530,6.56e+00,\\n531,6.62e+00,\\n532,6.56e+00,\\n533,6.62e+00,\\n534,6.56e+00,\\n535,6.62e+00,\\n536,6.56e+00,\\n537,6.62e+00,\\n538,6.56e+00,\\n539,6.60e+00,\\n540,6.56e+00,\\n541,6.62e+00,\\n542,6.56e+00,\\n543,6.62e+00,\\n544,6.56e+00,\\n545,6.60e+00,\\n546,6.60e+00,\\n547,6.56e+00,\\n548,6.56e+00,\\n549,6.58e+00,\\n550,6.56e+00,\\n551,6.58e+00,\\n552,6.58e+00,\\n553,6.56e+00,\\n554,6.56e+00,\\n555,6.58e+00,\\n556,6.56e+00,\\n557,6.58e+00,\\n558,6.56e+00,\\n559,6.58e+00,\\n560,6.56e+00,\\n561,6.58e+00,\\n562,6.56e+00,\\n563,6.58e+00,\\n564,6.56e+00,\\n565,6.58e+00,\\n566,6.56e+00,\\n567,6.58e+00,\\n568,6.58e+00,\\n569,6.56e+00,\\n570,6.56e+00,\\n571,6.58e+00,\\n572,6.56e+00,\\n573,6.58e+00,\\n574,6.56e+00,\\n575,6.58e+00,\\n576,6.56e+00,\\n577,6.58e+00,\\n578,6.56e+00,\\n579,6.58e+00,\\n580,6.56e+00,\\n581,6.58e+00,\\n582,6.58e+00,\\n583,6.56e+00,\\n584,6.56e+00,\\n585,6.58e+00,\\n586,6.56e+00,\\n587,6.58e+00,\\n588,6.56e+00,\\n589,6.58e+00,\\n590,6.56e+00,\\n591,6.58e+00,\\n592,6.56e+00,\\n593,6.58e+00,\\n594,6.56e+00,\\n595,6.58e+00,\\n596,6.56e+00,\\n597,6.60e+00,\\n598,6.56e+00,\\n599,6.58e+00,\\n600,6.56e+00,\\n601,6.58e+00,\\n602,6.56e+00,\\n603,6.60e+00,\\n604,6.56e+00,\\n605,6.60e+00,\\n606,6.58e+00,\\n607,6.56e+00,\\n608,6.56e+00,\\n609,6.60e+00,\\n610,6.56e+00,\\n611,6.60e+00,\\n612,6.56e+00,\\n613,6.60e+00,\\n614,6.56e+00,\\n615,6.60e+00,\\n616,6.56e+00,\\n617,6.60e+00,\\n618,6.56e+00,\\n619,6.60e+00,\\n620,6.56e+00,\\n621,6.60e+00,\\n622,6.60e+00,\\n623,6.56e+00,\\n624,6.56e+00,\\n625,6.60e+00,\\n626,6.56e+00,\\n627,6.60e+00,\\n628,6.56e+00,\\n629,6.60e+00,\\n630,6.60e+00,\\n631,6.56e+00,\\n632,6.56e+00,\\n633,6.60e+00,\\n634,6.56e+00,\\n635,6.60e+00,\\n636,6.60e+00,\\n637,6.56e+00,\\n638,6.56e+00,\\n639,6.60e+00,\\n640,6.60e+00,\\n641,6.56e+00,\\n642,6.60e+00,\\n643,6.56e+00,\\n644,6.56e+00,\\n645,6.60e+00,\\n646,6.60e+00,\\n647,6.56e+00,\\n648,6.60e+00,\\n649,6.56e+00,\\n650,6.60e+00,\\n651,6.54e+00,\\n652,6.60e+00,\\n653,6.56e+00,\\n654,6.60e+00,\\n655,6.54e+00,\\n656,6.54e+00,\\n657,6.60e+00,\\n658,6.60e+00,\\n659,6.54e+00,\\n660,6.60e+00,\\n661,6.54e+00,\\n662,6.54e+00,\\n663,6.60e+00,\\n664,6.60e+00,\\n665,6.54e+00,\\n666,6.54e+00,\\n667,6.60e+00,\\n668,6.54e+00,\\n669,6.60e+00,\\n670,6.54e+00,\\n671,6.60e+00,\\n672,6.54e+00,\\n673,6.60e+00,\\n674,6.54e+00,\\n675,6.60e+00,\\n676,6.60e+00,\\n677,6.54e+00,\\n678,6.54e+00,\\n679,6.60e+00,\\n680,6.60e+00,\\n681,6.54e+00,\\n682,6.54e+00,\\n683,6.60e+00,\\n684,6.54e+00,\\n685,6.60e+00,\\n686,6.54e+00,\\n687,6.60e+00,\\n688,6.54e+00,\\n689,6.60e+00,\\n690,6.54e+00,\\n691,6.60e+00,\\n692,6.54e+00,\\n693,6.60e+00,\\n694,6.54e+00,\\n695,6.60e+00,\\n696,6.54e+00,\\n697,6.58e+00,\\n698,6.60e+00,\\n699,6.54e+00,\\n700,6.54e+00,\\n701,6.60e+00,\\n702,6.54e+00,\\n703,6.58e+00,\\n704,6.54e+00,\\n705,6.60e+00,\\n706,6.54e+00,\\n707,6.58e+00,\\n708,6.54e+00,\\n709,6.60e+00,\\n710,6.54e+00,\\n711,6.58e+00,\\n712,6.54e+00,\\n713,6.58e+00,\\n714,6.54e+00,\\n715,6.56e+00,\\n716,6.54e+00,\\n717,6.58e+00,\\n718,6.54e+00,\\n719,6.56e+00,\\n720,6.54e+00,\\n721,6.58e+00,\\n722,6.54e+00,\\n723,6.58e+00,\\n724,6.54e+00,\\n725,6.58e+00,\\n726,6.54e+00,\\n727,6.56e+00,\\n728,6.54e+00,\\n729,6.56e+00,\\n730,6.54e+00,\\n731,6.56e+00,\\n732,6.54e+00,\\n733,6.58e+00,\\n734,6.54e+00,\\n735,6.56e+00,\\n736,6.54e+00,\\n737,6.56e+00,\\n738,6.54e+00,\\n739,6.56e+00,\\n740,6.54e+00,\\n741,6.56e+00,\\n742,6.54e+00,\\n743,6.56e+00,\\n744,6.54e+00,\\n745,6.56e+00,\\n746,6.56e+00,\\n747,6.54e+00,\\n748,6.54e+00,\\n749,6.56e+00,\\n750,6.54e+00,\\n751,6.56e+00,\\n752,6.54e+00,\\n753,6.56e+00,\\n754,6.54e+00,\\n755,6.56e+00,\\n756,6.54e+00,\\n757,6.56e+00,\\n758,6.54e+00,\\n759,6.56e+00,\\n760,6.54e+00,\\n761,6.56e+00,\\n762,6.54e+00,\\n763,6.56e+00,\\n764,6.54e+00,\\n765,6.56e+00,\\n766,6.54e+00,\\n767,6.56e+00,\\n768,6.54e+00,\\n769,6.56e+00,\\n770,6.54e+00,\\n771,6.56e+00,\\n772,6.54e+00,\\n773,6.56e+00,\\n774,6.54e+00,\\n775,6.56e+00,\\n776,6.56e+00,\\n777,6.54e+00,\\n778,6.54e+00,\\n779,6.56e+00,\\n780,6.54e+00,\\n781,6.56e+00,\\n782,6.54e+00,\\n783,6.56e+00,\\n784,6.54e+00,\\n785,6.56e+00,\\n786,6.54e+00,\\n787,6.56e+00,\\n788,6.54e+00,\\n789,6.58e+00,\\n790,6.54e+00,\\n791,6.56e+00,\\n792,6.54e+00,\\n793,6.56e+00,\\n794,6.54e+00,\\n795,6.56e+00,\\n796,6.54e+00,\\n797,6.56e+00,\\n798,6.54e+00,\\n799,6.58e+00,\\n800,6.56e+00,\\n801,6.54e+00,\\n802,6.54e+00,\\n803,6.58e+00,\\n804,6.54e+00,\\n805,6.58e+00,\\n806,6.58e+00,\\n807,6.54e+00,\\n808,6.54e+00,\\n809,6.58e+00,\\n810,6.54e+00,\\n811,6.58e+00,\\n812,6.58e+00,\\n813,6.54e+00,\\n814,6.58e+00,\\n815,6.54e+00,\\n816,6.52e+00,\\n817,6.58e+00,\\n818,6.58e+00,\\n819,6.52e+00,\\n820,6.52e+00,\\n821,6.56e+00,\\n822,6.52e+00,\\n823,6.56e+00,\\n824,6.52e+00,\\n825,6.54e+00,\\n826,6.52e+00,\\n827,6.54e+00,\\n828,6.52e+00,\\n829,6.54e+00,\\n830,6.52e+00,\\n831,6.54e+00,\\n832,6.52e+00,\\n833,6.56e+00,\\n834,6.56e+00,\\n835,6.52e+00,\\n836,6.56e+00,\\n837,6.52e+00,\\n838,6.56e+00,\\n839,6.50e+00,\\n840,6.50e+00,\\n841,6.54e+00,\\n842,6.50e+00,\\n843,6.52e+00,\\n844,6.54e+00,\\n845,6.48e+00,\\n846,6.52e+00,\\n847,6.48e+00,\\n848,6.52e+00,\\n849,6.44e+00,\\n850,6.44e+00,\\n851,6.48e+00,\\n852,6.48e+00,\\n853,6.42e+00,\\n854,6.46e+00,\\n855,6.40e+00,\\n856,6.42e+00,\\n857,6.36e+00,\\n858,6.40e+00,\\n859,6.34e+00,\\n860,6.36e+00,\\n861,6.30e+00,\\n862,6.34e+00,\\n863,6.26e+00,\\n864,6.30e+00,\\n865,6.22e+00,\\n866,6.24e+00,\\n867,6.16e+00,\\n868,6.20e+00,\\n869,6.12e+00,\\n870,6.16e+00,\\n871,6.06e+00,\\n872,6.10e+00,\\n873,6.02e+00,\\n874,6.04e+00,\\n875,5.96e+00,\\n876,5.98e+00,\\n877,5.90e+00,\\n878,5.94e+00,\\n879,5.84e+00,\\n880,5.88e+00,\\n881,5.78e+00,\\n882,5.80e+00,\\n883,5.72e+00,\\n884,5.74e+00,\\n885,5.64e+00,\\n886,5.66e+00,\\n887,5.58e+00,\\n888,5.58e+00,\\n889,5.50e+00,\\n890,5.52e+00,\\n891,5.42e+00,\\n892,5.44e+00,\\n893,5.34e+00,\\n894,5.38e+00,\\n895,5.28e+00,\\n896,5.30e+00,\\n897,5.20e+00,\\n898,5.22e+00,\\n899,5.12e+00,\\n900,5.12e+00,\\n901,5.04e+00,\\n902,5.06e+00,\\n903,4.96e+00,\\n904,4.96e+00,\\n905,4.90e+00,\\n906,4.90e+00,\\n907,4.80e+00,\\n908,4.84e+00,\\n909,4.76e+00,\\n910,4.78e+00,\\n911,4.70e+00,\\n912,4.74e+00,\\n913,4.66e+00,\\n914,4.70e+00,\\n915,4.64e+00,\\n916,4.66e+00,\\n917,4.60e+00,\\n918,4.62e+00,\\n919,4.56e+00,\\n920,4.60e+00,\\n921,4.54e+00,\\n922,4.56e+00,\\n923,4.50e+00,\\n924,4.54e+00,\\n925,4.48e+00,\\n926,4.50e+00,\\n927,4.44e+00,\\n928,4.48e+00,\\n929,4.40e+00,\\n930,4.44e+00,\\n931,4.38e+00,\\n932,4.42e+00,\\n933,4.34e+00,\\n934,4.38e+00,\\n935,4.32e+00,\\n936,4.36e+00,\\n937,4.30e+00,\\n938,4.32e+00,\\n939,4.26e+00,\\n940,4.30e+00,\\n941,4.24e+00,\\n942,4.28e+00,\\n943,4.22e+00,\\n944,4.24e+00,\\n945,4.18e+00,\\n946,4.22e+00,\\n947,4.16e+00,\\n948,4.20e+00,\\n949,4.14e+00,\\n950,4.16e+00,\\n951,4.10e+00,\\n952,4.14e+00,\\n953,4.08e+00,\\n954,4.12e+00,\\n955,4.06e+00,\\n956,4.08e+00,\\n957,4.02e+00,\\n958,4.06e+00,\\n959,4.00e+00,\\n960,4.02e+00,\\n961,4.04e+00,\\n962,4.04e+00,\\n963,3.98e+00,\\n964,4.02e+00,\\n965,4.00e+00,\\n966,4.02e+00,\\n967,3.96e+00,\\n968,3.96e+00,\\n969,4.00e+00,\\n970,4.00e+00,\\n971,3.98e+00,\\n972,4.00e+00,\\n973,3.94e+00,\\n974,4.00e+00,\\n975,3.94e+00,\\n976,3.94e+00,\\n977,3.98e+00,\\n978,3.94e+00,\\n979,3.98e+00,\\n980,3.94e+00,\\n981,3.98e+00,\\n982,3.98e+00,\\n983,3.96e+00,\\n984,3.98e+00,\\n985,3.94e+00,\\n986,3.98e+00,\\n987,3.92e+00,\\n988,3.98e+00,\\n989,3.92e+00,\\n990,3.96e+00,\\n991,3.92e+00,\\n992,3.96e+00,\\n993,3.92e+00,\\n994,3.92e+00,\\n995,3.96e+00,\\n996,3.96e+00,\\n997,3.92e+00,\\n998,3.92e+00,\\n999,3.96e+00,\\n1000,3.96e+00,\\n1001,3.92e+00,\\n1002,3.96e+00,\\n1003,3.92e+00,\\n1004,3.96e+00,\\n1005,3.92e+00,\\n1006,3.96e+00,\\n1007,3.94e+00,\\n1008,3.96e+00,\\n1009,3.94e+00,\\n1010,3.96e+00,\\n1011,3.94e+00,\\n1012,3.96e+00,\\n1013,3.94e+00,\\n1014,3.96e+00,\\n1015,3.92e+00,\\n1016,3.96e+00,\\n1017,3.92e+00,\\n1018,3.96e+00,\\n1019,3.90e+00,\\n1020,3.96e+00,\\n1021,3.90e+00,\\n1022,3.96e+00,\\n1023,3.90e+00,\\n1024,3.90e+00,\\n1025,3.96e+00,\\n1026,3.90e+00,\\n1027,3.96e+00,\\n1028,3.90e+00,\\n1029,3.96e+00,\\n1030,3.94e+00,\\n1031,3.90e+00,\\n1032,3.90e+00,\\n1033,3.92e+00,\\n1034,3.92e+00,\\n1035,3.90e+00,\\n1036,3.94e+00,\\n1037,3.90e+00,\\n1038,3.90e+00,\\n1039,3.94e+00,\\n1040,3.94e+00,\\n1041,3.90e+00,\\n1042,3.94e+00,\\n1043,3.90e+00,\\n1044,3.94e+00,\\n1045,3.90e+00,\\n1046,3.94e+00,\\n1047,3.90e+00,\\n1048,3.94e+00,\\n1049,3.92e+00,\\n1050,3.94e+00,\\n1051,3.92e+00,\\n1052,3.92e+00,\\n1053,3.94e+00,\\n1054,3.94e+00,\\n1055,3.92e+00,\\n1056,3.94e+00,\\n1057,3.90e+00,\\n1058,3.94e+00,\\n1059,3.90e+00,\\n1060,3.94e+00,\\n1061,3.88e+00,\\n1062,3.94e+00,\\n1063,3.88e+00,\\n1064,3.94e+00,\\n1065,3.88e+00,\\n1066,3.94e+00,\\n1067,3.88e+00,\\n1068,3.94e+00,\\n1069,3.88e+00,\\n1070,3.88e+00,\\n1071,3.92e+00,\\n1072,3.88e+00,\\n1073,3.94e+00,\\n1074,3.88e+00,\\n1075,3.94e+00,\\n1076,3.94e+00,\\n1077,3.88e+00,\\n1078,3.88e+00,\\n1079,3.92e+00,\\n1080,3.88e+00,\\n1081,3.92e+00,\\n1082,3.88e+00,\\n1083,3.92e+00,\\n1084,3.90e+00,\\n1085,3.88e+00,\\n1086,3.90e+00,\\n1087,3.88e+00,\\n1088,3.88e+00,\\n1089,3.92e+00,\\n1090,3.88e+00,\\n1091,3.92e+00,\\n1092,3.88e+00,\\n1093,3.92e+00,\\n1094,3.88e+00,\\n1095,3.92e+00,\\n1096,3.88e+00,\\n1097,3.92e+00,\\n1098,3.92e+00,\\n1099,3.88e+00,\\n1100,3.88e+00,\\n1101,3.92e+00,\\n1102,3.92e+00,\\n1103,3.88e+00,\\n1104,3.92e+00,\\n1105,3.88e+00,\\n1106,3.92e+00,\\n1107,3.88e+00,\\n1108,3.88e+00,\\n1109,3.92e+00,\\n1110,3.88e+00,\\n1111,3.92e+00,\\n1112,3.92e+00,\\n1113,3.88e+00,\\n1114,3.88e+00,\\n1115,3.92e+00,\\n1116,3.88e+00,\\n1117,3.92e+00,\\n1118,3.88e+00,\\n1119,3.92e+00,\\n1120,3.88e+00,\\n1121,3.92e+00,\\n1122,3.92e+00,\\n1123,3.88e+00,\\n1124,3.88e+00,\\n1125,3.92e+00,\\n1126,3.88e+00,\\n1127,3.92e+00,\\n1128,3.88e+00,\\n1129,3.92e+00,\\n1130,3.88e+00,\\n1131,3.92e+00,\\n1132,3.92e+00,\\n1133,3.88e+00,\\n1134,3.92e+00,\\n1135,3.88e+00,\\n1136,3.92e+00,\\n1137,3.88e+00,\\n1138,3.88e+00,\\n1139,3.92e+00,\\n1140,3.92e+00,\\n1141,3.88e+00,\\n1142,3.88e+00,\\n1143,3.92e+00,\\n1144,3.92e+00,\\n1145,3.88e+00,\\n1146,3.92e+00,\\n1147,3.88e+00,\\n1148,3.92e+00,\\n1149,3.88e+00,\\n1150,3.92e+00,\\n1151,3.88e+00,\\n1152,3.92e+00,\\n1153,3.88e+00,\\n1154,3.92e+00,\\n1155,3.88e+00,\\n1156,3.92e+00,\\n1157,3.88e+00,\\n1158,3.92e+00,\\n1159,3.88e+00,\\n1160,3.92e+00,\\n1161,3.88e+00,\\n1162,3.92e+00,\\n1163,3.88e+00,\\n1164,3.92e+00,\\n1165,3.88e+00,\\n1166,3.92e+00,\\n1167,3.88e+00,\\n1168,3.92e+00,\\n1169,3.88e+00,\\n1170,3.88e+00,\\n1171,3.92e+00,\\n1172,3.92e+00,\\n1173,3.88e+00,\\n1174,3.92e+00,\\n1175,3.88e+00,\\n1176,3.92e+00,\\n1177,3.88e+00,\\n1178,3.92e+00,\\n1179,3.88e+00,\\n1180,3.92e+00,\\n1181,3.88e+00,\\n1182,3.92e+00,\\n1183,3.88e+00,\\n1184,3.92e+00,\\n1185,3.88e+00,\\n1186,3.92e+00,\\n1187,3.88e+00,\\n1188,3.92e+00,\\n1189,3.88e+00,\\n1190,3.88e+00,\\n1191,3.92e+00,\\n1192,3.92e+00,\\n1193,3.88e+00,\\n1194,3.92e+00,\\n1195,3.88e+00,\\n1196,3.92e+00,\\n1197,3.88e+00,\\n1198,3.88e+00,\\n1199,3.92e+00,',\n",
       " \"import os\\nimport logging\\nimport pandas as pd\\nfrom datetime import datetime, timedelta\\nfrom psycopg2.extras import execute_values\\nimport psycopg2\\nfrom airflow import DAG\\nfrom airflow.operators.python import PythonOperator\\nfrom airflow.providers.postgres.hooks.postgres import PostgresHook\\ndag_default_args = {\\n\\t'owner': 'at3_dbt',\\n\\t'start_date': datetime.now() - timedelta(days=2 + 4),\\n\\t'email': [],  \\n\\t'email_on_failure': True,\\n\\t'email_on_retry': False,\\n\\t'retries': 2,\\n\\t'retry_delay': timedelta(minutes=5),\\n\\t'depends_on_past': False,\\n\\t'wait_for_downstream': False,\\n}\\ndag = DAG(\\n\\tdag_id='dag_at3',\\n\\tdefault_args=dag_default_args,\\n\\tschedule_interval=None,  \\n\\tcatchup=True,\\n\\tmax_active_runs=1,\\n\\tconcurrency=5\\n)\\nAIRFLOW_DATA = &quot;/home/airflow/gcs/data/&quot;\\nLISTINGS = AIRFLOW_DATA+'listings/'\\ndef import_load_dim_census_g01_func(**kwargs):\\n\\tps_pg_hook = PostgresHook(postgres_conn_id=&quot;postgres&quot;)\\n\\tconn_ps = ps_pg_hook.get_conn()\\n\\tdf = pd.read_csv(AIRFLOW_DATA+'/2016Census_G01_NSW_LGA.csv')\\n\\tif not df.empty:\\n\\t\\tcol_names = df.columns.to_list()\\n\\t\\tvalues = df[col_names].to_dict('split')\\n\\t\\tvalues = values['data']\\n\\t\\tlogging.info(values)\\n\\t\\tinsert_sql = &quot;&quot;&quot;\\n\\t\\t\\t\\t\\tINSERT INTO raw.Census_G01({})\\n\\t\\t\\t\\t\\tVALUES %s\\n\\t\\t\\t\\t\\t&quot;&quot;&quot;.format(','.join(col_names))\\n\\t\\tcursor = conn_ps.cursor()\\n\\t\\texecute_values(cursor, insert_sql, values)\\n\\t\\tconn_ps.commit()\\n\\telse:\\n\\t\\tlogging.info(&quot;DataFrame is empty&quot;)\\n\\treturn None\\ndef import_load_dim_census_g02_func(**kwargs):\\n\\tps_pg_hook = PostgresHook(postgres_conn_id=&quot;postgres&quot;)\\n\\tconn_ps = ps_pg_hook.get_conn()\\n\\tdf = pd.read_csv(AIRFLOW_DATA+'2016Census_G02_NSW_LGA.csv')\\n\\tif not df.empty:\\n\\t\\tcol_names = df.columns.to_list()\\n\\t\\tvalues = df[col_names].to_dict('split')\\n\\t\\tvalues = values['data']\\n\\t\\tlogging.info(values)\\n\\t\\tinsert_sql = &quot;&quot;&quot;\\n\\t\\t\\t\\t\\tINSERT INTO raw.Census_G02({})\\n\\t\\t\\t\\t\\tVALUES %s\\n\\t\\t\\t\\t\\t&quot;&quot;&quot;.format(','.join(col_names))\\n\\t\\tcursor = conn_ps.cursor()\\n\\t\\texecute_values(cursor, insert_sql, values)\\n\\t\\tconn_ps.commit()\\n\\telse:\\n\\t\\tlogging.info(&quot;DataFrame is empty&quot;)\\n\\treturn None\\ndef import_load_dim_nsw_lga_code_func(**kwargs):\\n\\tps_pg_hook = PostgresHook(postgres_conn_id=&quot;postgres&quot;)\\n\\tconn_ps = ps_pg_hook.get_conn()\\n\\tdf = pd.read_csv(AIRFLOW_DATA+'NSW_LGA_CODE.csv')\\n\\tif not df.empty:\\n\\t\\tcol_names = df.columns.to_list()\\n\\t\\tvalues = df[col_names].to_dict('split')\\n\\t\\tvalues = values['data']\\n\\t\\tlogging.info(values)\\n\\t\\tinsert_sql = &quot;&quot;&quot;\\n\\t\\t\\t\\t\\tINSERT INTO raw.nsw_lga_code({})\\n\\t\\t\\t\\t\\tVALUES %s\\n\\t\\t\\t\\t\\t&quot;&quot;&quot;.format(','.join(col_names))\\n\\t\\tcursor = conn_ps.cursor()\\n\\t\\texecute_values(cursor, insert_sql, values)\\n\\t\\tconn_ps.commit()\\n\\telse:\\n\\t\\tlogging.info(&quot;DataFrame is empty&quot;)\\n\\treturn None\\ndef import_load_dim_nsw_lga_suburb_func(**kwargs):\\n\\tps_pg_hook = PostgresHook(postgres_conn_id=&quot;postgres&quot;)\\n\\tconn_ps = ps_pg_hook.get_conn()\\n\\tdf = pd.read_csv(AIRFLOW_DATA+'NSW_LGA_SUBURB.csv')\\n\\tif not df.empty:\\n\\t\\tcol_names = df.columns.to_list()\\n\\t\\tvalues = df[col_names].to_dict('split')\\n\\t\\tvalues = values['data']\\n\\t\\tlogging.info(values)\\n\\t\\tinsert_sql = &quot;&quot;&quot;\\n\\t\\t\\t\\t\\tINSERT INTO raw.nsw_lga_suburb({})\\n\\t\\t\\t\\t\\tVALUES %s\\n\\t\\t\\t\\t\\t&quot;&quot;&quot;.format(','.join(col_names))\\n\\t\\tcursor = conn_ps.cursor()\\n\\t\\texecute_values(cursor, insert_sql, values)\\n\\t\\tconn_ps.commit()\\n\\telse:\\n\\t\\tlogging.info(&quot;DataFrame is empty&quot;)\\n\\treturn None\\ndef import_load_listings_func(**kwargs):\\n\\tps_pg_hook = PostgresHook(postgres_conn_id=&quot;postgres&quot;)\\n\\tconn_ps = ps_pg_hook.get_conn()\\n\\tfilelist = [k for k in os.listdir(LISTINGS) if '.csv' in k]\\n\\tdf = pd.concat([pd.read_csv(LISTINGS + f) for f in filelist], ignore_index=True)\\n\\tif not df.empty:\\n\\t\\tcol_names = df.columns.to_list()\\n\\t\\tvalues = df[col_names].to_dict('split')\\n\\t\\tvalues = values['data']\\n\\t\\tlogging.info(values)\\n\\t\\tinsert_sql = &quot;&quot;&quot;\\n\\t\\t\\t\\t\\tINSERT INTO raw.listings({})\\n\\t\\t\\t\\t\\tVALUES %s\\n\\t\\t\\t\\t\\t&quot;&quot;&quot;.format(','.join(col_names))\\n\\t\\tcursor = conn_ps.cursor()\\n\\t\\texecute_values(cursor, insert_sql, values)\\n\\t\\tconn_ps.commit()\\n\\telse:\\n\\t\\tlogging.info(&quot;DataFrame is empty&quot;)\\n\\treturn None\\nimport_load_dim_census_g01_task = PythonOperator(\\n\\ttask_id='import_load_dim_census_g01',\\n\\tpython_callable=import_load_dim_census_g01_func,\\n\\tprovide_context=True,\\n\\tdag=dag\\n)\\nimport_load_dim_census_g02_task = PythonOperator(\\n\\ttask_id='import_load_dim_census_g02',\\n\\tpython_callable=import_load_dim_census_g02_func,\\n\\tprovide_context=True,\\n\\tdag=dag\\n)\\nimport_load_dim_nsw_lga_code_task = PythonOperator(\\n\\ttask_id='import_load_dim_nsw_lga_code',\\n\\tpython_callable=import_load_dim_nsw_lga_code_func,\\n\\tprovide_context=True,\\n\\tdag=dag\\n)\\nimport_load_dim_nsw_lga_suburb_task = PythonOperator(\\n\\ttask_id='import_load_dim_nsw_lga_suburb_func',\\n\\tpython_callable=import_load_dim_nsw_lga_suburb_func,\\n\\tprovide_context=True,\\n\\tdag=dag\\n)\\nimport_load_listings_task = PythonOperator(\\n\\ttask_id='import_load_listings',\\n\\tpython_callable=import_load_listings_func,\\n\\tprovide_context=True,\\n\\tdag=dag\\n)\\n[import_load_dim_census_g01_task, import_load_dim_census_g02_task, import_load_dim_nsw_lga_code_task, import_load_dim_nsw_lga_suburb_task, import_load_listings_task]\",\n",
       " 'error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\\n\\t  [end of output]\\n  note: This error originates from a subprocess, and is likely not a problem with pip.\\n  ERROR: Failed building wheel for httptools\\nFailed to build httptools\\nERROR: Could not build wheels for httptools, which is required to install pyproject.toml-based projects',\n",
       " 'pip install fastapi[all]',\n",
       " 'def createsubsetsamountthree(self):\\n\\t\\tsubs = []\\n\\t\\tfor i in range (1, 8):\\t\\t\\t  \\n\\t\\t\\tfor j in range (i+1, 9):\\t\\t\\n\\t\\t\\t\\tfor k in range (j+1, 10):   \\n\\t\\t\\t\\t\\ts = set([i, j, k])\\n\\t\\t\\t\\t\\tsubs.append(s)\\n\\t\\treturn subs',\n",
       " '[{1, 2, 3}, {1, 2, 4}, {1, 2, 5}, {1, 2, 6}, {1, 2, 7}, {8, 1, 2}, {1, 2, 9},\\n {1, 3, 4}, {1, 3, 5}, {1, 3, 6}, {1, 3, 7}, {8, 1, 3}, {1, 3, 9},\\n {1, 4, 5}, {1, 4, 6}, {1, 4, 7}, {8, 1, 4}, {1, 4, 9},\\n {1, 5, 6}, {1, 5, 7}, {8, 1, 5}, {1, 5, 9},\\n {1, 6, 7}, {8, 1, 6}, {1, 6, 9},\\n {8, 1, 7}, {1, 9, 7},\\n {8, 1, 9},\\n {2, 3, 4}, {2, 3, 5}, {2, 3, 6}, {2, 3, 7}, {8, 2, 3}, {9, 2, 3},\\n {2, 4, 5}, {2, 4, 6}, {2, 4, 7}, {8, 2, 4}, {9, 2, 4},\\n {2, 5, 6}, {2, 5, 7}, {8, 2, 5}, {9, 2, 5},\\n {2, 6, 7}, {8, 2, 6}, {9, 2, 6},\\n {8, 2, 7}, {9, 2, 7},\\n {8, 9, 2},\\n {3, 4, 5}, {3, 4, 6}, {3, 4, 7}, {8, 3, 4}, {9, 3, 4},\\n {3, 5, 6}, {3, 5, 7}, {8, 3, 5}, {9, 3, 5},\\n {3, 6, 7}, {8, 3, 6}, {9, 3, 6},\\n {8, 3, 7}, {9, 3, 7},\\n {8, 9, 3},\\n {4, 5, 6}, {4, 5, 7}, {8, 4, 5}, {9, 4, 5},\\n {4, 6, 7}, {8, 4, 6}, {9, 4, 6},\\n {8, 4, 7}, {9, 4, 7},\\n {8, 9, 4},\\n {5, 6, 7}, {8, 5, 6}, {9, 5, 6},\\n {8, 5, 7}, {9, 5, 7},\\n {8, 9, 5},\\n {8, 6, 7}, {9, 6, 7},\\n {8, 9, 6},\\n {8, 9, 7}]',\n",
       " \"if __name__ == '__main__':\\n\\timport csv\\n\\tfrom moviepy.tools import cvsecs\\n\\tfrom yt_dlp import YoutubeDL\\n\\timport os\\n\\timport moviepy.editor as mpe\\n\\tfrom src.config.dev_config import download_video_location, temp_folder_path, csv_path\\n\\tfrom src.services.videos.double_video import process_split_video\\n\\tfrom src.services.videos.video import write_video_to_file\\n\\tfrom pytube import extract\\n\\tcsv_set = set()\\n\\twith open(csv_path, 'r', newline='', encoding='utf-8') as csv_file:\\n\\t\\tcsv_reader = csv.reader(csv_file, delimiter=';')\\n\\t\\theader = next(csv_reader)\\n\\t\\tfor row in csv_reader:\\n\\t\\t\\turl, start_time = row\\n\\t\\t\\turl_id = extract.video_id(url)\\n\\t\\t\\tstart_time = int(cvsecs(start_time))\\n\\t\\t\\tname = f&quot;{str(url_id)}_{str(start_time)}&quot;\\n\\t\\t\\tcsv_set.add(name)\\n\\tstorage_set = set()\\n\\tfor filename in os.listdir(download_video_location):\\n\\t\\tname = filename.split(&quot;.&quot;)[0]\\n\\t\\tstorage_set.add(name)\\n\\tvideos_to_download = csv_set - storage_set\\n\\tvideos_to_delete = storage_set - csv_set\\n\\tfor video in videos_to_download:\\n\\t\\tvideo_start = int(video.split(&quot;_&quot;)[-1])\\n\\t\\tvideo_id = &quot;_&quot;.join(video.rsplit(&quot;_&quot;, 1)[:-1])\\n\\t\\tvideo_url = f&quot;https://www.youtube.com/watch?v={video_id}&quot;\\n\\t\\tparams = {\\n\\t\\t\\t&quot;outtmpl&quot;: os.path.join(temp_folder_path, f&quot;%(id)s.%(ext)s&quot;),\\n\\t\\t\\t&quot;format_sort&quot;: [f&quot;res:720&quot;],\\n\\t\\t\\t&quot;format&quot;: &quot;bv&quot;,\\n\\t\\t\\t&quot;noplaylist&quot;: True,\\n\\t\\t}\\n\\t\\twith YoutubeDL(params) as ydl:\\n\\t\\t\\tinfo = ydl.extract_info(video_url, download=True)\\n\\t\\t\\tpath = ydl.prepare_filename(info)\\n\\t\\tclip = mpe.VideoFileClip(path).without_audio()\\n\\t\\tclip = process_split_video(clip)\\n\\t\\tsubclip = clip.subclip(video_start, video_start + 60)\\n\\t\\twrite_video_to_file(subclip, f&quot;{video_id}_{video_start}&quot;)\\n\\t\\tclip.close()\\n\\t\\tclip = None\\n\\tfor video in videos_to_delete:\\n\\t\\tfile_to_delete = [file for file in os.listdir(download_video_location) if file.startswith(video)]\\n\\t\\tif file_to_delete:\\n\\t\\t\\tfile_to_delete = file_to_delete[0]\\n\\t\\t\\tfilepath_to_delete = os.path.join(download_video_location, file_to_delete)\\n\\t\\t\\ttry:\\n\\t\\t\\t\\tos.remove(filepath_to_delete)\\n\\t\\t\\t\\tprint(f&quot;File {file_to_delete} deleted successfully.&quot;)\\n\\t\\t\\t\\tbreak\\n\\t\\t\\texcept Exception as e:\\n\\t\\t\\t\\tprint(f&quot;Error deleting file {file_to_delete}: {str(e)}&quot;)\",\n",
       " \"Error deleting file n_Dv4JMiwK8_178.mp4: [WinError 32] Процесс не может получить доступ к файлу, так как этот файл занят другим процессом: 'C:\\\\\\\\Users\\\\\\\\nikita_turda\\\\\\\\PycharmProjects\\\\\\\\job\\\\\\\\storage\\\\\\\\n_Dv4JMiwK8_178.mp4'\",\n",
       " '\\tfor video in videos_to_download:\\n\\t\\tvideo_start = int(video.split(&quot;_&quot;)[-1])\\n\\t\\tvideo_id = &quot;_&quot;.join(video.rsplit(&quot;_&quot;, 1)[:-1])\\n\\t\\tvideo_url = f&quot;https://www.youtube.com/watch?v={video_id}&quot;\\n\\t\\tparams = {\\n\\t\\t\\t&quot;outtmpl&quot;: os.path.join(temp_folder_path, f&quot;%(id)s.%(ext)s&quot;),\\n\\t\\t\\t&quot;format_sort&quot;: [f&quot;res:720&quot;],\\n\\t\\t\\t&quot;format&quot;: &quot;bv&quot;,\\n\\t\\t\\t&quot;noplaylist&quot;: True,\\n\\t\\t}\\n\\t\\twith YoutubeDL(params) as ydl:\\n\\t\\t\\tinfo = ydl.extract_info(video_url, download=True)\\n\\t\\t\\tpath = ydl.prepare_filename(info)\\n\\t\\tclip = mpe.VideoFileClip(path).without_audio()\\n\\t\\tclip = process_split_video(clip)\\n\\t\\tsubclip = clip.subclip(video_start, video_start + 60)\\n\\t\\twrite_video_to_file(subclip, f&quot;{video_id}_{video_start}&quot;)\\n\\t\\tclip.close()\\n\\t\\tclip = None',\n",
       " 'def process_split_video(clip, strict_size: bool = True):\\n\\tresult = video.crop_to_ratio(clip, (9, 8))\\n\\tresult = video.resize_height(result, 1920 / 2, strict_size=strict_size)\\n\\treturn result',\n",
       " 'def write_video_to_file(clip, name_without_extension):\\n\\toutput_path = dev_config.video_output_path\\n\\tos.makedirs(output_path, exist_ok=True)\\n\\tclip.write_videofile(f&quot;{output_path}/{name_without_extension}.mp4&quot;)',\n",
       " \"import pyqtgraph as pg\\nfrom pyqtgraph.Qt import QtCore, QtGui\\nimport numpy as np\\nwindow = pg.plot()\\ntitle = &quot;GeeksforGeeks PyQtGraph&quot;\\nwindow.setWindowTitle(title)\\ny1 = [5, 5, 7, 10, 3, 8, 9, 1, 6, 2]\\nx = [1, 10, 4, 5, 7, 3, 6, 8, 9, 2]\\nbargraph1 = pg.BarGraphItem(x = x, height = y1, width = 0.6, brush ='g')\\nwindow.addItem(bargraph1)\\nif __name__ == '__main__':\\n\\timport sys\\n\\tif (sys.flags.interactive != 1) or not hasattr(QtCore, 'PYQT_VERSION'):\\n\\t\\tQtGui.QApplication.instance().exec_()\",\n",
       " 'TypeError: Column is not iterable',\n",
       " 'from pyspark.sql import SparkSession\\nimport pyspark.sql.functions as F\\nspark: SparkSession = SparkSession.builder.appName(&quot;&quot;).getOrCreate()\\ndf1 = spark.createDataFrame(\\n\\t[\\n\\t\\t(1, &quot;123-xy&quot;, &quot;Description 1&quot;),\\n\\t\\t(1, &quot;234-zb&quot;, &quot;Description 2&quot;),\\n\\t\\t(2, &quot;444-xa&quot;, &quot;Description 3&quot;),\\n\\t],\\n\\tschema=[&quot;commodity&quot;, &quot;material&quot;, &quot;description&quot;],\\n)\\ndf1 = df1.withColumn(&quot;material_formatted&quot;, F.substring(&quot;material&quot;, 1, F.length(&quot;material&quot;) - 3))\\ndf1.show()',\n",
       " \"df1 = df1.withColumn(&quot;material_formatted&quot;, F.expr('substring(material, 1, length(material) - 3)'))\",\n",
       " 'df1 = df1.withColumn(&quot;material_formatted&quot;, F.substring(&quot;material&quot;, 1, 3))',\n",
       " \"from collections import Counter\\nimport re\\nexclude_words = ['in', 'for', 'and', 'the', 'price']\\ndef extract_words(text):\\n\\twords = re.findall(r'\\\\w+', text.lower())\\n\\treturn (words, [word for word in words if word not in exclude_words and word.isalpha()])\\ndef count_and_write_lines(text, filename):\\n\\tall_words, filtered_words = extract_words(text)\\n\\tword_counts = Counter(filtered_words)\\n\\tsorted_words = sorted(word_counts.items(), key=lambda item: item[1])\\n\\tlines = text.split('\\\\n')\\n\\twith open(filename, 'w') as output_file:\\n\\t\\tfor word, count in sorted_words:\\n\\t\\t\\tif word:\\n\\t\\t\\t\\tlines_with_word = []\\n\\t\\t\\t\\tfor line in lines:\\n\\t\\t\\t\\t\\tif re.search(rf'\\\\b{word}\\\\b', line.lower()):\\n\\t\\t\\t\\t\\t\\tlines_with_word.append(line.strip())\\n\\t\\t\\t\\t\\t\\tlines.remove(line)\\n\\t\\t\\t\\tif len(lines_with_word) &gt;= 5:\\n\\t\\t\\t\\t\\toutput_file.write(f'Common word: {word}\\\\n\\\\n')\\n\\t\\t\\t\\t\\tfor line in lines_with_word:\\n\\t\\t\\t\\t\\t\\toutput_file.write(line + '\\\\n')\\n\\t\\t\\t\\t\\toutput_file.write('\\\\n' * 2)\\n\\t\\toutput_file.write('Lines without common words:\\\\n\\\\n')\\n\\t\\tfor line in lines:\\n\\t\\t\\toutput_file.write(line + '\\\\n')\\nif __name__ == '__main__':\\n\\twith open('C:/Users/Oluwa/Desktop/python_work/My Programs/file.txt', 'r') as input_file:\\n\\t\\tcontent = input_file.read()\\n\\tcount_and_write_lines(content, 'C:/Users/Oluwa/Desktop/python_work/My Programs/common_words.txt')\",\n",
       " 'Used Toyota Corolla Zambezi\\nUsed Toyota Corolla Zr\\nUsed Toyota Highlander Vs Honda Pilot\\nUsed Toyota Hilux\\nUsed Toyota Hilux For Sale\\nUsed Toyota Hilux Price In Nigeria\\nUsed Toyota Hilux Za\\nUsed Toyota Hilux Zambia\\nUsed Toyota Hilux Zimbabwe\\nUsed Toyota Jeep\\nUsed Toyota Jeep For Sale In Nigeria\\nUsed Toyota Jeep For Sale In Lagos Nigeria\\nUsed Toyota Land Cruiser',\n",
       " \"current_date = datetime.datetime.now().strftime('%Y%m%d')\\nlogfilename = f'UAW_BCBS_log_{current_date}.log'\\nlogfilepath= os.path.join(mapping_filepath, logfilename)\\nlog = loggersetup(__name__,logfilepath)\\nimport logging\\nimport logging.handlers\\ndef loggersetup(modulename,log_file_name):\\n\\t<str>\\n\\tlogger = logging.getLogger(modulename)\\n\\tlogger.setLevel(logging.INFO)\\n\\tformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\\n\\tfile_handler = logging.FileHandler(log_file_name)\\n\\tfile_handler.setLevel(logging.INFO)\\n\\tfile_handler.setFormatter(formatter)\\n\\tstream_handler = logging.StreamHandler()\\n\\tstream_handler.setLevel(logging.INFO)\\n\\tstream_handler.setFormatter(formatter)\\n\\tif (logger.hasHandlers()):\\n\\t\\tlogger.handlers.clear()\\n\\tlogger.addHandler(file_handler)\\n\\tlogger.addHandler(stream_handler)\\n\\treturn logger\\nif __name__== &quot;__main__&quot;:\\n   start_time = time.time()\\n   log.info('{} PROGRAM START {}'.format('********************', '**********************'))\\n   username = os.getenv(&quot;USERNAME&quot;) \\n   log.info('User is {}'.format(username))\\n   ouputpath = main_controlChecks() \\n   end_time = time.time()\\n   log.info('Execution time is %s seconds', (end_time - start_time))\\n   log.info('{} PROGRAM END {}'.format('********************', '**********************'))\\n   if (log.hasHandlers()):\\n\\t\\tlog.handlers.clear()\\n   del log\\n   finallogfilepath= os.path.join(ouputpath, logfilename)\\n   shutil.move(logfilepath, finallogfilepath)\",\n",
       " 'os.startfile',\n",
       " \"import socket\\ns = socket.socket()\\nip=input(&quot;IP: &quot;)\\nport=input(&quot;Port: &quot;)\\ns.connect((ip,int(port)))\\nprint(&quot;Connected!&quot;)\\nwhile True:\\n\\trecv=str(s.recv(2048).decode())\\n\\tif recv.replace(&quot; &quot;, '')=='':pass\\n\\telse:print(recv)\",\n",
       " 'for document in client1.stream_documents():\\n  client2.update_document(document)',\n",
       " 'client1',\n",
       " 'client2',\n",
       " 'requests.Session',\n",
       " 'class Client:\\n\\tdef __init__(self):\\n\\t\\tself.session = requests.Session()',\n",
       " 'stream_documents',\n",
       " 'response = self.session.request(... stream=True ...)',\n",
       " \"for line in response.iter_lines():\\n\\tyield json.loads(line.decode('utf-8'))\",\n",
       " 'update_document',\n",
       " 'for document in list(client1.stream_documents()): \\n  client2.update_document(document)',\n",
       " 'requests.request',\n",
       " 'Session',\n",
       " \"query = <str>\\ndf = sqldf(query)\\nfig = px.scatter_geo(df, locations=&quot;state&quot;, locationmode='USA-states', scope=&quot;usa&quot;, size=&quot;rich_pop&quot;, color='count')\\nfig.show()\",\n",
       " 'class JobGateway(ABC):\\n\\t@abstractmethod\\n\\tdef get_by_id(self, id: str):\\n\\t\\tpass\\nclass JobGatewayImpl(JobGateway):\\n\\t@inject.autoparams()\\n\\tdef __init__(self, db: Database):\\n\\t\\tself.collection = db[&quot;jobs&quot;]\\n\\tdef get_by_id(self, id: str):\\n\\t\\tdata = self.collection.find_one({&quot;_id&quot;: ObjectId(id)})\\n\\t\\tif data is None:\\n\\t\\t\\treturn None\\n\\t\\treturn data\\nclass MessageProcessor:\\n\\t@inject.autoparams()\\n\\tdef __init__(\\n\\t\\tself,\\n\\t\\tjob_gateway: JobGateway\\n\\t) -&gt; None:\\n\\t\\tself.job_gateway = job_gateway\\n\\tdef run(self, id):\\n\\t\\tjob = self.job_gateway.get_by_id(id)',\n",
       " 'binder.bind_to_constructor(JobGateway, lambda: inject.instance(JobGatewayImpl))',\n",
       " 'processor: MessageProcessor = inject.instance(MessageProcessor)',\n",
       " 'j2: JobGateway = inject.instance(JobGateway)',\n",
       " 'processor: MessageProcessor = inject.instance(MessageProcessor)',\n",
       " \"from selenium import webdriver\\nfrom selenium.webdriver.chrome.service import Service\\nfrom selenium.webdriver.common.by import By\\nurls = ['https://www.techwithtim.net/']\\ncService = webdriver.ChromeService(executable_path='/Users/mac/Downloads/chromedriver-mac-arm64/chromedriver')\\nfor url in urls:\\ndriver = webdriver.Chrome(service=cService)\\ndriver.get(url)\",\n",
       " 'my_package\\n|\\n├── config\\n│   ├── config.yaml\\n└── main.py',\n",
       " 'main.py',\n",
       " \"import hydra\\n@hydra.main(version_base=None, config_path=&quot;conf&quot;, config_name=&quot;config&quot;)\\ndef main(cfg: DictConfig):\\n\\tprint('hello!')\\nif __name__ == '__main__':\\n\\tmain()\",\n",
       " 'python main.py',\n",
       " \"import my_package\\nimport os\\nfrom importlib.resources import files\\nfrom omegaconf import OmegaConf\\ncfg = OmegaConf.load(os.path.join(files(&quot;my_package&quot;), 'conf', 'config.yaml'))\\nmy_package.main(cfg)\",\n",
       " 'UnsupportedInterpolationType: Unsupported interpolation type hydra',\n",
       " '@hydra.main',\n",
       " 'conf',\n",
       " \"while True:\\n\\tret, frame = cap.read()\\n\\tif not ret:\\n\\t\\tbreak\\n\\tprocessed_frame = some_processing_function(frame)\\n\\tcv2.putText(processed_frame, text_gen, (x1, y1-10), cv2.FONT_HERSHEY_DUPLEX, 0.5, color, 1)\\n\\tcv2.imshow('Processed Stream', processed_frame)\\n\\tif cv2.waitKey(1) &amp; 0xFF == ord('q'):\\n\\t\\tbreak\",\n",
       " 'selenium.common.exceptions.InvalidArgumentException: Message: invalid argument: cannot parse capability: goog:chromeOptions\\nfrom invalid argument: unrecognized chrome option: mobileEmulation',\n",
       " 'from selenium import webdriver\\nfrom selenium.webdriver.chrome.service import Service\\nmobile_emulation = {&quot;deviceMetrics&quot;: {&quot;width&quot;: 1920, &quot;height&quot;: 1080, &quot;pixelRatio&quot;: 1.0}}\\nchrome_options = webdriver.ChromeOptions()\\nchrome_options.add_experimental_option(&quot;mobileEmulation&quot;, mobile_emulation)\\nchrome_options.debugger_address = &quot;127.0.0.1:9222&quot;\\ns = Service(executable_path=&quot;chromedriver.exe&quot;)\\ndriver = webdriver.Chrome(service=s, options=chrome_options)\\ndriver.get(&quot;https://www.bing.com/&quot;)\\ndriver.save_screenshot(&quot;screenshot.png&quot;)',\n",
       " \"import gym\\nimport numpy as np\\nfrom gym import wrappers\\nif __name__ == '__main__':\\n\\tenv = gym.make('InvertedPendulumBulletEnv-v0')\\n\\tagent = Agent(input_dims=env.observation_space.shape, env=env,\\n\\t\\t\\tn_actions=env.action_space.shape[0])\\n\\tn_games = 250\\n\\tfilename = 'inverted_pendulum.png'\\n\\tfigure_file = 'plots/' + filename\\n\\tbest_score = env.reward_range[0]\\n\\tscore_history = []\\n\\tload_checkpoint = False\\n\\tif load_checkpoint:\\n\\t\\tagent.load_models()\\n\\t\\tenv.render(mode='human')\\n\\tfor i in range(n_games):\\n\\t\\tobservation = env.reset()\\n\\t\\tdone = False\\n\\t\\tscore = 0\\n\\t\\twhile not done:\\n\\t\\t\\taction = agent.choose_action(observation)\\n\\t\\t\\tobservation_, reward, done, info = env.step(action)\\n\\t\\t\\tscore += reward\\n\\t\\t\\tagent.remember(observation, action, reward, observation_, done)\\n\\t\\t\\tif not load_checkpoint:\\n\\t\\t\\t\\tagent.learn()\\n\\t\\t\\tobservation = observation_\\n\\t\\tscore_history.append(score)\\n\\t\\tavg_score = np.mean(score_history[-100:])\\n\\t\\tif avg_score &gt; best_score:\\n\\t\\t\\tbest_score = avg_score\\n\\t\\t\\tif not load_checkpoint:\\n\\t\\t\\t\\tagent.save_models()\\n\\t\\tprint('episode ', i, 'score %.1f' % score, 'avg_score %.1f' % avg_score)\\n\\tif not load_checkpoint:\\n\\t\\tx = [i+1 for i in range(n_games)]\\n\\t\\tplot_learning_curve(x, score_history, figure_file)\",\n",
       " \"Cell In[20], line 1\\n----&gt; 1 import pybullet_envs\\n\\t  2 import gym\\n\\t  3 import numpy as np\\nFile ~\\\\anaconda3\\\\lib\\\\site-packages\\\\pybullet_envs\\\\__init__.py:14\\n\\t  9\\t return gym.envs.registration.register(id, *args, **kvargs)\\n\\t 12 \\n---&gt; 14 register(\\n\\t 15\\t id='HumanoidDeepMimicBackflipBulletEnv-v1',\\n\\t 16\\t entry_point='pybullet_envs.deep_mimic.gym_env:HumanoidDeepMimicBackflipBulletEnv',\\n\\t 17\\t max_episode_steps=2000,\\n\\t 18\\t reward_threshold=2000.0,\\n\\t 19 )\\n\\t 21 register(\\n\\t 22\\t id='HumanoidDeepMimicWalkBulletEnv-v1',\\n\\t 23\\t entry_point='pybullet_envs.deep_mimic.gym_env:HumanoidDeepMimicWalkBulletEnv',\\n\\t 24\\t max_episode_steps=2000,\\n\\t 25\\t reward_threshold=2000.0,\\n\\t 26 )\\n\\t 28 register(\\n\\t 29\\t id='CartPoleBulletEnv-v1',\\n\\t 30\\t entry_point='pybullet_envs.bullet:CartPoleBulletEnv',\\n\\t 31\\t max_episode_steps=200,\\n\\t 32\\t reward_threshold=190.0,\\n\\t 33 )\\nFile ~\\\\anaconda3\\\\lib\\\\site-packages\\\\pybullet_envs\\\\__init__.py:6, in register(id, *args, **kvargs)\\n\\t  5 def register(id, *args, **kvargs):\\n----&gt; 6   if id in registry.env_specs:\\n\\t  7\\t return\\n\\t  8   else:\\nAttributeError: 'dict' object has no attribute 'env_specs'\",\n",
       " 'y = [1.79 1.79 1.79 1.79 1.79 2.12 2.12 2.12 2.61 2.61 2.61 3.09 3.09 3.09\\n3.26 3.26 3.26 3.26 3.26 4.07 4.07 4.07 4.07 4.07 2.93 2.93 2.93 2.93\\n2.93 2.28 2.28 2.28 2.28 2.28 3.26 3.26 3.26 3.26 2.28 2.28 2.28 2.28\\n2.61 2.61 2.61 2.61 2.61 4.07 4.07 4.07 4.07 4.07]\\nx = [[3.51714000e-05 1.41935534e+00 3.41061326e-02 1.85240055e-01]\\n[3.71250000e-05 1.45824179e+00 3.55173112e-02 1.90315125e-01]\\n[1.48500000e-04 2.91648357e+00 3.09101928e-02 3.60360000e-02]\\n[7.27650000e-05 2.04153850e+00 4.34470222e-02 1.45297152e-01]\\n[8.57736000e-05 2.21652751e+00 4.71031486e-02 1.44879134e-01]\\n[3.14226000e-05 1.34158244e+00 3.61634395e-02 2.33107875e-01]\\n[7.00194000e-05 2.00265205e+00 5.27645109e-02 2.22702480e-01]\\n[1.22073600e-04 2.64427844e+00 5.33707349e-02 1.30690560e-01]\\n[7.55634000e-05 2.08042495e+00 6.98347784e-02 3.61486125e-01]\\n[2.53704000e-05 1.20547988e+00 3.77841965e-02 3.15175661e-01]\\n[1.25690400e-04 2.68316488e+00 7.84190007e-02 2.74031257e-01]\\n[1.72142850e-04 3.14008064e+00 8.63303743e-02 2.42492250e-01]\\n[6.60000000e-05 1.94432238e+00 7.36110279e-02 4.59834375e-01]\\n[1.05600000e-05 7.77728952e-01 2.34108672e-02 2.90690400e-01]\\n[2.65038400e-04 3.72052961e+00 2.84183419e-02 1.70666496e-02]\\n[1.00000000e-04 2.28533760e+00 1.00327169e-01 5.63763200e-01]\\n[1.82790400e-04 3.08977644e+00 1.11120098e-01 3.78348006e-01]\\n[6.40000000e-05 1.82827008e+00 8.15775894e-02 5.82400000e-01]\\n[2.93094400e-04 3.91249797e+00 5.61842009e-02 6.03226624e-02]\\n[1.32710400e-04 2.63270892e+00 1.40966074e-01 8.38656000e-01]\\n[2.38393600e-04 3.52856125e+00 1.46548587e-01 5.04577965e-01]\\n[1.80633600e-04 3.07149373e+00 1.50991923e-01 7.06917120e-01]\\n[5.95984000e-05 1.76428063e+00 8.89323315e-02 7.43266160e-01]\\n[6.14656000e-05 1.79170468e+00 8.70567934e-02 6.90609920e-01]\\n[7.46496000e-05 1.97453169e+00 6.63811096e-02 3.30613920e-01]\\n[1.93766400e-04 3.18118994e+00 7.48953288e-02 1.62140160e-01]\\n[5.65504000e-05 1.71857388e+00 6.24513649e-02 3.86284954e-01]\\n[1.00000000e-04 2.28533760e+00 9.12065177e-02 4.65920000e-01]\\n[1.74240000e-04 3.01664563e+00 6.05152495e-02 1.17717600e-01]\\n[9.21600000e-05 2.19392410e+00 6.97037420e-02 2.95276800e-01]\\n[8.76096000e-05 2.13907599e+00 5.57498137e-02 1.98698573e-01]\\n[5.18400000e-05 1.64544307e+00 5.36321685e-02 3.10774464e-01]\\n[1.76358400e-04 3.03492833e+00 2.44264884e-02 1.89489664e-02]\\n[1.32710400e-04 2.63270892e+00 5.63864298e-02 1.34184960e-01]\\n[2.63737600e-04 3.71138826e+00 4.24705055e-02 3.83056128e-02]\\n[6.65856000e-05 1.86483548e+00 7.47930308e-02 4.70545421e-01]\\n[1.36422400e-04 2.66927432e+00 9.71413029e-02 3.87419760e-01]\\n[1.90440000e-04 3.15376589e+00 9.05629575e-02 2.41214064e-01]\\n[7.32736000e-05 1.95624899e+00 5.50777727e-02 2.31880813e-01]\\n[1.48840000e-04 2.78811187e+00 6.14519438e-02 1.42105600e-01]\\n[6.56100000e-05 1.85112346e+00 5.56849993e-02 2.64707352e-01]\\n[1.00000000e-04 2.28533760e+00 6.61247253e-02 2.44899200e-01]\\n[1.44000000e-04 2.74240512e+00 7.86804907e-02 2.40786000e-01]\\n[5.71536000e-05 1.72771523e+00 5.62056331e-02 3.09582000e-01]\\n[8.46400000e-05 2.10251059e+00 7.04231859e-02 3.28182400e-01]\\n[1.11513600e-04 2.41331651e+00 7.85607263e-02 3.09986477e-01]\\n[1.98246400e-04 3.21775534e+00 4.19046821e-02 4.96111616e-02]\\n[2.31040000e-04 3.47371315e+00 1.33530749e-01 4.32250000e-01]\\n[1.10670400e-04 2.40417516e+00 1.23015404e-01 7.65856000e-01]\\n[1.40185600e-04 2.70583972e+00 1.35129842e-01 7.29556173e-01]\\n[6.40000000e-05 1.82827008e+00 8.56564689e-02 6.42096000e-01]\\n[6.72400000e-05 1.87397683e+00 9.10049741e-02 6.89861900e-01]\\n[1.71500000e-04 2.44959624e+00 9.58437919e-02 3.00001520e-01]\\n[1.36281600e-04 2.18364008e+00 8.69252274e-02 3.10537500e-01]\\n[7.79744000e-05 1.65172775e+00 8.23463666e-02 4.87075680e-01]\\n[1.57304000e-05 7.41877718e-01 2.89189170e-02 2.97772020e-01]\\n[4.23864000e-05 1.21779927e+00 5.96616176e-02 4.70352137e-01]\\n[8.61056000e-05 1.73571391e+00 4.13962250e-02 1.11467866e-01]\\n[1.50617600e-04 2.29562162e+00 4.12265874e-02 6.32031400e-02]\\n[4.89566000e-05 1.30878428e+00 3.87210912e-02 1.71531360e-01]\\n[1.69400000e-05 7.69873104e-01 1.95073267e-02 1.25817692e-01]\\n[4.73984000e-05 1.28778774e+00 2.51953649e-02 7.50131200e-02]\\n[1.63296000e-05 7.55875411e-01 1.47289879e-02 7.44097536e-02]\\n[7.93016000e-05 1.66572544e+00 2.87250674e-02 5.82773464e-02]\\n[2.98424000e-05 1.02183157e+00 2.22604129e-02 9.30020000e-02]\\n[5.82624000e-05 1.42776467e+00 5.29433813e-02 2.69460173e-01]\\n[9.75744000e-05 1.84769545e+00 4.54662471e-02 1.18659341e-01]\\n[7.60046000e-05 1.63073121e+00 7.18055141e-02 3.79957760e-01]\\n[1.14514400e-04 2.00167007e+00 7.62891883e-02 2.84659375e-01]\\n[3.32024000e-05 1.07782235e+00 4.09952873e-02 2.83503220e-01]\\n[3.58400000e-05 1.11981542e+00 4.08605199e-02 2.60915200e-01]\\n[1.40000000e-05 6.99884640e-01 2.27131012e-02 2.06388000e-01]\\n[4.14176000e-05 1.20380158e+00 2.04941117e-02 5.67979776e-02]\\n[6.29216000e-05 1.48375544e+00 1.55800094e-02 2.16070400e-02]\\n[3.23456000e-05 1.06382465e+00 1.46609125e-02 3.72191456e-02]\\n[2.36600000e-05 9.09850032e-01 1.49626648e-02 5.29984000e-02]]',\n",
       " 'reg = LinearRegression(positive = True, fit_intercept = False).fit(x, y)\\npopt = reg.coef_',\n",
       " '[0.\\t\\t 0.71429347 0.\\t\\t 3.62406594]',\n",
       " 'ChildType',\n",
       " \"class Parent(Base):\\n\\t...\\n\\tid\\t\\t  : Mapped[int]\\n\\ttype\\t\\t: Mapped[str]\\n\\tchild_type_a: Mapped['ChildTypeA | None'] = relationship(uselist=False)\\n\\tchild_type_b: Mapped['ChildTypeB | None'] = relationship(uselist=False)\\n\\tchild_type_c: Mapped['ChildTypeC | None'] = relationship(uselist=False)\\nclass ChildTypeA/B/C(Base):\\n\\tid\\t   : Mapped[int]\\n\\tparent_id: Mapped[int]\\t  = mapped_column(BigIntegerType, ForeignKey('parent_table.id'))\\n\\tparent   : Mapped['Parent'] = relationship(back_populates=&quot;child_type_a/b/c&quot;)\",\n",
       " 'Parent',\n",
       " 'Parent',\n",
       " 'ChildType',\n",
       " 'select(Parent)\\n.join(ChildTypeA, ChildTypeA.parent_id == Parent.id)\\n.join(ChildTypeB, ChildTypeB.parent_id == Parent.id)\\n.join(ChildTypeC, ChildTypeC.parent_id == Parent.id)\\n.options(\\n\\tcontains_eager(Parent.child_type_a),\\n\\tcontains_eager(Parent.child_type_b),\\n\\tcontains_eager(Parent.child_type_c),\\n)',\n",
       " 'Parent',\n",
       " 'Parent.type',\n",
       " 'from bs4 import BeautifulSoup\\nurl = &quot;https://www.bvb.de/Spiele/Alle-Spiele&quot;\\nsoup = BeautifulSoup(requests.get(url).content, &quot;html.parser&quot;)\\ntable = soup.select(&quot;table.statistics&quot;)\\nfor row in soup.select(&quot;tr:has(td)&quot;):\\n\\ttds = [td.get_text(strip=True, separator=&quot; &quot;) for td in row.select(&quot;td&quot;)]\\n\\tif len(tds) &gt; 2:\\n\\t\\tteam1, team2 = tds[1], tds[2]\\n\\t\\tdate = tds[0]\\n\\t\\topponent1 = tds[1]\\n\\t\\topponent2 = tds[2]\\n\\t\\tscore = tds[3]\\n\\t\\tprint(score)',\n",
       " 'def infinity_thread_function():\\n\\tstatus, res = OSHelperClass.execute(&quot;infinity command&quot;) \\ndef thread_starter():\\n\\tthread_player = threading.Thread(target=infinity_thread_function, daemon=True)\\nthread_starter()',\n",
       " \"board = [['bR', 'bN', 'bB', 'bQ', 'bK', 'bB', 'bN', 'bR'],\\n\\t\\t ['bp', 'bp', 'bp', 'bp', 'bp', 'bp', 'bp', 'bp'],\\n\\t\\t ['xx', 'xx', 'xx', 'xx', 'xx', 'xx', 'xx', 'xx'],\\n\\t\\t ['xx', 'xx', 'xx', 'xx', 'xx', 'xx', 'xx', 'xx'],\\n\\t\\t ['xx', 'xx', 'xx', 'xx', 'xx', 'xx', 'xx', 'xx'],\\n\\t\\t ['xx', 'xx', 'xx', 'xx', 'xx', 'xx', 'xx', 'xx'],\\n\\t\\t ['wp', 'wp', 'wp', 'wp', 'wp', 'wp', 'wp', 'wp'],\\n\\t\\t ['wR', 'wN', 'wB', 'wK', 'wQ', 'wB', 'wN', 'wR']]\\ndef get_valid_moves(piece, row, col):\\nglobal board\\nmoves = []\\nif piece == 'wp':\\n\\tif row &gt; 0 and board[row - 1][col] == 'xx':  \\n\\t\\tmoves.append((row - 1, col))\\n\\tif row == 6 and board[row - 1][col] == 'xx' and board[row - 2][col] == 'xx':\\n\\t\\tmoves.append((row - 2, col))\\n\\tif row &gt; 0 and col &gt; 0 and board[row - 1][col - 1][0] == 'b':\\n\\t\\tmoves.append((row - 1, col - 1))\\n\\tif row &gt; 0 and col &lt; 7 and board[row - 1][col + 1][0] == 'b':\\n\\t\\tmoves.append((row - 1, col + 1))\\nelif piece == 'bp':\\n\\tif row &lt; 7 and board[row + 1][col] == 'xx':\\n\\t\\tmoves.append((row + 1, col))\\n\\tif row == 1 and board[row + 1][col] == 'xx' and board[row + 2][col] == 'xx':\\n\\t\\tmoves.append((row + 2, col))\\n\\tif row &lt; 7 and col &gt; 0 and board[row + 1][col - 1][0] == 'w':\\n\\t\\tmoves.append((row + 1, col - 1))\\n\\tif row &lt; 7 and col &lt; 7 and board[row + 1][col + 1][0] == 'w':\\n\\t\\tmoves.append((row + 1, col + 1))\\nelif piece == 'wR' or piece == 'bR':\\n\\tfor c in range(col - 1, -1, -1):\\n\\t\\tif board[row][c] == 'xx':\\n\\t\\t\\tmoves.append((row, c))\\n\\t\\telif board[row][c][0] != piece[0]:\\n\\t\\t\\tmoves.append((row, c))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\n\\tfor c in range(col + 1, 8):\\n\\t\\tif board[row][c] == 'xx':\\n\\t\\t\\tmoves.append((row, c))\\n\\t\\telif board[row][c][0] != piece[0]:\\n\\t\\t\\tmoves.append((row, c))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\n\\tfor r in range(row - 1, -1, -1):\\n\\t\\tif board[r][col] == 'xx':\\n\\t\\t\\tmoves.append((r, col))\\n\\t\\telif board[r][col][0] != piece[0]:\\n\\t\\t\\tmoves.append((r, col))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\n\\tfor r in range(row + 1, 8):\\n\\t\\tif board[r][col] == 'xx':\\n\\t\\t\\tmoves.append((r, col))\\n\\t\\telif board[r][col][0] != piece[0]:\\n\\t\\t\\tmoves.append((r, col))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\nelif piece == 'wB' or piece == 'bB':\\n\\tfor i in range(1, min(8 - row, 8 - col)):\\n\\t\\tif board[row + i][col + i] == 'xx':\\n\\t\\t\\tmoves.append((row + i, col + i))\\n\\t\\telif board[row + i][col + i][0] != piece[0]:\\n\\t\\t\\tmoves.append((row + i, col + i))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\n\\tfor i in range(1, min(8 - row, col + 1)):\\n\\t\\tif board[row + i][col - i] == 'xx':\\n\\t\\t\\tmoves.append((row + i, col - i))\\n\\t\\telif board[row + i][col - i][0] != piece[0]:\\n\\t\\t\\tmoves.append((row + i, col - i))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\n\\tfor i in range(1, min(row + 1, 8 - col)):\\n\\t\\tif board[row - i][col + i] == 'xx':\\n\\t\\t\\tmoves.append((row - i, col + i))\\n\\t\\telif board[row - i][col + i][0] != piece[0]:\\n\\t\\t\\tmoves.append((row - i, col + i))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\n\\tfor i in range(1, min(row + 1, col + 1)):\\n\\t\\tif board[row - i][col - i] == 'xx':\\n\\t\\t\\tmoves.append((row - i, col - i))\\n\\t\\telif board[row - i][col - i][0] != piece[0]:\\n\\t\\t\\tmoves.append((row - i, col - i))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\nelif piece == 'wN' or piece == 'bN':\\n\\tknight_moves = [(-1, -2), (-2, -1), (-2, 1), (-1, 2), (1, -2), (2, -1), (2, 1), (1, 2)]\\n\\tfor move in knight_moves:\\n\\t\\tnew_row = row + move[0]\\n\\t\\tnew_col = col + move[1]\\n\\t\\tif 0 &lt;= new_row &lt; 8 and 0 &lt;= new_col &lt; 8:\\n\\t\\t\\tif board[new_row][new_col] == 'xx' or board[new_row][new_col][0] != piece[0]:\\n\\t\\t\\t\\tmoves.append((new_row, new_col))\\nelif piece == 'wQ' or piece == 'bQ':\\n\\tfor c in range(col - 1, -1, -1):\\n\\t\\tif board[row][c] == 'xx':\\n\\t\\t\\tmoves.append((row, c))\\n\\t\\telif board[row][c][0] != piece[0]:\\n\\t\\t\\tmoves.append((row, c))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\n\\tfor c in range(col + 1, 8):\\n\\t\\tif board[row][c] == 'xx':\\n\\t\\t\\tmoves.append((row, c))\\n\\t\\telif board[row][c][0] != piece[0]:\\n\\t\\t\\tmoves.append((row, c))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\n\\tfor r in range(row - 1, -1, -1):\\n\\t\\tif board[r][col] == 'xx':\\n\\t\\t\\tmoves.append((r, col))\\n\\t\\telif board[r][col][0] != piece[0]:\\n\\t\\t\\tmoves.append((r, col))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\n\\tfor r in range(row + 1, 8):\\n\\t\\tif board[r][col] == 'xx':\\n\\t\\t\\tmoves.append((r, col))\\n\\t\\telif board[r][col][0] != piece[0]:\\n\\t\\t\\tmoves.append((r, col))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\n\\tfor i in range(1, min(8 - row, 8 - col)):\\n\\t\\tif board[row + i][col + i] == 'xx':\\n\\t\\t\\tmoves.append((row + i, col + i))\\n\\t\\telif board[row + i][col + i][0] != piece[0]:\\n\\t\\t\\tmoves.append((row + i, col + i))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\n\\tfor i in range(1, min(8 - row, col + 1)):\\n\\t\\tif board[row + i][col - i] == 'xx':\\n\\t\\t\\tmoves.append((row + i, col - i))\\n\\t\\telif board[row + i][col - i][0] != piece[0]:\\n\\t\\t\\tmoves.append((row + i, col - i))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\n\\tfor i in range(1, min(row + 1, 8 - col)):\\n\\t\\tif board[row - i][col + i] == 'xx':\\n\\t\\t\\tmoves.append((row - i, col + i))\\n\\t\\telif board[row - i][col + i][0] != piece[0]:\\n\\t\\t\\tmoves.append((row - i, col + i))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\n\\tfor i in range(1, min(row + 1, col + 1)):\\n\\t\\tif board[row - i][col - i] == 'xx':\\n\\t\\t\\tmoves.append((row - i, col - i))\\n\\t\\telif board[row - i][col - i][0] != piece[0]:\\n\\t\\t\\tmoves.append((row - i, col - i))\\n\\t\\t\\tbreak\\n\\t\\telse:\\n\\t\\t\\tbreak\\nelif piece == 'wK' or piece == 'bK':\\n\\tking_moves = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\\n\\tfor move in king_moves:\\n\\t\\tnew_row = row + move[0]\\n\\t\\tnew_col = col + move[1]\\n\\t\\tif 0 &lt;= new_row &lt; 8 and 0 &lt;= new_col &lt; 8:\\n\\t\\t\\tif board[new_row][new_col] == 'xx' or board[new_row][new_col][0] != piece[0]:\\n\\t\\t\\t\\tmoves.append((new_row, new_col))\\ndef find_king_coordinates(player_color):\\n\\tfor r in range(8):\\n\\t\\tfor c in range(8):\\n\\t\\t\\tif board[r][c] == f'{player_color}K':\\n\\t\\t\\t\\treturn r, c\\ndef is_check(player_color, king_row, king_col, board):\\n\\tknight_moves = [(1, 2), (2, 1), (-1, -2), (-2, -1), (1, -2), (2, -1), (-1, 2), (-2, 1)]\\n\\tdirections = [(1, 0), (-1, 0), (0, 1), (0, -1), (1, 1), (-1, -1), (1, -1), (-1, 1)]\\n\\tfor dr, dc in knight_moves:\\n\\t\\tif 0 &lt;= king_row + dr &lt; 8 and 0 &lt;= king_col + dc &lt; 8:\\n\\t\\t\\tif board[king_row + dr][king_col + dc] == f'{player_color}N':\\n\\t\\t\\t\\treturn True\\n\\tfor dr, dc in directions[:4]:\\n\\t\\tr, c = king_row + dr, king_col + dc\\n\\t\\twhile 0 &lt;= r &lt; 8 and 0 &lt;= c &lt; 8:\\n\\t\\t\\tpiece = board[r][c]\\n\\t\\t\\tif piece[0] == player_color:\\n\\t\\t\\t\\tbreak\\n\\t\\t\\tif piece == f'{player_color}R' or piece == f'{player_color}Q':\\n\\t\\t\\t\\treturn True\\n\\t\\t\\tif piece != 'xx':\\n\\t\\t\\t\\tbreak\\n\\t\\t\\tr, c = r + dr, c + dc\\n\\tfor dr, dc in directions[4:]:\\n\\t\\tr, c = king_row + dr, king_col + dc\\n\\t\\twhile 0 &lt;= r &lt; 8 and 0 &lt;= c &lt; 8:\\n\\t\\t\\tpiece = board[r][c]\\n\\t\\t\\tif piece[0] == player_color:\\n\\t\\t\\t\\tbreak\\n\\t\\t\\tif piece == f'{player_color}B' or piece == f'{player_color}Q':\\n\\t\\t\\t\\treturn True\\n\\t\\t\\tif piece != 'xx':\\n\\t\\t\\t\\tbreak\\n\\t\\t\\tr, c = r + dr, c + dc\\n\\tpawn_attacks = [(1, 1), (1, -1)] if player_color == 'w' else [(-1, 1), (-1, -1)]\\n\\tfor dr, dc in pawn_attacks:\\n\\t\\tif 0 &lt;= king_row + dr &lt; 8 and 0 &lt;= king_col + dc &lt; 8:\\n\\t\\t\\tif board[king_row + dr][king_col + dc] == f'{player_color}p':\\n\\t\\t\\t\\treturn True\\n\\treturn False  \\nif is_check(piece[0], find_king_coordinates(piece[0]), board):\\n\\ttemp_board = board\\n\\tpass\",\n",
       " \"import pandas as pd\\ncalendar_date = pd.date_range(&quot;2020-01-01&quot;, &quot;2020-01-31&quot;)\\nstock_out_flag = [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\\n\\t   0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.]\\norders = [45., 51., 48., 52., 51., 47., 49., 48., 51., 51., 49., 49., 52.,\\n\\t   47., 51., 55., 51., 48., 49., 53., 50., 52., 51., 48., 51., 53.,\\n\\t   49., 56., 0., 0., 0.]\\ndf =pd.DataFrame.from_dict({'calendar_date':calendar_date, 'stock_out':stock_out_flag,\\n'orders':orders})\\ndf\\ncalendar_date   stock_out   orders\\n0   2020-01-01\\t 0.0  45.0\\n1   2020-01-02\\t 0.0  51.0\\n2   2020-01-03\\t 0.0  48.0\\n3   2020-01-04\\t 0.0  52.0\\n4   2020-01-05\\t 0.0  51.0\\n5   2020-01-06\\t 0.0  47.0\\n6   2020-01-07\\t 0.0  49.0\\n7   2020-01-08\\t 0.0  48.0\\n8   2020-01-09\\t 0.0  51.0\\n9   2020-01-10\\t 0.0  51.0\\n10  2020-01-11\\t 0.0  49.0\\n11  2020-01-12  -  0.0  49.0\\n12  2020-01-13\\t 0.0  52.0\\n13  2020-01-14\\t 0.0  47.0\\n14  2020-01-15\\t 0.0  51.0\\n15  2020-01-16\\t 0.0  55.0\\n16  2020-01-17\\t 0.0  51.0\\n17  2020-01-18\\t 0.0  48.0\\n18  2020-01-19\\t 0.0  49.0\\n19  2020-01-20\\t 0.0  53.0\\n20  2020-01-21\\t 0.0  50.0\\n21  2020-01-22\\t 0.0  52.0\\n22  2020-01-23\\t 0.0  51.0\\n23  2020-01-24\\t 0.0  48.0\\n24  2020-01-25\\t 0.0  51.0\\n25  2020-01-26\\t 0.0  53.0\\n26  2020-01-27\\t 0.0  49.0\\n27  2020-01-28\\t 0.0  56.0\\n28  2020-01-29\\t 1.0  0.0\\n29  2020-01-30\\t 1.0  0.0\\n30  2020-01-31\\t 1.0  0.0\",\n",
       " '56',\n",
       " 'Pandas',\n",
       " 'shift',\n",
       " \"import asyncio\\nimport websockets\\nimport json\\nimport ssl\\nimport certifi\\nimport json\\nimport logging\\nimport time\\nimport hashlib\\nWS_URL = &quot;wss://perpetual.coinex.com/&quot;\\naccess_id = &quot;xxx&quot;\\nsecret_key = &quot;xxx&quot;\\nssl_context = ssl.create_default_context()\\nssl_context.load_verify_locations(certifi.where())\\nasync def ping(conn):\\n\\tparam = {\\n\\t\\t&quot;id&quot;: 1,\\n\\t\\t&quot;method&quot;: &quot;server.ping&quot;,\\n\\t\\t&quot;params&quot;: []\\n\\t}\\n\\twhile True:\\n\\t\\tawait conn.send(json.dumps(param))\\n\\t\\tawait asyncio.sleep(3)\\nasync def authorize(conn):\\n\\tcurrent_time = int(time.time() * 1000)\\n\\tsign_str = f&quot;access_id={access_id}&amp;timestamp={current_time}&amp;secret_key={secret_key}&quot;\\n\\ttoken = hashlib.sha256(sign_str.encode('utf-8')).hexdigest().lower()\\n\\tparam = {\\n\\t\\t&quot;id&quot;: 2,\\n\\t\\t&quot;method&quot;: &quot;server.sign&quot;,\\n\\t\\t&quot;params&quot;: [access_id, token, current_time]\\n\\t}\\n\\tawait conn.send(json.dumps(param))\\n\\tresp = await conn.recv()\\n\\tresult = json.loads(resp)\\n\\treturn result\\nasync def connect_websocket():\\n\\tasync with websockets.connect(WS_URL, ssl=ssl_context) as ws:\\n\\t\\tresult = await authorize(ws)\\n\\t\\tprint(result)\\n\\t\\tasyncio.ensure_future(ping(ws))\\n\\t\\tparam = {\\n\\t\\t\\t&quot;method&quot;: &quot;kline.subscribe&quot;,\\n\\t\\t\\t&quot;params&quot;: [&quot;MKRUSDT&quot;, &quot;30&quot;],\\n\\t\\t\\t&quot;id&quot;: 5\\n\\t\\t}\\n\\t\\tawait ws.send(json.dumps(param))\\n\\t\\tresp = await ws.recv()\\n\\t\\tresult = json.loads(resp)\\n\\t\\tprint(result)\\n\\t\\twhile True:\\n\\t\\t\\tresp = await ws.recv()\\n\\t\\t\\tmsg = json.loads(resp)\\n\\t\\t\\tif msg[&quot;method&quot;] == &quot;kline.update&quot;:\\n\\t\\t\\t\\tprint(msg)\\n\\t\\tawait asyncio.sleep(2)\\nif __name__ == &quot;__main__&quot;:\\n\\tasyncio.run(connect_websocket())\",\n",
       " 'print(train_x.shape,train_y.shape,test_x.shape,test_y.shape)\\n(9219, 7, 7, 12) (9219,) (3951, 7, 7, 12) (3951,)',\n",
       " \"model = Sequential()\\nmodel.add(Conv1D(32, 4, activation='relu', padding='same', input_shape= (-----)))\\nmodel.add(LSTM(32, return_sequences=True))\\nmodel.add(MaxPooling1D(2))\\nmodel.add(Conv1D(16, 8, activation=&quot;relu&quot;, padding='same'))\\nmodel.add(LSTM(64, return_sequences=True))\\nmodel.add(MaxPooling1D(2))\\nmodel.add(Conv1D(16, 8, activation=&quot;relu&quot;, padding='same'))\\nmodel.add(LSTM(128))\\nmodel.add(Dense(3, activation='sigmoid'))\",\n",
       " \"from tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout\\nfrom tensorflow.keras.utils import to_categorical\\nfrom tensorflow.keras.callbacks import LearningRateScheduler\\nfrom tensorflow.keras.layers import BatchNormalization\\nfrom tensorflow.keras.regularizers import l2\\nfrom tensorflow.keras.metrics import Precision, Recall\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers\\nfrom keras.callbacks import ModelCheckpoint\\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nimport pandas as pd\\ndef scheduler(epoch, lr):\\n  if epoch &lt; 360:\\n\\treturn lr\\n  if epoch &gt;360 and epoch &lt;380:\\n\\treturn lr * 0.5\\n  else:\\n\\treturn 0.0001\\nprecision = Precision()\\nrecall = Recall()\\ndef f1_score(y_true, y_pred):\\n\\tp = precision(y_true, y_pred)\\n\\tr = recall(y_true, y_pred)\\n\\treturn 2 * ((p * r) / (p + r + 1e-5))\\nd = {'target': [1, 2, 3, 1, 2, 3, 1, 2, 3, 1], 'feature': [10, 20, 30, 10, 20, 30, 10, 20, 30, 10]}\\ndf = pd.DataFrame(data=d)\\nX = df.drop(columns=['target'])\\ny = df['target']\\nlabel_encoder = LabelEncoder()\\ny_encoded = label_encoder.fit_transform(y)\\ny_onehot = to_categorical(y_encoded)\\nX_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.1, random_state=42)\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\nmodel = Sequential()\\nmodel.add(Dense(1024, input_shape=(X_train_scaled.shape[1],), activation='relu'))\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(512, activation='relu'))\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(256, activation='relu'))\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(128, activation='relu'))\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(64, activation='relu'))\\nmodel.add(Dense(y_onehot.shape[1], activation='softmax'))\\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',  f1_score])\\ncheckpoint = ModelCheckpoint('best_model_test.h5', monitor='val_f1_score', verbose=1, save_best_only=True, mode='max')\\ncallbacks = [LearningRateScheduler(scheduler), checkpoint]\\nhistory_1 = model.fit(X_train_scaled, y_train, epochs=400, batch_size=128, validation_data=(X_test_scaled, y_test), callbacks=callbacks)\",\n",
       " \"import mlflow\\nlogged_model = 'runs:/6db172cf2c0247bb8393287a63e50b20/model'\\nloaded_model = mlflow.pyfunc.load_model(logged_model)\",\n",
       " \"ValueError: Unable to restore custom object of type _tf_keras_metric. Please make sure that any custom layers are included in the `custom_objects` arg when calling `load_model()` and make sure that all layers implement `get_config` and `from_config`.\\n---------------------------------------------------------------------------\\nValueError\\t\\t\\t\\t\\t\\t\\t\\tTraceback (most recent call last)\\nFile &lt;command-1950128807397632&gt;:5\\n\\t  2 logged_model = 'runs:/6db172cf2c0247bb8393287a63e50b20/model'\\n\\t  4 \\n----&gt; 5 loaded_model = mlflow.pyfunc.load_model(logged_model)\\nFile /databricks/python/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:597, in load_model(model_uri, suppress_warnings, dst_path)\\n\\t595 _add_code_from_conf_to_system_path(local_path, conf, code_key=CODE)\\n\\t596 data_path = os.path.join(local_path, conf[DATA]) if (DATA in conf) else local_path\\n--&gt; 597 model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\\n\\t598 predict_fn = conf.get(&quot;predict_fn&quot;, &quot;predict&quot;)\\n\\t599 return PyFuncModel(model_meta=model_meta, model_impl=model_impl, predict_fn=predict_fn)\\nFile /databricks/python/lib/python3.10/site-packages/mlflow/tensorflow/__init__.py:741, in _load_pyfunc(path)\\n\\t739 if K.backend() == &quot;tensorflow&quot;:\\n\\t740\\t K.set_learning_phase(0)\\n--&gt; 741\\t m = _load_keras_model(\\n\\t742\\t\\t path, keras_module=keras_module, save_format=save_format, compile=should_compile\\n\\t743\\t )\\n\\t744\\t return _KerasModelWrapper(m, model_meta.signature)\",\n",
       " \"import numpy as np \\nimport pandas as pd \\nimport cv2\\nimport keras\\nfrom numpy import random\\nimport tensorflow as tf\\nimport tensorflow_datasets as tfds\\nfrom matplotlib import pyplot as plt\\nfrom keras.models import Sequential, Model\\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D\\nfrom keras.layers import MaxPooling2D, BatchNormalization\\nfrom keras.optimizers import SGD\\nfrom keras.utils import np_utils\\nfrom keras.applications import MobileNet, VGG16, ResNet50\\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score\\nfrom sklearn.metrics import classification_report ,confusion_matrix\\nfrom keras.preprocessing.image import ImageDataGenerator\\nfrom sklearn.model_selection import train_test_split\\nimport seaborn as sns\\nimport tensorflow_hub as hub\\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\\nfrom tensorflow.keras.models import Model\\nimport os\\nimport zipfile\\nwith zipfile.ZipFile('/content/drive/MyDrive/lungcancer.zip', 'r') as zip_ref:\\n\\tzip_ref.extractall('/content/')\\n!pip install tensorflow tensorflow_hub\\n!ls\\ndata_dir = '/content/Data'\\ntrain_dir = data_dir + '/train'\\nvalidation_dir = data_dir + '/valid'\\ntest_dir = data_dir + '/test'\\nlistImageFilePaths = []\\nfor dirname, _, filenames in os.walk('/content/Data/test/normal'):\\n\\tfor filename in filenames:\\n\\t\\tlistImageFilePaths.append( os.path.join(dirname, filename))\\nprint('Total images ', len(listImageFilePaths))\\ninput_shape = (224,224,3)\\ntrain_datagen = ImageDataGenerator(\\n   dtype='float32',\\n\\tpreprocessing_function=preprocess_input,\\n  rotation_range=10,\\n   width_shift_range=0.2,\\n   height_shift_range=0.2,\\n   shear_range=0.2,\\n  zoom_range=0.2,\\n   horizontal_flip=True,\\n\\tvertical_flip=False\\n)\\nval_datagen = ImageDataGenerator(\\n   dtype='float32',\\n   preprocessing_function=preprocess_input,\\n)\\ntest_datagen = ImageDataGenerator(\\n   dtype='float32',\\n\\tpreprocessing_function=preprocess_input,\\n)\\ntrain_generator = train_datagen.flow_from_directory(\\n\\ttrain_dir,\\n\\ttarget_size=(224,224),\\n\\tbatch_size=32,\\n\\tclass_mode='categorical',\\n)\\ntest_generator = test_datagen.flow_from_directory(\\n\\ttest_dir,\\n\\ttarget_size=(224,224),\\n\\tbatch_size=32,\\n\\tclass_mode='categorical',\\n\\tshuffle = False,\\n)\\nvalidation_generator = val_datagen.flow_from_directory(\\n\\tvalidation_dir,\\n\\ttarget_size=(224,224),\\n\\tbatch_size=32,\\n\\tclass_mode='categorical',\\n)\\nfeature_extractor = hub.KerasLayer(&quot;https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5&quot;, trainable=False)\\ninput_layer = tf.keras.layers.Input(shape=(224, 224, 3))\\nfeature_output = feature_extractor(input_layer)\\ncancer_head = tf.keras.layers.Dense(2, activation='softmax', name='cancer_head')(feature_output)\\nlung_cancer_head = tf.keras.layers.Dense(4, activation='softmax', name='lung_cancer_head')(feature_output)\\nmulti_task_model = tf.keras.Model(inputs=input_layer, outputs=[cancer_head, lung_cancer_head])\\nmulti_task_model.compile(\\n\\toptimizer=tf.keras.optimizers.Adam(),\\n\\tloss={'cancer_head': 'categorical_crossentropy', 'lung_cancer_head': 'categorical_crossentropy'},\\n\\tmetrics={'cancer_head': 'accuracy', 'lung_cancer_head': 'accuracy'}\\n)\\nhistory = multi_task_model.fit(train_generator, epochs=10, validation_data=validation_generator)\\neval_scores = multi_task_model.evaluate(validation_generator)\\nprint(&quot;Cancer Infection - Loss:&quot;, eval_scores[1])\\nprint(&quot;Cancer Infection - Accuracy:&quot;, eval_scores[2])\\nprint(&quot;Lung Cancer Type - Loss:&quot;, eval_scores[3])\\nprint(&quot;Lung Cancer Type - Accuracy:&quot;, eval_scores[4])`\\nError\\nEpoch 1/10\\n---------------------------------------------------------------------------\\nInvalidArgumentError\\t\\t\\t\\t\\t  Traceback (most recent call last)\\n&lt;ipython-input-18-b769f3dab356&gt; in &lt;cell line: 2&gt;()\\n\\t  1 \\n----&gt; 2 history = multi_task_model.fit(train_generator, epochs=10, validation_data=validation_generator)\\n1 frames\\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\\n\\t 50   try:\\n\\t 51\\t ctx.ensure_initialized()\\n---&gt; 52\\t tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\\n\\t 53\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t inputs, attrs, num_outputs)\\n\\t 54   except core._NotOkStatusException as e:\\nInvalidArgumentError: Graph execution error:\\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\\n\\tFile &quot;/usr/lib/python3.10/runpy.py&quot;, line 196, in _run_module_as_main\\n\\t  return _run_code(code, main_globals, None,\\n\\tFile &quot;/usr/lib/python3.10/runpy.py&quot;, line 86, in _run_code\\n\\t  exec(code, run_globals)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py&quot;, line 16, in &lt;module&gt;\\n\\t  app.launch_new_instance()\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py&quot;, line 992, in launch_instance\\n\\t  app.start()\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py&quot;, line 619, in start\\n\\t  self.io_loop.start()\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py&quot;, line 195, in start\\n\\t  self.asyncio_loop.run_forever()\\n\\tFile &quot;/usr/lib/python3.10/asyncio/base_events.py&quot;, line 603, in run_forever\\n\\t  self._run_once()\\n\\tFile &quot;/usr/lib/python3.10/asyncio/base_events.py&quot;, line 1909, in _run_once\\n\\t  handle._run()\\n\\tFile &quot;/usr/lib/python3.10/asyncio/events.py&quot;, line 80, in _run\\n\\t  self._context.run(self._callback, *self._args)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py&quot;, line 685, in &lt;lambda&gt;\\n\\t  lambda f: self._run_callback(functools.partial(callback, future))\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py&quot;, line 738, in _run_callback\\n\\t  ret = callback()\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 825, in inner\\n\\t  self.ctx_run(self.run)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 786, in run\\n\\t  yielded = self.gen.send(value)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py&quot;, line 361, in process_one\\n\\t  yield gen.maybe_future(dispatch(*args))\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 234, in wrapper\\n\\t  yielded = ctx_run(next, result)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py&quot;, line 261, in dispatch_shell\\n\\t  yield gen.maybe_future(handler(stream, idents, msg))\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 234, in wrapper\\n\\t  yielded = ctx_run(next, result)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py&quot;, line 539, in execute_request\\n\\t  self.do_execute(\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 234, in wrapper\\n\\t  yielded = ctx_run(next, result)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py&quot;, line 302, in do_execute\\n\\t  res = shell.run_cell(code, store_history=store_history, silent=silent)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py&quot;, line 539, in run_cell\\n\\t  return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 2975, in run_cell\\n\\t  result = self._run_cell(\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 3030, in _run_cell\\n\\t  return runner(coro)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py&quot;, line 78, in _pseudo_sync_runner\\n\\t  coro.send(None)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 3257, in run_cell_async\\n\\t  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 3473, in run_ast_nodes\\n\\t  if (await self.run_code(code, result,  async_=asy)):\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 3553, in run_code\\n\\t  exec(code_obj, self.user_global_ns, self.user_ns)\\n\\tFile &quot;&lt;ipython-input-18-b769f3dab356&gt;&quot;, line 2, in &lt;cell line: 2&gt;\\n\\t  history = multi_task_model.fit(train_generator, epochs=10, validation_data=validation_generator)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py&quot;, line 65, in error_handler\\n\\t  return fn(*args, **kwargs)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/keras/engine/training.py&quot;, line 1685, in fit\\n\\t  tmp_logs = self.train_function(iterator)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/keras/engine/training.py&quot;, line 1284, in train_function\\n\\t  return step_function(self, iterator)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/keras/engine/training.py&quot;, line 1268, in step_function\\n\\t  outputs = model.distribute_strategy.run(run_step, args=(data,))\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/keras/engine/training.py&quot;, line 1249, in run_step\\n\\t  outputs = model.train_step(data)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/keras/engine/training.py&quot;, line 1051, in train_step\\n\\t  loss = self.compute_loss(x, y, y_pred, sample_weight)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/keras/engine/training.py&quot;, line 1109, in compute_loss\\n\\t  return self.compiled_loss(\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py&quot;, line 265, in __call__\\n\\t  loss_value = loss_obj(y_t, y_p, sample_weight=sw)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/keras/losses.py&quot;, line 142, in __call__\\n\\t  losses = call_fn(y_true, y_pred)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/keras/losses.py&quot;, line 268, in call\\n\\t  return ag_fn(y_true, y_pred, **self._fn_kwargs)\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/keras/losses.py&quot;, line 1984, in categorical_crossentropy\\n\\t  return backend.categorical_crossentropy(\\n\\tFile &quot;/usr/local/lib/python3.10/dist-packages/keras/backend.py&quot;, line 5565, in categorical_crossentropy\\n\\t  return tf.nn.softmax_cross_entropy_with_logits(\\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\\nlogits and labels must be broadcastable: logits_size=[32,2] labels_size=[32,4]\\n\\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_23304]\",\n",
       " \"mnist_dataset = datasets.MNIST(root='../data', train=True, download=True, transform=transform)\\ndef twoclass_split_strat(clients):\\n\\tglobal nb_clients\\n\\tglobal num_classes\\n\\tnb_clients = clients\\n\\tnum_classes = 10\\n\\tdupl = int(nb_clients/num_classes)\\n\\tr = []\\n\\tto_save = f'general data repartition: {save_data_distribution(mnist_dataset)}'\\n\\tcli_class = []\\n\\tprint(&quot;starting&quot;, flush=True)\\n\\tfor i in range(num_classes):\\n\\t\\tr.append([])\\n\\t\\ta = [ran.random() for _ in range(dupl*2)]\\n\\t\\ts = sum(a)\\n\\t\\ta = [b/s for b in a]\\n\\t\\tl = 0\\n\\t\\tfor cli in range(nb_clients):\\n\\t\\t\\tif(cli % num_classes == i or cli % num_classes == (i+1)%num_classes ):\\n\\t\\t\\t\\tr[-1].append(a[l])\\n\\t\\t\\t\\tl += 1\\n\\t\\t\\telse:\\n\\t\\t\\t\\tr[-1].append(0)\\n\\t\\tprint(r[-1], flush=True)\\n\\t\\tprint(sum(r[-1]), flush=True)\\n\\tfor _ in range(nb_clients):\\n\\t\\tcli_class.append([])\\n\\tfor i in range(num_classes):\\n\\t\\tmnist_subsets = []\\n\\t\\tfor j in range(0,len(mnist_dataset)):\\n\\t\\t\\tif mnist_dataset[j][1] == i:\\n\\t\\t\\t\\tmnist_subsets.append(mnist_dataset[j])\\n\\t\\tmnist_subsets_class = random_split(mnist_subsets, r[i], generator=torch.Generator().manual_seed(42))\\n\\t\\tfor m, subset in enumerate(mnist_subsets_class):\\n\\t\\t\\tif len(subset) == 0:\\n\\t\\t\\t\\tcontinue\\n\\t\\t\\tif(len(cli_class[m]) == 0):\\n\\t\\t\\t\\tcli_class[m] = subset\\n\\t\\t\\telse:\\n\\t\\t\\t\\tcli_class[m] = torch.utils.data.ConcatDataset([subset, cli_class[m]])\\n\\tfor l in range(nb_clients):\\n\\t\\tto_save += f'client{l}: {save_data_distribution(cli_class[l])}\\\\n'\\n\\t\\tfilename = f'mnist_subset_{l}.pt'\\n\\t\\ttorch.save(subset, path+filename)\\n\\tto_save += f'r: {r}\\\\n'\\n\\tfilename = 'data_distribution.txt'\\n\\tf = open(path+filename, &quot;w&quot;)\\n\\tf.write(to_save)\\n\\tf.close()\\ndef save_data_distribution(train_set):\\n\\ttrain_targets = [sample[1] for sample in train_set]\\n\\tclass_counts = [train_targets.count(i) for i in range(10)]\\n\\tclass_distribution = [count for count in class_counts]\\n\\treturn class_distribution\",\n",
       " 'general data repartition: [5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\\nclient0: [882, 1, 1, 1, 1, 1, 1, 1, 1, 1353]\\nclient1: [2678, 2038, 1, 1, 1, 1, 0, 0, 1, 1]\\nclient2: [0, 1518, 955, 0, 0, 0, 0, 0, 0, 0]\\nclient3: [0, 0, 1816, 295, 0, 0, 0, 0, 0, 0]\\nclient4: [0, 0, 0, 1518, 1438, 0, 0, 0, 0, 0]\\nclient5: [0, 0, 0, 0, 1734, 940, 0, 0, 0, 0]\\nclient6: [0, 0, 0, 0, 0, 476, 2070, 0, 0, 0]\\nclient7: [0, 0, 0, 0, 0, 0, 239, 2428, 0, 0]\\nclient8: [0, 0, 0, 0, 0, 0, 0, 1354, 829, 0]\\nclient9: [0, 0, 0, 0, 0, 0, 0, 0, 1386, 1540]\\nclient10: [54, 0, 0, 0, 0, 0, 0, 0, 0, 1534]\\nclient11: [2309, 1251, 0, 0, 0, 0, 0, 0, 0, 0]\\nclient12: [0, 1934, 1742, 0, 0, 0, 0, 0, 0, 0]\\nclient13: [0, 0, 1443, 2107, 0, 0, 0, 0, 0, 0]\\nclient14: [0, 0, 0, 2209, 718, 0, 0, 0, 0, 0]\\nclient15: [0, 0, 0, 0, 1950, 1715, 0, 0, 0, 0]\\nclient16: [0, 0, 0, 0, 0, 2288, 2256, 0, 0, 0]\\nclient17: [0, 0, 0, 0, 0, 0, 1352, 1403, 0, 0]\\nclient18: [0, 0, 0, 0, 0, 0, 0, 1079, 2389, 0]\\nclient19: [0, 0, 0, 0, 0, 0, 0, 0, 1245, 1521]\\npercentage of data per class by client\\nr: [[0.1487569991441706, 0.4520673047303473, 0, 0, 0, 0, 0, 0, 0, 0, 0.009199241350956257, 0.3899764547745259, 0, 0, 0, 0, 0, 0, 0, 0],\\n\\t[0, 0.3021821171320493, 0.2252463655212973, 0, 0, 0, 0, 0, 0, 0, 0, 0.18564540590960202, 0.28692611143705143, 0, 0, 0, 0, 0, 0, 0],\\n\\t[0, 0, 0.1603166759114562, 0.3049090970691048, 0, 0, 0, 0, 0, 0, 0, 0, 0.29246395399849495, 0.24231027302094407, 0, 0, 0, 0, 0, 0],\\n\\t[0, 0, 0, 0.04814668026923616, 0.24773036934240952, 0, 0, 0, 0, 0, 0, 0, 0, 0.34377280062387866, 0.36035014976447566, 0, 0, 0, 0, 0],\\n\\t[0, 0, 0, 0, 0.24630359780591282, 0.2968923062811091, 0, 0, 0, 0, 0, 0, 0, 0, 0.12297673540337589, 0.33382736050960227, 0, 0, 0, 0],\\n\\t[0, 0, 0, 0, 0, 0.17353545008323226, 0.08794784425647079, 0, 0, 0, 0, 0, 0, 0, 0, 0.3164518273000846, 0.42206487836021245, 0, 0, 0],\\n\\t[0, 0, 0, 0, 0, 0, 0.34983075186253837, 0.04040125657288295, 0, 0, 0, 0, 0, 0, 0, 0, 0.38130553434345765, 0.228462457221121, 0, 0],\\n\\t[0, 0, 0, 0, 0, 0, 0, 0.3875893081540053, 0.2161609015241546, 0, 0, 0, 0, 0, 0, 0, 0, 0.22399185824655646, 0.17225793207528356, 0],\\n\\t[0, 0, 0, 0, 0, 0, 0, 0, 0.14168683451834266, 0.2370124986910882, 0, 0, 0, 0, 0, 0, 0, 0, 0.40836477260539944, 0.21293589418516962],\\n\\t[0.2274232031801365, 0, 0, 0, 0, 0, 0, 0, 0, 0.2589765922872685, 0.25788282591524647, 0, 0, 0, 0, 0, 0, 0, 0, 0.25571737861734856]]',\n",
       " \"(max_row, max_col) = table_filld.shape\\ncolumn_settings = [{&quot;header&quot;: column} for column in table_filld.columns]\\nwriter = pd.ExcelWriter('test.xlsx', engine='xlsxwriter')\\ntable_filld.to_excel(writer, sheet_name='Sheet1', index=False)\\nworkbook = writer.book\\nworksheet = writer.sheets['Sheet1']\\ncolumn_settings = []\\nfor header in df.columns:\\n\\tcolumn_settings.append({'header': header})\\nworksheet.add_table(0, 0, max_row, max_col - 1, {&quot;columns&quot;: column_settings})\\nmerge_format = workbook.add_format({'align': 'center', 'valign': 'vcenter'})\\nlastRow = len(table_filld)-1\\nfor row in startCells:\\n\\ttry:\\n\\t\\tendRow = startCells[startCells.index(row)+1]-1\\n\\t\\tif row == endRow:\\n\\t\\t\\tworksheet.write(row+1, 0, table_filld.loc[row-1,'Questions'], merge_format)\\n\\t\\telse:\\n\\t\\t\\tworksheet.merge_range(row+1, 0, endRow+1, 0, table_filld.loc[row,'Questions'], merge_format)\\n\\texcept IndexError:\\n\\t\\tif row == lastRow:\\n\\t\\t\\tworksheet.write(row+1, 0, table_filld.loc[row-2,'Questions'], merge_format)\\n\\t\\telse:\\n\\t\\t\\tworksheet.merge_range(row+1, 0, lastRow+1, 0, table_filld.loc[row-1,'Questions'], merge_format)\\nwriter.close()\",\n",
       " \"from tkinter import *\\nimport time as t\\nfrom math import *\\nclass Game:\\n\\tdef __init__(self):\\n\\t\\tself.root = Tk()\\n\\t\\tself.load()\\n\\t\\tself.joystick()\\n\\t\\tself.player()\\n\\t\\tself.root.mainloop()\\n\\tdef load(self):\\n\\t\\tself.joyactive = False\\n\\t\\tself.joymiddlepartX = 0\\n\\t\\tself.joymiddlepartY = 0\\n\\t\\tself.ring_dict = {}\\n\\t\\tself.screenX = self.root.winfo_screenwidth()\\n\\t\\tself.screenY = self.root.winfo_screenheight()\\n\\t\\tself.text = Label(self.root, text=&quot;screenX: {}  screenY: {}&quot;.format(self.screenX, self.screenY), fg='white', bg='black')\\n\\t\\tself.text.pack()\\n\\t\\tself.canvas = Canvas(self.root, width=self.screenX, height=self.screenY, bg='black')\\n\\t\\tself.canvas.pack()\\n\\t\\tself.canvas.bind('&lt;ButtonPress&gt;', self.CanvasOnTouch)\\n\\t\\tself.canvas.bind('&lt;ButtonRelease-1&gt;', self.CanvasOnRelease)\\n\\t\\tself.canvas.bind('&lt;Motion&gt;', self.CanvasOnMotion)\\n\\t\\tself.root.after(1000, self.void)\\n\\tdef void(self):\\n\\t\\tself.text.configure(text='X: {}, Y: {}, Active: {}'.format(self.joymiddlepartX, self.joymiddlepartY, self.joyactive))\\n\\t\\tself.root.after(1, self.void)\\n\\tdef joystick(self):\\n\\t\\tself.joysize = 100\\n\\t\\tself.joyspace = 150\\n\\t\\tself.joyposX = self.screenX * 100 / self.screenX\\n\\t\\tself.joyposY = self.screenY * 1600 / self.screenY\\n\\t\\tself.joyedgewidth = 10\\n\\t\\tself.joydiameter = self.joyspace * 2 + self.joysize\\n\\t\\tself.joyextraspace = 10\\n\\t\\tself.joymaxX = self.joysize/2 + self.joyspace + self.joyextraspace\\n\\t\\tself.joymaxY = self.joymaxX\\n\\t\\tself.joyrestingpos = [self.joyposX + self.joydiameter / 2 - self.joysize / 4, self.joyposY + self.joydiameter / 2 - self.joysize / 4]\\n\\t\\tself.edge = self.canvas.create_oval(self.joyposX, self.joyposY, self.joyposX + self.joydiameter, self.joyposY + self.joydiameter, width=self.joyedgewidth, outline='white')\\n\\t\\tself.middlepart = self.canvas.create_oval(self.joyrestingpos[0] - self.joysize / 2, self.joyrestingpos[1] - self.joysize / 2, self.joyrestingpos[0] + self.joysize, self.joyrestingpos[1] + self.joysize, fill='white', width=10)\\n\\t\\tself.joystickCode()\\n\\tdef joystickCode(self):\\n\\t\\tself.joyXoffset = self.joyposX + self.joyspace + self.joysize/2\\n\\t\\tself.joyYoffset = self.joyposY + self.joyspace + self.joysize/2\\n\\t\\tself.squareroot = sqrt((self.joyrestingpos[0] - (self.joyrestingpos[0] - self.joysize/2 + self.joymiddlepartX - self.joyXoffset + self.joysize / 2))**2 + (self.joyrestingpos[1] - (self.joyrestingpos[1] - self.joysize / 2 - (self.joyYoffset - self.joymiddlepartY) + self.joysize / 2))**2)\\n\\t\\tself.joyaddedsize = self.joysize/2 + self.joyspace + self.joyextraspace\\n\\t\\tif not self.squareroot &gt; self.joyaddedsize:\\n\\t\\t\\tif self.joyactive == True:\\n\\t\\t\\t\\tself.joyXoffset = self.joyposX + self.joyspace + self.joysize/2\\n\\t\\t\\t\\tself.joyYoffset = self.joyposY + self.joyspace + self.joysize/2\\n\\t\\t\\t\\tself.canvas.delete(self.middlepart)\\n\\t\\t\\t\\tself.middlepart = self.canvas.create_oval(self.joyrestingpos[0] - self.joysize/2 + self.joymiddlepartX - self.joyXoffset, self.joyrestingpos[1] - self.joysize / 2 - (self.joyYoffset - self.joymiddlepartY), self.joyrestingpos[0] + self.joysize + self.joymiddlepartX - self.joyXoffset, self.joyrestingpos[1] + self.joysize - (self.joyYoffset - self.joymiddlepartY), fill='white', width=10)\\n\\t\\t\\telse:\\n\\t\\t\\t\\tself.joymiddlepartX = 0\\n\\t\\t\\t\\tself.joymiddlepartY = 0\\n\\t\\t\\t\\tself.moveX = 0\\n\\t\\t\\t\\tself.moveY = 0\\n\\t\\t\\t\\tself.canvas.delete(self.middlepart)\\n\\t\\t\\t\\tself.middlepart = self.canvas.create_oval(self.joyrestingpos[0] - self.joysize / 2, self.joyrestingpos[1] - self.joysize / 2, self.joyrestingpos[0] + self.joysize, self.joyrestingpos[1] + self.joysize, fill='white', width=10)\\n\\t\\tself.joyXoffset = self.joyposX + self.joyspace + self.joysize/2\\n\\t\\tself.joyYoffset = self.joyposY + self.joyspace + self.joysize/2\\n\\t\\tself.squareroot = sqrt((self.joyrestingpos[0] - (self.joyrestingpos[0] - self.joysize/2 + self.joymiddlepartX - self.joyXoffset + self.joysize / 2))**2 + (self.joyrestingpos[1] - (self.joyrestingpos[1] - self.joysize / 2 - (self.joyYoffset - self.joymiddlepartY) + self.joysize / 2))**2)\\n\\t\\tself.joyaddedsize = self.joysize/2 + self.joyspace + self.joyextraspace\\n\\t\\tif self.squareroot &gt; self.joyaddedsize:\\n\\t\\t\\t  self.angleX = self.joymiddlepartX - self.joyrestingpos[0] - self.joysize/4\\n\\t\\t\\t  self.angleY = self.joymiddlepartY - self.joyrestingpos[1] - self.joysize/4\\n\\t\\t\\t  self.angle = degrees(atan2(self.angleY, self.angleX))\\n\\t\\t\\t  self.validposY = sin(radians(self.angle))*self.joyaddedsize\\n\\t\\t\\t  self.validposX = cos(radians(self.angle))*self.joyaddedsize\\n\\t\\t\\t  self.joymiddlepartX = self.joyrestingpos[0] + self.joysize/4 + self.validposX\\n\\t\\t\\t  self.joymiddlepartY = self.joyrestingpos[1] + self.joysize/4 + self.validposY\\n\\t\\telse:\\n\\t\\t\\tself.angleX = self.joymiddlepartX - self.joyrestingpos[0] - self.joysize/4\\n\\t\\t\\tself.angleY = self.joymiddlepartY - self.joyrestingpos[1] - self.joysize/4\\n\\t\\t\\tself.angle = degrees(atan2(self.angleY, self.angleX))\\n\\t\\tfor self.item in self.ring_dict.values():\\n\\t\\t\\tself.canvas.delete(self.item)\\n\\t\\tif self.joyactive:\\n\\t\\t\\tself.joyextrarings = 4\\n\\t\\t\\tself.joyeringwidth = 25\\n\\t\\t\\tfor self.i in range(-1, self.joyextrarings):\\n\\t\\t\\t\\tif self.i == -1:\\n\\t\\t\\t\\t\\tself.i = 0.1\\n\\t\\t\\t\\telif self.i == 0:\\n\\t\\t\\t\\t\\tself.i = 0.33\\n\\t\\t\\t\\tself.joyeringsize = self.joysize/self.joyextrarings*self.i\\n\\t\\t\\t\\tself.mpc = self.canvas.coords(self.middlepart)\\n\\t\\t\\t\\tself.offsetX = self.joyposX + self.joydiameter / 2 - self.joyeringsize / 4\\n\\t\\t\\t\\tself.offsetY = self.joyposY + self.joydiameter / 2 - self.joyeringsize / 4\\n\\t\\t\\t\\tself.mpc[0] -= self.offsetX\\n\\t\\t\\t\\tself.mpc[1] -= self.offsetY\\n\\t\\t\\t\\tself.mpc[2] -= self.offsetX\\n\\t\\t\\t\\tself.mpc[3] -= self.offsetY\\n\\t\\t\\t\\tself.x1 = self.mpc[0]/self.joyextrarings*self.i+self.offsetX\\n\\t\\t\\t\\tself.y1 = self.mpc[1]/self.joyextrarings*self.i+self.offsetY\\n\\t\\t\\t\\tself.x2 = self.mpc[2]/self.joyextrarings*self.i+self.offsetX\\n\\t\\t\\t\\tself.y2 = self.mpc[3]/self.joyextrarings*self.i+self.offsetY\\n\\t\\t\\t\\tself.width = self.joyeringwidth/self.joyextrarings*self.i\\n\\t\\t\\t\\tself.ring_dict[self.i] = self.canvas.create_oval(self.x1, self.y1, self.x2, self.y2, outline='red', width=self.width)\\n\\t\\tself.canvas.tag_raise(self.middlepart)\\n\\t\\tif self.joyactive:\\n\\t\\t\\tself.moveX = cos(radians(self.angle))*self.squareroot/self.joymaxX\\n\\t\\t\\tself.moveY = sin(radians(self.angle))*self.squareroot/self.joymaxY\\n\\t\\tself.root.after(1, self.joystickCode)\\n\\tdef CanvasOnTouch(self, event):\\n\\t   self.joyactive = True\\n\\tdef CanvasOnRelease(self, event):\\n\\t   self.joyactive = False\\n\\tdef CanvasOnMotion(self, event):\\n\\t   if self.joyactive:\\n\\t\\t   self.joymiddlepartX = event.x\\n\\t\\t   self.joymiddlepartY = event.y \\n\\t   else:\\n\\t\\t   self.joyactive = False\\n\\tdef player(self):\\n\\t\\tself.maxspeed = 5\\n\\t\\tself.size = 100\\n\\t\\tself.posX = self.screenX/2\\n\\t\\tself.posY = self.screenY/2\\n\\t\\tself.player = self.canvas.create_rectangle(self.posX-self.size/2, self.posY-self.size/2, self.posX+self.size/2, self.posY+self.size/2, fill='white')\\n\\t\\tself.root.after(1, self.playerCode)\\n\\tdef playerCode(self):\\n\\t\\t   self.posX += self.maxspeed*self.moveX\\n\\t\\t   self.posY += self.maxspeed*self.moveY\\n\\t\\t   self.canvas.delete(self.player)\\n\\t\\t   self.player = self.canvas.create_rectangle(self.posX-self.size/2, self.posY-self.size/2, self.posX+self.size/2, self.posY+self.size/2, fill='blue')\\n\\t\\t   self.root.after(1, self.playerCode)\\ngame = Game()\",\n",
       " \"from tkinter import *\\nimport time as t\\nfrom math import *\\nclass Game:\\n\\tdef __init__(self):\\n\\t\\tself.root = Tk()\\n\\t\\tself.joystick()\\n\\t\\tself.root.mainloop()\\n\\tdef joystick(self):\\n\\t\\tself.joyactive = False\\n\\t\\tself.joymiddlepartX = 0\\n\\t\\tself.joymiddlepartY = 0\\n\\t\\tself.joysize = 100\\n\\t\\tself.joyspace = 150\\n\\t\\tself.joyposX = self.screenX * 100 / self.screenX\\n\\t\\tself.joyposY = self.screenY * 1600 / self.screenY\\n\\t\\tself.joyedgewidth = 10\\n\\t\\tself.joydiameter = self.joyspace * 2 + self.joysize\\n\\t\\tself.joyextraspace = 10\\n\\t\\tself.joymaxX = self.joysize/2 + self.joyspace + self.joyextraspace\\n\\t\\tself.joymaxY = self.joymaxX\\n\\t\\tself.joyrestingpos = [self.joyposX + self.joydiameter / 2 - self.joysize / 4, self.joyposY + self.joydiameter / 2 - self.joysize / 4]\\n\\t\\tself.edge = self.canvas.create_oval(self.joyposX, self.joyposY, self.joyposX + self.joydiameter, self.joyposY + self.joydiameter, width=self.joyedgewidth, outline='white')\\n\\t\\tself.middlepart = self.canvas.create_oval(self.joyrestingpos[0] - self.joysize / 2, self.joyrestingpos[1] - self.joysize / 2, self.joyrestingpos[0] + self.joysize, self.joyrestingpos[1] + self.joysize, fill='white', width=10)\\n\\t\\tself.joystickCode()\\n\\tdef joystickCode(self):\\n\\t\\tself.joyXoffset = self.joyposX + self.joyspace + self.joysize/2\\n\\t\\tself.joyYoffset = self.joyposY + self.joyspace + self.joysize/2\\n\\t\\tself.squareroot = sqrt((self.joyrestingpos[0] - (self.joyrestingpos[0] - self.joysize/2 + self.joymiddlepartX - self.joyXoffset + self.joysize / 2))**2 + (self.joyrestingpos[1] - (self.joyrestingpos[1] - self.joysize / 2 - (self.joyYoffset - self.joymiddlepartY) + self.joysize / 2))**2)\\n\\t\\tself.joyaddedsize = self.joysize/2 + self.joyspace + self.joyextraspace\\n\\t\\tif not self.squareroot &gt; self.joyaddedsize:\\n\\t\\t\\tif self.joyactive == True:\\n\\t\\t\\t\\tself.joyXoffset = self.joyposX + self.joyspace + self.joysize/2\\n\\t\\t\\t\\tself.joyYoffset = self.joyposY + self.joyspace + self.joysize/2\\n\\t\\t\\t\\tself.canvas.delete(self.middlepart)\\n\\t\\t\\t\\tself.middlepart = self.canvas.create_oval(self.joyrestingpos[0] - self.joysize/2 + self.joymiddlepartX - self.joyXoffset, self.joyrestingpos[1] - self.joysize / 2 - (self.joyYoffset - self.joymiddlepartY), self.joyrestingpos[0] + self.joysize + self.joymiddlepartX - self.joyXoffset, self.joyrestingpos[1] + self.joysize - (self.joyYoffset - self.joymiddlepartY), fill='white', width=10)\\n\\t\\t\\telse:\\n\\t\\t\\t\\tself.joymiddlepartX = 0\\n\\t\\t\\t\\tself.joymiddlepartY = 0\\n\\t\\t\\t\\tself.canvas.delete(self.middlepart)\\n\\t\\t\\t\\tself.middlepart = self.canvas.create_oval(self.joyrestingpos[0] - self.joysize / 2, self.joyrestingpos[1] - self.joysize / 2, self.joyrestingpos[0] + self.joysize, self.joyrestingpos[1] + self.joysize, fill='white', width=10)\\n\\t\\tself.root.after(1, self.joystickCode)\\n\\tdef CanvasOnRelease(self, event):\\n\\t   self.joyactive = False\\n\\tdef CanvasOnMotion(self, event):\\n\\t   if self.joyactive:\\n\\t\\t   self.joymiddlepartX = event.x\\n\\t\\t   self.joymiddlepartY = event.y \\ngame = Game()\",\n",
       " \"import serial\\nimport time\\nport = 'COM6'\\nbaud_rate = 9600\\nparity = serial.PARITY_NONE\\nstop_bits = serial.STOPBITS_ONE\\ndata_bits = serial.EIGHTBITS\\ntimeout = 1\\nser = serial.Serial(\\n\\tport=port,\\n\\tbaudrate=baud_rate,\\n\\tparity=parity,\\n\\tstopbits=stop_bits,\\n\\tbytesize=data_bits,\\n\\ttimeout=timeout\\n)\\nif ser.is_open:\\n\\tprint(&quot;Serial port &quot;+port+&quot; is open&quot;)\\nelse:\\n\\tprint(&quot;Serial port &quot;+port+&quot; is closed&quot;)\\nprint(&quot; &quot;)\\nhex_command  = '43303637030D0A' \\nhex_success  = '06303036030D0A' \\nhex_failure  = '14303231030D0A' \\nnoofattempts = 5\\ndef hex_to_bytes(hex_string):\\n\\treturn bytes.fromhex(hex_string)\\ndef read_responses(duration):\\n\\tend_time = time.time() + duration\\n\\tresponses = []\\n\\twhile time.time() &lt; end_time:\\n\\t\\tif ser.in_waiting &gt; 0:\\n\\t\\t\\tresponse = ser.readline()\\n\\t\\t\\tresponses.append(response)\\n\\treturn responses\\nattempts = 0\\nwhile attempts &lt; noofattempts:\\n\\ttry:\\n\\t\\tser.write(hex_to_bytes(hex_command))\\n\\texcept serial.SerialException:\\n\\t\\tprint(&quot;Error: serial.SerialException&quot;)\\n\\texcept serial.SerialTimeoutException:\\n\\t\\tprint(&quot;Error: serial.SerialTimeoutException&quot;)\\n\\tprint(str(attempts) + '.')\\n\\tprint('Sent:', hex_command)\\n\\tprint('Sent:', hex_to_bytes(hex_command))\\n\\ttime.sleep(0.1)\\n\\tresponses = read_responses(1)\\n\\tif responses == '\\\\x06' or responses == b'\\\\x06' or responses == b'\\\\x06\\\\x30\\\\x30\\\\x36\\\\x03':\\n\\t\\tprint('ACK RECEIVED:', responses)\\n\\t\\tresponses = read_responses(1)\\n\\t\\tprint(responses)\\n\\t\\tser.write(hex_to_bytes(hex_success))\\n\\t\\tprint('Sent success:', hex_success)\\n\\t\\tbreak\\n\\telse:\\n\\t\\tprint('RECEIVED:', responses)\\n\\t\\tattempts += 1\\n\\tser.flush()\\n\\tprint(&quot; &quot;)\\nser.close()\",\n",
       " 'script_01.py',\n",
       " 'script_02.py',\n",
       " 'script_01.py',\n",
       " 'script_02.py',\n",
       " 'script_02.py',\n",
       " '.vscode/launch.json',\n",
       " '{\\n\\t&quot;version&quot;: &quot;0.2.0&quot;,\\n\\t&quot;configurations&quot;: [\\n\\t\\t{\\n\\t\\t\\t&quot;name&quot;: &quot;Python Debugging Test&quot;,\\n\\t\\t\\t&quot;type&quot;: &quot;python&quot;,\\n\\t\\t\\t&quot;request&quot;: &quot;launch&quot;,\\n\\t\\t\\t&quot;program&quot;: &quot;${file}&quot;,\\n\\t\\t\\t&quot;justMyCode&quot;: true,\\n\\t\\t\\t&quot;preLaunchTask&quot;: &quot;startup&quot;,\\n\\t\\t}\\n\\t]\\n}',\n",
       " '.vscode/tasks.json',\n",
       " '{\\n\\t&quot;version&quot;: &quot;2.0.0&quot;,\\n\\t&quot;tasks&quot;: [\\n\\t\\t{\\n\\t\\t\\t&quot;label&quot; : &quot;startup&quot;,\\n\\t\\t\\t&quot;type&quot; : &quot;shell&quot;,\\n\\t\\t\\t&quot;command&quot;: &quot;bash task_resources/startup.sh&quot;,\\n\\t   },\\n\\t]\\n}',\n",
       " 'task_resources/startup.sh',\n",
       " 'python3 script_02.py',\n",
       " 'File &quot;C:\\\\anaconda\\\\lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 2548, in __call__\\n\\treturn self.wsgi_app(environ, start_response)\\n  File &quot;C:\\\\anaconda\\\\lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 2528, in wsgi_app\\n\\tresponse = self.handle_exception(e)\\n  File &quot;C:\\\\anaconda\\\\lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 2525, in wsgi_app\\n\\tresponse = self.full_dispatch_request()\\n  File &quot;C:\\\\anaconda\\\\lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 1822, in full_dispatch_request\\n\\trv = self.handle_user_exception(e)\\n  File &quot;C:\\\\anaconda\\\\lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 1820, in full_dispatch_request\\n\\trv = self.dispatch_request()\\n  File &quot;C:\\\\anaconda\\\\lib\\\\site-packages\\\\flask\\\\app.py&quot;, line 1796, in dispatch_request\\n\\treturn self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\\n  File &quot;c:\\\\Users\\\\лена\\\\Documents\\\\Б\\\\Second library site back-end\\\\website\\\\views.py&quot;, line 7, in home\\n\\treturn render_template(&quot;home.html&quot;)\\n  File &quot;C:\\\\anaconda\\\\lib\\\\site-packages\\\\flask\\\\templating.py&quot;, line 146, in render_template\\n\\ttemplate = app.jinja_env.get_or_select_template(template_name_or_list)\\n  File &quot;C:\\\\anaconda\\\\lib\\\\site-packages\\\\jinja2\\\\environment.py&quot;, line 1081, in get_or_select_template\\n\\treturn self.get_template(template_name_or_list, parent, globals)\\n  File &quot;C:\\\\anaconda\\\\lib\\\\site-packages\\\\jinja2\\\\environment.py&quot;, line 1010, in get_template\\n\\treturn self._load_template(name, globals)\\n  File &quot;C:\\\\anaconda\\\\lib\\\\site-packages\\\\jinja2\\\\environment.py&quot;, line 969, in _load_template\\n\\ttemplate = self.loader.load(self, name, self.make_globals(globals))\\n  File &quot;C:\\\\anaconda\\\\lib\\\\site-packages\\\\jinja2\\\\loaders.py&quot;, line 126, in load\\n\\tsource, filename, uptodate = self.get_source(environment, name)\\n  File &quot;C:\\\\anaconda\\\\lib\\\\site-packages\\\\flask\\\\templating.py&quot;, line 62, in get_source\\n\\treturn self._get_source_fast(environment, template)\\n  File &quot;C:\\\\anaconda\\\\lib\\\\site-packages\\\\flask\\\\templating.py&quot;, line 98, in _get_source_fast\\n\\traise TemplateNotFound(template)\\njinja2.exceptions.TemplateNotFound: home.html',\n",
       " 'main.py',\n",
       " \"from website import create_app\\napp = create_app(__name__)\\nif __name__ == '__main__':\\n\\tapp.run(debug=True)\",\n",
       " '__init__.py',\n",
       " \"from flask import Flask\\ndef create_app(__name__):\\n\\tapp = Flask(__name__)\\n\\tapp.config['SECRET_KEY'] = 'i love bananas'\\n\\tfrom .views import views\\n\\tfrom .auth import auth\\n\\tapp.register_blueprint (views, url_prefix='/')\\n\\tapp.register_blueprint (auth, url_prefix='/')\\n\\treturn app\",\n",
       " 'views.py',\n",
       " \"from flask import Blueprint, render_template\\nviews = Blueprint('views', __name__)\\n@views.route('/')\\ndef home():\\n\\treturn render_template(&quot;home.html&quot;)\",\n",
       " '{% extends &quot;base.html&quot; %}\\n{% block title %}TheAkashicLibrary{% endblock %}',\n",
       " 'Jun 21 17:48:49 lgfxvoice-laptop python3.8[237324]: 2023-06-21 17:48:49.770 | DEBUG\\t|\\nJun 21 17:48:50 lgfxvoice-laptop python3.8[237324]: Exception in thread Thread-3:\\nJun 21 17:48:50 lgfxvoice-laptop python3.8[237324]: Traceback (most recent call last):\\nJun 21 17:48:50 lgfxvoice-laptop python3.8[237324]:   File &quot;/usr/local/python3.8/lib/python3.8/threading.py&quot;, line 932, in _bootstrap_inner\\nJun 21 17:48:50 lgfxvoice-laptop python3.8[237324]:\\t self.run()\\nJun 21 17:48:50 lgfxvoice-laptop python3.8[237324]:   File &quot;/usr/local/python3.8/lib/python3.8/threading.py&quot;, line 870, in run\\nJun 21 17:48:50 lgfxvoice-laptop python3.8[237324]:\\t self._target(*self._args, **self._kwargs)\\nJun 21 17:48:50 lgfxvoice-laptop python3.8[237324]:   File &quot;/home/lgfx-voice/Desktop/voice-box/api/receive_audio_data.py&quot;, line 48, in receive_data\\nJun 21 17:48:50 lgfxvoice-laptop python3.8[237324]:\\t voice_data = self.stream.read(7680)\\nJun 21 17:48:50 lgfxvoice-laptop python3.8[237324]:   File &quot;/home/lgfx-voice/.local/lib/python3.8/site-packages/pyaudio/__init__.py&quot;, line 570, in read\\nJun 21 17:48:50 lgfxvoice-laptop python3.8[237324]:\\t return pa.read_stream(self._stream, num_frames\\nJun 21 17:48:50 lgfxvoice-laptop python3.8[237324]: OSError: [Errno -9981] Input overflowed',\n",
       " \"for j in range(3):\\n\\tdate_offset = pd.DateOffset(days=-j)\\n\\tquery_date_start = pd.to_datetime(datatime).date() + date_offset\\n\\tquery_date_end = pd.to_datetime(datatime).date() + date_offset + pd.DateOffset(days=1)\\n\\tquery = f<str>\\n\\tdf = pd.read_sql(query, cnx)\\n\\tdf['time_slot'] = pd.to_datetime(df['time_slot'], format='%Y-%m-%d %H:%M')\\n\\tdf_combined = pd.concat([df_combined, df])\\n\\tdf_combined['date'] = pd.to_datetime(df_combined['time_slot']).dt.date\\n\\tyear = query_date_start.year\\n\\tmonth = query_date_start.month\\n\\tday = query_date_start.day\\n\\tstart_hour = 0\\n\\tstart_minute = 0\\n\\tstart_second = 0\\n\\tend_hour = 23\\n\\tend_minute = 45\\n\\tend_second = 0\\n\\tstart_time = datetime(year, month, day, start_hour, start_minute, start_second)\\n\\tend_time = datetime(year, month, day, end_hour, end_minute, end_second)\\n\\ttime_range = pd.date_range(start=start_time, end=end_time, freq='15min')\\n\\treference_df = pd.DataFrame({'time_slot': time_range})\\n\\tmerged_df = reference_df.merge(df_combined, on='time_slot', how='outer', sort=True)\\n\\tmerged_df['car_count'] = merged_df['car_count'].fillna(0)\\n\\tmerged_df['date'] = pd.to_datetime(merged_df['time_slot']).dt.date\\nfinal_df = merged_df.groupby('date')\\nsorted_categories = final_df.groups.keys()\\nsorted_categories = sorted(sorted_categories, reverse=True)\\nsorted_df = merged_df.set_index('date').loc[sorted_categories].reset_index()\\nsorted_df.groupby('date')['car_count'].plot(legend = True)\",\n",
       " \"Traceback (most recent call last):\\nFile &quot;c:\\\\Users\\\\nick_\\\\Projects\\\\python-vt-apiv3\\\\vt-ip-url-\\nanalysis.py&quot;, line 454, in &lt;module&gt;urlReport(args.single_entry)\\nFile &quot;c:\\\\Users\\\\nick_\\\\Projects\\\\python-vt-apiv3\\\\vt-ip-url-\\nanalysis.py&quot;, line 104, in urlReport epoch_time =\\n(decodedResponse[&quot;data&quot;][&quot;attributes&quot;][&quot;last_analysis_date&quot;])\\nKeyError: 'data'\",\n",
       " 'File &quot;c:\\\\Users\\\\nick_\\\\Projects\\\\python-vt-apiv3\\\\vt-ip-url-analysis.py&quot;, line 454, in &lt;module&gt;\\nurlReport(args.single_entry)',\n",
       " 'File &quot;c:\\\\Users\\\\nick_\\\\Projects\\\\python-vt-apiv3\\\\vt-ip-url-analysis.py&quot;, line 104, in urlReport\\nepoch_time = (decodedResponse[&quot;data&quot;][&quot;attributes&quot;][&quot;last_analysis_date&quot;])',\n",
       " '{\\n  &quot;data&quot;: {\\n\\t&quot;attributes&quot;: {\\n\\t  &quot;categories&quot;: {dict},\\n\\t  &quot;favicon&quot;: {\\n\\t\\t&quot;dhash&quot;: &quot;&lt;string&gt;&quot;,\\n\\t\\t&quot;raw_md5&quot;: &quot;&lt;string&gt;&quot;\\n\\t  },\\n\\t  &quot;first_submission_date&quot;: &lt;int:timestamp&gt;,\\n\\t  &quot;html_meta&quot;: {\\n\\t\\t&quot;&lt;str:tag_name&gt;&quot;: [&quot;&lt;tag_value:string&gt;&quot;]\\n\\t  },\\n\\t  &quot;last_analysis_date&quot;: &lt;int:timestamp&gt;,',\n",
       " 'epoch_time = (decodedResponse[&quot;data&quot;][&quot;attributes&quot;][&quot;last_analysis_date&quot;])',\n",
       " 'Python',\n",
       " 'aiohttp',\n",
       " 'jQuery',\n",
       " 'React',\n",
       " 'Polyglot.js',\n",
       " 'vite.config.js',\n",
       " \"export default defineConfig({\\n  server: {\\n\\tproxy: {\\n\\t  '/': {\\n\\t\\ttarget: 'http://localhost:8080',\\n\\t\\tchangeOrigin: true,\\n\\t\\tconfigure: (proxy, options) =&gt; {\\n\\t\\t\\t // call some custom JavaScript here\\n\\t\\t\\t // 1) Grab HTML\\n\\t\\t\\t // 2) Run the page through Polyglot library\\n\\t\\t\\t // 3) Spit page out to the browser\\n\\t\\t},\\n\\t  },\\n\\t},\\n  },\\n})\",\n",
       " 'df_kafka = spark \\\\\\n  .read \\\\\\n  .format(&quot;kafka&quot;) \\\\\\n  .option(&quot;kafka.bootstrap.servers&quot;, &quot;bootstrap_servers&quot;) \\\\\\n  .option(&quot;subscribePattern&quot;, &quot;topic&quot;) \\\\\\n  .option(&quot;kafka.security.protocol&quot;,&quot;SSL&quot;) \\\\\\n  .option(&quot;kafka.ssl.truststore.location&quot;, &quot;cert.jks&quot;) \\\\\\n  .option(&quot;startingOffsets&quot;, &quot;earliest&quot;) \\\\\\n  .option(&quot;endingOffsets&quot;, &quot;latest&quot;) \\\\\\n  .option(&quot;mode&quot;, &quot;PERMISSIVE&quot;) \\\\\\n  .load()',\n",
       " \"m = folium.Map(location=[7.245361, -73.692524], zoom_start=10)\\npolygons = [{'name': 'Polygon 1', 'vpn': 'positive', 'coordinates': [(-73.692524, 7.113611), (-73.700712, 7.118302), (-73.691428, 7.13561), (-73.683846, 7.130675), (-73.692524, 7.113611)]},{'name': 'Polygon 2', 'vpn': 'negative', 'coordinates': [(-73.70558, 7.245361), (-73.71528, 7.250042), (-73.715232, 7.308858), (-73.68565, 7.308833), (-73.70558, 7.245361)]},]\\npositive_group = folium.FeatureGroup(name='Positive VPN')negative_group = folium.FeatureGroup(name='Negative VPN')polygons_group = folium.FeatureGroup(name='Polygons')\\nfor polygon in polygons:coordinates = polygon['coordinates']feature = folium.GeoJson({'type': 'Polygon', 'coordinates': [coordinates]},name=polygon['name'], style_function=lambda x: {'fillColor': 'green' if polygon['vpn'] == 'positive' else 'red'})\\nfeature_2 = folium.GeoJson({'type': 'Polygon', 'coordinates': [coordinates]},name=polygon['name'], style_function=lambda x: {'fillColor': 'green' if polygon['vpn'] == 'positive' else 'red'})\\npolygons_group.add_child(feature_2)\\nif polygon['vpn'] == 'positive':\\n\\tpositive_group.add_child(feature)\\nelse:\\n\\tnegative_group.add_child(feature)\\npolygons_group.add_to(m)positive_group.add_to(m)negative_group.add_to(m)\\ngrouped_layers = {'VPN': [positive_group, negative_group],'Polygons': [polygons_group],}\\ngrouped_layer_control = GroupedLayerControl(grouped_layers, exclusive_groups=False)m.add_child(grouped_layer_control)\",\n",
       " '!pip install onnx\\nimport os\\nimport shutil\\nimport torch\\nimport onnx\\nimport tensorflow as tf\\nfrom google.colab import files',\n",
       " \"upload_folder = 'upload'\\nresult_folder = 'results'\\nif os.path.isdir(upload_folder):\\n\\tshutil.rmtree(upload_folder)\\nif os.path.isdir(result_folder):\\n\\tshutil.rmtree(result_folder)\\nos.mkdir(upload_folder)\\nos.mkdir(result_folder)\\nuploaded = files.upload()\\nfor filename in uploaded.keys():\\n  dst_path = os.path.join(upload_folder, filename)\",\n",
       " 'def convert_torch_to_onnx(model_path, output_filename=&quot;model.onnx&quot;):\\n\\tmodel = torch.load(dst_path)\\n\\tonnx_model = torch.onnx.export(model, None, output_filename)\\n\\tonnx.save_model(onnx_model, output_filename)\\n\\tonnx_path = os.path.join(upload_folder, output_filename)',\n",
       " \"print(onnx_path) \\noutput_filename = &quot;/content/output.onnx&quot;\\nprint(f'move {output_filename} to {onnx_path}')\\nshutil.move(output_filename, '/content/upload')\",\n",
       " \"\\tprint(f'move {output_filename} to {onnx_path}')\\n\\tshutil.move(output_filename, onnx_path)\",\n",
       " \"upload_folder = 'upload'\\nresult_folder = 'results'\\nif os.path.isdir(upload_folder):\\n\\tshutil.rmtree(upload_folder)\\nif os.path.isdir(result_folder):\\n\\tshutil.rmtree(result_folder)\\nos.mkdir(upload_folder)\\nos.mkdir(result_folder)\\nuploaded = files.upload()\\nfor filename in uploaded.keys():\\n  dst_path = os.path.join(upload_folder, filename)\\n   print(f'move {filename} to {dst_path}')\\n  shutil.move(filename, dst_path)\",\n",
       " \"def writing_logs(request, action):\\n\\tlogger.info('{} {} {} {}'.format(\\n\\t\\trequest.user.email,\\n\\t\\tget_client_ip(request),\\n\\t\\tget_client_type_device(request),\\n\\t\\taction))\\n\\twith open('loggers/log_user_activity/user_activity.log', 'r', encoding='utf8') as filelog:\\n\\t\\tfor i_line in filelog.readlines():\\n\\t\\t\\tif i_line.startswith('INFO') and len(i_line.split()) == 9:\\n\\t\\t\\t\\tline_list = i_line.split()\\n\\t\\t\\t\\tif line_list[3] != 'Watching':\\n\\t\\t\\t\\t\\tif not Log.objects.filter(log_date=line_list[1]):\\n\\t\\t\\t\\t\\t\\tLog.objects.create(log_category=line_list[0],\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   log_date=line_list[1])\",\n",
       " \"import re\\nfrom unidecode import unidecode\\ndef standarize_str(mystring):\\n\\tmystring = unidecode(mystring, errors='replace', replace_str='_')\\n\\tmystring = re.sub('[^A-Za-z-_0-9]', '_', mystring)\\n\\treturn mystring\",\n",
       " 'df.colums',\n",
       " 'dict',\n",
       " 'str',\n",
       " 'df.rename_with_callable(standarize_str)',\n",
       " 'test_transforms = A.Compose(\\n\\t[\\n\\t\\tA.LongestMaxSize(max_size=IMAGE_SIZE),\\n\\t\\tA.PadIfNeeded(\\n\\t\\t\\tmin_height=IMAGE_SIZE, min_width=IMAGE_SIZE, border_mode=cv2.BORDER_CONSTANT\\n\\t\\t),\\n\\t\\tA.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255),\\n\\t],\\n\\tbbox_params=A.BboxParams(format=&quot;yolo&quot;, min_visibility=0.4, label_fields=[]),\\n)',\n",
       " 'import os.path\\nimport numpy as np\\nimport albumentations as A\\nimport cv2\\nimport torch\\nfrom albumentations.pytorch import ToTensorV2\\nfrom PIL import Image, ImageFile\\nimport config\\ndef yolo_to_xml_bbox_xyxy(bbox, w, h):\\n\\tw_half_len = (bbox[2] * w) / 2\\n\\th_half_len = (bbox[3] * h) / 2\\n\\txmin = int((bbox[0] * w) - w_half_len)\\n\\tymin = int((bbox[1] * h) - h_half_len)\\n\\txmax = int((bbox[0] * w) + w_half_len)\\n\\tymax = int((bbox[1] * h) + h_half_len)\\n\\treturn (xmin, ymin, xmax, ymax, bbox[4])\\ndef xml_bbox_xyxy_to_yolo_bbox(bbox, w, h):\\n\\txmin,ymin,xmax,ymax, c = bbox\\n\\tx = (xmin + xmax) / 2.0 / w\\n\\ty = (ymin + ymax) / 2.0 / h\\n\\tw = (xmax - xmin) / float(w)\\n\\th = (ymax - ymin) / float(h)\\n\\treturn (x, y, w, h, c)\\ndef yolo_to_xml_bbox_xyxy_np(bbox, w, h):\\n\\tw_half_len = (bbox[2] * w) / 2\\n\\th_half_len = (bbox[3] * h) / 2\\n\\txmin = int((bbox[0] * w) - w_half_len)\\n\\tymin = int((bbox[1] * h) - h_half_len)\\n\\txmax = int((bbox[0] * w) + w_half_len)\\n\\tymax = int((bbox[1] * h) + h_half_len)\\n\\treturn [xmin, ymin, xmax, ymax, bbox[4]]\\noriginal_width = 1280\\noriginal_height = 720\\nIMAGE_SIZE=608\\nlabels_path = config.DATASET + &quot;/labels&quot;\\nlabels_fns = os.listdir(labels_path)\\nlabels_pathswe = [os.path.join(labels_path, os.path.splitext(label_fn)[0]) for label_fn in labels_fns]\\ntest_transforms = A.Compose(\\n\\t[\\n\\t\\tA.LongestMaxSize(max_size=IMAGE_SIZE),\\n\\t\\tA.PadIfNeeded(\\n\\t\\t\\tmin_height=IMAGE_SIZE, min_width=IMAGE_SIZE, border_mode=cv2.BORDER_CONSTANT\\n\\t\\t),\\n\\t\\tA.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255),\\n\\t],\\n\\tbbox_params=A.BboxParams(format=&quot;yolo&quot;, min_visibility=0.4, label_fields=[]),\\n)\\nfor label_pathwe in labels_pathswe:\\n\\tprint(&quot;Label: &quot;, label_pathwe)\\n\\tannotations = np.loadtxt(fname=label_pathwe+&quot;.txt&quot;, delimiter=&quot; &quot;, ndmin=2)\\n\\tannotation_base = annotations[:, 0:5]\\n\\tcontacts = annotations[:, 5:6]\\n\\tannotation_unit_vec_xy = annotations[:, 6:8]\\n\\tannotation_unit_vec_mag = annotations[:, 8:9]\\n\\tbboxes_base = np.roll(annotation_base, 4, axis=1)\\n\\timg_path = label_pathwe.replace(&quot;labels&quot;, &quot;images&quot;)+&quot;.jpg&quot;\\n\\torg_image = np.array(Image.open(img_path).convert(&quot;RGB&quot;))\\n\\torg_xyxy_boxes = []\\n\\tfor bbox in bboxes_base.tolist():\\n\\t\\torg_xyxy_boxes.append(yolo_to_xml_bbox_xyxy(bbox, original_width, original_height))\\n\\taugmentations = test_transforms(image=org_image, bboxes=bboxes_base)\\n\\ttf_image = augmentations[&quot;image&quot;]\\n\\ttransformed_bbox = augmentations[&quot;bboxes&quot;]\\n\\tinverted_transform = A.Compose(\\n\\t\\t[\\n\\t\\t\\tA.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255,),\\n\\t\\t\\tA.Resize(height=original_height, width=original_width, interpolation=cv2.INTER_LINEAR, always_apply=True),\\n\\t\\t],\\n\\t\\tbbox_params=A.BboxParams(format=&quot;yolo&quot;, min_visibility=0.4, label_fields=[]),\\n\\t)\\n\\tnon_padded_rows = np.where(tf_image[:, :, 0].sum(axis=1) &gt; 0)[0]\\n\\tnon_padded_cols = np.where(tf_image[:, :, 0].sum(axis=0) &gt; 0)[0]\\n\\ttop_row, bottom_row = non_padded_rows[0], non_padded_rows[-1]\\n\\tleft_col, right_col = non_padded_cols[0], non_padded_cols[-1]\\n\\tcropped_image = tf_image[top_row:bottom_row, left_col:right_col, :]\\n\\tnew_bboxes = []\\n\\tfor bbox in transformed_bbox:\\n\\t\\tx, y, w, h, c = bbox\\n\\t\\txyxy_bbox = yolo_to_xml_bbox_xyxy(bbox, tf_image.shape[1], tf_image.shape[0])\\n\\t\\txmin, ymin, xmax, ymax, c = xyxy_bbox\\n\\t\\tnew_x1 = xmin - left_col\\n\\t\\tnew_y1 = ymin - top_row\\n\\t\\tnew_x2 = xmax - left_col\\n\\t\\tnew_y2 = ymax - top_row\\n\\t\\tyolo_inv_bbox = xml_bbox_xyxy_to_yolo_bbox([new_x1, new_y1, new_x2, new_y2,c],cropped_image.shape[1], cropped_image.shape[0])\\n\\t\\tnew_bboxes.append(yolo_inv_bbox)\\n\\taugmentations_inv = inverted_transform(image=tf_image, bboxes=new_bboxes)\\n\\tinvtf_image = augmentations_inv[&quot;image&quot;]\\n\\tinvtransformed_bboxes = augmentations_inv[&quot;bboxes&quot;]\\n\\tinv_org_xyxy_boxes = []\\n\\tfor bbox in invtransformed_bboxes:\\n\\t\\tinv_org_xyxy_boxes.append(yolo_to_xml_bbox_xyxy(bbox, original_width, original_height))\\n\\tif len(org_xyxy_boxes) != len(inv_org_xyxy_boxes):\\n\\t\\tprint(&quot;Original and inverted annotations not matching!&quot;)\\n\\t\\tcontinue\\n\\ttheyAreSame = True\\n\\tfor bbidx, org_bbox in enumerate(org_xyxy_boxes):\\n\\t\\tif set(org_xyxy_boxes) != set(inv_org_xyxy_boxes[bbidx]):\\n\\t\\t\\ttheyAreSame = False\\n\\t\\t\\tbreak\\n\\tif theyAreSame == False:\\n\\t\\tprint(&quot;Original and inverted annotations not matching!&quot;)\\n\\telse:\\n\\t\\tprint(&quot;Ok!&quot;)',\n",
       " \"from django.contrib.auth.models import AbstractBaseUser, BaseUserManager, PermissionsMixin\\nfrom django.db import models\\nfrom djongo import models as djongo_models\\nfrom bson.objectid import ObjectId\\nfrom django.contrib.auth.hashers import make_password, check_password\\nfrom django.core.validators import RegexValidator\\nfrom api.enums import Status, UserRole\\nclass UserManager(BaseUserManager):\\n\\tdef create_user(self, username, email, password=None, **extra_fields):\\n\\t\\tif not email:\\n\\t\\t\\traise ValueError('The email is required')\\n\\t\\temail = self.normalize_email(email)\\n\\t\\tuser = self.model(username=username, email=email, **extra_fields)\\n\\t\\tuser.set_password(password)\\n\\t\\tuser.save(using=self._db)\\n\\t\\treturn user\\n\\tdef create_superuser(self, username, email, password=None, **extra_fields):\\n\\t\\textra_fields.setdefault('is_staff', True)\\n\\t\\textra_fields.setdefault('is_superuser', True)\\n\\t\\textra_fields.setdefault('role', UserRole.ADMIN)\\n\\t\\treturn self.create_user(username, email, password, **extra_fields)\\nclass User(AbstractBaseUser, PermissionsMixin):\\n\\tmongo_id = djongo_models.ObjectIdField()\\n\\tdef save(self, *args, **kwargs):\\n\\t\\tif not self.mongo_id:\\n\\t\\t\\tself.mongo_id = ObjectId()\\n\\t\\tsuper().save(*args, **kwargs)\\n\\tusername = models.CharField(max_length=20, blank=False)\\n\\tname = models.CharField(max_length=20, blank=False, default='')\\n\\tlastname = models.CharField(max_length=20, blank=False, default='')\\n\\tpassword = models.CharField(max_length=128, blank=False,)\\n\\tdef set_password(self, raw_password):\\n\\t\\tself.password = make_password(raw_password)\\n\\tdef check_password(self, raw_password):\\n\\t\\treturn check_password(raw_password, self.password)\\n\\tphone_number = RegexValidator(regex=r'^\\\\+\\\\d{1,3}\\\\s\\\\d{6, 14}$', message='Insert a valid phone number and it\\\\'s country code')\\n\\temail = models.EmailField(unique=True, blank=False)\\n\\tbirth_date = models.DateField(null=True)\\n\\trole = models.CharField(max_length=10, choices=[(role, role.value) for role in UserRole],)\\n\\tstatus = models.CharField(max_length=20, choices=[(tag, tag.value) for tag in Status])\\n\\tcreated_at = models.DateTimeField(auto_now_add=True)\\n\\tupdated_at = models.DateTimeField(default=None)\\n\\tdeleted = models.BooleanField(default=False)\\n\\tUSERNAME_FIELD = 'email'\\n\\tREQUIRED_FIELDS = ['username', 'phone_number', 'birth_date', 'role', 'status']\\n\\tobjects = UserManager()\\n\\tdef __str__(self):\\n\\t\\treturn self.email\",\n",
       " \"from rest_framework import serializers\\nfrom api.models import User\\nfrom rest_framework_simplejwt.tokens import RefreshToken\\nclass UserRegistrationsSerializer(serializers.ModelSerializer):\\n\\tpassword = serializers.CharField(write_only=True)\\n\\tclass Meta:\\n\\t\\tmodel = User\\n\\t\\tfields = (\\n\\t\\t\\t'username',\\n\\t\\t\\t'email',\\n\\t\\t\\t'password',\\n\\t\\t\\t'phone_number',\\n\\t\\t\\t'birth_date',\\n\\t\\t\\t'role',\\n\\t\\t\\t'status',\\n\\t\\t)\\n\\tdef create(self, validated_data):\\n\\t\\tuser = User.objects.create(\\n\\t\\t\\tusername=validated_data['username'],\\n\\t\\t\\temail=validated_data['email'],\\n\\t\\t\\tname=validated_data['name'],\\n\\t\\t\\tlastname=validated_data['lastname'],\\n\\t\\t\\tphone_number=validated_data['phone_number'],\\n\\t\\t\\tbirth_date=validated_data['birth_date'],\\n\\t\\t\\trole=validated_data['role'],\\n\\t\\t\\tstatus=validated_data['status'],\\n\\t\\t)\\n\\t\\tuser.set_password(validated_data['password'])\\n\\t\\tuser.save()\\n\\t\\treturn user\\nclass UserSerializer(serializers.ModelSerializer):\\n\\tclass Meta:\\n\\t\\tmodel = User\\n\\t\\tfields = (\\n\\t\\t\\t'name',\\n\\t\\t\\t'lastname',\\n\\t\\t\\t'password',\\n\\t\\t\\t'phone_number',\\n\\t\\t\\t'email',\\n\\t\\t\\t'birth_date',\\n\\t\\t\\t'role',\\n\\t\\t\\t'status',\\n\\t\\t)\\n\\t\\tread_only_fields = (\\n\\t\\t\\t'id',\\n\\t\\t\\t'mongo_id',\\n\\t\\t\\t'created_at',\\n\\t\\t\\t'updated_at',\\n\\t\\t\\t'deleted'\\n\\t\\t)\\n\\tdef get_token(self, obj):\\n\\t\\trefresh = RefreshToken.for_user(obj)\\n\\t\\ttoken = {\\n\\t\\t\\t'refresh': str(refresh),\\n\\t\\t\\t'access': str(refresh.access_token),\\n\\t\\t}\\n\\t\\treturn token\",\n",
       " \"from django.http.response import JsonResponse\\nfrom rest_framework import status\\nfrom django.contrib.auth import authenticate\\nfrom api.models import User\\nfrom api.serializers import UserSerializer, UserRegistrationsSerializer\\nfrom rest_framework.permissions import IsAuthenticated\\nfrom rest_framework_simplejwt.authentication import JWTAuthentication\\nfrom rest_framework.views import APIView\\nfrom rest_framework.generics import ListAPIView\\nclass UserRegister(APIView):\\n\\tdef post(self, request):\\n\\t\\tserializer = UserRegistrationsSerializer(data=request.data)\\n\\t\\tif serializer.is_valid():\\n\\t\\t\\tuser = serializer.save()\\n\\t\\t\\tserializer = UserSerializer(user)\\n\\t\\t\\treturn JsonResponse(serializer.data, status=status.HTTP_201_CREATED)\\n\\t\\treturn JsonResponse(serializer.errors, status=status.HTTP_400_BAD_REQUEST)\\nclass UserLogin(APIView):\\n\\tdef post(self, request):\\n\\t\\temail_or_username = request.data.get('email_or_username')\\n\\t\\tpassword = request.data.get('password')\\n\\t\\tuser = authenticate(request, email=email_or_username, password=password)\\n\\t\\tif not user is None:\\n\\t\\t\\tserializer = UserSerializer(user)\\n\\t\\t\\treturn JsonResponse(serializer.data, status=status.HTTP_200_OK)\\n\\t\\treturn JsonResponse({'Detail': 'Invalid Credentials'}, status=status.HTTP_401_UNAUTHORIZED)\\nclass UserList(ListAPIView):\\n\\tauthentication_classes = [JWTAuthentication]\\n\\tpermission_classes = [IsAuthenticated]\\n\\tdef get(self, request, format=None):\\n\\t\\tusers = User.objects.all()\\n\\t\\tusers_serializer = UserSerializer(users, many=True)\\n\\t\\treturn JsonResponse(users_serializer.data, status=status.HTTP_200_OK)\\nclass UserDetail(APIView):\\n\\tauthentication_classes = [JWTAuthentication]\\n\\tpermission_classes = [IsAuthenticated]\\n\\tdef get_object(self, pk):\\n\\t\\ttry:\\n\\t\\t\\treturn User.objects.get(pk=pk)\\n\\t\\texcept User.DoesNotExist:\\n\\t\\t\\treturn JsonResponse({'message': 'The User does not exists'}, status=status.HTTP_404_NOT_FOUND)\\n\\tdef get(self, request, pk, format=None):\\n\\t\\tuser = self.get_object(pk)\\n\\t\\tserializer = UserSerializer(user)\\n\\t\\treturn JsonResponse(serializer.data)\\n\\tdef put(self, request, pk, format=None):\\n\\t\\tuser = self.get_object(pk)\\n\\t\\tserializer = UserSerializer(user, data=request.data)\\n\\t\\tif serializer.is_valid():\\n\\t\\t\\tserializer.save()\\n\\t\\t\\treturn JsonResponse(serializer.data)\\n\\t\\treturn JsonResponse(serializer.errors, status=status.HTTP_400_BAD_REQUEST)\\n\\tdef delete(self, request, pk, format=None):\\n\\t\\tuser = self.get_object(pk)\\n\\t\\tuser.deleted = True\\n\\t\\tuser.save()\\n\\t\\treturn JsonResponse(status=status.HTTP_204_NO_CONTENT)\\nclass DeletedUsers(ListAPIView):\\n\\tserializer_class = UserSerializer\\n\\tpermission_classes = [IsAuthenticated]\\n\\tauthentication_classes = [JWTAuthentication]\\n\\tqueryset = User.objects.filter(deleted=True)\",\n",
       " '`class DataRecord(EmbeddedDocument):\\n\\tfield = StringField()\\n\\told = DynamicField()\\n\\tnew = DynamicField()\\n class Audit(BaseModel):\\n\\tdata = EmbeddedDocumentListField(DataRecord)`',\n",
       " '`@strawberry.type\\nclass DataRecordRead:\\n\\tfield: str\\n\\told: Optional[?]\\n\\tnew: Optional[?]\\n@strawberry.type\\nclass BaseAudit:\\n\\tdata: Optional[List[DataRecordRead]]`',\n",
       " 'def clearScreen():\\n\\tfor widget in root.winfo_children():\\n\\t\\twidget.pack_forget()',\n",
       " 'def clearScreen():\\n\\tfor widget in root.winfo_children():\\n\\t\\twidget.pack_forget()\\n\\tsleep(5)',\n",
       " 'widget.update()',\n",
       " 'widget.update_idletasks()',\n",
       " \"def optionsWindow():\\n\\tclearScreen()\\n\\taudio = ttk.Checkbutton(root, text=&quot;Audio Only&quot;, variable=audioToggle, onvalue=1, offvalue=0)\\n\\taudio.pack(pady=20)\\n\\tbackButton = ttk.Button(root, text=&quot;Back to Main&quot;, command=lambda: [clearScreen(), mainWindow()])\\n\\tbackButton.pack(pady=20)\\ndef clearScreen():\\n\\tfor widget in root.winfo_children():\\n\\t\\twidget.pack_forget()\\n\\troot.update()\\ninputBox = tk.Text(root, height=10, width=50, borderwidth=2, relief='groove')\\ndownloadButton = ttk.Button(root, text=&quot;Download&quot;, command=downloadVideo)\\noptionsButton = ttk.Button(root, text=&quot;Options&quot;, command=optionsWindow)\\nprogressBar = ttk.Progressbar(root, length=300)\\nstatusText = ttk.Label(root)\\ndef mainWindow():\\n\\tclearScreen()\\n\\tinputBox.pack(anchor='center', pady=20)\\n\\tdownloadButton.pack(anchor='center', pady=10)\\n\\toptionsButton.pack(anchor='center', pady=10)\\n\\tstatusText.pack(anchor='center', pady=20)\\n\\tstatusText.config(text=&quot;&quot;)\",\n",
       " \"import numpy as np\\nimport time\\nimport cv2\\nimport cv2.aruco as aruco\\ndist=np.array(([[-0.58650416 , 0.59103816, -0.00443272 , 0.00357844 ,-0.27203275]]))\\nnewcameramtx=np.array([[189.076828   ,  0.\\t,\\t 361.20126638]\\n ,[  0 ,2.01627296e+04 ,4.52759577e+02]\\n ,[0, 0, 1]])\\nmtx=np.array([[398.12724231  , 0.\\t  ,   304.35638757],\\n [  0.\\t   ,  345.38259888, 282.49861858],\\n [  0.,\\t\\t   0.,\\t\\t   1.\\t\\t]])\\ncap = cv2.VideoCapture(0)\\nfont = cv2.FONT_HERSHEY_SIMPLEX \\ndef detect():\\n\\tmtx = np.array([[8.2177218160147447e+02, 0.0\\t\\t\\t\\t   , 3.4694289806342221e+02],\\n\\t\\t\\t\\t\\t\\t\\t [0.0\\t\\t\\t\\t   , 8.2177218160147447e+02, 2.4795144956871457e+02],\\n\\t\\t\\t\\t\\t\\t\\t [0.0\\t\\t\\t\\t   , 0.0\\t\\t\\t\\t   , 1.0\\t\\t\\t\\t   ]])\\n\\tdist = np.array([4.4824308523616324e-02, -7.4951985348854000e-01, 3.7539708742088725e-03, 8.8931335565222442e-03, 3.7214188475390984e+00])\\n\\trvec = np.array([])\\n\\ttvec = np.array([])\\n\\tret, frame = cap.read()\\n\\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\\n\\taruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\\n\\tparameters =  aruco.DetectorParameters_create()\\n\\tcorners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\\n\\trvec, tvec, x = aruco.estimatePoseSingleMarkers(corners, 0.04, mtx, dist)\\n\\trmat, jacobian = cv2.Rodrigues(rvec)\\n\\tif (corners != []):\\n\\t\\trvec, tvec, _ = aruco.estimatePoseSingleMarkers(corners, 5.4, mtx, dist)\\n\\tprint(rmat)\\n\\treturn frame, rvec, tvec\\nwhile True:\\n\\tret, frame = cap.read()\\n\\th1, w1 = frame.shape[:2]\\n\\tnewcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (h1, w1), 0, (h1, w1))\\n\\tdst1 = cv2.undistort(frame, mtx, dist, None, newcameramtx)\\n\\tx, y, w1, h1 = roi\\n\\tdst1 = dst1[y:y + h1, x:x + w1]\\n\\tframe=dst1\\n\\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\\n\\taruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\\n\\tparameters =  aruco.DetectorParameters_create()\\n\\tdst1 = cv2.undistort(frame, mtx, dist, None, newcameramtx)\\n\\tcorners, ids, rejectedImgPoints = aruco.detectMarkers(gray,aruco_dict,parameters=parameters)\\n\\tif ids is not None:\\n\\t\\trvec, tvec, _ = aruco.estimatePoseSingleMarkers(corners, 0.05, mtx, dist)\\n\\t\\tdetect()\\n\\t\\t(rvec-tvec).any() \\n\\t\\taruco.drawDetectedMarkers(frame, corners) \\n\\t\\tfor i in range(rvec.shape[0]):\\n\\t\\t\\tcv2.drawFrameAxes(frame, mtx, dist, rvec[i, :, :], tvec[i, :, :], 0.03)\\n\\t\\t\\tcv2.drawFrameAxes(dst1, mtx, dist, rvec[i, :, :], tvec[i, :, :],0.03)\\n\\t\\tcv2.putText(frame, &quot;Id: &quot; + str(ids), (0,64), font, 1, (0,255,0),2,cv2.LINE_AA)\\n\\telse:\\n\\t\\tcv2.putText(frame, &quot;No Ids&quot;, (0,64), font, 1, (0,255,0),2,cv2.LINE_AA)\\n\\tcv2.imshow(&quot;frame&quot;,frame)\\n\\tkey = cv2.waitKey(1)\\n\\tif key == 27:\\t\\t \\n\\t\\tprint('esc break...')\\n\\t\\tcap.release()\\n\\t\\tcv2.destroyAllWindows()\\n\\t\\tbreak\\n\\tif key == ord(' '):   \\n\\t\\tfilename = str(time.time())[:10] + &quot;.jpg&quot;\\n\\t\\tcv2.imwrite(filename, frame)\",\n",
       " \"\\timport keyboard\\n\\tbarcode_data = ''\\n\\tdef on_key_press(event):\\n\\t\\tglobal barcode_data\\n\\t\\tkey = event.name\\n\\t   if len(key) == 1 and (key.isalnum() or key == '-'):\\n\\t\\t   barcode_data += key\\n\\t   elif key == 'enter':\\n\\t\\t   print('Barcode scanned:', barcode_data\\n\\t\\t\\t\\t\\t\\t\\t\\t  )\\n\\t\\tbarcode_data = ''\\n\\t   keyboard.on_press(on_key_press)\\n\\twhile True:\\n\\tpass\",\n",
       " \"df = pd.DataFrame({\\n\\t'ga:productAddsToCart': [2, 2, 4, 2],\\n\\t'ga:mobileDeviceModel_(not set)': [True, False, False, False],\\n\\t'ga:mobileDeviceModel_2109119DG': [False, True, False, False],\\n\\t'ga:mobileDeviceModel_2201117SG': [False, False, True, False],\\n\\t'ga:mobileDeviceModel_2201117TG': [False, False, False, True],\\n\\t'ga:mobileDeviceModel_2201117TL': [False, False, False, False],\\n\\t'ga:mobileDeviceModel_2811': [False, False, False, False],\\n\\t'ga:mobileDeviceModel_5.4': [False, False, False, False],\\n\\t'ga:mobileDeviceModel_5085J': [False, False, False, False],\\n\\t'ga:mobileDeviceModel_A11': [False, False, False, False],\\n\\t'ga:source_l.instagram.com': [False, False, False, False],\\n\\t'ga:source_l.wl.co': [False, False, False, False],\\n\\t'ga:source_linkedin.com': [False, False, False, False],\\n\\t'ga:source_linktr.ee': [False, False, False, False],\\n\\t'ga:source_m.facebook.com': [False, False, False, False],\\n\\t'ga:source_mercadopago.com.br': [False, False, False, False],\\n\\t'ga:source_naturus.com.br': [False, False, False, False],\\n\\t'ga:source_ofertadia.com.br': [False, False, False, False],\\n\\t'ga:source_pinterest.com': [True, False, False, False],\\n\\t'ga:source_youtube.com': [False, False, False, False],\\n})\",\n",
       " 'X = df.drop(&quot;ga:productAddsToCart&quot;, axis=1)\\nX = X.astype(int)\\ny = df[&quot;ga:productAddsToCart&quot;]',\n",
       " \"model = sm.NegativeBinomial(df['ga:productAddsToCart'], df.drop('ga:productAddsToCart', axis=1))\",\n",
       " \"seletor_forward = SequentialFeatureSelector(clone(model), forward=True, scoring='neg_mean_squared_error')\\nseletor_forward.fit(X, y)\\nplot_sequential_feature_selection(seletor_forward.get_metric_dict())\",\n",
       " './setup.py build',\n",
       " 'WARNING: the following files are not recognized by DistUtilsExtra.auto:\\n&lt;the list of .c/.h files in Onboard/osk/&gt;',\n",
       " './onboard',\n",
       " \"Traceback (most recent call last):\\n  File &quot;/home/....../onboard/./onboard&quot;, line 35, in &lt;module&gt;\\n\\tfrom Onboard.OnboardGtk import OnboardGtk as Onboard\\n  File &quot;/home/....../onboard/Onboard/OnboardGtk.py&quot;, line 48, in &lt;module&gt;\\n\\tfrom Onboard.Keyboard\\t\\timport Keyboard\\n  File &quot;/home/....../onboard/Onboard/Keyboard.py&quot;, line 45, in &lt;module&gt;\\n\\tfrom Onboard.KeyboardPopups\\t\\timport TouchFeedback\\n  File &quot;/home/....../onboard/Onboard/KeyboardPopups.py&quot;, line 256, in &lt;module&gt;\\n\\tclass LabelPopup(KeyboardPopupDrawable):\\n  File &quot;/home/....../onboard/Onboard/KeyboardPopups.py&quot;, line 264, in LabelPopup\\n\\t_osk_util = osk.Util()\\nAttributeError: module 'Onboard.osk' has no attribute 'Util'\",\n",
       " \"import asyncio\\nimport logging\\nfrom aiogram import Bot, Dispatcher, types\\nfrom aiogram.filters import Text\\nfrom aiogram.filters.command import Command\\nfrom aiogram.utils.keyboard import ReplyKeyboardBuilder\\nlogging.basicConfig(level=logging.INFO)\\nbot = Bot(token=&quot;TOKEN&quot;)\\ndp = Dispatcher()\\n@dp.message(Command(&quot;start&quot;))\\nasync def cmd_start(message: types.Message):\\n\\tbuilder = ReplyKeyboardBuilder()\\n\\tbuilder.row(\\n\\t\\ttypes.KeyboardButton(text=&quot;Begin&quot;),\\n\\t)\\n\\tawait message.answer('Hello, press to button',\\t\\treply_markup=builder.as_markup(resize_keyboard=True))\\n@dp.message(Text('Begin'))\\nasync def new_client_services(message: types.Message):\\n\\tbuilder = ReplyKeyboardBuilder()\\n\\tbuilder.row(\\n\\t\\ttypes.KeyboardButton(text=&quot;End&quot;),\\n\\t)\\n\\tawait message.answer(&quot;Please write down all your items lying on the table one by one&quot;,\\n\\t\\t\\t\\t\\t\\t reply_markup=builder.as_markup(resize_keyboard=True))\\n\\t@dp.message(Text('End'))\\n\\tasync def end_save_services(message: types.Message):\\n\\t\\tawait message.reply(&quot;Excellent&quot;,\\n\\t\\t\\t\\t\\t\\t\\treply_markup=types.ReplyKeyboardRemove())\\n\\t@dp.message()\\n\\tasync def with_puree(message: types.Message):\\n\\t\\tawait message.answer(f&quot;Items {message.text} add✅\\\\n&quot;)\\n@dp.message()\\nasync def end_save_services(message: types.Message):\\n\\tawait message.reply(&quot;Please, push button&quot;)\\nasync def main():\\n\\tawait dp.start_polling(bot)\\nif __name__ == &quot;__main__&quot;:\\n\\tasyncio.run(main())\",\n",
       " \"---------------------------------------------------------------------------\\nOSError\\t\\t\\t\\t\\t\\t\\t\\t   Traceback (most recent call last)\\n~\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_19332\\\\1902527957.py in &lt;module&gt;\\n----&gt; 1 data=wf_loader('adb', state=2)\\n\\t  2 \\n\\t  3 \\n\\t  4 \\n~\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_19332\\\\168813414.py in wf_loader(representation, state, save)\\n\\t 22\\t with open(file) as di_data:\\n\\t 23\\t\\t print(di_data)\\n---&gt; 24\\t\\t lines = di_data.readlines()\\n\\t 25\\n\\t 26\\t xlims, ylims, x_gridpoints, y_gridpoints = get_data_shape_fromlog()\\nOSError: [Errno 22] Invalid argument\",\n",
       " \" def wf_loader(representation='adb', state=2, save=True):\\n\\t<str>\\n\\tcwd = os.getcwd()\\n\\tif representation == 'adb':\\n\\t\\tfile = os.path.join(cwd, 'adb2d_x_y')\\n\\telif representation == 'diab':\\n\\t\\tfile = os.path.join(cwd, 'dens2d_x_y')\\n\\telse:\\n\\t\\tprint('Unkown representation')\\n\\t\\treturn\\n\\twith open(file) as di_data:\\n\\t\\tprint(di_data)\\n\\t\\tlines = di_data.readlines()\",\n",
       " \"&lt;Demo&gt;\\n\\tScreen:\\n\\t\\tMDBoxLayout:\\n\\t\\t\\torientation:'vertical'\\n\\t\\t\\tMDTopAppBar:\\n\\t\\t\\t\\tpos_hint: {&quot;top&quot;:1}\\n\\t\\t\\t\\ttitle: &quot;Navigation&quot;\\n\\t\\t\\t\\tleft_action_items: [[&quot;menu&quot;, lambda x: nav_drawer.set_state(&quot;open&quot;)]]\\n\\t\\tScrollView:\\n\\t\\t\\tGridLayout:\\n\\t\\t\\t\\tcols:1\\n\\t\\t\\t\\tsize_hint_y:None\\n\\t\\t\\t\\tsize_hint:1,None\\n\\t\\t\\t\\theight:self.minimum_height\\n\\t\\t\\t\\tLabel:\\n\\t\\t\\t\\t\\tname:&quot;Label1&quot;\\n\\t\\t\\t\\t\\tcanvas.before:\\n\\t\\t\\t\\t\\t\\tColor:\\n\\t\\t\\t\\t\\t\\t\\trgba:(109/255.0,114/255.0,219/255.0,1)\\n\\t\\t\\t\\t\\t\\tRectangle:\\n\\t\\t\\t\\t\\t\\t\\tpos:self.pos\\n\\t\\t\\t\\t\\t\\t\\tsize:self.size\\n\\t\\t\\t\\t\\tsize_hint_y: None\\n\\t\\t\\t\\t\\theight: self.texture_size[1]\\n\\t\\t\\t\\t\\ttext_size:self.width,None\\n\\t\\t\\t\\t\\ttext:'Really long text *100'\\n\\t\\t\\t\\t\\tfont_size:'52sp'\\n\\t\\t\\t\\tLabel:\\n\\t\\t\\t\\t\\tname:&quot;Label2&quot;\\n\\t\\t\\t\\t\\tcanvas.before:\\n\\t\\t\\t\\t\\t\\tColor:\\n\\t\\t\\t\\t\\t\\t\\trgba:(1,1,1,1)\\n\\t\\t\\t\\t\\t\\tRectangle:\\n\\t\\t\\t\\t\\t\\t\\tpos:self.pos\\n\\t\\t\\t\\t\\t\\t\\tsize:self.size\\n\\t\\t\\t\\t\\tsize_hint_y: None\\n\\t\\t\\t\\t\\theight: self.texture_size[1]\\n\\t\\t\\t\\t\\ttext_size:self.width,None\\n\\t\\t\\t\\t\\ttext:&quot;Really long text *100&quot;\\n\\t\\t\\t\\t\\tcolor: 0,0,0,1\\n\\t\\t\\t\\t\\tfont_size:'16sp'\\n\\tMDNavigationDrawer:\\n\\t\\tid:nav_drawer\\n\\t\\tMDBoxLayout:\\n\\t\\t\\torientation: 'vertical'\\n\\t\\t\\tScrollView:\\n\\t\\t\\t\\tGridLayout:\\n\\t\\t\\t\\t\\tcols:1\\n\\t\\t\\t\\t\\tsize_hint_y:None\\n\\t\\t\\t\\t\\tsize_hint:1,None\\n\\t\\t\\t\\t\\theight:self.minimum_height\\n\\t\\t\\t\\t\\tButton:\\n\\t\\t\\t\\t\\t\\tname:&quot;BLabel1&quot;\\n\\t\\t\\t\\t\\t\\tcanvas.before:\\n\\t\\t\\t\\t\\t\\t\\tColor:\\n\\t\\t\\t\\t\\t\\t\\t\\trgba:(21/255.0,113/255.0,146/255.0,1)\\n\\t\\t\\t\\t\\t\\t\\tRectangle:\\n\\t\\t\\t\\t\\t\\t\\t\\tpos:self.pos\\n\\t\\t\\t\\t\\t\\t\\t\\tsize:self.size\\n\\t\\t\\t\\t\\t\\tsize_hint_y: None\\n\\t\\t\\t\\t\\t\\theight: self.texture_size[1]\\n\\t\\t\\t\\t\\t\\ttext_size:self.width,None\\n\\t\\t\\t\\t\\t\\ttext:'Label1'\\n\\t\\t\\t\\t\\t\\tfont_size:'20sp'\\n\\t\\t\\t\\t\\tButton:\\n\\t\\t\\t\\t\\t\\tname:&quot;BLabel2&quot;\\n\\t\\t\\t\\t\\t\\tcanvas.before:\\n\\t\\t\\t\\t\\t\\t\\tColor:\\n\\t\\t\\t\\t\\t\\t\\t\\trgba:(21/255.0,113/255.0,146/255.0,1)\\n\\t\\t\\t\\t\\t\\t\\tRectangle:\\n\\t\\t\\t\\t\\t\\t\\t\\tpos:self.pos\\n\\t\\t\\t\\t\\t\\t\\t\\tsize:self.size\\n\\t\\t\\t\\t\\t\\tsize_hint_y: None\\n\\t\\t\\t\\t\\t\\theight: self.texture_size[1]\\n\\t\\t\\t\\t\\t\\ttext_size:self.width,None\\n\\t\\t\\t\\t\\t\\ttext:'Label2'\\n\\t\\t\\t\\t\\t\\tfont_size:'20sp'\",\n",
       " \" TypeError: load() missing 1 required positional argument: 'Loader'\",\n",
       " 'trainer = ChatterBotCorpusTrainer(chatbot)\\ntrainer.train (\\n\\t&quot;chatterbot.corpus.english&quot;,\\n\\t&quot;chatterbot.corpus.english.greetings&quot;,\\n\\t&quot;chatterbot.corpus.english.conversations&quot;,\\n\\t&quot;./data/greetings_corpus/custom.corpus.json&quot;,\\n\\t&quot;./data/my_corpus/&quot;\\n)',\n",
       " 'from chatterbot.trainers import ChatterBotCorpusTrainer\\ntrainer = ChatterBotCorpusTrainer(chatbot)\\ntrainer.train',\n",
       " 'yaml',\n",
       " 'dcc.Dropdown',\n",
       " 'cocktail_names',\n",
       " \"['\",\n",
       " \"&quot;1880's Americana&quot;\",\n",
       " '&quot;188&quot;',\n",
       " '&quot;10 to 7&quot;',\n",
       " '&quot;10 &quot;',\n",
       " '&quot;',\n",
       " '&quot;',\n",
       " \"import dash\\nimport dash_bootstrap_components as dbc\\nfrom dash import Input, Output, State, dcc, html, callback\\nimport dash_html_components as html\\nimport pandas as pd\\nimport os\\nimport pymysql.cursors\\ndash.register_page(__name__, path='/Search')\\ncocktail_names.sort()\\noptions = [{'label': name, 'value': name} for name in cocktail_names]\\nlayout = html.Div(children=[\\n\\thtml.Div([\\n\\t\\tdcc.Dropdown(options=options,\\n\\t\\tplaceholder = &quot;Select or Search for Cocktail&quot;,\\n\\t\\tvalue= None,  \\n\\t\\tclearable=False,\\n\\t\\tsearchable = True,\\n\\t\\tstyle={&quot;backgroundColor&quot;: &quot;white&quot;, &quot;color&quot;: &quot;black&quot;},\\n\\t\\tid = &quot;dropdown_cocktail&quot;),\\n\\t]),\\n\\thtml.Br(),\\n\\thtml.H1(id = &quot;Cocktail_Output&quot;, style={'textAlign': 'center', 'margin-bottom':25, 'margin-top':25}),\\n])\\n@callback(\\nOutput(&quot;Cocktail_Output&quot;, component_property = &quot;children&quot;),\\nInput(&quot;dropdown_cocktail&quot;, component_property = &quot;value&quot;)\\n)\\ndef cocktail_output(user_input):\\n\\toutput = &quot;&quot;\\n\\tif user_input is None:\\n\\t\\toutput = None\\n\\telse:\\n\\t\\treturn user_input\\n\\treturn output\",\n",
       " 'cocktails_names',\n",
       " \"from automata.fa.nfa import NFA\\nfrom visual_automata.fa.nfa import VisualNFA\\nvisualnfa = VisualNFA(\\n\\tstates={'Q0', 'Q1', 'Q2'},\\n\\tinput_symbols={'A', 'B'},\\n\\ttransitions={\\n\\t\\t'Q0': {'A': {'Q0'}, 'B': {'Q0','Q1'}},\\n\\t\\t'Q1': {'A': {'Q2'}, 'B': {'Q1'}},\\n\\t\\t'Q2': {'A': {'Q2'}, 'B': {'Q2','Q1'}},\\n\\t},\\n\\tinitial_state='Q0',\\n\\tfinal_states={'Q0','Q1'},\\n)\\nvisualnfa.table;\",\n",
       " \"AttributeError: 'frozendict.frozendict' object has no attribute 'deepcopy'.\",\n",
       " 'default_config:\\nfrontend:\\n  themes: !include_dir_merge_named themes\\ninput_number:\\n  box1:\\n\\tname: some_number\\n\\tmin: 0\\n\\tmax: 100\\n\\tstep: 1\\n\\tmode: box\\n\\tunit_of_measurement: &quot;%&quot;',\n",
       " '&gt;&gt;&gt; import network\\n&gt;&gt;&gt; ssid = &quot;ssid&quot;\\n&gt;&gt;&gt; password = &quot;password&quot;\\n&gt;&gt;&gt; sta_if = network.WLAN(network.STA_IF)\\n&gt;&gt;&gt; ap_if = network.WLAN(network.AP_IF)\\n&gt;&gt;&gt; sta_if.active(True)\\n&gt;&gt;&gt; sta_if.connect(ssid, password)',\n",
       " 'sta_if.isconnected()',\n",
       " 'True',\n",
       " '&gt;&gt;&gt; import urequests\\n&gt;&gt;&gt; url = &quot;http://homeassistant.local:8123/api/states/input_number.box1&quot;\\n&gt;&gt;&gt; token=&quot;token&quot;\\n&gt;&gt;&gt; headers = {&quot;Authorization&quot;: f&quot;Bearer {token}&quot;, &quot;content-type&quot;: &quot;application/json&quot;}\\n&gt;&gt;&gt; response = urequests.get(url, headers=headers)',\n",
       " '&gt;&gt;&gt; response = urequests.get(url, headers=headers)\\nTraceback (most recent call last):\\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\\n  File &quot;urequests.py&quot;, line 116, in get\\n  File &quot;urequests.py&quot;, line 55, in request\\nOSError: -2\\n&gt;&gt;&gt;',\n",
       " 'from machine import ADC, Pin, I2C\\nfrom ssd1306 import SSD1306_I2C\\nimport utime\\nsoil = ADC(Pin(26)) \\ngpio_pin = machine.Pin(15, machine.Pin.OUT)\\nmin_moisture=19200\\nmax_moisture=49300\\nreadDelay = 0.5 \\nwhile True:\\n\\tmoisture = (max_moisture-soil.read_u16())*100/(max_moisture-min_moisture)\\n\\tprint(&quot;moisture: &quot; + &quot;%.2f&quot; % moisture +&quot;% (adc: &quot;+str(soil.read_u16())+&quot;)&quot;)\\n\\tif moisture &lt; 80:\\n\\t\\tgpio_pin.value(1)\\n\\t\\tutime.sleep(2)\\n\\t\\tgpio_pin.value(0)\\n\\telse:\\n\\t\\tgpio_pin.value(0)\\n\\tutime.sleep(readDelay) ',\n",
       " 'moisture: 2.53% (adc: 48347)',\n",
       " 'import streamlit as st\\nst.title(&quot;My Todo App&quot;)',\n",
       " 'streamlit run web.py',\n",
       " '  File &quot;&lt;frozen runpy&gt;&quot;, line 198, in _run_module_as_main\\n  File &quot;&lt;frozen runpy&gt;&quot;, line 88, in _run_code\\n  File &quot;C:\\\\Users\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Scripts\\\\streamlit.exe\\\\__main__.py&quot;, line 7, in &lt;module&gt;\\n  File &quot;C:\\\\Users\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\click\\\\core.py&quot;, line 1130, in __call__\\n\\treturn self.main(*args, **kwargs)\\n\\t\\t   ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File &quot;C:\\\\Users\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\click\\\\core.py&quot;, line 1055, in main\\n\\trv = self.invoke(ctx)\\n\\t\\t ^^^^^^^^^^^^^^^^\\n  File &quot;C:\\\\Users\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\click\\\\core.py&quot;, line 1657, in invoke\\n\\treturn _process_result(sub_ctx.command.invoke(sub_ctx))\\n\\t\\t\\t\\t\\t\\t   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File &quot;C:\\\\Users\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\click\\\\core.py&quot;, line 1404, in invoke\\n\\treturn ctx.invoke(self.callback, **ctx.params)\\n\\t\\t   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File &quot;C:\\\\Users\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\click\\\\core.py&quot;, line 760, in invoke\\n\\treturn __callback(*args, **kwargs)\\n\\t\\t   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File &quot;C:\\\\Users\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\streamlit\\\\web\\\\cli.py&quot;, line 206, in main_run\\n\\t_main_run(target, args, flag_options=kwargs)\\n  File &quot;C:\\\\Users\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\streamlit\\\\web\\\\cli.py&quot;, line 242, in _main_run\\n\\tbootstrap.run(file, command_line, args, flag_options)\\n  File &quot;C:\\\\Users\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\streamlit\\\\web\\\\bootstrap.py&quot;, line 416, in run\\n\\tasyncio.run(run_server())\\n  File &quot;C:\\\\Users\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\asyncio\\\\runners.py&quot;, line 190, in run\\n\\treturn runner.run(main)\\n\\tstart_listening_tcp_socket(http_server)\\n  File &quot;C:\\\\Users\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\streamlit\\\\web\\\\server\\\\server.py&quot;, line 140, in start_listening_tcp_socket\\n\\thttp_server.listen(port, address)\\n  File &quot;C:\\\\Users\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\tornado\\\\tcpserver.py&quot;, line 183, in listen\\tsockets = bind_sockets(\\n\\t\\t\\t  ^^^^^^^^^^^^^\\n  File &quot;C:\\\\Users\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\tornado\\\\netutil.py&quot;, line 162, in bind_sockets\\tsock.bind(sockaddr)\\nPermissionError: [WinError 10013] An attempt was made to access a socket in a way forbidden by its access permissions',\n",
       " \"import plim\\nstr = 'div\\nplim.compile_plim_source(str, plim.syntax.BaseSyntax())\",\n",
       " 'pygame.draw.line(sc, GREEN, player.pos, (player.x + WIDTH * math.cos(player.angle),  player.y + WIDTH * math.sin(player_angle)))',\n",
       " 'from config import *\\nimport pygame\\nclass Player:\\n\\tdef __init__(self):\\n\\t\\tself.x, self.y = player_pos\\n\\t\\tself.angle = player_angle\\n\\t@property\\n\\tdef pos(self):\\n\\t\\treturn(self.x, self.y)\\n\\tdef movement(self):\\n\\t\\tkeys = pygame.key.get_pressed()\\n\\t\\tif keys[pygame.K_w]:\\n\\t\\t\\tself.y -= player_speed\\n\\t\\tif keys[pygame.K_s]:\\n\\t\\t\\tself.y += player_speed\\n\\t\\tif keys[pygame.K_a]:\\n\\t\\t\\tself.x -= player_speed\\n\\t\\tif keys[pygame.K_d]:\\n\\t\\t\\tself.x += player_speed\\n\\t\\tif keys[pygame.K_LEFT]:\\n\\t\\t\\tself.angle -= 0.02\\n\\t\\tif keys[pygame.K_RIGHT]:\\n\\t\\t\\tself.angle += 0.02',\n",
       " 'WIDTH = 1200\\nHEIGHT = 800\\nHALF_WIDTH = WIDTH // 2\\nHALF_HEIGHT = HEIGHT // 2\\nFPS = 75\\nWHITE = (255, 255, 255)\\nBLACK = (0, 0, 0)\\nRED = (255, 0, 0)\\nGREEN = (0, 255, 0)\\nBLUE = (0, 0, 255)\\nGRAY = (110, 110, 110)\\nDARKBLUE = (0, 120, 0)\\nplayer_pos = (HALF_WIDTH, HALF_HEIGHT)\\nplayer_angle = 0\\nplayer_speed = 2',\n",
       " \"import numpy as np\\nimport scipy as sp\\nimport sympy as smp\\nimport matplotlib.pyplot as plt\\nfrom scipy.misc import derivative\\nfrom sympy import Eq,solve\\nfrom itertools import groupby\\nabsulom= 2.844 \\nsigma= 0.34 \\ndef potential(a):\\n\\ta1= np.array([3/2*a,3.**0.5/2.*a])\\n\\ta2= np.array([3/2*a,-3.**0.5/2.*a])\\n\\tnmax = 10\\n\\tcoordsA =[ i * a1 + j* a2 for i in range(-nmax,nmax) for j in range(-nmax,nmax)]\\n\\tcoordsB= [i * a1 + j* a2 + [a,0.] for i in range(-nmax,nmax) for j in range(-nmax,nmax)]\\n\\tdistance1=[((- coordsA[k][0])**2+(-coordsA[k][1])**2)**0.5 for k in range(len(coordsA)-1)]\\n\\tdistance1= [round(num, 5.) for num in distance1]\\n\\tdistance2=[((- coordsB[s][0])**2+(-coordsB[s][1])**2)**0.5 for s in range(len(coordsB)-1)]\\n\\tdistance2= [round(num, 5.) for num in distance2]\\n\\tdistance=distance1+distance2\\n\\tdistance.sort()\\n\\tdistance.pop(0)\\n\\tgrouped_neighbors=[list(j) for i, j in groupby(distance)]\\n\\twoutrep=[grouped_neighbors[v][0]for v in range(31)]\\n\\tU=0\\n\\tfor t in range(30):\\n\\t\\tV=2*absulom*((sigma/grouped_neighbors[t][0])**12-(sigma/grouped_neighbors[t][0])**6)*np.size(grouped_neighbors[t])\\n\\t\\tU=U+V\\na = smp.symbols('a', real=True)\\nf = potential(a)\",\n",
       " \"import numpy\\nimport pandas\\nimport geopandas\\nimport pysal\\nimport seaborn\\nimport contextily\\nimport matplotlib.pyplot as plt\\nCH_points = gpd.read_file('CH_points04.shp')\\nprint(CH_points.crs)\\nCH_points_3857 = CH_points.to_crs(&quot;epsg:3857&quot;)\\nprint(CH_points_3857.crs)\",\n",
       " 'seaborn.jointplot(x = &quot;Longitude&quot;, y = &quot;Latitude&quot;, data = CH_points, s = 2.0);',\n",
       " 'f, ax = plt.subplots(1, figsize=(10, 10))\\nseaborn.kdeplot(\\n\\tCH_points_3857[&quot;X&quot;],\\n\\tCH_points_3857[&quot;Y&quot;],\\n\\tn_levels=50,\\n\\tshade=True,\\n\\talpha=0.55,\\n\\tcmap=&quot;viridis_r&quot;,\\n)\\ncontextily.add_basemap(\\n\\tax, crs = CH_points_3857.crs.to_string(), source=contextily.providers.OpenStreetMap.CH\\n)\\nax.set_axis_off()',\n",
       " 'pylint',\n",
       " 'python2.7',\n",
       " 'file.py',\n",
       " 'import attr\\nfrom base import BaseClass\\n@attr.s\\nclass MyClass(BaseClass):\\n  def set_ids(self, args):\\n\\tif id not in self.daily.obj_dict:\\n\\t  print(&quot;testing&quot;)',\n",
       " 'base.py',\n",
       " 'from abc import ABCMeta, abstractmethod\\nfrom six import with_metaclass\\nfrom daily import Daily\\nclass BaseClass(with_metaclass(ABCMeta, object)):\\n  @abstractmethod\\n  def set_ids(self, args):\\n\\tpass\\n  def process(self, vals, ids):\\n\\tobj_dict = {\\n\\t  id: vals[id]\\n\\t  for id in ids\\n\\t}\\n\\tself.daily = Daily(obj_dict)',\n",
       " 'daily.py',\n",
       " 'import attr\\nfrom builtins import object\\n@attr.s(frozen=True)\\nclass Daily(object):\\n\\tobj_dict = attr.ib(default=None)',\n",
       " 'python2.7 -m pylint file.py',\n",
       " \"E:  8,17: Value 'self.daily.obj_dict' doesn't support membership test (unsupported-membership-test)\",\n",
       " 'dict',\n",
       " 'python2.7',\n",
       " \"df1 = pd.DataFrame({'Col1' : ['A_B_C', 'A_B_C', 'A_B_C', 'D_E_F', 'D_E_F', 'G_H', 'A_B_C'],\\n\\t\\t\\t\\t\\t'Col2' : ['red', 'red', 'red', 'ash', 'ash', 'green', 'red']})\\ndf1\",\n",
       " \"df2 = pd.DataFrame({'ID_Number' : [100, 200, 300, 400, 500],\\n\\t\\t\\t\\t\\t'Col1' : ['A_B_C', 'D_E_F','G_H', 'DD', 'WW'],\\n\\t\\t\\t\\t\\t'Col2' : ['red',  'ash', 'green', 'black', 'sky']})\\ndf2\",\n",
       " 'ID_Number Col1   Col2\\n100   A_B_C  red\\n100   A_B_C  red\\n100   A_B_C  red\\n200   D_E_F  ash\\n200   D_E_F  ash\\n300   G_H\\tgreen\\n100   A_B_C  red',\n",
       " \"My_desire_df = df2['Col1'].map(df1.set_index('Col1')['ID_Number']) My_desire_df\",\n",
       " 'ID_Number Col1   Col2\\n100   A_B_C  red\\n100   A_B_C  red\\n100   A_B_C  red\\n200   D_E_F  ash\\n200   D_E_F  ash\\n300   G_H\\tgreen\\n100   A_B_C  red',\n",
       " 'cmd /c &lt;name-of-app&gt;.exe',\n",
       " 'usage: MyApp [-h] [-c CONFIG] [-C CACHE] [-l LOG] [--devices] [--default-config]\\nMyApp: error: unrecognized arguments: /home/myapp/MyApp',\n",
       " 'debian11',\n",
       " '3.9.2',\n",
       " '5.7.0',\n",
       " \"class RestartCommand(Command):\\n\\xa0 \\xa0 @property\\n\\xa0 \\xa0 def help(self) -&gt; str:\\n\\xa0 \\xa0 \\xa0 \\xa0 return &quot;Restarts the app&quot;\\n\\xa0 \\xa0 def __call__(self, arg: str, user: User) -&gt; Optional[str]:\\n\\xa0 \\xa0 \\xa0 \\xa0 self._myapp.close()\\n\\xa0 \\xa0 \\xa0 \\xa0 try:\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 if 'frozen' in sys.builtin_module_names:\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 executable = sys.executable\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 if sys.platform == &quot;win32&quot;:\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 subprocess.run([executable] + sys.argv[1:])\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 else:\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 subprocess.run([executable, &quot;-m&quot;, &quot;__main__&quot;] + sys.argv[1:])\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 else:\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 args = sys.argv\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 if sys.platform == &quot;win32&quot;:\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 subprocess.run([sys.executable] + args)\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 else:\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 args.insert(0, sys.executable)\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 os.execv(sys.executable, args)\\n\\xa0 \\xa0 \\xa0 \\xa0 except Exception as e:\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 print(&quot;Error while restarting: &quot;, e)\",\n",
       " \"\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 if 'frozen' in sys.builtin_module_names:\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 executable = sys.executable\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 if sys.platform == &quot;win32&quot;:\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 subprocess.run([executable])\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 else:\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 subprocess.run([executable, &quot;-m&quot;, &quot;__main__&quot;])\",\n",
       " 'sst',\n",
       " 'Dataset',\n",
       " \"class CustomDataset(Dataset):\\n\\tdef __init__(self, dataframe):\\n\\t\\tself.dataframe = dataframe\\n\\t\\tself.column_names = ['text','label']\\n\\tdef __getitem__(self, index):\\n\\t\\tprint('index: ',index)\\n\\t\\trow = self.dataframe.iloc[index].to_numpy()\\n\\t\\tfeatures = row[1:]\\n\\t\\tlabel = row[0]\\n\\t\\treturn features, label\\n\\tdef __len__(self):\\n\\t\\treturn len(self.dataframe)\\ndf = pd.DataFrame(np.array([\\n\\t[&quot;hello&quot;, 0] ,\\n\\t[&quot;sex&quot;, 1] ,\\n\\t[&quot;beshi kore sex&quot;, 1],]),\\n  columns=['text','label'])\\ndataset = CustomDataset(dataframe=df)\",\n",
       " 'Dataset',\n",
       " 'Cannot index by location index with a non-integer key',\n",
       " 'df.iloc[0].to_numpy()',\n",
       " 'index:  text',\n",
       " \"from sentence_transformers.losses import CosineSimilarityLoss\\nfrom torch.utils.data import Dataset\\nimport pandas as pd\\nimport numpy as np\\nfrom setfit import SetFitModel, SetFitTrainer, sample_dataset\\nclass CustomDataset(Dataset):\\n\\tdef __init__(self, dataframe):\\n\\t\\tself.dataframe = dataframe\\n\\t\\tself.column_names = ['id','text','label']\\n\\tdef __getitem__(self, index):\\n\\t\\tprint('index: ',index)\\n\\t\\trow = self.dataframe.iloc[index].to_numpy()\\n\\t\\tfeatures = row[1:]\\n\\t\\tlabel = row[0]\\n\\t\\treturn features, label\\n\\tdef __len__(self):\\n\\t\\treturn len(self.dataframe)\\ndf = pd.DataFrame(np.array([ [1,&quot;hello&quot;, 0] ,\\n[2,&quot;sex&quot;, 1] ,\\n[3,&quot;beshi kore sex&quot;, 1],]),columns=['id','text','label'])\\ndataset = CustomDataset(dataframe=df)\\ntrain_dataset = dataset\\neval_dataset = dataset\\nmodel = SetFitModel.from_pretrained(&quot;sentence-transformers/paraphrase-mpnet-base-v2&quot;)\\ntrainer = SetFitTrainer(\\n\\tmodel=model,\\n\\ttrain_dataset=train_dataset,\\n\\teval_dataset=eval_dataset,\\n\\tloss_class=CosineSimilarityLoss,\\n\\tmetric=&quot;accuracy&quot;,\\n\\tbatch_size=16,\\n\\tnum_iterations=1, \\n\\tnum_epochs=1, \\n)\\ntrainer.train()\",\n",
       " 'import bert  from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights',\n",
       " \"if load == 'y':\\n\\tprint('Loading...')\\n\\tsleep(1)\\n\\tprint(line)\\n\\tloading_screen(os)\\n\\tplaysound(&quot;windows_startup_sound.wav&quot;)\",\n",
       " '\\tError 259 for command:\\n\\t\\tplay windows_startup_sound.wav wait\\n\\tThe driver cannot recognize the specified command parameter.\\n\\tError 263 for command:\\n\\t\\tclose windows_startup_sound.wav\\n\\tThe specified device is not open or is not recognized by MCI.\\nFailed to close the file: windows_startup_sound.wav',\n",
       " \"elif cmd == 'open_Telegram':\\n\\ttext = &quot;Запускаю телеграм&quot;\\n\\ttts.va_speak(text)\\n\\tos.startfile('C:\\\\Users\\\\likop\\\\AppData\\\\Roaming\\\\Telegram Desktop\\\\Telegram.exe')\",\n",
       " \"[WinError 32] Процесс не может получить доступ к файлу, так как этот файл занят другим процессом: 'C:\\\\\\\\Users\\\\\\\\likop\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Temp\\\\\\\\tmp9t13ry7t'\",\n",
       " 'MainDirectory\\\\\\n   prj\\\\\\n\\t   api\\\\\\n\\t\\t  a.py\\n*\\t\\t\\t from b import B\\n\\t\\t\\t  class A:\\n\\t\\t\\t\\t  ...\\n\\t\\t  b.py\\n\\t\\t\\t  class B:\\n\\t\\t\\t\\t  ...\\n   app.py\\n\\t  from prj.api.a import A',\n",
       " '\\tdist/\\n\\t  frontend/\\n\\t\\tassets/\\n\\t\\t  images/...\\n\\t\\tindex.html\\n\\t\\tfavicon.ico\\n\\t\\tsome_relevant_js_files.js\\n\\ttest_project/\\n\\t  __init__.py\\n\\t  asgi.py\\n\\t  urls.py\\n\\t  settings.py\\n\\t  wsgi.py',\n",
       " 'server {\\n\\t\\tlisten 80;\\n\\t\\tserver_name IP_ADDRESS www.DOMAIN_NAME DOMAIN_NAME;\\n\\t\\tlocation = /favicon.ico { access_log off; log_not_found off; }\\n\\t\\tlocation /api/ {\\n\\t\\t\\t\\tinclude proxy_params;\\n\\t\\t\\t\\tproxy_pass http://unix:/run/gunicorn.sock;\\n\\t\\t}\\n\\t\\tlocation / {\\n\\t\\t\\t\\troot /home/USER_NAME/projectdir/test_project/dist/frontend;\\n\\t\\t\\t\\ttry_files /index.html $uri $uri/;\\n\\t\\t}\\n}',\n",
       " \"\\ttimeframe = '1h'\\ndef populate_indicators(self, dataframe: DataFrame, metadata: dict) -&gt; DataFrame:\\n\\t\\t.\\n\\t\\t.\\n\\t\\tpass\\ndef populate_entry_trend(self, dataframe: DataFrame, metadata: dict) -&gt; DataFrame:\\n\\t\\t.\\n\\t\\t.\\n\\t\\tpass\\ndef populate_exit_trend(self, dataframe: DataFrame, metadata: dict) -&gt; DataFrame:\\n\\t\\t.\\n\\t\\t.\\n\\t\\tpass\",\n",
       " 'def populate_indicators,def populate_entry_trend,def populate_exit_trend',\n",
       " \"import yasa\\nimport pandas as pd\\ndata = pd.Series([4, 8, 7, 1, 2, 3, 5],\\nindex=['F4', 'F3', 'C4', 'C3', 'P3', 'P4', 'Oz'],\\nname='Values'\\nyasa.topoplot(data,title='My first topoplot')\",\n",
       " \"TypeError: plot_topomap() got an unexpeced keyword argument 'vmin't\",\n",
       " \"\\tfull_url = f'https://&lt;company_name&gt;.sharepoint.com/sites/&lt;site_folder&gt;/'\\n\\trelative_url = f'Shared Documents/General/3.PAYMENTS Operations/TIES/CRS Report files'\\n\\tctx = get_sharepoint_context_using_user()\\n\\tprint(ctx)\\n\\ttarget_folder = ctx.web.get_folder_by_server_relative_url(relative_url)\\n\\tprint(target_folder)\\n\\twith open(temp_file, 'rb') as content_file:\\n\\t\\tfile_content = content_file.read()\\n\\t\\ttarget_folder.upload_file(temp_file, file_content).execute_query()\",\n",
       " \"\\ts3 = Aws::S3::Client.new(region: 'eu-west-3')\\n\\timage_data = s3.get_object(bucket: &quot;bucket-name&quot;, key: &quot;file-name&quot;)\\n\\timage_data.body\",\n",
       " \"m = df['ZWECK'].eq(7)\\nsubdfs = [d for _,d in df[~m].groupby(m.cumsum())]\",\n",
       " 'Query([User, Phone].select_from(User).join(Phone, Phone.user_id == User.id).filter(User.id == the_user)',\n",
       " 'from SPARQLWrapper import SPARQLWrapper, JSON, XML, N3, RDF\\nsparql = SPARQLWrapper(&quot;http://dbpedia.org/sparql&quot;)\\nsparql.setQuery(&quot;&quot;&quot;\\n\\tPREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema\\n\\tSELECT ?label\\n\\tWHERE { &lt;http://dbpedia.org/resource/Asturias&gt; rdfs:label ?label }\\n&quot;&quot;&quot;)\\nprint(sparql)\\nsparql.setReturnFormat(JSON)\\nresults = sparql.query()\\nresults = results.convert()\\nfor result in results[&quot;results&quot;][&quot;bindings&quot;]:\\n\\tprint (result[&quot;label&quot;][&quot;value&quot;])',\n",
       " 'Traceback (most recent call last):\\n  File &quot;D:\\\\All_python_projects\\\\geometric_learning\\\\SPARQL_test.py&quot;, line 11, in &lt;module&gt;\\n\\tresults = sparql.query()\\n  File &quot;D:\\\\Anaconda\\\\envs\\\\normal\\\\lib\\\\site-packages\\\\SPARQLWrapper\\\\Wrapper.py&quot;, line 960, in query\\n\\treturn QueryResult(self._query())\\n  File &quot;D:\\\\Anaconda\\\\envs\\\\normal\\\\lib\\\\site-packages\\\\SPARQLWrapper\\\\Wrapper.py&quot;, line 926, in _query\\n\\tresponse = urlopener(request)\\n  File &quot;D:\\\\Anaconda\\\\envs\\\\normal\\\\lib\\\\urllib\\\\request.py&quot;, line 214, in urlopen\\n\\treturn opener.open(url, data, timeout)\\n  File &quot;D:\\\\Anaconda\\\\envs\\\\normal\\\\lib\\\\urllib\\\\request.py&quot;, line 517, in open\\n\\tresponse = self._open(req, data)\\n  File &quot;D:\\\\Anaconda\\\\envs\\\\normal\\\\lib\\\\urllib\\\\request.py&quot;, line 534, in _open\\n\\tresult = self._call_chain(self.handle_open, protocol, protocol +\\n  File &quot;D:\\\\Anaconda\\\\envs\\\\normal\\\\lib\\\\urllib\\\\request.py&quot;, line 494, in _call_chain\\n\\tresult = func(*args)\\n  File &quot;D:\\\\Anaconda\\\\envs\\\\normal\\\\lib\\\\urllib\\\\request.py&quot;, line 1375, in http_open\\n\\treturn self.do_open(http.client.HTTPConnection, req)\\n  File &quot;D:\\\\Anaconda\\\\envs\\\\normal\\\\lib\\\\urllib\\\\request.py&quot;, line 1350, in do_open\\n\\tr = h.getresponse()\\n  File &quot;D:\\\\Anaconda\\\\envs\\\\normal\\\\lib\\\\http\\\\client.py&quot;, line 1377, in getresponse\\n\\tresponse.begin()\\n  File &quot;D:\\\\Anaconda\\\\envs\\\\normal\\\\lib\\\\http\\\\client.py&quot;, line 320, in begin\\n\\tversion, status, reason = self._read_status()\\n  File &quot;D:\\\\Anaconda\\\\envs\\\\normal\\\\lib\\\\http\\\\client.py&quot;, line 281, in _read_status\\n\\tline = str(self.fp.readline(_MAXLINE + 1), &quot;iso-8859-1&quot;)\\n  File &quot;D:\\\\Anaconda\\\\envs\\\\normal\\\\lib\\\\socket.py&quot;, line 704, in readinto\\n\\treturn self._sock.recv_into(b)\\nConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。',\n",
       " \"X = [i for i in range(100)]\\npositions = [i for i in permutations(X,2)]\\npositions += [(i,i) for i in range(100)]\\nAPC = np.array([placeCells(i) for i in positions])\\ncrit = [np.dot(CriticWeights.T, APC[i]) for i in range(len(positions))]\\nxx,yy = zip(*positions)\\nflatX = [item for item in list(xx)]\\nflatY = [item for item in list(yy)]\\ndf = pd.DataFrame({&quot;X&quot;: flatX, &quot;Y&quot;: flatY, &quot;V&quot;: crit})\\ndf = df.astype('float')\\nHeatmap = df.pivot(index=&quot;X&quot;, columns=&quot;Y&quot;, values='V')\\nsn.heatmap(Heatmap, linewidths = 1, linecolor = &quot;black&quot;)\\nplt.show()\",\n",
       " \"import polars as pl\\ndata = ['// 2023.09.01.',\\n\\t\\t'var mydata = [',\\n\\t\\t'[11.407538,22.003241,51,,&quot;L&quot;,&quot;T&quot;,,67',\\n\\t\\t'[12.547899,21.033232,112,,&quot;L&quot;,&quot;T&quot;,,139',\\n\\t\\t'];']\\ndf = pl.DataFrame(data, schema=['X'])\\ndf.write_csv('myfile.js', has_header = False, quote_style = None)\",\n",
       " \"import socket\\nimport struct\\nimport time\\nimport numpy as np\\nimport sys\\nUDP_IP = &quot;127.0.0.1&quot;\\nUDP_PORT = 2000\\nsock = socket.socket(socket.AF_INET, \\n\\t\\t\\t\\t\\t socket.SOCK_DGRAM) \\nsock.bind((UDP_IP, UDP_PORT))\\ndata_fifo = []\\ndef receive_data():\\n\\twhile True:\\n\\t\\tdata, addr = sock.recvfrom(1472) \\n\\t\\ttemp = struct.unpack('368f', data)\\n\\t\\tdata_fifo.extend(temp)\",\n",
       " \"import gradio as gr\\nimport torch\\nimport numpy as np\\nimport modin.pandas as pd\\nfrom PIL import Image\\nfrom diffusers import DiffusionPipeline\\nimport os\\nos.environ[&quot;PYTORCH_MPS_HIGH_WATERMARK_RATIO&quot;] = &quot;0.0&quot;\\ndevice = 'cuda' if torch.cuda.is_available() else 'mps'\\nif torch.cuda.is_available():\\n\\tPYTORCH_CUDA_ALLOC_CONF = {'max_split_size_mb': 8000}\\n\\ttorch.cuda.max_memory_allocated(device=device)\\n\\ttorch.cuda.empty_cache()\\n\\tpipe = DiffusionPipeline.from_pretrained(&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;, torch_dtype=torch.float16,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t variant=&quot;fp16&quot;, use_safetensors=True)\\n\\tpipe.enable_xformers_memory_efficient_attention()\\n\\tpipe = pipe.to(device)\\n\\ttorch.cuda.empty_cache()\\n\\trefiner = DiffusionPipeline.from_pretrained(&quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;, use_safetensors=True,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ttorch_dtype=torch.float16, variant=&quot;fp16&quot;)\\n\\trefiner.enable_xformers_memory_efficient_attention()\\n\\trefiner = refiner.to(device)\\n\\ttorch.cuda.empty_cache()\\n\\tupscaler = DiffusionPipeline.from_pretrained(&quot;stabilityai/sd-x2-latent-upscaler&quot;, torch_dtype=torch.float16,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t use_safetensors=True)\\n\\tupscaler.enable_xformers_memory_efficient_attention()\\n\\tupscaler = upscaler.to(device)\\n\\ttorch.cuda.empty_cache()\\nelse:\\n\\tpipe = DiffusionPipeline.from_pretrained(&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;, use_safetensors=True)\\n\\tpipe = pipe.to(device)\\n\\tpipe.unet = torch.compile(pipe.unet, mode=&quot;reduce-overhead&quot;, fullgraph=True)\\n\\trefiner = DiffusionPipeline.from_pretrained(&quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;, use_safetensors=True)\\n\\trefiner = refiner.to(device)\\n\\trefiner.unet = torch.compile(refiner.unet, mode=&quot;reduce-overhead&quot;, fullgraph=True)\\nn_steps = 40\\nhigh_noise_frac = 0.8\\npipe.enable_attention_slicing()\\nPYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0\\ndef genie(prompt, negative_prompt, height, width, scale, steps, seed, upscaling, prompt_2, negative_prompt_2):\\n\\tgenerator = torch.Generator(device=device).manual_seed(seed)\\n\\tint_image = pipe(prompt, prompt_2=prompt_2, negative_prompt=negative_prompt, negative_prompt_2=negative_prompt_2,\\n\\t\\t\\t\\t\\t num_inference_steps=steps, height=height, width=width, guidance_scale=scale,\\n\\t\\t\\t\\t\\t num_images_per_prompt=1, generator=generator, output_type=&quot;latent&quot;).images\\n\\tif upscaling == 'Yes':\\n\\t\\timage = \\\\\\n\\t\\t\\trefiner(prompt=prompt, prompt_2=prompt_2, negative_prompt=negative_prompt,\\n\\t\\t\\t\\t\\tnegative_prompt_2=negative_prompt_2,\\n\\t\\t\\t\\t\\timage=int_image).images[0]\\n\\t\\tupscaled = upscaler(prompt=prompt, negative_prompt=negative_prompt, image=image, num_inference_steps=5,\\n\\t\\t\\t\\t\\t\\t\\tguidance_scale=0).images[0]\\n\\t\\ttorch.cuda.empty_cache()\\n\\t\\treturn (image, upscaled)\\n\\telse:\\n\\t\\timage = \\\\\\n\\t\\t\\trefiner(prompt=prompt, prompt_2=prompt_2, negative_prompt=negative_prompt,\\n\\t\\t\\t\\t\\tnegative_prompt_2=negative_prompt_2,\\n\\t\\t\\t\\t\\timage=int_image).images[0]\\n\\t\\ttorch.cuda.empty_cache()\\n\\treturn (image, image)\\ngr.Interface(fn=genie, inputs=[gr.Textbox(\\n\\tlabel='What you want the AI to generate. 77 Token Limit. A Token is Any Word, Number, Symbol, or Punctuation. Everything Over 77 Will Be Truncated!'),\\n\\tgr.Textbox(label='What you Do Not want the AI to generate. 77 Token Limit'),\\n\\tgr.Slider(512, 1024, 768, step=128, label='Height'),\\n\\tgr.Slider(512, 1024, 768, step=128, label='Width'),\\n\\tgr.Slider(1, 15, 10, step=.25,\\n\\t\\t\\t  label='Guidance Scale: How Closely the AI follows the Prompt'),\\n\\tgr.Slider(25, maximum=100, value=50, step=25, label='Number of Iterations'),\\n\\tgr.Slider(minimum=1, step=1, maximum=999999999999999999, randomize=True, label='Seed'),\\n\\tgr.Radio(['Yes', 'No'], value='No', label='Upscale?'),\\n\\tgr.Textbox(label='Embedded Prompt'),\\n\\tgr.Textbox(label='Embedded Negative Prompt')],\\n\\t\\t\\t outputs=['image', 'image'],\\n\\t\\t\\t title=&quot;Stable Diffusion XL 1.0 GPU&quot;,\\n\\t\\t\\t description=&quot;SDXL 1.0 GPU. &lt;br&gt;&lt;br&gt;&lt;b&gt;WARNING: Capable of producing NSFW (Softcore) images.&lt;/b&gt;&quot;,\\n\\t\\t\\t article=&quot;If You Enjoyed this Demo and would like to Donate, you can send to any of these Wallets. &lt;br&gt;BTC: bc1qzdm9j73mj8ucwwtsjx4x4ylyfvr6kp7svzjn84 &lt;br&gt;3LWRoKYx6bCLnUrKEdnPo3FCSPQUSFDjFP &lt;br&gt;DOGE: DK6LRc4gfefdCTRk9xPD239N31jh9GjKez &lt;br&gt;SHIB (BEP20): 0xbE8f2f3B71DFEB84E5F7E3aae1909d60658aB891 &lt;br&gt;PayPal: https://www.paypal.me/ManjushriBodhisattva &lt;br&gt;ETH: 0xbE8f2f3B71DFEB84E5F7E3aae1909d60658aB891 &lt;br&gt;Code Monkey: &lt;a href=\\\\&quot;https://huggingface.co/Manjushri\\\\&quot;&gt;Manjushri&lt;/a&gt;&quot;).launch(\\n\\tdebug=True, max_threads=80)\",\n",
       " 'huggingface',\n",
       " 'step_index = (self.timesteps == timestep).nonzero().item()\\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nRuntimeError: Expected dst.dim() &gt;= src.dim() to be true, but got false. (Could this error message be improved? If so, please report an enhancement request to PyTorch.)',\n",
       " 'NVIDIA Jetson Nano Developer Kit\\nJetPack: 4.6.2\\nOS: Ubuntu 18.04.6 LTS\\nKernel Version: 4.9.253-tegra\\nCUDA: 10.2.300\\nCUDNN: 8.2.1.32\\nTensorRT: 8.2.1.8\\nVision Works: 1.6.0.501\\nVPI: 1.2.3\\nVulcan: 1.2.70',\n",
       " 'Pytorch 1.10.2',\n",
       " \"import torch\\nimport torchvision\\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\\nNUM_CLASSES = 2\\nCLASSES = ['__background__', 'license-plate']\\nDEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\\nOUT_DIR = ''\\nWEIGHTS_PATH = 'best_model.pth'\\ndef create_model(num_classes, pretrained=True):\\n\\tmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn()\\n\\tin_features = model.roi_heads.box_predictor.cls_score.in_features\\n\\tmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\\n\\treturn model\\ndef main():\\n\\tcheckpoint = torch.load(WEIGHTS_PATH, map_location=DEVICE)\\n\\tmodel = create_model(num_classes=NUM_CLASSES, coco_model=False)\\n\\tmodel.load_state_dict(checkpoint['model_state_dict'])\\n\\tmodel.to(DEVICE).eval()\\n\\tmodel_scripted = torch.jit.script(model)\\n\\tmodel_scripted.save('model_scripted.pt')\\nmain()\",\n",
       " \"Traceback (most recent call last):\\n  File &quot;jetson_inference.py&quot;, line 34, in &lt;module&gt;\\n\\tmain()\\n  File &quot;jetson_inference.py&quot;, line 29, in main\\n\\tmodel.load_state_dict(checkpoint['model_state_dict'])\\n  File &quot;/home/vha/.local/lib/python3.6/site-packages/torch/nn/modules/module.py&quot;, line 1483, in load_state_dict\\n\\tself.__class__.__name__, &quot;\\\\n\\\\t&quot;.join(error_msgs)))\\nRuntimeError: Error(s) in loading state_dict for FasterRCNN:\\n\\tMissing key(s) in state_dict: &quot;backbone.fpn.inner_blocks.0.weight&quot;, &quot;backbone.fpn.inner_blocks.0.bias&quot;, &quot;backbone.fpn.inner_blocks.1.weight&quot;, &quot;backbone.fpn.inner_blocks.1.bias&quot;, &quot;backbone.fpn.inner_blocks.2.weight&quot;, &quot;backbone.fpn.inner_blocks.2.bias&quot;, &quot;backbone.fpn.inner_blocks.3.weight&quot;, &quot;backbone.fpn.inner_blocks.3.bias&quot;, &quot;backbone.fpn.layer_blocks.0.weight&quot;, &quot;backbone.fpn.layer_blocks.0.bias&quot;, &quot;backbone.fpn.layer_blocks.1.weight&quot;, &quot;backbone.fpn.layer_blocks.1.bias&quot;, &quot;backbone.fpn.layer_blocks.2.weight&quot;, &quot;backbone.fpn.layer_blocks.2.bias&quot;, &quot;backbone.fpn.layer_blocks.3.weight&quot;, &quot;backbone.fpn.layer_blocks.3.bias&quot;, &quot;rpn.head.conv.weight&quot;, &quot;rpn.head.conv.bias&quot;.\\n\\tUnexpected key(s) in state_dict: &quot;backbone.fpn.inner_blocks.0.0.weight&quot;, &quot;backbone.fpn.inner_blocks.0.0.bias&quot;, &quot;backbone.fpn.inner_blocks.1.0.weight&quot;, &quot;backbone.fpn.inner_blocks.1.0.bias&quot;, &quot;backbone.fpn.inner_blocks.2.0.weight&quot;, &quot;backbone.fpn.inner_blocks.2.0.bias&quot;, &quot;backbone.fpn.inner_blocks.3.0.weight&quot;, &quot;backbone.fpn.inner_blocks.3.0.bias&quot;, &quot;backbone.fpn.layer_blocks.0.0.weight&quot;, &quot;backbone.fpn.layer_blocks.0.0.bias&quot;, &quot;backbone.fpn.layer_blocks.1.0.weight&quot;, &quot;backbone.fpn.layer_blocks.1.0.bias&quot;, &quot;backbone.fpn.layer_blocks.2.0.weight&quot;, &quot;backbone.fpn.layer_blocks.2.0.bias&quot;, &quot;backbone.fpn.layer_blocks.3.0.weight&quot;, &quot;backbone.fpn.layer_blocks.3.0.bias&quot;, &quot;rpn.head.conv.0.0.weight&quot;, &quot;rpn.head.conv.0.0.bias&quot;.\",\n",
       " \"import requests\\nfrom threading import Thread\\nclass WithThreads:\\n  facts = []\\n  percentages = []\\n  threads = []\\n  HEADERS = {\\n\\t'X-RapidAPI-Key': 'API-KEY',\\n\\t'X-RapidAPI-Host': 'text-similarity-calculator.p.rapidapi.com'\\n  }\\n  @staticmethod\\n  def join_all(threads):\\n\\t&quot;&quot;&quot;\\n\\tJoin all threads in the array and clear the array.\\n\\t&quot;&quot;&quot;\\n\\twhile threads:\\n\\t  thread = threads.pop()\\n\\t  thread.join()\\n  def get_facts(self):\\n\\t&quot;&quot;&quot;\\n\\tCalls the first API n times with different parameters. (In real life.)\\n\\tShould ideally yield.\\n\\t&quot;&quot;&quot;\\n\\tfor _ in range(10):\\n\\t  thread = Thread(target=self.get_fact)\\n\\t  self.threads.append(thread)\\n\\t  thread.start()\\n  def get_fact(self):\\n\\t&quot;&quot;&quot;\\n\\tCalls the first API once.\\n\\t&quot;&quot;&quot;\\n\\tself.facts.append(requests.get('https://catfact.ninja/fact',\\n\\t   headers=self.HEADERS).json()['fact'])\\n  def get_percentage(self, ftext, stext):\\n\\t&quot;&quot;&quot;\\n\\tCalls the second API once.\\n\\t&quot;&quot;&quot;\\n\\tresponse = requests.get('https://text-similarity-calculator.p.rapidapi.com/'\\n\\t\\t\\t\\t\\t\\t\\tf'stringcalculator.php?ftext={ftext}&amp;stext={stext}',\\n\\t\\t\\t\\t\\t\\t\\theaders=self.HEADERS)\\n\\tself.percentages.append(response.json()['percentage'] + '%')\\n  def get_percentages(self):\\n\\t&quot;&quot;&quot;\\n\\tThis is the main class to be called.\\n\\tFeeds the result of the first API into the second API,\\n\\tuses threads instead of asyncio.\\n\\t&quot;&quot;&quot;\\n\\tself.get_facts()\\n\\tself.join_all(self.threads)\\n\\tfirst = self.facts[0]\\n\\tprevious = first\\n\\tfor fact in self.facts[1:]:\\n\\t  thread = Thread(target=self.get_percentage, args=(previous, fact))\\n\\t  self.threads.append(thread)\\n\\t  thread.start()\\n\\t  previous = fact\\n\\tthread = Thread(target=self.get_percentage, args=(previous, first))\\n\\tself.threads.append(thread)\\n\\tthread.start()\\n\\tself.join_all(self.threads)\\n\\treturn self.percentages\",\n",
       " 'ftext',\n",
       " 'stext',\n",
       " \"import requests\\nurl = 'http://localhost:80/project/php/files.php'\\nfile_path = 'C:\\\\\\\\wamp64\\\\\\\\www\\\\\\\\project\\\\\\\\python\\\\\\\\New folder\\\\\\\\directory_listing.txt'\\nwith open(file_path, 'rb') as file:\\n\\tfiles = {'file': file}\\n\\theaders = {'Content-Type': 'multipart/form-data'}\\n\\tresponse = requests.post(url, files=files, headers=headers)\\nprint(response.text)\",\n",
       " '&lt;?php\\n$target_dir = &quot;files_list/&quot;;\\nif (isset($_FILES[&quot;file&quot;])) {\\n\\t$target_file = $target_dir . basename($_FILES[&quot;file&quot;][&quot;name&quot;]);\\n\\tif (move_uploaded_file($_FILES[&quot;file&quot;][&quot;tmp_name&quot;], $target_file)) {\\n\\t\\techo &quot;The file &quot; . basename($_FILES[&quot;file&quot;][&quot;name&quot;]) . &quot; has been uploaded and moved.&quot;;\\n\\t} else {\\n\\t\\techo &quot;Error uploading file.&quot;;\\n\\t}\\n} else {\\n\\techo &quot;No file uploaded.&quot;;\\n}\\n?&gt;',\n",
       " \"\\timport cv2\\n\\timport numpy as np\\n\\timport json\\n\\timport onnxruntime as rt\\n\\tfrom PIL import Image\\n\\timport matplotlib.pyplot as plt\\n\\timport matplotlib.patches as patches\\n\\timport rasterio\\n\\ttile_size = (640, 640)\\n\\tstride = (320, 320)  \\n\\tsess = rt.InferenceSession('C:/Users/User/anaconda3/envs/taxnature/Contador_plantas_versiones/runs/detect/train4/weights/best.onnx')\\n\\tinput_name = sess.get_inputs()[0].name\\n\\twith rasterio.open('set_1_count_plants.tif') as src:\\n\\t\\timg_array = src.read([1, 2, 3], out_dtype='uint8')  \\n\\t\\timg = Image.fromarray(img_array.transpose([1, 2, 0]))  \\n\\timg_jpeg = img.convert(&quot;RGB&quot;)\\n\\timg_jpeg.save('set_1_count_plants.jpeg')\\n\\timagen = cv2.imread('set_1_count_plants.jpeg')\\n\\toriginal_height, original_width = imagen.shape[:2]\\n\\tscale_x, scale_y = original_width / tile_size[0], original_height / tile_size[1]\\n\\tdef process_image(img):\\n\\t\\timg = cv2.resize(img, tile_size)\\n\\t\\timg = np.expand_dims(img, axis=0)\\n\\t\\timg = img.astype('float32') / 255\\n\\t\\timg = np.transpose(img, (0, 3, 1, 2))\\n\\t\\tresult = sess.run(None, {input_name: img})[0]\\n\\t\\treturn result\\n\\tdef process_output(output, confidence_threshold=0.5):\\n\\t\\tdetections = output[0]\\n\\t\\tvalid_boxes = []\\n\\t\\tfor detection in detections.T:\\n\\t\\t\\tx, y, width, height, confidence = detection\\n\\t\\t\\tif confidence &gt; confidence_threshold:\\n\\t\\t\\t\\tvalid_boxes.append([x - width / 2, y - height / 2, x + width / 2, y + height / 2])\\n\\t\\treturn valid_boxes\\n\\tdef sliding_window(image, stepSize, windowSize):\\n\\t\\tfor y in range(0, image.shape[0], stepSize[1]):\\n\\t\\t\\tfor x in range(0, image.shape[1], stepSize[0]):\\n\\t\\t\\t\\tyield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\\n\\tthreshold = 0.5\\n\\tall_boxes = []\\n\\tfor (x, y, window) in sliding_window(imagen, stride, tile_size):\\n\\t\\tif window.shape[0] != tile_size[1] or window.shape[1] != tile_size[0]:\\n\\t\\t\\tcontinue\\n\\t\\toutput = process_image(window)\\n\\t\\tvalid_boxes = process_output(output, threshold)\\n\\t\\tfor box in valid_boxes:\\n\\t\\t\\tbox[0] = box[0] * scale_x + x * scale_x\\n\\t\\t\\tbox[1] = box[1] * scale_y + y * scale_y\\n\\t\\t\\tbox[2] = box[2] * scale_x + x * scale_x\\n\\t\\t\\tbox[3] = box[3] * scale_y + y * scale_y\\n\\t\\t\\twidth = box[2] - box[0]\\n\\t\\t\\theight = box[3] - box[1]\\n\\t\\t\\tbox[0] -= width * 0.1\\n\\t\\t\\tbox[1] -= height * 0.1\\n\\t\\t\\tbox[2] += width * 0.1\\n\\t\\t\\tbox[3] += height * 0.1\\n\\t\\t\\tall_boxes.append(box)\\n\\twith open(&quot;boxes.json&quot;, &quot;w&quot;) as file:\\n\\t\\tjson.dump(all_boxes, file)\\n\\tfig, ax = plt.subplots(1)\\n\\tax.imshow(imagen)\\n\\tfor box in all_boxes:\\n\\t\\trect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1], linewidth=1, edgecolor='b', facecolor='none')\\n\\t\\tax.add_patch(rect)\\n\\ttotal_boxes = len(all_boxes)\\n\\tprint(f'Total bounding boxes: {total_boxes}')\\n\\tax.text(0.01, 0.95, f'Total bounding boxes: {total_boxes}', transform=ax.transAxes, color='green')\\n\\tplt.show()\",\n",
       " \"&lt;t t-name=&quot;ClientDetailsEdit&quot; t-inherit=&quot;point_of_sale.ClientDetailsEdit&quot; t-inherit-mode=&quot;extension&quot; owl=&quot;1&quot;&gt;\\n\\t&lt;xpath expr=&quot;//input[hasclass('client-name')]&quot; position=&quot;after&quot;&gt;\\n\\t\\t&lt;div class=&quot;client-detail&quot;&gt;\\n\\t\\t\\t&lt;div class='client-details-right mb-3' style=&quot;font-size: initial;&quot;&gt;\\n\\t\\t&lt;input class=&quot;detail&quot; name=&quot;numeroRUC&quot;\\n\\t\\t\\t\\t   t-on-change=&quot;captureChange&quot;\\n\\t\\t\\t\\t   placeholder=&quot;Número de RUC ()&quot; /&gt;\\n\\t\\t&lt;/div&gt;\\n\\t&lt;/xpath&gt;\\n&lt;/t&gt;\",\n",
       " 'import os\\nimport sys\\nimport time\\nimport tkinter as tk\\nclass Time:\\n\\tdef __init__(self):\\n\\t\\tself.Time_sleep()\\n\\t\\tself.Num_calc()\\n\\tdef Time_sleep(self):\\n\\t\\ttime.sleep(100)  \\n\\tdef Num_calc(self):\\n\\t\\tfor i in range(250000000):  \\n\\t\\t\\tpass\\nclass GUI:\\n\\tdef __init__(self):  \\n\\t\\tself.count = 3\\n\\t\\tself.root = tk.Tk()\\n\\t\\tself.root.geometry(&quot;1400x200&quot;)\\n\\t\\tself.integer_variable = tk.BooleanVar()\\n\\t\\tself.label = tk.Label(self.root, text=&quot;&quot;)\\n\\t\\tself.label.pack()\\n\\t\\tself.button = tk.Button(self.root, text=&quot;interruption&quot;, command=self.end)\\n\\t\\tself.button.pack()\\n\\t\\tself.label.after(1, lambda: self.countdown(self.count, self.processing, True))\\n\\tdef countdown(self, remaining, callback, coll):\\n\\t\\tif coll == False:\\n\\t\\t\\tpuo = &quot;\\\\nProcess is complete.&quot;\\n\\t\\t\\tpip = &quot;Closes&quot;\\n\\t\\t\\tself.button.pack_forget()\\n\\t\\telse:\\n\\t\\t\\tpuo = &quot;Execute the process&quot;\\n\\t\\t\\tpip = &quot;Starts&quot;\\n\\t\\tif remaining &lt;= 0:\\n\\t\\t\\tcallback()\\n\\t\\telse:\\n\\t\\t\\tself.root.title(&quot;Backup&quot;)\\n\\t\\t\\tself.label.configure(\\n\\t\\t\\t\\ttext=&quot;{}：{} after {} second&quot;.format(puo, pip,remaining), font=(&quot;Helvetica&quot;, 20)\\n\\t\\t\\t)\\n\\t\\t\\tself.root.after(1000, lambda: self.countdown(remaining - 1, callback, coll))\\n\\tdef processing(self):\\n\\t\\tself.label.configure(text=&quot;Processing&quot;, font=(&quot;Helvetica&quot;, 20))\\n\\t\\tself.root.update_idletasks()\\n\\t\\tTime_arg = Time()\\n\\t\\tself.countdown(5, self.end_taken, False)\\n\\tdef end(self):\\n\\t\\tself.integer_variable.set(False)\\n\\t\\tself.root.destroy()\\n\\tdef end_taken(self):\\n\\t\\tself.integer_variable.set(True)\\n\\t\\tself.root.destroy()\\nclass Interruption:\\n\\tdef __init__(self, app):\\n\\t\\tif app == False:\\n\\t\\t\\tself.root = tk.Tk()\\n\\t\\t\\tself.label = tk.Label(\\n\\t\\t\\t\\tself.root,\\n\\t\\t\\t\\ttext=&quot;Processing has been interrupted.&quot;,\\n\\t\\t\\t\\tfont=(&quot;Helvetica&quot;, 20),\\n\\t\\t\\t).pack()\\n\\t\\t\\tself.button = tk.Button(\\n\\t\\t\\t\\tself.root, text=&quot;Quit&quot;, command=self.root.destroy\\n\\t\\t\\t).pack()\\n\\t\\telse:\\n\\t\\t\\tself.root = tk.Tk()\\n\\t\\t\\tself.root.destroy()\\nif __name__ == &quot;__main__&quot;:\\n\\tGUI = GUI()\\n\\tGUI.root.mainloop()\\n\\tnum = GUI.integer_variable.get()\\n\\tInterruption(num).root.mainloop()',\n",
       " 'conda env create -f environment.yml',\n",
       " 'name: environment\\nchannels:\\n  - defaults\\ndependencies:\\n  - python = 3.9.12\\n  - pip:\\n\\t  - --index-url=https://bcms.bloomberg.com/pip/simple blpapi\\n\\t  - greenlet==2.0.1\\n\\t  - pyutil==3.3.0',\n",
       " 'Pip subprocess error:\\nERROR: Could not find a version that satisfies the requirement greenlet==2.0.1 (from versions: none)\\nERROR: No matching distribution found for greenlet==2.0.1\\nfailed\\nCondaEnvException: Pip failed',\n",
       " 'greenlet',\n",
       " 'sklearn.ensemble.StackingRegressor',\n",
       " '.fit()',\n",
       " 'sklearn.ensemble.MultiOutputRegressor',\n",
       " '+-----------------------+----+--------------+-------------------------------------------+----+-------------+----+------------------+\\n| Set of observations 1 | -&gt; | Base Model 1 |\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   |\\t|\\t\\t\\t |\\t|\\t\\t\\t\\t  |\\n|\\t(nsmpls, nfeats)   |\\t|\\t\\t\\t  |\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   |\\t|\\t\\t\\t |\\t|\\t\\t\\t\\t  |\\n+-----------------------+----+--------------+-------------------------------------------+----+-------------+----+------------------+\\n|\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   | Concatenated predictions from base models | -&gt; | Final model | -&gt; | Final prediction |\\n|\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   |\\t\\t\\t (nsmpls, 2 * nfeats)\\t\\t  |\\t|\\t\\t\\t |\\t| (nsmpls, nfeats) |\\n+-----------------------+----+--------------+-------------------------------------------+----+-------------+----+------------------+\\n| Set of observations 2 | -&gt; | Base Model 2 |\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   |\\t|\\t\\t\\t |\\t|\\t\\t\\t\\t  |\\n|\\t(nsmpls, nfeats)   |\\t|\\t\\t\\t  |\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   |\\t|\\t\\t\\t |\\t|\\t\\t\\t\\t  |\\n+-----------------------+----+--------------+-------------------------------------------+----+-------------+----+------------------+',\n",
       " \"ve() {\\n\\tlocal venv=&quot;virtual_env_ant&quot;\\n\\techo &quot;running install virtual env&quot;\\n\\techo &quot;Creating and activating virtual environment ${venv}&quot;\\n\\tsudo -u $USER /Users/my-device-username/Downloads/portable_python/bin/python3.9 -m venv $HOME/${venv} --system-site-package\\n\\techo $'appdirs==1.4.4\\\\ncertifi==2020.12.5\\\\nchardet==4.0.0\\\\ncolorama==0.4.4\\\\ncolorlog==4.8.0 \\\\neasydev==0.11.0\\\\nidna==2.10\\\\ngit+https://github.com/lark-parser/lark.git@5b8c04ca83b9\\n\\t$HOME/${venv}/bin/python3 -m pip --disable-pip-version-check install -t $HOME/${venv}/lib/python3.9/site-packages --no-cache-dir --upgrade -r $HOME/${venv}/all-requirements.txt &amp;&amp; success=1\\n}\\nve &quot;$@&quot;\",\n",
       " 'cd /Users/my-device-username/Downloads',\n",
       " 'git clone --branch v3.9.12 https://github.com/python/cpython.git',\n",
       " 'cd cpython',\n",
       " 'chmod -R 777 .',\n",
       " '/configure LDFLAGS=&quot;-L/opt/homebrew/opt/xz/lib&quot; CPPFLAGS=&quot;-I/opt/homebrew/opt/xz/include&quot; --prefix=/Users/my-device-username/Downloads/portable_python',\n",
       " 'make',\n",
       " 'make install',\n",
       " 'cd ..',\n",
       " 'pkgbuild --root ./portable_python --identifier com.example.package --version 0.2.13 --install-location &quot;$HOME/Downloads/portable_python&quot; portable_python.pkg',\n",
       " \"def cust_ledger(request, pk):\\n\\tcust = Customer.objects.get(id = pk)\\ndbs = [Issue, Receive, SalesReturn]\\ntransactions = sorted(\\n\\t[m\\n\\tfor db in dbs\\n\\tfor m in db.objects.filter(customer=cust).order_by('date_time')],\\n\\tkey=attrgetter('date_time')\\n)\\n\\tquant_bal = 0\\n\\tamt_bal = 0\\n\\tsb_q = 0\\n\\trb_q = 0\\n\\tsr_q = 0\\n\\tmain = []\\n\\tfor tx in transactions:\\n\\t\\tif tx.tt == 'SB':\\n\\t\\t\\tsb_q = sb_q + tx.quantity\\n\\t\\t\\tmain.append(sb_q)\\n\\t\\t\\tquant_bal = quant_bal + tx.quantity\\n\\t\\t\\tamt_bal = amt_bal + tx.amount\\n\\t\\telif tx.tt == 'RB':\\n\\t\\t\\trb_q = sb_q - tx.quantity\\n\\t\\t\\tmain.append(rb_q)\\n\\t\\t\\tquant_bal = quant_bal - tx.quantity\\n\\t\\t\\tamt_bal = amt_bal - tx.amount\\n\\t\\telse:\\n\\t\\t\\tsr_q = sb_q - tx.quantity\\n\\t\\t\\tmain.append(sr_q)\\n\\t\\t\\tquant_bal = quant_bal - tx.quantity\\n\\t\\t\\tamt_bal = amt_bal - tx.amount\\n\\tcontext = {'transactions':transactions, 'cust':cust, 'quant_bal':quant_bal, 'amt_bal':amt_bal,\\n\\t\\t\\t\\t'sb_q':sb_q, 'rb_q':rb_q, 'sr_q':sr_q,\\n\\t\\t\\t\\t'main':main}\\n\\treturn render(request, 'customer/ledger.html', context)\",\n",
       " \"\\t{% extends 'base2.html' %}\\n{% load widget_tweaks %}\\n{% load static%}\\n{% block css %}\\n\\t&lt;link rel=&quot;stylesheet&quot; href=&quot;{% static 'utility.css' %}&quot;&gt;\\n\\t&lt;link rel=&quot;stylesheet&quot; href=&quot;{% static 'customer/ledger.css' %}&quot;&gt;\\n{% endblock css %}\\n{% block unique %}\\n\\t&lt;div class=&quot;header&quot;&gt;\\n\\t\\t&lt;a class=&quot;link inv&quot; href=&quot;{% url 'inventory' %}&quot;&gt; Inventory&lt;/a&gt;\\n\\t\\t&lt;a class=&quot;link hist&quot; href=&quot;{% url 'cust_board' %}&quot;&gt; Dashboard&lt;/a&gt;\\n\\t\\t&lt;h1&gt;Dinar Company&lt;/h1&gt;\\n\\t\\t&lt;a class=&quot;link home&quot; href=&quot;{% url 'cust-l' %}&quot;&gt;Back&lt;/a&gt;\\n\\t&lt;/div&gt;\\n{% endblock unique %}\\n{% block content %}\\n\\t&lt;div class=&quot;title_div&quot;&gt;\\n\\t\\t&lt;h1 class=&quot;title&quot;&gt;{{cust.name}}'s Ledger&lt;/h1&gt;\\n\\t&lt;/div&gt;\\n\\t&lt;h2 class=&quot;date heading&quot;&gt;Date&lt;/h2&gt;\\n\\t&lt;h2 class=&quot;tt heading&quot;&gt;TT&lt;/h2&gt;\\n\\t&lt;h2 class=&quot;id heading&quot;&gt;ID&lt;/h2&gt;\\n\\t&lt;h2 class=&quot;voucher heading&quot;&gt;Voucher&lt;/h2&gt;\\n\\t&lt;h2 class=&quot;debit_q heading&quot;&gt;Debit Quantity(g)&lt;/h2&gt;\\n\\t&lt;h2 class=&quot;debit_c heading&quot;&gt;Debit Cash&lt;/h2&gt;\\n\\t&lt;h2 class=&quot;credit_q heading&quot;&gt;Credit Quantity(g)&lt;/h2&gt;\\n\\t&lt;h2 class=&quot;credit_c heading&quot;&gt;Credit Cash&lt;/h2&gt;\\n\\t&lt;h2 class=&quot;balance_q heading&quot;&gt;Balance Quantity(g)&lt;/h2&gt;\\n\\t&lt;h2 class=&quot;balance_c heading&quot;&gt;Balance Cash&lt;/h2&gt;\\n\\t&lt;div class=&quot;flex-wrap&quot;&gt;\\n\\t\\t{% for tx in transactions %}\\n\\t\\t\\t{% if tx.tt == 'SB' %}\\n\\t\\t\\t\\t&lt;a href=&quot;{% url 'issue-detail' tx.id %}&quot;&gt;\\n\\t\\t\\t{% elif tx.tt == 'RB' %}\\n\\t\\t\\t\\t&lt;a href=&quot;{% url 'rec-detail' tx.id %}&quot;&gt;\\n\\t\\t\\t{% else %}\\n\\t\\t\\t\\t&lt;a href=&quot;{% url 'sr-detail' tx.id %}&quot;&gt;\\n\\t\\t\\t{% endif %}\\n\\t\\t\\t\\t\\t&lt;div class=&quot;bar name&quot;&gt;\\n\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p1&quot;&gt;{{tx.date_time| date:&quot;F j, Y&quot;}}&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p2&quot;&gt;{{tx.tt}}&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p3&quot;&gt;{{tx.id}}&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p4&quot;&gt;{{tx.voucher}}&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t{% if tx.tt == 'SB' %}\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p5 ic_q&quot;&gt;{{tx.quantity}}g&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p6 ic_c&quot;&gt;{{tx.amount}} SAR&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p5 rc_q&quot;&gt;-&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p6 rc_c&quot;&gt;-&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t{% elif tx.tt == 'RB' %}\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p5 ic_q&quot;&gt;-&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p6 ic_c&quot;&gt;-&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p5 rc_q&quot;&gt;{{tx.quantity}}g&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p6 rc_c&quot;&gt;{{tx.amount}} SAR&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t{% else %}\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p5 ic_q&quot;&gt;-&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p6 ic_c&quot;&gt;-&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p5 rc_q&quot;&gt;{{tx.quantity}}g&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p6 rc_c&quot;&gt;{{tx.amount}} SAR&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t{% endif %}\\n\\t\\t\\t\\t\\t\\t{% for i in main %}\\n\\t\\t\\t\\t\\t\\t\\t{% if tx.tt == 'SB' %}\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p7&quot;&gt;{{i}}g&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p8&quot;&gt;{{sb_cash_bal}} SAR&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t{% elif tx.tt == 'RB' %}\\n\\t\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p7&quot;&gt;{{i}}g&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p8&quot;&gt;{{rb_cash_bal}} SAR&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t{% else %}\\n\\t\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p7&quot;&gt;{{i}}g&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t\\t&lt;p class=&quot;p8&quot;&gt;{{rb_cash_bal}} SAR&lt;/p&gt;\\n\\t\\t\\t\\t\\t\\t\\t{% endif %}\\n\\t\\t\\t\\t\\t\\t{% endfor %}\\n\\t\\t\\t\\t\\t&lt;/div&gt;\\n\\t\\t\\t\\t&lt;/a&gt;\\n\\t\\t{% endfor %}\\n\\t\\t&lt;div class=&quot;bar final&quot;&gt;\\n\\t\\t\\t&lt;h3&gt;Total&lt;/h3&gt;\\n\\t\\t\\t&lt;p class=&quot;p9&quot;&gt;{{quant_bal}}g&lt;/p&gt;\\n\\t\\t\\t&lt;p class=&quot;p10&quot;&gt;{{amt_bal}} SAR&lt;/p&gt;\\n\\t\\t&lt;/div&gt;\\n\\t&lt;/div&gt;\\n{% endblock content %}\",\n",
       " 'main',\n",
       " 'main',\n",
       " 'main = [1,2,3]',\n",
       " '{\\n\\t&quot;dev2&quot;: {\\n\\t\\t&quot;app_function&quot;: &quot;app.app&quot;,\\n\\t\\t&quot;aws_region&quot;: &quot;ap-southeast-2&quot;,\\n\\t\\t&quot;profile_name&quot;: &quot;xxxx&quot;,\\n\\t\\t&quot;project_name&quot;: &quot;product-assista&quot;,\\n\\t\\t&quot;runtime&quot;: &quot;python3.9&quot;,\\n\\t\\t&quot;s3_bucket&quot;: &quot;zappa-xxxx&quot;\\n\\t}\\n}',\n",
       " '(.venv39) PS C:\\\\Users\\\\JMatson\\\\source\\\\repos\\\\product_assistant&gt; zappa deploy dev2\\nCalling deploy for stage dev2..\\nCreating product-assista-dev2-ZappaLambdaExecutionRole IAM Role..\\nCreating zappa-permissions policy on product-assista-dev2-ZappaLambdaExecutionRole IAM Role.\\nC:\\\\Users\\\\JMatson\\\\source\\\\repos\\\\product_assistant\\\\.venv39\\\\lib\\\\site-packages\\\\_distutils_hack\\\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\\n  warnings.warn(&quot;Setuptools is replacing distutils.&quot;)',\n",
       " 'import numpy as np\\ndef nptran(pcd:np.ndarray, rigdtran:np.ndarray) -&gt; np.ndarray:\\n\\tpcd_ = pcd.copy().T  \\n\\tpcd_ = rigdtran[:3, :3] @ pcd_ + rigdtran[:3, [3]]\\n\\treturn pcd_.T\\ndef npproj(pcd:np.ndarray, extran:np.ndarray, intran:np.ndarray, img_shape:tuple) -&gt; np.ndarray:\\n\\tH, W = img_shape\\n\\tpcd_ = nptran(pcd, extran)  \\n\\tpcd_ = intran @ pcd_.T  \\n\\tu, v, w = pcd_[0], pcd_[1], pcd_[2]\\n\\traw_index = np.arange(u.size)\\n\\trev = w &gt; 0  \\n\\traw_index = raw_index[rev]\\n\\tu = u[rev]/w[rev]\\n\\tv = v[rev]/w[rev]\\n\\trev2 = (0&lt;=u) * (u&lt;W) * (0&lt;=v) * (v&lt;H)  \\n\\treturn np.stack((u[rev2],v[rev2]),axis=1), raw_index[rev2]  ',\n",
       " 'cv.projectPoints',\n",
       " 'cv.projectPoints',\n",
       " 'cv.projectPoints',\n",
       " 'from scipy.spatial.transform import Rotation\\ndef toMat(rvec:np.ndarray, tvec:np.ndarray):\\n\\t&quot;&quot;&quot;rvec and tvec to SE3 Matrix\\n\\tArgs:\\n\\t\\trvec (`np.ndarray`): 1x3 rotation vector\\\\n\\n\\t\\ttvec (`np.ndarray`): 1x3 translation vector\\n\\tReturns:\\n\\t\\tSE3: 4x4 `np.ndarray`\\n\\t&quot;&quot;&quot;\\n\\tR = Rotation.from_rotvec(rvec)\\n\\tmat = np.eye(4)\\n\\tmat[:3,:3] = R.as_matrix()\\n\\tmat[:3,3] = tvec\\n\\treturn mat\\ndef npproj_jac(pcd:np.ndarray, rvec:np.ndarray, tvec:np.ndarray, intran:np.ndarray, img_shape:tuple):\\n\\tdistCoeffs = np.zeros(4)\\n\\textran = toMat(rvec, tvec)\\n\\t_, rev_idx = npproj(pcd, extran, intran, img_shape)\\n\\timg_pts, jac = cv2.projectPoints(pcd[rev_idx], rvec, tvec, intran, distCoeffs)\\n\\tjac:np.ndarray = jac.reshape(-1,2,jac.shape[-1])  \\n\\treturn img_pts, jac[...,:6], rev_idx',\n",
       " 'cv.projectPoints',\n",
       " \"contract_address = w3.to_checksum_address(value=contract)\\nreceiver_address = w3.to_checksum_address(value='0x47a33aB87C8f97Da779576D7862F8A69399d7716')\\ntx_data = [[(2, w3.to_checksum_address(value=contract_address), 731, 1), (2, w3.to_checksum_address(value=contract_address), 732, 1)], receiver_address, True]\\nmetadata = b'0x0000007b02230091a7ed01230072f7006a004d60a8d4e71d599b8104250f0000'  \\nfunction = bulk_contract.functions.bulkTransfer(tx_data, metadata)\",\n",
       " 'bulkTransfer',\n",
       " '(((int,address,int,int),(int,address,int,int)),address,bool),bytes',\n",
       " '{}',\n",
       " 'bulkTransfer',\n",
       " \"import pgzrun\\nfrom pgzhelper import *\\nWIDTH = 800\\nHEIGHT = 600\\nplayer = Actor('player.png', (20,20))\\nscore = 0\\nlives = 3\\nlevel = 1\\nlevel_complete = False\\nend_rect = Rect((700, 500), (50, 50))\\ngame_state = &quot;show_intro&quot;\\ndef reset_player():\\n\\tglobal player\\n\\tplayer.pos = (20,20)\\ndef reset_player_begining():\\n\\tglobal player\\n\\tglobal lives\\n\\tglobal score\\n\\tglobal level_complete\\n\\tlives = 3\\n\\tscore = 0\\n\\tlevel_complete = False\\n\\tplayer.pos = (20,20)\\nintro_text = &quot;&quot;&quot;\\nWelcome to the Maze Game!\\nInstructions:\\nUse the arrow keys to move the player sprite through the maze.\\nAvoid touching the walls, or you'll lose a life.\\nCollect all the stars to complete the level\\nGood luck, and have fun!\\n&quot;&quot;&quot;\\nshow_intro = True\\ndef draw_intro():\\n\\tscreen.clear()\\n\\tscreen.draw.text(intro_text, (50,50), color='white', fontsize=30)\\n\\tscreen.draw.text(&quot;Press Enter to start playing&quot;, (250,300), color='white', fontsize=30)\\ndef on_key_down_intro(key):\\n\\tglobal game_state\\n\\tif key == keys.RETURN:\\n\\t\\tgame_state = &quot;playing&quot;\\n\\t\\treset_player_begining()\\ngame_over_text = &quot;&quot;&quot;\\nGame Over!\\nYou have run out of lives.\\nPress Enter to restart the game.\\n&quot;&quot;&quot;\\nshow_game_over = False\\ndef draw_game_over():\\n\\tscreen.clear()\\n\\tscreen.draw.text(game_over_text, (50,50), color='white', fontsize=30)\\ndef on_key_down_game_over(key):\\n\\tglobal game_state\\n\\tif key == keys.RETURN:\\n\\t\\tlose_life()\\n\\t\\tgame_state = &quot;show_intro&quot;\\nwin_text = &quot;&quot;&quot;\\nCongragulations!!!!!\\nYou have finished the last level and completed all the stars.\\nIf you want to play again, simply press the &quot;replay&quot; button to go\\nback to the begining to play again.\\nThanks for playing my maze game!!!!!!\\n&quot;&quot;&quot;\\nshow_win = False\\ndef draw_win():\\n\\tscreen.clear()\\n\\tscreen.draw.text(win_text, (50,50), color='white', fontsize=30)\\ndef on_key_down_win(key):\\n\\tglobal game_state\\n\\tif key == keys.RETURN:\\n\\t\\tgame_state = &quot;show_intro&quot;\\nclass MazeWalls:\\n\\tmaze_walls_level_1 = [\\n\\t\\tRect((80, 80), (80, 320)),\\n\\t\\tRect((80, 80), (480, 80)),\\n\\t\\tRect((480, 80), (80, 320)),\\n\\t\\tRect((80, 320), (480, 80)),\\n\\t\\tRect((240,160), (80, 160)),\\n\\t\\tRect((750,0), (50, 60)),\\n\\t\\tRect((100, 100), (600, 10)),\\n\\t\\tRect((690, 100), (10, 200)),\\n\\t\\tRect((0, 0), (800, 50)),\\n\\t\\tRect((0, 550), (800, 50)),\\n\\t\\tRect((0, 0), (50, 600)),\\n\\t\\tRect((750, 0), (50, 600)),\\n\\t\\tend_rect\\n\\t\\t]\\n\\tmaze_walls_level_2 = [\\n\\t\\tRect((80, 80), (80, 320)),\\n\\t\\tRect((80, 80), (480, 80)),\\n\\t\\tRect((480, 80), (80, 320)),\\n\\t\\tRect((80, 320), (480, 80)),\\n\\t\\tRect((240,160), (80, 160)),\\n\\t\\tRect((750,0), (50, 60)),\\n\\t\\tRect((100, 100), (600, 10)),\\n\\t\\tRect((690, 100), (10, 200)),\\n\\t\\tRect((0, 0), (800, 50)),\\n\\t\\tRect((0, 550), (800, 50)),\\n\\t\\tRect((0, 0), (50, 600)),\\n\\t\\tRect((750, 0), (50, 600)),\\n\\t\\tRect((100, 400), (200, 10)),\\n\\t\\tRect((500, 400), (200, 10)),\\n\\t\\tRect((300, 200), (200, 10)),\\n\\t\\tend_rect\\n\\t\\t]\\n\\tmaze_walls_level_3 = [\\n\\t\\tRect((80, 80), (80, 320)),\\n\\t\\tRect((80, 80), (480, 80)),\\n\\t\\tRect((480, 80), (80, 320)),\\n\\t\\tRect((80, 320), (480, 80)),\\n\\t\\tRect((240,160), (80, 160)),\\n\\t\\tRect((750,0), (50, 60)),\\n\\t\\tRect((100, 100), (600, 10)),\\n\\t\\tRect((690, 100), (10, 200)),\\n\\t\\tRect((0, 0), (800, 50)),\\n\\t\\tRect((0, 550), (800, 50)),\\n\\t\\tRect((0, 0), (50, 600)),\\n\\t\\tRect((750, 0), (50, 600)),\\n\\t\\tRect((100, 400), (200, 10)),\\n\\t\\tRect((500, 400), (200, 10)),\\n\\t\\tRect((300, 200), (200, 10)),\\n\\t\\tRect((100, 50), (200, 10)),\\n\\t\\tRect((500, 250), (200, 10)),\\n\\t\\tRect((300, 100), (200, 10)),\\n\\t\\tend_rect\\n\\t\\t]\\nclass stars:\\n\\tstars_level_1 = [\\n\\t\\tActor('star.png',(240,240)),\\n\\t\\tActor('star.png',(400,400)),\\n\\t\\t]\\ndef draw_stars(level):\\n\\tfor wall in MazeWalls.maze_walls_level_1:\\n\\t\\twall.draw()\\n\\t\\tfor star in stars[levels]:\\n\\t\\t\\tstar.draw()\\ndef lose_life():\\n\\tglobal lives\\n\\tlives -= 1\\n\\tif lives == 0:\\n\\t\\tshow_game_over = True\\n\\t\\treset_player_begining()\\ndef draw_game():\\n\\tglobal score\\n\\tglobal lives\\n\\tscreen.clear()\\n\\tscreen.draw.text(&quot;Score: &quot; + str(score), (10,10), color='white')\\n\\tscreen.draw.text(&quot;Lives: &quot; + str(lives), (20,10), color='white')\\n\\tplayer.draw()\\n\\tfor wall in MazeWalls.maze_walls_level_1:\\n\\t\\tscreen.draw.filled_rect(wall, (0, 0, 225))\\ndef draw():\\n\\tglobal show_intro\\n\\tglobal show_game_over\\n\\tglobal show_win\\n\\tglobal game_state\\n\\tif show_intro:\\n\\t\\tdraw_intro()\\n\\t\\treturn\\n\\telif show_game_over:\\n\\t\\tdraw_game_over()\\n\\t\\treturn\\n\\telif show_win:\\n\\t\\tdraw_win()\\n\\telif game_state == &quot;playing&quot;:\\n\\t\\tdraw_game()\\npgzrun.go()\",\n",
       " 'sphinx.ext.autodoc',\n",
       " '/home/mbcn/Software_Projects/Sphinx',\n",
       " '/home/mbcn/Software_Projects/Python_Projects/Svnx',\n",
       " 'conf.py',\n",
       " \"import os\\nimport sys\\nsys.path.insert(0, os.path.abspath('.'))\",\n",
       " \"sys.path.insert(0, os.path.abspath('/home/mbcn/Software_Projects/Python_Projects/Svnx/'))\",\n",
       " \"sys.path.insert(0, os.path.abspath('os.path.realpath('/home/mbcn/Software_Projects/Python_Projects/Svnx/’)'))\",\n",
       " '%.2f',\n",
       " '%.3e',\n",
       " '{0:,.2f}',\n",
       " '%.2%',\n",
       " \"for x in range(10):\\n\\tprint(x, end='\\\\r')\\n\\ttime.sleep(0.1)\",\n",
       " \"def ft_progress(list):\\n\\tto_print = range(0, len(list), min(int(len(list) / 30) + 1, 30))\\n\\tfor i2 in list:\\n\\t\\ti = abs(i2)\\n\\t\\tprint(&quot;[&quot;, str(&quot;%.2f&quot; % (100 * (i + 1) / len(list))).rjust(6), &quot;% ]&quot;, end='\\\\r')\\n\\t\\tyield i\\nfor elem in ft_progress(X):\\n\\tret += (elem + 3) % 5\\n\\ttime.sleep(0.01)\\n\\tprint()\\n\\tprint(ret)\",\n",
       " 'print',\n",
       " \"import requests\\nurl = &quot;url&quot;\\nauth = {\\n\\t'authorization': 'token'\\n}\\nmessage = {\\n\\t'content': 'logged in'\\n}\\nrequests.post(url, headers=auth, data=message)\\ncommand_data = {\\n\\t'name': 'imagine',\\n\\t'description': 'Create images with Midjourney',\\n\\t'options': [\\n\\t\\t{\\n\\t\\t\\t'name': 'prompt',\\n\\t\\t\\t'description': 'The prompt to imagine',\\n\\t\\t\\t'type': 3,\\n\\t\\t\\t'required': True,\\n\\t\\t\\t'value': 'a cat'\\n\\t\\t}\\n\\t]\\n}\\nresponse = requests.post(url, headers=auth, json=command_data)\",\n",
       " '/imagine a cat',\n",
       " \"def unet(Image_size):\\n\\tinply = Input(Image_size)\\n\\tconv1 = Conv2D(2 ** 6, (3, 3), activation='relu', padding='same')(inply)\\n\\tconv1 = Conv2D(2 ** 6, (3, 3), activation='relu', padding='same')(conv1)\\n\\tpool1 = MaxPooling2D((2, 2), strides=2, padding='same')(conv1)\\n\\tdrop1 = Dropout(0.2)(pool1)\\n\\tconv2 = Conv2D(2 ** 7, (3, 3), activation='relu', padding='same')(drop1)\\n\\tconv2 = Conv2D(2 ** 7, (3, 3), activation='relu', padding='same')(conv2)\\n\\tpool2 = MaxPooling2D((2, 2), strides=2, padding='same')(conv2)\\n\\tdrop2 = Dropout(0.2)(pool2)\\n\\tconv3 = Conv2D(2 ** 8, (3, 3), activation='relu', padding='same')(drop2)\\n\\tconv3 = Conv2D(2 ** 8, (3, 3), activation='relu', padding='same')(conv3)\\n\\tpool3 = MaxPooling2D((2, 2), strides=2, padding='same')(conv3)\\n\\tdrop3 = Dropout(0.2)(pool3)\\n\\tconv4 = Conv2D(2 ** 9, (3, 3), activation='relu', padding='same')(drop3)\\n\\tconv4 = Conv2D(2 ** 9, (3, 3), activation='relu', padding='same')(conv4)\\n\\tpool4 = MaxPooling2D((2, 2), strides=2, padding='same')(conv4)\\n\\tdrop4 = Dropout(0.2)(pool4)\\n\\tconvm = Conv2D(2 ** 10, (3, 3), activation='relu', padding='same')(drop4)\\n\\tconvm = Conv2D(2 ** 10, (3, 3), activation='relu', padding='same')(convm)\\n\\ttran5 = Conv2DTranspose(2 ** 9, (2, 2), strides=2, padding='same', activation='relu')(convm)\\n\\tconc5 = Concatenate()([tran5, conv4])\\n\\tconv5 = Conv2D(2 ** 9, (3, 3), activation='relu', padding='same')(conc5)\\n\\tconv5 = Conv2D(2 ** 9, (3, 3), activation='relu', padding='same')(conv5)\\n\\tdrop5 = Dropout(0.1)(conv5)\\n\\ttran6 = Conv2DTranspose(2 ** 8, (2, 2), strides=2, padding='same', activation='relu')(drop5)\\n\\tconc6 = Concatenate()([tran6, conv3])\\n\\tconv6 = Conv2D(2 ** 8, (3, 3), activation='relu', padding='same')(conc6)\\n\\tconv6 = Conv2D(2 ** 8, (3, 3), activation='relu', padding='same')(conv6)\\n\\tdrop6 = Dropout(0.1)(conv6)\\n\\ttran7 = Conv2DTranspose(2 ** 7, (2, 2), strides=2, padding='same', activation='relu')(drop6)\\n\\tconc7 = Concatenate()([tran7, conv2])\\n\\tconv7 = Conv2D(2 ** 7, (3, 3), activation='relu', padding='same')(conc7)\\n\\tconv7 = Conv2D(2 ** 7, (3, 3), activation='relu', padding='same')(conv7)\\n\\tdrop7 = Dropout(0.1)(conv7)\\n\\ttran8 = Conv2DTranspose(2 ** 6, (2, 2), strides=2, padding='same', activation='relu')(drop7)\\n\\tconc8 = Concatenate()([tran8, conv1])\\n\\tconv8 = Conv2D(2 ** 6, (3, 3), activation='relu', padding='same')(conc8)\\n\\tconv8 = Conv2D(2 ** 6, (3, 3), activation='relu', padding='same')(conv8)\\n\\tdrop8 = Dropout(0.1)(conv8)\\n\\toutly = Conv2D(2 ** 0, (1, 1), activation='relu', padding='same')(drop8)\\n\\tmodel = Model(inputs=inply, outputs=outly, name='U-net')\\n\\treturn model\",\n",
       " 'def iou_score(y_true, y_pred):\\n\\ty_true_f = K.flatten(y_true)\\n\\ty_pred_f = K.flatten(y_pred)\\n\\tintersection = K.sum(y_true_f * y_pred_f)\\n\\tunion = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\\n\\treturn intersection / union\\ndef dice_score(y_true, y_pred):\\n\\tsmooth = 1.\\n\\ty_true_f = K.flatten(y_true)\\n\\ty_pred_f = K.flatten(y_pred)\\n\\tintersection = K.sum(y_true_f * y_pred_f)\\n\\tscore = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\\n\\treturn score\\ndef dice_loss(y_true, y_pred):\\n\\tloss = 1 - dice_score(y_true, y_pred)\\n\\treturn loss',\n",
       " \"model.compile(loss=dice_loss, optimizer='adam', metrics=['accuracy', iou_score, dice_score])\\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', iou_score, dice_score])\",\n",
       " \"C:\\\\›python PowerMasterUPS.py install\\nInstalling service PowerMasterUPS\\ncopying host exe 'C:\\\\Users\\\\x\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packa\\nC:\\\\Users\\\\x\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\pythonservice.exe'\\nService installed\",\n",
       " \"C:\\\\›python PowerMasterUPS.py debug\\nDebugging service PowerMasterUPS - press Ctrl+C to stop.\\nError (xC0000004 - Python could not import the service's module\\nModuleNotFoundError: No module named 'PowerMasterUPS'\\n(null): (null)\",\n",
       " 'sys.path.append(&quot;C:\\\\\\\\&quot;)',\n",
       " \"import socket\\nimport win32serviceutil\\nimport servicemanager\\nimport win32event\\nimport win32service\\nimport requests ,time ,json, os, sys\\nsys.path.append(&quot;C:\\\\\\\\&quot;)\\nclass SMWinservice(win32serviceutil.ServiceFramework):\\n\\t<str>\\n\\t_svc_name_ = 'pythonService'\\n\\t_svc_display_name_ = 'Python Service'\\n\\t_svc_description_ = 'Python Service Description'\\n\\t@classmethod\\n\\tdef parse_command_line(cls):\\n\\t\\t<str>\\n\\t\\twin32serviceutil.HandleCommandLine(cls)\\n\\tdef __init__(self, args):\\n\\t\\t<str>\\n\\t\\twin32serviceutil.ServiceFramework.__init__(self, args)\\n\\t\\tself.hWaitStop = win32event.CreateEvent(None, 0, 0, None)\\n\\t\\tsocket.setdefaulttimeout(60)\\n\\tdef SvcStop(self):\\n\\t\\t<str>\\n\\t\\tself.stop()\\n\\t\\tself.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\\n\\t\\twin32event.SetEvent(self.hWaitStop)\\n\\tdef SvcDoRun(self):\\n\\t\\t<str>\\n\\t\\tself.start()\\n\\t\\tservicemanager.LogMsg(servicemanager.EVENTLOG_INFORMATION_TYPE,\\n\\t\\t\\t\\t\\t\\t\\t  servicemanager.PYS_SERVICE_STARTED,\\n\\t\\t\\t\\t\\t\\t\\t  (self._svc_name_, ''))\\n\\t\\tself.main()\\n\\tdef start(self):\\n\\t\\t<str>\\n\\t\\tpass\\n\\tdef stop(self):\\n\\t\\t<str>\\n\\t\\tpass\\n\\tdef main(self):\\n\\t\\t<str>\\n\\t\\tpass\\nclass PowerMasterUPS(SMWinservice):\\n\\t_svc_name_ = &quot;PowerMasterUPS&quot;\\n\\t_svc_display_name_ = &quot;PowerMasterUPS&quot;\\n\\t_svc_description_ = &quot;PowerMasterUPS will Shutdown Windows when UPS battery is depleting&quot;\\n\\tdef start(self):\\n\\t\\tself.isrunning = True\\n\\tdef stop(self):\\n\\t\\tself.isrunning = False\\n\\tdef main(self):\\n\\t\\twhile self.isrunning:\\nif __name__ == '__main__':\\n\\tPowerMasterUPS.parse_command_line()\",\n",
       " 'values = [int(values) for values in input(&quot;Enter values: &quot;).split()]',\n",
       " 'def multi(firstValue, *otherValues):\\n\\tresult = firstValue\\n\\tfor i in otherValues:\\n\\t\\tresult = result * i\\n\\tprint(result)',\n",
       " 'firstValue',\n",
       " 'otherValue',\n",
       " 'multi(1, 2, 3, 4, 5)',\n",
       " 'values = [int(values) for values in input(&quot;Enter values: &quot;).split()]\\nmulti(values)',\n",
       " 'matplotlib',\n",
       " 'dataframe',\n",
       " 'PdfPages',\n",
       " \"fig, ax = plt.subplots(dpi=100)\\nfig, ax = plt.subplots()\\nax.axis('tight')\\nax.axis('off')\\nax.table(cellText=df.values, colLabels=df.columns, rowLabels=df.index, loc='center', colWidths=[0.1] * 75)\",\n",
       " 'slider',\n",
       " 'ax.table',\n",
       " '   static_params_dict = dict(\\n\\t\\tobjective=&quot;binary&quot;,\\n\\t\\tlabelCol=target,\\n\\t\\tearlyStoppingRound=100,\\n\\t\\tnumThreads=20,\\n\\t\\tnumBatches=10,\\n\\t\\tfeaturesCol=&quot;features&quot;,\\n\\t\\tcategoricalSlotNames=cat_features_indexed,\\n\\t\\tlearningRate=0.01,\\n\\t\\tverbosity=1,\\n\\t\\tisUnbalance=True,\\n\\t\\tmaxDepth=20,\\n\\t\\tnumIterations=1000,\\n\\t\\tboostingType=&quot;gbdt&quot;\\n\\t)\\n\\tgbt = LightGBMClassifier().setParams(**static_params_dict)\\n\\tsmlmodels = [gbt]\\n\\tmmlmodels = [TrainClassifier(model=model, labelCol=target) for model in smlmodels]\\n\\tfrom synapse.ml.automl import *\\n\\tparamBuilder = (\\n\\t\\tHyperparamBuilder()\\n\\t\\t.addHyperparam(gbt,gbt.numLeaves, DiscreteHyperParam([30, 40,70]))\\n\\t)\\n\\tsearchSpace = paramBuilder.build()\\n\\trandomSpace = RandomSpace(searchSpace)\\n\\tbestModel = TuneHyperparameters(\\n\\t\\tevaluationMetric=&quot;precision&quot;,\\n\\t\\tmodels=mmlmodels,\\n\\t\\tnumFolds=2,\\n\\t\\tnumRuns=len(mmlmodels) * 1,\\n\\t\\tparallelism=1,\\n\\t\\tparamSpace=randomSpace.space(),\\n\\t\\tseed=0,\\n\\t).fit(train_valid_sample_iteration)\\n\\tprint(bestModel.getBestModelInfo())',\n",
       " 'actualNumClasses: 2, featuresCol: TrainClassifier_e7a1f8587a87_features, featuresShapCol: , labelCol: is_opt_out_1_month, leafPredictionCol: , lightGBMBooster: com.microsoft.azure.synapse.ml.lightgbm.booster.LightGBMBooster@4e56743a, numIterations: 1000, predictionCol: prediction, probabilityCol: probability, rawPredictionCol: rawPrediction, startIteration: 0',\n",
       " 'Traceback (most recent call last):\\n  File &quot;C:\\\\Users\\\\---\\\\Desktop\\\\LLTF\\\\SDK1.2.1\\\\win64\\\\dllInterface.py&quot;, line 81, in &lt;module&gt;\\n\\tprint(GetSystemCount(my_handle))\\n  File &quot;C:\\\\Users\\\\---\\\\Desktop\\\\LLTF\\\\SDK1.2.1\\\\win64\\\\dllInterface.py&quot;, line 49, in GetSystemCount\\n\\treturn pe_lib.PE_GetSystemCount(PEHandle)\\nOSError: exception: access violation reading 0x0000003000350036',\n",
       " 'Create',\n",
       " \"import ctypes\\nimport traceback\\npe_lib = ctypes.cdll.LoadLibrary('exampleDll.dll')\\npe_lib.PE_Create.argtypes = [c_char_p, POINTER(c_void_p)]\\npe_lib.PE_Create.restype = c_int\\ndef Create(configFile, PEHandle):\\n\\tres = pe_lib.PE_Create(configFile.encode(), PEHandle)\\n\\treturn res\\npe_lib.PE_Destroy.argtypes = [c_void_p]\\npe_lib.PE_Destroy.restype = c_int\\ndef Destroy(PEHandle):\\n\\treturn pe_lib.PE_Destroy(PEHandle)\\npe_lib.PE_GetSystemCount.argtypes = [c_void_p]\\npe_lib.PE_GetSystemCount.restype = c_int\\ndef GetSystemCount(PEHandle):\\n\\treturn pe_lib.PE_GetSystemCount(PEHandle)\\ntry:\\n\\tmy_handle = c_void_p()\\n\\tCreate('system.xml', byref(my_handle))\\n\\tGetSystemCount(my_handle)\\n\\tprint(Destroy(my_handle))\\nexcept Exception as e:\\n\\tprint(traceback.format_exc())\\n\\tprint(Destroy(my_handle))\",\n",
       " 'typedef void* PE_HANDLE;\\ntypedef const void* CPE_HANDLE;\\nextern &quot;C&quot; {\\n//=============================================================================\\n// MANAGEMENT FUNCTIONS\\n//=============================================================================\\n//! Creates filter resource with configuration file but do not connect to filter.\\n//! @param[in] conffile Full path to the XML configuration file\\n//! @param[out] peHandle Handle to the resource created\\n//! @return Error code\\nPEFILTERSDK_API PE_STATUS PE_Create(const char* conffile, PE_HANDLE* peHandle);\\n//! Destroys filter resource previously created with PE_Create().\\n//! @param[in] peHandle Handle to the resource\\n//! @return Error code\\nPEFILTERSDK_API PE_STATUS PE_Destroy(PE_HANDLE peHandle);\\n//! Gets the number of systems available in the configuration file.\\n//! @param[in] peHandle Handle to the resource\\n//! @return Number of configured systems\\nPEFILTERSDK_API int PE_GetSystemCount(CPE_HANDLE peHandle);',\n",
       " '// EXAMPLE C CODE FOR RUNNING SYSTEM\\nPE_HANDLE handle = NULL;\\nchar systemName[256];\\n/* Please note that error checks are omitted for clarity reasons */\\nPE_Create(&quot;system.xml&quot;, &amp;handle);\\n/* Retrieve the number of systems available */\\nPE_GetSystemCount(handle);',\n",
       " 'def maze(graph: List[List[int]], start: List[int], end: List[int], F: int) -&gt; int:\\n\\tqueue = deque()\\n\\tst = list(start)\\n\\tst.append(0)\\n\\tst.append(F)\\n\\tqueue.append(st)\\n\\tvisited = [([False] * len(graph[0])) for i in range(len(graph))]\\n\\twhile queue:\\n\\t\\tcurrent = queue.popleft()\\n\\t\\trow = current[0]\\n\\t\\tcol = current[1]\\n\\t\\tflash_count = current[3]\\n\\t\\tif not visited[row][col] and not graph[row][col]:\\n\\t\\t\\tif [row, col] == list(end):\\n\\t\\t\\t\\treturn current[2]\\n\\t\\t\\tcurrent[2] += 1\\n\\t\\t\\tvisited[row][col] = True\\n\\t\\t\\tif row &lt; (len(graph) - 1):\\n\\t\\t\\t\\tqueue.append([row + 1, col, current[2], flash_count])\\n\\t\\t\\tif col &lt; (len(graph[0]) - 1):\\n\\t\\t\\t\\tqueue.append([row, col + 1, current[2], flash_count])\\n\\t\\t\\tif row &gt; 0:\\n\\t\\t\\t\\tqueue.append([row - 1, col, current[2], flash_count])\\n\\t\\t\\tif col &gt; 0:\\n\\t\\t\\t\\tqueue.append([row, col - 1, current[2], flash_count])\\n\\t\\t\\tif flash_count &gt; 0:\\n\\t\\t\\t\\tfor flashRange in range(flash_count, 1, -1):\\n\\t\\t\\t\\t\\tflash_count -= flashRange\\n\\t\\t\\t\\t\\tif row + flashRange &lt; len(graph):\\n\\t\\t\\t\\t\\t\\tqueue.append([row + flashRange, col, current[2], flash_count])\\n\\t\\t\\t\\t\\tif col + flashRange &lt; len(graph[0]):\\n\\t\\t\\t\\t\\t\\tqueue.append([row, col + flashRange, current[2], flash_count])\\n\\t\\t\\t\\t\\tif row - flashRange &gt;= 0:\\n\\t\\t\\t\\t\\t\\tqueue.append([row - flashRange, col, current[2], flash_count])\\n\\t\\t\\t\\t\\tif col - flashRange &gt;= 0:\\n\\t\\t\\t\\t\\t\\tqueue.append([row, col - flashRange, current[2], flash_count])\\n\\t\\t\\t\\t\\tflash_count += flashRange\\n\\treturn -1',\n",
       " 'mazeQ1c(\\\\[\\\\[0,1,0,0,1,0\\\\],\\\\[0,1,0,0,1,0\\\\],\\\\[0,1,0,0,1,0\\\\],\\\\[0,1,0,0,1,0\\\\],\\\\[0,1,0,0,1,0\\\\],\\\\[0,1,0,0,1,0\\\\]\\\\],\\\\[0,0\\\\],\\\\[5,5\\\\],4)',\n",
       " '[0,1,0,0,1,0]\\n[0,1,0,0,1,0]\\n[0,1,0,0,1,0]\\n[0,1,0,0,1,0]\\n[0,1,0,0,1,0]\\n[0,1,0,0,1,0]',\n",
       " \"import unreal\\nactorsList = unreal.EditorLevelLibrary.get_actor_by_actor_label('agent')\\ncollision_actor = 0\\nfor actor in actorsList:\\n\\tactorLabel = actor.get_actor_label()\\n\\tactorPos = actor.get_actor_location()\\n\\tif actorLabel == 'agent':\\n\\t\\tprint('actorLabel= %s actorPos=%s' % (actorLabel, actorPos))\\n\\t\\tlocation = unreal.Vector(actorPos.x, actorPos.y+100, actorPos.z)\\n\\t\\tactor.set_actor_location(location, False, True)\",\n",
       " 'from django.shortcuts import render\\nfrom .models import Post\\nfrom django.contrib.auth.models import User\\nfrom django.views.generic import ListView, DetailView, CreateView, UpdateView, DeleteView\\nfrom django.contrib.auth.mixins import LoginRequiredMixin, UserPassesTestMixin\\nfrom django.shortcuts import get_object_or_404',\n",
       " \"class UserPostListView(PostListView):\\n\\tmodel = Post\\n\\tfields = ['title', 'content']\\n\\tcontext_object_name = 'posts'\\n\\tpaginate_by = 2\\n\\tdef get_queryset(self):\\n\\t\\tuser = get_object_or_404(User, username= self.kwargs.get('username'))\\n\\t\\treturn Post.objects.filter(author=user).order_by['-date']\",\n",
       " 'window_size = 100\\nnum_windows = len(data) // window_size\\nwindowed_data = np.zeros((num_windows, window_size))\\nfor i in range(num_windows):\\n\\twindowed_data[i] = data[i*window_size:(i+1)*window_size]',\n",
       " 'def foo():\\n\\tx = 9\\n\\tyield x\\n\\tyield x+1',\n",
       " 'next()',\n",
       " 'foo()',\n",
       " '9',\n",
       " '10',\n",
       " '10',\n",
       " \"DATABASES = {\\n\\t'default': {\\n\\t\\t\\t'ENGINE': 'django.db.backends.postgresql_psycopg2',\\n\\t\\t\\t'NAME': 'fail_over',\\n\\t\\t\\t'USER': 'SomeUser',\\n\\t\\t\\t'PASSWORD': 'SomePassword',\\n\\t\\t\\t'HOST': '127.0.0.1',\\n\\t\\t\\t'PORT': '',\\n\\t},\\n\\t'cl_db': {\\n\\t\\t\\t'ENGINE': 'django.db.backends.postgresql_psycopg2',\\n\\t\\t\\t'NAME': 'cl_dev',\\n\\t\\t\\t'USER': 'SomeUser',\\n\\t\\t\\t'PASSWORD': 'SomePassword',\\n\\t\\t\\t'HOST': '127.0.0.1',\\n\\t\\t\\t'PORT': '',\\n\\t},\\n}\",\n",
       " \"DATABASE_ROUTERS = ['app.dbrouters.AuthRounter']\",\n",
       " \"class AuthRouter:\\n\\t&quot;&quot;&quot;\\n\\tA router to control all database operations on models in the\\n\\tauth and contenttypes applications.\\n\\t&quot;&quot;&quot;\\n\\troute_app_labels = {'auth', 'contenttypes'}\\n\\tdef db_for_read(self, model, **hints):\\n\\t\\t&quot;&quot;&quot;\\n\\t\\tAttempts to read auth and contenttypes models go to auth_db.\\n\\t\\t&quot;&quot;&quot;\\n\\t\\tif model._meta.app_label in self.route_app_labels:\\n\\t\\t\\treturn 'default'\\n\\t\\treturn None\\n\\tdef db_for_write(self, model, **hints):\\n\\t\\t&quot;&quot;&quot;\\n\\t\\tAttempts to write auth and contenttypes models go to auth_db.\\n\\t\\t&quot;&quot;&quot;\\n\\t\\tif model._meta.app_label in self.route_app_labels:\\n\\t\\t\\treturn 'default'\\n\\t\\treturn None\\n\\tdef allow_relation(self, obj1, obj2, **hints):\\n\\t\\t&quot;&quot;&quot;\\n\\t\\tAllow relations if a model in the auth or contenttypes apps is\\n\\t\\tinvolved.\\n\\t\\t&quot;&quot;&quot;\\n\\t\\tif (\\n\\t\\t\\tobj1._meta.app_label in self.route_app_labels or\\n\\t\\t\\tobj2._meta.app_label in self.route_app_labels\\n\\t\\t):\\n\\t\\t   return True\\n\\t\\treturn None\\n\\tdef allow_migrate(self, db, app_label, model_name=None, **hints):\\n\\t\\t&quot;&quot;&quot;\\n\\t\\tMake sure the auth and contenttypes apps only appear in the\\n\\t\\t'auth_db' database.\\n\\t\\t&quot;&quot;&quot;\\n\\t\\tif app_label in self.route_app_labels:\\n\\t\\t\\treturn db == 'default'\\n\\t\\treturn None\",\n",
       " \"class usermaster(models.Model):\\n  userid = models.AutoField(primary_key=True, unique=True)\\n  class Meta:\\n\\tapp_label = 'user_master'\",\n",
       " \"import matplotlib.pyplot as plt\\nimport pyodbc\\nimport pandas as pd\\ndatabase_file = input(&quot;Enter the path to the database file: &quot;)\\nconn = pyodbc.connect(\\n\\tr'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};'\\n\\tr'DBQ=' + database_file + ';'\\n)\\nwhile True:\\n\\tprint(&quot;MENU:\\\\n 1.Query for checking the number of masterCodes in each WBID\\\\n 2.Plot with this data&quot;)\\n\\tnum1 = int(input(&quot;Enter your response: &quot;))\\n\\tif num1 == 1:\\n\\t\\ttable_name = input(&quot;Enter the name of the table: &quot;)\\n\\t\\tcolumn_to_count = input(&quot;Enter the name of the column to count the variables in: &quot;)\\n\\t\\tcondition_column = input(&quot;Enter the name of the column to use as a condition: &quot;)\\n\\t\\tcondition_value = input(&quot;Enter the value to use as a condition: &quot;)\\n\\t\\tpd.options.display.max_rows = None\\n\\t\\tquery = &quot;SELECT &quot; + column_to_count + &quot;, &quot; + condition_column + &quot; FROM &quot;+ table_name+ &quot; WHERE &quot; + condition_column + &quot; = '&quot; + condition_value + &quot;'&quot;\\n\\t\\tdf = pd.read_sql(query, conn)\\n\\tif num1 == 2:\\n\\t\\tprint(&quot;Going to next steps&quot;)\\n\\t\\tbreak\\n\\tcounts = df[column_to_count].value_counts()\\n\\tprint(counts)\\nwhile True:\\n\\tprint(&quot;MENU:\\\\n 1.QUERY\\\\n 2.EXIT&quot;)\\n\\tnum = int(input(&quot;Enter your response: &quot;))\\n\\tif num == 1:\\n\\t\\trow = input(&quot;Enter row : &quot;)\\n\\t\\tcolumn = input(&quot;Enter column : &quot;)\\n\\t\\tcondition = input(&quot;Enter condition : &quot;)\\n\\t\\tquery = &quot;SELECT &quot; + row + &quot;, &quot; + column + &quot; FROM rawData1 Where (&quot; + condition + &quot;)&quot;\\n\\tif num == 2:\\n\\t\\tprint(&quot;Program is completed&quot;)\\n\\t\\tbreak\\n\\tprint(query)\\n\\tdf = pd.read_sql(query, conn)\\n\\tprint(df)\\n\\tdf = df.sort_values(by='year')\\n\\tx = df['year']\\n\\ty = df['result']\\n\\tplt.plot(x, y)\\n\\tplt.xlabel(row)\\n\\tplt.ylabel(column)\\n\\tplt.title(&quot;Plot Title&quot;)\\n\\tplt.show()\",\n",
       " \"query = &quot;SELECT &quot; + column_to_count + &quot;, &quot; + condition_column + &quot; FROM &quot;+ table_name+ &quot; WHERE &quot; + condition_column + &quot; = '&quot; + condition_value + &quot;'&quot;\",\n",
       " \"for i in range(20): \\ndata, sr = librosa.load(file_name[i])\\nmfcc = librosa.feature.mfcc(y = data, sr = sr)\\ndot = []\\nfor i in range(20):\\n\\tnew= np.pad(mfcc[i], (0,1293 - len(mfcc[i])), 'constant',constant_values=(0, 0))\\n\\tn = (new - new.mean()) / new.std()\\n\\tproduct = np.dot(n, rvec[i]) \\n\\tif product &gt;= 0:\\n\\t\\tdot.append(1)\\n\\telse:\\n\\t\\tdot.append(0)\\nprint(dot)\",\n",
       " 'fibonacci &lt;- function(n) {\\n  fn &lt;- c(1,1)\\n  for (i in 2:n+1) {\\n\\tfn &lt;- c(fn, (fn[i-1]+fn[i-2]))\\n  }\\n  return(fn)\\n}',\n",
       " 'fib_search &lt;- function(f, xl, xr, n){\\n  F = fibonacci(n) \\n  L0 = xr - xl \\n  R1 = L0 \\n  Li = (F[n-2]/F[n])*L0\\n  R = Li/L0\\n  for (i in 2:n+1)\\n  {\\n\\tif (Li &gt; L0/2) {\\n\\t  x1 = xr - Li\\n\\t  x2 = xl + Li\\n\\t} else {\\n\\t  x1 = xl + Li\\n\\t  x2 = xr - Li\\n\\t}\\n\\tf1 = f(x1)\\n\\tf2 = f(x2)\\n\\tif (f1 &lt; f2) {\\n\\t  xr = x2\\n\\t  Li = (F[n - i]/F[n - (i - 2)])*L0 \\n\\t} else if (f1 &gt; f2) {\\n\\t  xl = x1\\n\\t  Li = (F[n - i]/F[n - (i - 2)])*L0 \\n\\t} else {\\n\\t  xl = x1\\n\\t  xr = x2\\n\\t  Li = (F[n - i]/F[n - (i - 2)])*(xr - xl) \\n\\t}\\n\\tL0 = xr - xl\\n\\tR = c(R, Li/R1)\\n  }\\n  list1 &lt;- list(x1, f(x1), R)\\n  list2 &lt;- list(x2, f(x2), R)\\n  if (f1 &lt;= f2) {\\n\\treturn(list1) \\n  } else {\\n\\treturn(list2) \\n  }\\n}',\n",
       " 'f &lt;- function(x) {\\n  x**5 - 5*x**3 - 20*x + 5\\n}\\nFib = fib_search(f, -2.5, 2.5, 25)',\n",
       " \"def create_4_in_one(number):\\nshutil.copy(&quot;start.mp4&quot;, f&quot;video.mp4&quot;)\\nfor i in range(number):\\n\\tshutil.copy(&quot;video.mp4&quot;, f&quot;temp_videa/{i}.mp4&quot;)\\n\\tsubprocess.call(f'ffmpeg -y -i video.mp4 -vf &quot;scale=iw/2:ih/2&quot; -c:a copy video_half.mp4',\\n\\t\\t\\t\\t  shell=True)\\n\\tsubprocess.call(f'ffmpeg -y -i video_half.mp4 -i video_half.mp4 -i video_half.mp4 -i video_half.mp4 -filter_complex &quot;[0:v][1:v]hstack[t];[2:v][3:v]hstack[b];[t][b]vstack[v]; [0:a][1:a][2:a][3:a]amerge=inputs=4[a]&quot; -map &quot;[v]&quot; -map &quot;[a]&quot; -map 0:a -map 1:a -map 2:a -map 3:a -c:a aac -b:a 128k -ac 2 -shortest output.mp4',\\n\\t\\t\\t\\t  shell=True)\\n\\tos.remove(&quot;video.mp4&quot;)\\n\\tos.remove(&quot;video_half.mp4&quot;)\\n\\tos.rename('output.mp4', 'video.mp4')\\nos.remove(&quot;video.mp4&quot;)\",\n",
       " 'import smtplib as sm\\nimport ssl as s\\nhost = &quot;smtp.gmail.com&quot;\\nport = 465\\nusername1 = &quot;xxxxxxxx@gmail.com&quot;\\npassword1 = &quot;xxxxxxxxxx&quot;\\nmsg = &quot;&quot;&quot;\\\\\\\\\\nSubject: Test Mail\\nSending from Python\\n&quot;&quot;&quot;\\nreceiver1 = &quot;xxxxxxxx@gmail.com&quot;\\nmy_context = s.create_default_context()\\nwith sm.SMTP_SSL(host, port, context=my_context) as connection:\\n\\tconnection.login(username1, password1)\\n\\tconnection.sendmail(username1, receiver1, msg)',\n",
       " 'requests.post(&quot;https://www.httpdebugger.com/tools/ViewHttpHeaders.aspx&quot;, payload_getupdate).text',\n",
       " \"from playwright.sync_api import sync_playwright\\nimport func\\nimport os, time, shutil\\nimport requests\\nfrom tqdm.auto import tqdm\\ndef download():\\n\\twith page.expect_download() as download_info:\\n\\t\\tpage.click(&quot;text=720p (MP4&quot;)\\n\\t\\tdownload = download_info.value\\n\\t\\twith requests.get(download.url, stream=True) as r:\\n\\t\\t\\ttotal_length = int(r.headers.get(&quot;Content-Length&quot;))\\n\\t\\t\\twith tqdm.wrapattr(r.raw, &quot;read&quot;, total=total_length, desc=&quot;&quot;) as raw:\\n\\t\\t\\t\\twith open(f&quot;{os.path.basename(r.url)}&quot;, 'wb') as output:\\n\\t\\t\\t\\t\\tshutil.copyfileobj(raw, output)\\n\\t\\t\\t\\t\\tdownload.save_as(os.path.join(func.report_folder_path, download.suggested_filename))\\nwith sync_playwright() as p:\\n\\tbrowser = p.chromium.launch(channel=&quot;msedge&quot;, headless=False)\\n\\tcontext = browser.new_context(accept_downloads=True)\\n\\tpage = context.new_page()\\n\\tprint(&quot;Entering on download page&quot;)\\n\\tpage.goto('https://www.jw.org/en/library/videos/\\n\\tpage.wait_for_selector(&quot;text=Download&quot;)\\n\\tpage.locator(&quot;text=Download&quot;).first.click()\\n\\tdownload()\\n\\ttime.sleep(3)\\n\\tprint('end')\",\n",
       " 'sudo apt install python3.7 python3-venv python3.7-venv',\n",
       " 'matplotlib',\n",
       " \"import matplotlib.pyplot as plt\\nfrom matplotlib.patches import Rectangle\\nfig, ax = plt.subplots()\\nax.add_patch(Rectangle((0,0), 4, 5))\\nax.add_patch(Rectangle((5,0), 4, 5))\\nplt.text(0, 5.5, 'very very very very long text')\\nplt.text(5, 5.5, 'another text')\\nplt.xlim([-1, 11])\\nplt.ylim([-1, 7])\\nplt.show()\",\n",
       " 'Text',\n",
       " 'get_window_extent()',\n",
       " '(x,y)',\n",
       " 'binom.pmf()',\n",
       " 'binom.cdf()',\n",
       " 'from scipy.stats import binom\\nn = 2  \\np = 0.5 \\nx = 1 \\nEqual_cond = binom.pmf(x, n, p)\\nMorethan_cond= 1 - binom.cdf(x, n, p)',\n",
       " \"curl -X 'POST'   \\\\\\n'https://xxx/bulk'   \\\\\\n-H 'accept: application/json;odata.metadata=minimal;odata.streaming=true'\\n-H 'Authorization: Basic xxx'\\n-H 'Content-Type: multipart/form-data'\\n-F 'File=@/home/dominik/ok/batch.zip;type=application/x-zip-compressed'\",\n",
       " \"headers = {\\n\\t'accept': 'application/json;odata.metadata=minimal;odata.streaming=true',\\n\\t'Content-Type': 'multipart/form-data',\\n\\t'Authorization' : 'Basic xxx'}\\ndef send_zip(zip_path, url, headers):\\n\\tstart_time = time.perf_counter()\\n\\tzip_to_send = {'file': ('batch.zip', open(zip_path, 'rb'), 'application/x-zip-compressed')}\\n\\tresponse = requests.request('POST', url, headers=headers, files=zip_to_send)\\n\\tprint(response.text, response.status_code)\\n\\tend_time = time.perf_counter()\\n\\ttotal_time = end_time - start_time\\n\\tprint(f'Total time to send zip: {total_time}')\",\n",
       " 'Failed to read the request form. Missing content-type boundary',\n",
       " \"  headers = {'accept': 'application/json;odata.metadata=minimal;odata.streaming=true',\\n\\t'Authorization': 'Basic xxx,\\n\\t}\\n  fils = {'File': open('/hoome/ok/batch.zip;type=application/x-zip-compressed', 'rb'),}\\n  response = requests.post('https://xxx/bulk', headers=headers, files=files, )\",\n",
       " 'from colorsys import hsv_to_rgb\\nfrom math import radians\\nx = 0\\ny = 2\\nfor j in range(y):\\n\\tprint(radians(x)/10, 1, 1)\\n\\tprint(hsv_to_rgb(radians(x)/10, 1, 1))\\n\\tx += 360 / y\\nx = 0',\n",
       " '0 1 1\\n(1, 0, 0)\\n0.3141592653589793 1 1\\n(0, 1, 1)',\n",
       " '0.0 1 1\\n(1, 0.0, 0.0)\\n0.3141592653589793 1 1\\n(0.11504440784612413, 1, 0.0)',\n",
       " 'from colorsys import hsv_to_rgb\\nfrom math import radians\\nx = 0\\ny = 3\\nfor j in range(y):\\n\\tprint(radians(x)/10, 1, 1)\\n\\tprint(hsv_to_rgb(radians(x)/10, 1, 1))\\n\\tx += 360 / y\\nx = 0',\n",
       " '0 1 1\\n(1, 0, 0)\\n0.20943951023931953 1 1\\n(0, 1, 0)\\n0.41887902047863906 1 1\\n(0, 0, 1)',\n",
       " '0.0 1 1\\n(1, 0.0, 0.0)\\n0.20943951023931953 1 1\\n(0.7433629385640828, 1, 0.0)\\n0.41887902047863906 1 1\\n(0.0, 1, 0.5132741228718345)',\n",
       " 'import pypdf   \\nreader = pypdf.PdfReader(source_filename)\\nwriter = pypdf.PdfWriter()\\npage = reader.pages[0]\\nnew_page = pypdf.PageObject.create_blank_page( None, width = page.mediabox.width, height = page.mediabox.height )\\npage.mediabox.bottom = ( page.mediabox.top - page.mediabox.bottom ) / 2 + page.mediabox.bottom\\nnew_page.merge_page( page )\\nwriter.add_page(new_page)\\nwith open(output_file, &quot;wb&quot;) as fp:\\n\\twriter.write(fp)',\n",
       " \"def lookup_IP(ip):\\n\\tresult = tuple()\\n\\ttry:\\n\\t\\thost, aliases, _ = socket.gethostbyaddr(ip)\\n\\t\\tresult = (ip, host)\\n\\texcept socket.herror:\\n\\t\\tresult = (ip, 'no host found')\\n\\texcept Exception:\\n\\t\\tresult = (ip, 'error finding host')\\n\\treturn result\\nwith futures.ThreadPoolExecutor(500) as executor:\\n\\tsubmitted_threads = {executor.submit(lookup_IP, ip): ip for ip in all_IPs}\\n\\tfor thread in futures.as_completed(submitted_threads):\\n\\t\\ttry:\\n\\t\\t\\tdata = thread.result()\\n\\t\\texcept Exception as err:\",\n",
       " 'GeoSeries',\n",
       " 'import geopandas as gpd\\nx = gpd.GeoSeries()',\n",
       " \"FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\\n  s = pd.Series(data, index=index, name=name, **kwargs)\",\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n",
      "173400\n"
     ]
    }
   ],
   "source": [
    "print(type(src))\n",
    "print(type(src[0]))\n",
    "print(len(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = src[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "data = src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeBERT 모델과 토크나이저 로드\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 함수 정의\n",
    "def embed_text(text):\n",
    "    encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    return model_output.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 텍스트에 대한 임베딩 계산\n",
    "embeddings = torch.cat([embed_text(text) for text in data], dim=0).numpy()  # 텐서로 연결 후 numpy 배열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 768)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_neighbors=10, n_components=5, min_dist=0.0, metric='cosine', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_model = HDBSCAN(min_cluster_size=20, metric='euclidean', cluster_selection_method='eom', prediction_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_model = KeyBERTInspired()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# BERTopic 모델 초기화 및 훈련\n",
    "topic_model = BERTopic( embedding_model=model,\n",
    "                        umap_model=umap_model,\n",
    "                        hdbscan_model=hdbscan_model,\n",
    "                        representation_model=representation_model)  # 임베딩 모델 사용을 비활성화\n",
    "topics, probabilities = topic_model.fit_transform(data, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic  Count                                             Name  \\\n",
      "0     -1     34              -1_bootstrap_button_href_stylesheet   \n",
      "1      0    337                       0_python3_python_pygame_py   \n",
      "2      1    275                                1_10_py_error_100   \n",
      "3      2    241                   2_projectpoints_cv_pyenv_index   \n",
      "4      3     85  3_uninitializederror_typeerror_to_dlpack_module   \n",
      "5      4     28             4_script_02_script_01_python3_python   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [bootstrap, button, href, stylesheet, onclick,...   \n",
      "1  [python3, python, pygame, py, print, 00, 01, t...   \n",
      "2  [10, py, error, 100, name, python, used, type,...   \n",
      "3  [projectpoints, cv, pyenv, index, env, path, n...   \n",
      "4  [uninitializederror, typeerror, to_dlpack, mod...   \n",
      "5  [script_02, script_01, python3, python, py, gu...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [&lt;?xml version=&quot;1.0&quot;?&gt;\\n&lt;Al...  \n",
      "1  [{&quot;8&quot;: &quot;huit&quot;, &quot;5&quo...  \n",
      "2  [{\\n  &quot;repoOwner&quot;: &quot;&lt;REPOSIT...  \n",
      "3  [cv.projectPoints, cv.projectPoints, cv.projec...  \n",
      "4  [no module named numpy, ModuleNotFoundError: N...  \n",
      "5         [script_02.py, script_02.py, script_02.py]  \n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(topic_model.get_topic_info())  # 토픽 정보 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>34</td>\n",
       "      <td>-1_bootstrap_button_href_stylesheet</td>\n",
       "      <td>[bootstrap, button, href, stylesheet, onclick,...</td>\n",
       "      <td>[&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;\\n&amp;lt;Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>0_python3_python_pygame_py</td>\n",
       "      <td>[python3, python, pygame, py, print, 00, 01, t...</td>\n",
       "      <td>[{&amp;quot;8&amp;quot;: &amp;quot;huit&amp;quot;, &amp;quot;5&amp;quo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>275</td>\n",
       "      <td>1_10_py_error_100</td>\n",
       "      <td>[10, py, error, 100, name, python, used, type,...</td>\n",
       "      <td>[{\\n  &amp;quot;repoOwner&amp;quot;: &amp;quot;&amp;lt;REPOSIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>241</td>\n",
       "      <td>2_projectpoints_cv_pyenv_index</td>\n",
       "      <td>[projectpoints, cv, pyenv, index, env, path, n...</td>\n",
       "      <td>[cv.projectPoints, cv.projectPoints, cv.projec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>3_uninitializederror_typeerror_to_dlpack_module</td>\n",
       "      <td>[uninitializederror, typeerror, to_dlpack, mod...</td>\n",
       "      <td>[no module named numpy, ModuleNotFoundError: N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>4_script_02_script_01_python3_python</td>\n",
       "      <td>[script_02, script_01, python3, python, py, gu...</td>\n",
       "      <td>[script_02.py, script_02.py, script_02.py]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                             Name  \\\n",
       "0     -1     34              -1_bootstrap_button_href_stylesheet   \n",
       "1      0    337                       0_python3_python_pygame_py   \n",
       "2      1    275                                1_10_py_error_100   \n",
       "3      2    241                   2_projectpoints_cv_pyenv_index   \n",
       "4      3     85  3_uninitializederror_typeerror_to_dlpack_module   \n",
       "5      4     28             4_script_02_script_01_python3_python   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [bootstrap, button, href, stylesheet, onclick,...   \n",
       "1  [python3, python, pygame, py, print, 00, 01, t...   \n",
       "2  [10, py, error, 100, name, python, used, type,...   \n",
       "3  [projectpoints, cv, pyenv, index, env, path, n...   \n",
       "4  [uninitializederror, typeerror, to_dlpack, mod...   \n",
       "5  [script_02, script_01, python3, python, py, gu...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [&lt;?xml version=&quot;1.0&quot;?&gt;\\n&lt;Al...  \n",
       "1  [{&quot;8&quot;: &quot;huit&quot;, &quot;5&quo...  \n",
       "2  [{\\n  &quot;repoOwner&quot;: &quot;&lt;REPOSIT...  \n",
       "3  [cv.projectPoints, cv.projectPoints, cv.projec...  \n",
       "4  [no module named numpy, ModuleNotFoundError: N...  \n",
       "5         [script_02.py, script_02.py, script_02.py]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('python3', 0.35473585),\n",
       " ('python', 0.32156235),\n",
       " ('pygame', 0.3008075),\n",
       " ('py', 0.29041278),\n",
       " ('print', 0.26775756),\n",
       " ('00', 0.24752432),\n",
       " ('01', 0.23277721),\n",
       " ('tf', 0.22753753),\n",
       " ('20', 0.22458306),\n",
       " ('tk', 0.22380301)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', 0.37775224),\n",
       " ('py', 0.32384515),\n",
       " ('error', 0.31744936),\n",
       " ('100', 0.28027898),\n",
       " ('name', 0.27083427),\n",
       " ('python', 0.26763445),\n",
       " ('used', 0.26676336),\n",
       " ('type', 0.26123512),\n",
       " ('encoded', 0.26109916),\n",
       " ('module', 0.2557831)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(6, full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Label the topics yourself\n",
    "# topic_model.set_topic_labels({1: \"Space Travel\", 7: \"Religion\"})\n",
    "\n",
    "# # or use one of the other topic representations, like KeyBERTInspired\n",
    "# keybert_topic_labels = {topic: \" | \".join(list(zip(*values))[0][:3]) for topic, values in topic_model.topic_aspects_[\"KeyBERT\"].items()}\n",
    "# topic_model.set_topic_labels(keybert_topic_labels)\n",
    "\n",
    "# # or ChatGPT's labels\n",
    "# chatgpt_topic_labels = {topic: \" | \".join(list(zip(*values))[0]) for topic, values in topic_model.topic_aspects_[\"OpenAI\"].items()}\n",
    "# chatgpt_topic_labels[-1] = \"Outlier Topic\"\n",
    "# topic_model.set_topic_labels(chatgpt_topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_distr, _ = topic_model.approximate_distribution(data, window=8, stride=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nbformat>=4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topic-document distribution for a single document\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_documents(data, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_documents(data, reduced_embeddings=reduced_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topa_df = topic_model.get_document_info(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topa_org_df = bert_src_af.iloc[:1000, :]\n",
    "topa_org_df.reset_index(drop=True, inplace=True)\n",
    "topa_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_topa_df = pd.concat([topa_org_df, topa_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_topa_df[tot_topa_df['Topic'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_topa_df[tot_topa_df['Topic'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
