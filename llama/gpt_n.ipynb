{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb\n",
    "# https://stackoverflow.com/questions/77285102/how-to-format-a-few-shot-prompt-for-gpt4-chat-completion-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "p = os.path.abspath('..')\n",
    "# p = p+r'\\config'\n",
    "sys.path.insert(1, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import config.config as conf\n",
    "\n",
    "import json\n",
    "from itertools import chain\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# https://wikidocs.net/233348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the OpenAI Python library for calling the OpenAI API\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key= conf.OEPN_AI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example OpenAI Python library request\n",
    "# MODEL = \"gpt-4o-2024-08-06\"\n",
    "# response = client.chat.completions.create(\n",
    "#     model=MODEL,\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Explain asynchronous programming in the style of the pirate Blackbeard.\"},\n",
    "#     ],\n",
    "#     temperature=0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(json.loads(response.model_dump_json()), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/part_one_q_output_code_y.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Title>Why joblib is not recommended when saving keras model?</Title>. <Question><p>According to <a href=\"https://keras.io/getting_started/faq/#how-can-i-save-a-keras-model\" rel=\"nofollow noreferrer\">this</a> keras documentation, pickle is not recommended to save keras mode, and since <code>joblib.dump()</code> and <code>joblib.load()</code> are based on the Python pickle serialization model, joblib is also not recommended to save keras model. What is the reason for that ?</p>\\n</Question>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_promt=\"\"\"\\nYou are an expert in analyzing and categorizing the difficulty level of Python-related programming questions based on examples below. \n",
    "Questions are sourced from the \"StackOverflow\" community using the keyword \"Python.\"\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_front = \"\"\"\\nFor the given (target) post that is marked by\n",
    "    <target_post> </target_post>, please let me know the\n",
    "    \"Difficulty Level\" of the target post, where the\n",
    "    \"Difficulty Level\" can be one of the followings: (0) Basic, (1)\n",
    "    Intermediate, and (2) Advanced\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_back = \"\"\"\\nplease output only the difficulty label of the target post, where it can only be one of, (0) Basic, (1)\n",
    "    Intermediate, and (2) Advanced, \n",
    "    and mark '0' if it is basic, '1' if is is intermediate, and '2' if it is advanced question. \n",
    "    Please refer to the samples below that may be helpful to measure the baseline of the difficulty labels, where each\n",
    "    of the sample is delimited by \"----\"\\n\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_dict = {'Difficulty class : Basic':0 ,\n",
    " 'Difficulty class : Intermediate':1, \n",
    " 'Difficulty class : Advanced':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['answer_encode'] = df['answer'].apply(lambda x : diff_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74693871</td>\n",
       "      <td>&lt;Title&gt;Why joblib is not recommended when savi...</td>\n",
       "      <td>Difficulty class : Advanced</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74751254</td>\n",
       "      <td>&lt;Title&gt;Removing all duplicate images with diff...</td>\n",
       "      <td>Difficulty class : Intermediate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74760874</td>\n",
       "      <td>&lt;Title&gt;How do I extract a binary pattern from ...</td>\n",
       "      <td>Difficulty class : Intermediate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74774389</td>\n",
       "      <td>&lt;Title&gt;How to join these 2 tables by date with...</td>\n",
       "      <td>Difficulty class : Intermediate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74778102</td>\n",
       "      <td>&lt;Title&gt;Error when trying to save a form in dja...</td>\n",
       "      <td>Difficulty class : Intermediate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           question  \\\n",
       "0  74693871  <Title>Why joblib is not recommended when savi...   \n",
       "1  74751254  <Title>Removing all duplicate images with diff...   \n",
       "2  74760874  <Title>How do I extract a binary pattern from ...   \n",
       "3  74774389  <Title>How to join these 2 tables by date with...   \n",
       "4  74778102  <Title>Error when trying to save a form in dja...   \n",
       "\n",
       "                            answer  answer_encode  \n",
       "0      Difficulty class : Advanced              2  \n",
       "1  Difficulty class : Intermediate              1  \n",
       "2  Difficulty class : Intermediate              1  \n",
       "3  Difficulty class : Intermediate              1  \n",
       "4  Difficulty class : Intermediate              1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_idx = {x : list(df[df['answer']==x].index) for x in list(diff_dict.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difficulty class : Basic [10, 21, 23, 25, 31, 35, 36, 38, 40]\n",
      "Difficulty class : Intermediate [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 24, 26, 28, 29, 30, 32, 33, 37, 39]\n",
      "Difficulty class : Advanced [0, 9, 20, 27, 34, 41, 42]\n"
     ]
    }
   ],
   "source": [
    "diff_s_idx = {}\n",
    "for key, value in diff_idx.items():\n",
    "    print(key, value)\n",
    "    dic_col = f'{key}_sample_idx'\n",
    "    diff_population = value\n",
    "    diff_s_idx[dic_col] = np.random.choice(diff_population, size=3, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Difficulty class : Basic_sample_idx': array([23, 31, 35]),\n",
       " 'Difficulty class : Intermediate_sample_idx': array([12, 24, 30]),\n",
       " 'Difficulty class : Advanced_sample_idx': array([20, 27, 34])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_s_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_q_id = list(chain.from_iterable(diff_s_idx.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_q_id =np.setdiff1d(list(df.index), fewshot_q_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for idx in fewshot_q_id:\n",
    "# for idx in [19]:\n",
    "    temp_dict = {\"question\" : str(df.loc[idx, 'question']),\n",
    "                 \"answer\"   : str(df.loc[idx, 'answer'])}\n",
    "    examples.append(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': '<Title>How to convert values of tuple from a dictionary into a list?</Title>. <Question><p>I am trying to convert the values from a dictionary into a list.</p>\\n<p><code>D = {&quotA&quot: [(1, 2)], &quotB&quot: [(3, 4), (5, 6)]}</code></p>\\n<p>How do I get the following result?</p>\\n<p><code>[[1, 2], [3,4], [5, 6]]</code></p>\\n<p>I am trying to use max 1 for-loop</p>\\n<pre><code># My attempt\\nmy_list = list(D.values())\\nprint(my_list)\\n# [[(1, 2)], [(3, 4), (5, 6)]]\\n</code></pre>\\n</Question>',\n",
       "  'answer': 'Difficulty class : Basic'},\n",
       " {'question': \"<Title>How do I iterate for all HDF5 files and save them as csv files</Title>. <Question><p>I am writing a python code that will loop over my SMAP HDF5 (10,000) files. I want to extract soil moisture rootzone and vegetation greenness. My code looks like this</p>\\n<pre><code>import os\\nimport tables\\nimport h5py\\nimport datetime as dt\\nimport glob\\nimport h5py\\nimport matplotlib.pyplot as mpl\\nimport numpy as np\\nimport os\\nimport pandas as pd\\nimport xarray as xr\\n\\ndirec = '/Users/24715447/Library/CloudStorage/OneDrive-UTS/Soil_Moisture/SMAP/HDF' # the working directory (where your files are stored)\\ndirs = os.listdir(direc)\\n\\nfor idir in dirs: # this will iterate over the files in your working directory\\n\\n    if idir.endswith('.h5'): # only for HDF5 files...\\n        hdf5 = tables.open_file(os.path.join(direc,idir))\\n\\n        dataset = h5py.File(hdf5, 'r')\\n\\n        longitude_values = np.array(list(dataset['cell_lon'])).flatten()\\n        latitude_values = np.array(list(dataset['cell_lat'])).flatten()\\n        soilMoisture_values = np.array(list(geo['sm_rootzone'])).flatten()\\n        Vegetation_greenness_values = np.array(list(geo['vegetation_greenness_fraction'])).flatten()\\n        dataset = pd.DataFrame({&quotlon&quot: longitude_values, &quotlat&quot: latitude_values, &quotsoil_root&quot: soilMoisture_values, &quotgreenness&quot: Vegetation_greenness_values})\\n\\n        dataset.to_csv('/Users/24715447/Library/CloudStorage/OneDrive-UTS/Soil_Moisture/SMAP/CSV_{idir}.csv')\\n\\n        hdf5.close()\\n</code></pre>\\n<p>I get an error like this</p>\\n<pre><code>Traceback (most recent call last):\\n  File &quot/Users/24715447/Library/CloudStorage/OneDrive-UTS/Soil_Moisture/SMAP/h5tocsv.py&quot, line 14, in &ltmodule&gt;\\n    dirs = os.listdir(direc)\\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/24715447/Library/CloudStorage/OneDrive-UTS/Soil_Moisture/SMAP/HDF&quot)'\\n(climate_process) UTS046280:SMAP 24715447$ python h5tocsv.py\\nTraceback (most recent call last):\\n  File &quot/Users/24715447/Library/CloudStorage/OneDrive-UTS/Soil_Moisture/SMAP/h5tocsv.py&quot, line 14, in &ltmodule&gt;\\n    dirs = os.listdir(direc)\\nFileNotFoundError: [Errno 2] No such file or directory: './HDF&quot)'\\n(climate_process) UTS046280:SMAP 24715447$ python h5tocsv.py\\nTraceback (most recent call last):\\n  File &quot/Users/24715447/Library/CloudStorage/OneDrive-UTS/Soil_Moisture/SMAP/h5tocsv.py&quot, line 19, in &ltmodule&gt;\\n    hdf5 = tables.openFile(os.path.join(direc,idir))\\nAttributeError: module 'tables' has no attribute 'openFile'\\n(climate_process) UTS046280:SMAP 24715447$ python h5tocsv.py\\nTraceback (most recent call last):\\n  File &quot/Users/24715447/Library/CloudStorage/OneDrive-UTS/Soil_Moisture/SMAP/h5tocsv.py&quot, line 19, in &ltmodule&gt;\\n    hdf5 = tables.open_file(os.path.join(direc,idir))\\n  File &quot/Users/24715447/anaconda3/envs/climate_process/lib/python3.9/site-packages/tables/file.py&quot, line 300, in open_file\\n    return File(filename, mode, title, root_uep, filters, **kwargs)\\n  File &quot/Users/24715447/anaconda3/envs/climate_process/lib/python3.9/site-packages/tables/file.py&quot, line 750, in __init__\\n    self._g_new(filename, mode, **params)\\n  File &quottables/hdf5extension.pyx&quot, line 486, in tables.hdf5extension.File._g_new\\ntables.exceptions.HDF5ExtError: HDF5 error back trace\\n\\n  File &quotH5F.c&quot, line 620, in H5Fopen\\n    unable to open file\\n  File &quotH5VLcallback.c&quot, line 3502, in H5VL_file_open\\n    failed to iterate over available VOL connector plugins\\n  File &quotH5PLpath.c&quot, line 579, in H5PL__path_table_iterate\\n    can't iterate over plugins in plugin path '(null)'\\n  File &quotH5PLpath.c&quot, line 620, in H5PL__path_table_iterate_process_path\\n    can't open directory: /Users/24715447/anaconda3/envs/climate_process/lib/hdf5/plugin\\n  File &quotH5VLcallback.c&quot, line 3351, in H5VL__file_open\\n    open failed\\n  File &quotH5VLnative_file.c&quot, line 97, in H5VL__native_file_open\\n    unable to open file\\n  File &quotH5Fint.c&quot, line 1990, in H5F_open\\n    unable to read superblock\\n  File &quotH5Fsuper.c&quot, line 617, in H5F__super_read\\n    truncated file: eof = 120927924, sblock-&gtbase_addr = 0, stored_eof = 150224576\\n\\nEnd of HDF5 error back trace\\n</code></pre>\\n<p>I expect to get csv files of the same filenames with only soil moisture and vegetation greenness. I want also to clip the values to these coordinates</p>\\n<p>box_lat = [-43.63, -10.66]\\nbox_lon = [113.34, -153.57]</p>\\n<p>How do I revise my code? Please help me </p>\\n</Question>\",\n",
       "  'answer': 'Difficulty class : Basic'},\n",
       " {'question': '<Title>\"Python: Select Linter\" option is missing</Title>. <Question><p>VS Code is missing &quotPython: Select Linter&quot; option when trying to run a command (F1 or Ctrl/CMD+Shift+P). Previously, (2 days ago) this option was available. Is there a way to restore this option or is there a new alternative?</p>\\n<p>I have tried creating new VS Code profile and installing just Python extension - still no mentioned option.</p>\\n</Question>',\n",
       "  'answer': 'Difficulty class : Basic'},\n",
       " {'question': '<Title>convert the dict list to dataframe where we have 3 cols and making all keys into rows and a specific key into a column</Title>. <Question><p>I have input dict as below</p>\\n<p>sample=</p>\\n<pre><code>    [\\n   {\\n      &quotSOURCE_VALUE&quot:&quot1272323&quot,\\n      &quotASSOCIATED_ID_1&quot:&quot1261523&quot,\\n      &quotCHANGE_REQUEST_SUBMIT_ID&quot:&quot11417&quot,\\n      &quotENTITIES_ID&quot:&quot390258,390346&quot,\\n      &quotPROPOSED_GROUP&quot:&quot385920&quot,\\n      &quotPROPOSED_UNIT&quot:&quot403937&quot,\\n      &quotPROPOSED_CENTER&quot:&quot393306&quot,\\n      &quotPROPOSED_DIVISION&quot:&quot386774&quot,\\n      &quotPROPOSED_ENTITIES&quot:&quot390258,390346&quot,\\n      &quotPROPOSED_COMPANY&quot:&quot385895&quot,\\n      &quotPROPOSED_1&quot:&quot388316&quot,\\n      &quotPROPOSED_2&quot:&quot389046&quot;\\n   },\\n   {\\n      &quotSOURCE_VALUE&quot:&quot1272413&quot,\\n      &quotASSOCIATED_ID_1&quot:&quot1261523&quot,\\n      &quotCHANGE_REQUEST_SUBMIT_ID&quot:&quot11417&quot,\\n      &quotENTITIES_ID&quot:&quot390258,390346&quot;\\n   },\\n   {\\n      &quotSOURCE_VALUE&quot:&quot1272415&quot,\\n      &quotASSOCIATED_ID_1&quot:&quot1261523&quot,\\n      &quotCHANGE_REQUEST_SUBMIT_ID&quot:&quot11417&quot,\\n      &quotENTITIES_ID&quot:&quot390258,390346&quot;\\n   }]\\n</code></pre>\\n<p>I want to have the output as</p>\\n<p><a href=\"https://i.stack.imgur.com/OwgES.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/OwgES.png\" alt=\"enter image description here\" /></a></p>\\n<p>I want to have the souce_value from dict as a seperate column and rest all keys are as rows under &quotadd keys&quot; and targetvalue as values.</p>\\n</Question>',\n",
       "  'answer': 'Difficulty class : Intermediate'},\n",
       " {'question': \"<Title>Vectorize a For Statement - Zeros In A Diagonal</Title>. <Question><p>Want to replace a Python 'for' loop with a vectorized comprehension statement to replace the left diagonal in a pandas <code>DataFrame</code> with zeroes.</p>\\n<p>The <code>dataframe</code> is instantiated using a standard <code>numpy.random.randint()</code> method.</p>\\n<pre><code>df = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\\n</code></pre>\\n<p>I tried to apply a lambda function that locates/replaces the diagonal cells using the <code>df.iloc[]</code> method. Was expecting the left diagonal to be replaced with zeroes.</p>\\n<pre><code>df = df.apply(lambda i : [df.iloc[i, i] * 0 for i in range(df.shape[0])])\\n</code></pre>\\n<p>The result yields an entire <code>DataFrame</code> loaded with zeroes.  Need help on how to write the lambda function since an assignment is not allowed in the lambda function.</p>\\n</Question>\",\n",
       "  'answer': 'Difficulty class : Intermediate'},\n",
       " {'question': \"<Title>Capturing digits in sentences unless specific words appear in it (Python)</Title>. <Question><p>I'm trying to write regex (in Python) that finds lines of text which contain specific words and captures the first number that appears after the word. The digit matching is done to match different types of numbers with different thousand and decimal separators.</p>\\n<p>My issue is that I want to add a blacklist of words that if these words appear between the match word and number, it breaks the match and returns None instead.</p>\\n<p>Currently regex looks like this - match words are <code>car</code> and <code>price</code>. Let's assume a blacklisted word <code>insurance</code>.</p>\\n<p><code>(?:car|price)[^\\\\r\\\\n]+?(\\\\d{1,3}[\\\\s\\\\.]\\\\d{3}[\\\\.\\\\,]?\\\\d{0,2}|\\\\d{3,6}[\\\\.\\\\,]?\\\\d{0,2})</code></p>\\n<pre><code>&quotprice is 161&quot; -&gt; 161\\n&quotcar: 5512.16&quot; -&gt; 5512.16\\n&quotthis car has two prices this year 1151 and last year 9912&quot; -&gt; 1151\\n&quotcar price is 1992 insurance 90&quot; -&gt; 1992\\n&quotcar ID is an invalid number 92.16.17&quot; -&gt; No match\\n&quotin this case the price of the car spans over\\ntwo lines of text 912&quot; -&gt; No match\\n&quotprice of insurance 199.116,16&quot; -&gt; 119.116,16\\n</code></pre>\\n<p>The last is an example where I want no match. So essentially some way to add an option to blacklist words between <code>(?:car|price)&lthere&gt(\\\\d{1,3}...</code>.</p>\\n<p>Here are the test sentences as a list for your convenience:</p>\\n<pre><code>import re\\npattern = r'(?:car|price)[^\\\\r\\\\n]+?(\\\\d{1,3}[\\\\s\\\\.]\\\\d{3}[\\\\.\\\\,]?\\\\d{0,2}|\\\\d{3,6}[\\\\.\\\\,]?\\\\d{0,2})'\\nlist_of_sentences = [&quotprice is 161&quot, &quotcar: 5512.16&quot, &quotthis car has two prices this year 1151 and last year 9912&quot, &quotcar price is 1992 insurance 90&quot, &quotcar ID is an invalid number 92.16.17&quot, &quotin this case the price of the car spans over\\\\ntwo lines of text 912&quot, &quotprice of insurance 199.116,16&quot]\\nfor sentence in list_of_sentences:\\n    print(re.findall(pattern, sentence))\\n</code></pre>\\n<p>Current output</p>\\n<pre><code>['161']\\n['5512.16']\\n['1151']\\n['1992']\\n[]\\n[]\\n['199.116,16']\\n</code></pre>\\n<p>Desired output</p>\\n<pre><code>['161']\\n['5512.16']\\n['1151']\\n['1992']\\n[]\\n[]\\n[]\\n</code></pre>\\n</Question>\",\n",
       "  'answer': 'Difficulty class : Intermediate'},\n",
       " {'question': \"<Title>in my trainer, a thread doesn't stop when the condition is met</Title>. <Question><p>i am making a Alan Wake remaster trainer in python with customtkinter and pymem, everything worked fine until i started adding threading.</p>\\n<p>in the window there are checkboxes that, when active, starts setting a value to the batteries or revolver ammo to simulate a NOP instruction, but when that happens the rest of the program freezes, i solved that by adding threads, the thing is, when you activate both batteries and revolver checkboxes, and uncheck the battery one, it doesn't stop doing the battery cheat.</p>\\n<pre><code>from pymem import *\\nfrom pymem.process import *\\nfrom customtkinter import *\\nimport threading\\n\\nclass Trainer:\\n    def __init__(self):\\n        \\n        self.root = CTk()\\n        self.root.title(&quotAlan Wake Remaster Trainer&quot)\\n        set_appearance_mode(&quotdark&quot)\\n        self.root.geometry(&quot400x600&quot)\\n        self.root.resizable(0,0)\\n    \\n        self.mf = CTkFrame(master=self.root)\\n        self.mf.pack(fill=&quotboth&quot, expand= True)\\n    \\n        self.bc_var = IntVar()\\n        self.rv_var = IntVar()\\n        \\n        self.battery_checkbox = CTkCheckBox(master=self.mf,text=&quotUnlimited Batteries&quot,variable=self.bc_var,command=self.check)\\n        self.battery_checkbox.pack()\\n        self.battery_checkbox.place(x=140,y=50)\\n        \\n        self.revolver_checkbox = CTkCheckBox(master=self.mf, text=&quotUnlimited Revolver Ammo&quot, variable=self.rv_var,command=self.check)\\n        self.revolver_checkbox.pack()\\n        self.revolver_checkbox.place(x=140,y=80)\\n\\n        self.keep_running = True\\n    \\n    def check(self):\\n        if self.bc_var.get() == 1:\\n            self.keep_running = True\\n            t = threading.Thread(target=self.write_bat)\\n            t.start()\\n        if self.rv_var.get() == 1:\\n            self.keep_running = True\\n            t1 = threading.Thread(target=self.write_rev)\\n            t1.start()\\n        elif self.bc_var.get() == 0:\\n            self.keep_running = False\\n        elif self.rv_var.get() == 0:\\n            self.keep_running == False\\n            \\n    \\n        \\n    \\n    def write_bat(self):\\n        while self.keep_running:\\n            Pymem.write_int(mem, self.getpointer(module_bat + 0x00AE69D0, offsets_bat), 20)\\n        \\n    def write_rev(self):\\n        while self.keep_running:\\n            Pymem.write_int(mem, self.getpointer(module_rev + 0x0000027C, offsets_rev), 42)\\n    \\n    def run(self):\\n        self.root.mainloop()\\n    \\n    def getpointer(self,base,offsets):\\n        addr = mem.read_int(base)\\n        for offset in offsets:\\n            if offset != offsets[-1]:\\n                addr = mem.read_int(addr + offset)\\n        addr = addr + offsets[-1]\\n        return addr\\n \\n\\nmem = Pymem(&quotGame_f_x64_EOS.exe&quot)\\nmodule_bat = module_from_name(mem.process_handle, &quotGame_f_x64_EOS.exe&quot).lpBaseOfDll\\nmodule_rev = module_from_name(mem.process_handle, &quotfmod.dll&quot).lpBaseOfDll\\noffsets_bat = [0x50,0x128,0x10,0x48,0xD0,0x144]\\noffsets_rev = [0xC0,0x68,0x10,0xE0,0x148]\\n\\napp = Trainer()\\napp.run()\\n</code></pre>\\n<p>what im trying to explain is that the battery thread doesn't stop when the checkbox is unmarked and the revolver ammo is.</p>\\n<p>i tried separating the threads with another check function but the same happens, and tried other stuff but it just breaks.</p>\\n<p>my knowledge in threading is new and very limited, so if there is an alternative or a better way to do this, i'd appreciate to be told.</p>\\n</Question>\",\n",
       "  'answer': 'Difficulty class : Advanced'},\n",
       " {'question': '<Title>Numpy error when importing pandas: ValueError: numpy.ndarray size changed, may indicate binary incompatibility</Title>. <Question><p>I am getting this on a Raspberry Pi zero after having used it no problem for months, I just turned it on again after a few months and now I can\\'t import pandas:</p>\\n<pre><code>Python 3.7.3 (default, Oct 31 2022, 14:04:00) \\n[GCC 8.3.0] on linux\\nType &quothelp&quot, &quotcopyright&quot, &quotcredits&quot; or &quotlicense&quot; for more information.\\n&gt&gt&gt; import numpy as np\\n&gt&gt&gt; import pandas as pd\\nTraceback (most recent call last):\\n  File &quot&ltstdin&gt&quot, line 1, in &ltmodule&gt;\\n  File &quot/home/pi/.local/lib/python3.7/site-packages/pandas/__init__.py&quot, line 22, in &ltmodule&gt;\\n    from pandas.compat import (\\n  File &quot/home/pi/.local/lib/python3.7/site-packages/pandas/compat/__init__.py&quot, line 15, in &ltmodule&gt;\\n    from pandas.compat.numpy import (\\n  File &quot/home/pi/.local/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py&quot, line 7, in &ltmodule&gt;\\n    from pandas.util.version import Version\\n  File &quot/home/pi/.local/lib/python3.7/site-packages/pandas/util/__init__.py&quot, line 1, in &ltmodule&gt;\\n    from pandas.util._decorators import (  # noqa\\n  File &quot/home/pi/.local/lib/python3.7/site-packages/pandas/util/_decorators.py&quot, line 14, in &ltmodule&gt;\\n    from pandas._libs.properties import cache_readonly  # noqa\\n  File &quot/home/pi/.local/lib/python3.7/site-packages/pandas/_libs/__init__.py&quot, line 13, in &ltmodule&gt;\\n    from pandas._libs.interval import Interval\\n  File &quotpandas/_libs/interval.pyx&quot, line 1, in init pandas._libs.interval\\nValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 44 from C header, got 40 from PyObject\\n</code></pre>\\n<p>This error is very similar to the one in <a href=\"https://stackoverflow.com/q/66060487/1609514\">this question</a>, but slightly different.</p>\\n<p>I tried updating my system:</p>\\n<pre class=\"lang-bash prettyprint-override\"><code>sudo apt update\\n</code></pre>\\n<p>And I tried uninstalling and re-installing numpy and pandas:</p>\\n<pre class=\"lang-bash prettyprint-override\"><code>sudo apt remove python3-numpy python3-pandas\\nsudo apt-get install python3-numpy python3-pandas python3-scipy python3-sklearn python3-numexpr\\n</code></pre>\\n<p>but it does not fix it.</p>\\n<p>Any ideas?</p>\\n<p><strong>Version info</strong></p>\\n<pre class=\"lang-none prettyprint-override\"><code>python3-numpy/oldstable,now 1:1.16.2-1 armhf [installed]\\npython3-pandas-lib/oldstable,now 0.23.3+dfsg-3 armhf [installed,automatic]\\npython3-pandas/oldstable,now 0.23.3+dfsg-3 all [installed]\\n</code></pre>\\n<p><strong>System info</strong></p>\\n<pre class=\"lang-none prettyprint-override\"><code>PRETTY_NAME=&quotRaspbian GNU/Linux 10 (buster)&quot;\\nNAME=&quotRaspbian GNU/Linux&quot;\\nVERSION_ID=&quot10&quot;\\nVERSION=&quot10 (buster)&quot;\\nVERSION_CODENAME=buster\\nID=raspbian\\nID_LIKE=debian\\nHOME_URL=&quothttp://www.raspbian.org/&quot;\\nSUPPORT_URL=&quothttp://www.raspbian.org/RaspbianForums&quot;\\nBUG_REPORT_URL=&quothttp://www.raspbian.org/RaspbianBugs&quot;\\n</code></pre>\\n</Question>',\n",
       "  'answer': 'Difficulty class : Advanced'},\n",
       " {'question': \"<Title>RNG Challenge Python</Title>. <Question><p>I am trying to solve a CTF challenge in which the goal is to guess the generated number. Since the number is huge and you only have 10 attempts per number, I don't think you can apply binary search or any kind of algorithm to solve it, and that it has something to do with somehow getting the seed of the random function and being able to generate the next number, but I have no idea on where to start to get the correct seed. Do you have any idea?\\nHere's the code of the challenge:</p>\\n<pre><code>#!/usr/bin/env python3\\n\\nimport signal\\nimport os\\nimport random\\n\\nTIMEOUT = 300\\n\\nassert(&quotFLAG&quot; in os.environ)\\nFLAG = os.environ[&quotFLAG&quot]\\nassert(FLAG.startswith(&quotCCIT{&quot))\\nassert(FLAG.endswith(&quot}&quot))\\n\\n\\ndef handle():\\n    for i in range(625):\\n        print(f&quotRound {i+1}&quot)\\n        guess_count = 10\\n        to_guess = random.getrandbits(32)\\n        while True:\\n            print(&quotWhat do you want to do?&quot)\\n            print(&quot1. Guess my number&quot)\\n            print(&quot2. Give up on this round&quot)\\n            print(&quot0. Exit&quot)\\n            choice = int(input(&quot&gt; &quot))\\n            if choice == 0:\\n                exit()\\n            elif choice == 1:\\n                guess = int(input(&quot&gt; &quot))\\n                if guess == to_guess:\\n                    print(FLAG)\\n                    exit()\\n                elif guess &lt; to_guess:\\n                    print(&quotMy number is higher!&quot)\\n                    guess_count -= 1\\n                else:\\n                    print(&quotMy number is lower!&quot)\\n                    guess_count -= 1\\n            elif choice == 2:\\n                print(f&quotYou lost! My number was {to_guess}&quot)\\n                break\\n            if guess_count == 0:\\n                print(f&quotYou lost! My number was {to_guess}&quot)\\n                break\\n\\n\\nif __name__ == &quot__main__&quot:\\n    signal.alarm(TIMEOUT)\\n    handle()\\n\\n</code></pre>\\n</Question>\",\n",
       "  'answer': 'Difficulty class : Advanced'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_prompt = \"\"\"\"\"\"\n",
    "a=1\n",
    "for q_a in examples : \n",
    "    q_prompt = q_prompt+\"\"\"\\n----\\n\"\"\"\n",
    "    q_prompt = q_prompt+f\"{q_a['answer']}\\n\"\n",
    "    q_prompt = q_prompt+\"\"\"<post>\\n\"\"\"\n",
    "    q_prompt = q_prompt+f\"{q_a['question']}\\n\"\n",
    "    q_prompt = q_prompt+\"\"\"</post>\\n\"\"\"\n",
    "q_prompt = q_prompt+\"\"\"----\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_q_idx= np.random.choice(eval_q_id, size=1, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_post=\"\"\"\\n\"\"\"\n",
    "target_post = target_post+\"\"\"<target_post>\\n\"\"\"\n",
    "target_post = target_post+df.loc[eval_q_idx, 'question'].values[0]+'\\n'\n",
    "target_post = target_post+\"\"\"</target_post>\\n\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_prompt = sys_promt+user_prompt_front+target_post+user_prompt_back+q_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.json\", \"w\") as file:\n",
    "    json.dump(tot_prompt, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>76541602</td>\n",
       "      <td>&lt;Title&gt;Pyspark : Add, substract hour/minute/se...</td>\n",
       "      <td>Difficulty class : Intermediate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           question  \\\n",
       "26  76541602  <Title>Pyspark : Add, substract hour/minute/se...   \n",
       "\n",
       "                             answer  answer_encode  \n",
       "26  Difficulty class : Intermediate              1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[eval_q_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>76541602</td>\n",
       "      <td>&lt;Title&gt;Pyspark : Add, substract hour/minute/se...</td>\n",
       "      <td>Difficulty class : Intermediate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           question  \\\n",
       "26  76541602  <Title>Pyspark : Add, substract hour/minute/se...   \n",
       "\n",
       "                             answer  answer_encode  \n",
       "26  Difficulty class : Intermediate              1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[eval_q_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = user_prompt_front+target_post+user_prompt_back+q_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error code: 403 - {'error': {'message': 'Project `proj_m5SXqRytraFXpjlnKDMPT2Rz` does not have access to model `gpt-4o`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example OpenAI Python library request\u001b[39;00m\n\u001b[1;32m      2\u001b[0m MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# {\"role\": \"system\", \"content\": sys_promt},\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtot_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sopjt/git/stackoverflow_src/venv_stackoverflow_src/lib/python3.10/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sopjt/git/stackoverflow_src/venv_stackoverflow_src/lib/python3.10/site-packages/openai/resources/chat/completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sopjt/git/stackoverflow_src/venv_stackoverflow_src/lib/python3.10/site-packages/openai/_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1277\u001b[0m     )\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/sopjt/git/stackoverflow_src/venv_stackoverflow_src/lib/python3.10/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sopjt/git/stackoverflow_src/venv_stackoverflow_src/lib/python3.10/site-packages/openai/_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1068\u001b[0m )\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: Error code: 403 - {'error': {'message': 'Project `proj_m5SXqRytraFXpjlnKDMPT2Rz` does not have access to model `gpt-4o`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}"
     ]
    }
   ],
   "source": [
    "# Example OpenAI Python library request\n",
    "MODEL = \"gpt-4o\"\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": sys_promt},\n",
    "        {\"role\": \"user\", \"content\": tot_prompt},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(json.loads(response.model_dump_json()), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_stackoverflow_src",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
